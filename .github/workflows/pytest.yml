name: Pytest

on:
  push:
    paths:
      - "langroid/**"
      - "tests/**"
      - ".github/workflows/pytest.yml"
    branches:
      - main
  pull_request:
    branches:
      - main 

jobs:
  cancel:
    if: "contains(github.event.head_commit.message, 'notest') == false"
    name: Cancel Previous Runs
    runs-on: ubuntu-latest
    timeout-minutes: 3
    steps:
      - name: Cancel Previous Workflow Runs
        uses: styfle/cancel-workflow-action@0.9.1
        with:
          access_token: ${{ github.token }}
  pytest:
    if: "contains(github.event.head_commit.message, 'notest') == false"    
    runs-on: ubuntu-latest
    services:
      meilisearch:
        image: getmeili/meilisearch:latest
        ports:
          - 7700:7700
        options: --env MEILI_MASTER_KEY=masterKey
      arangodb:
        image: arangodb:latest
        ports:
          - 8529:8529
        env:
          ARANGO_ROOT_PASSWORD: rootpassword
      neo4j:
        image: neo4j:latest
        ports:
          - 7687:7687
          - 7474:7474
        env:
          NEO4J_AUTH: neo4j/password

    env:
      CI: true # allows conditional skipping of tests based on this env var
      OPENAI_API_KEY: ${{ secrets.OPENAI_KEY }}
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      GITHUB_ACCESS_TOKEN: ${{ secrets.GH_ACCESS_TOKEN }}
      REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD }}
      REDIS_HOST: ${{ secrets.REDIS_HOST }}
      REDIS_PORT: ${{ secrets.REDIS_PORT }}
      MOMENTO_AUTH_TOKEN: ${{ secrets.MOMENTO_AUTH_TOKEN }}
      MOMENTO_API_KEY: ${{ secrets.MOMENTO_API_KEY }}
      QDRANT_API_KEY: ${{ secrets.QDRANT_API_KEY }}
      QDRANT_API_URL: ${{ secrets.QDRANT_API_URL }}
      CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
      GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      GOOGLE_CSE_ID: ${{ secrets.GOOGLE_CSE_ID }}

      # Azure OpenAI env vars
      AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
      AZURE_OPENAI_API_BASE: ${{ secrets.AZURE_OPENAI_API_BASE }}
      AZURE_OPENAI_API_VERSION: "2023-05-15"
      AZURE_OPENAI_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_NAME }}
      AZURE_OPENAI_MODEL_NAME: ${{ secrets.AZURE_GPT_MODEL_NAME }} 
      AZURE_OPENAI_MODEL_VERSION: ${{ secrets.AZURE_OPENAI_MODEL_VERSION }}
      
    steps:
    - name: Check out repository
      uses: actions/checkout@v3
    - name: Increase ulimit
      run: ulimit -n 4096
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11  # Replace with your desired Python version

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libmagic1
        sudo apt-get install -y poppler-utils tesseract-ocr
    # - name: Restore uv cache
    #   uses: actions/cache@v4
    #   with:
    #     path: ~/.local
    #     key: uv-${{ runner.os }}-${{ hashFiles('uv.lock') }}
    #     restore-keys: |
    #       uv-${{ runner.os }}-${{ hashFiles('uv.lock') }}
    #       uv-${{ runner.os }}

    - name: Setup uv
      uses: astral-sh/setup-uv@v5
      with: 
        enable-cache: true
        cache-dependency-glob: "uv.lock"

    # - name: Load cached venv
    #   id: cached-uv-dependencies
    #   uses: actions/cache@v4
    #   with:
    #       path: .venv
    #       key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('uv.lock') }}
    
    - name: Install project dependencies with uv
      # if: steps.cached-uv-dependencies.outputs.cache-hit != 'true'
      run: |
        uv sync --dev \
          --extra neo4j \
          --extra arango \
          --extra lancedb \
          --extra momento \
          --extra meilisearch \
          --extra chromadb \
          --extra hf-embeddings \
          --extra unstructured \
          --extra pdf-parsers \
          --extra docx \
          --extra sql \
          --extra fastembed
      
    

    - name: Download NLTK data
      run: uv run python -c "import nltk; nltk.download('punkt_tab')"

    - name: Dump dependencies to file
      run: uv pip freeze > requirements_github.txt

    - name: Upload dependencies file
      uses: actions/upload-artifact@v4
      with:
        name: github-dependencies
        path: requirements_github.txt


    - name: Run ALL tests with coverage (GPT-4o-mini)
      id: first_test
      env:
        PYTEST_ADDOPTS: "-p no:logging"
      run: |
        uv run pytest --m gpt-4o-mini --cov langroid --cov-config .coveragerc \
          -rf -vv --log-cli-level=INFO --show-capture=no \
          -n auto --timeout=300 \
          --first-test-file=tests/extras/test_hf_embeddings.py \
          --first-test-file=tests/extras/test_fastembed_embeddings.py \
          --first-test-file=tests/main/test_llm.py \
          --first-test-file=tests/main/test_task.py \
          --first-test-file=tests/main/test_llm_async.py \
          --first-test-file=tests/main/test_task_inf_loop.py \
          --first-test-file=tests/main/test_lance_doc_chat_agent.py \
          tests/main
      continue-on-error: true

    - name: Retry FAILED tests ONLY with GPT-4o instead of GPT-4o-mini
      id: second_test
      if: steps.first_test.outcome == 'failure'
      env:
        PYTEST_ADDOPTS: "-p no:logging"
      run: |
        uv run pytest --cov langroid --cov-append --cov-config .coveragerc \
          -rf -vv --log-cli-level=INFO --show-capture=no \
          -n auto --timeout=300 \
          --first-test-file=tests/main/test_llm.py \
          --first-test-file=tests/main/test_task.py \
          --first-test-file=tests/main/test_llm_async.py \
          --first-test-file=tests/main/test_task_inf_loop.py \
          --first-test-file=tests/main/test_lance_doc_chat_agent.py \
          --lf --last-failed-no-failures none \
          tests/main tests/extras/test_hf_embeddings.py \
          tests/extras/test_fastembed_embeddings.py
      continue-on-error: true

    - name: Retry FAILED tests ONLY without cache (GPT-4o)
      id: third_test
      if: steps.second_test.outcome == 'failure'
      env:
        PYTEST_ADDOPTS: "-p no:logging"
      run: |
        uv run pytest --nc --cov langroid --cov-append --cov-config .coveragerc \
          -rf --show-capture=no --timeout=300 -n auto \
          --first-test-file=tests/main/test_llm.py \
          --first-test-file=tests/main/test_llm_async.py \
          --first-test-file=tests/main/test_task_inf_loop.py \
          --first-test-file=tests/main/test_task.py \
          --first-test-file=tests/main/test_lance_doc_chat_agent.py \
          --lf --last-failed-no-failures none \
          tests/main tests/extras/test_hf_embeddings.py \
          tests/extras/test_fastembed_embeddings.py
    - name: Generate final coverage report from all runs
      run: uv run coverage report

    - name: Generate XML coverage report
      run: uv run coverage xml
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
      env:
        CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
