name: Pytest

on:
  push:
    paths:
      - "langroid/**"
      - "tests/**"
      - ".github/workflows/pytest.yml"
    branches:
      - main  # Replace with your default branch name 
  pull_request:
    branches:
      - main  # Replace with your default branch name

jobs:
  cancel:
    if: "contains(github.event.head_commit.message, 'notest') == false"
    name: Cancel Previous Runs
    runs-on: ubuntu-latest
    timeout-minutes: 3
    steps:
      - name: Cancel Previous Workflow Runs
        uses: styfle/cancel-workflow-action@0.9.1
        with:
          access_token: ${{ github.token }}
  pytest:
    if: "contains(github.event.head_commit.message, 'notest') == false"    
    runs-on: ubuntu-latest
    services:
      meilisearch:
        image: getmeili/meilisearch:latest
        ports:
          - 7700:7700
        options: --env MEILI_MASTER_KEY=masterKey
      neo4j:
        image: neo4j:latest
        ports:
          - 7474:7474 # HTTP
          - 7687:7687 # Bolt
        env:
          options: --env NEO4J_AUTH=neo4j/password
    env:
      CI: true # allows conditional skipping of tests based on this env var
      OPENAI_API_KEY: ${{ secrets.OPENAI_KEY }}
      GITHUB_ACCESS_TOKEN: ${{ secrets.GH_ACCESS_TOKEN }}
      REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD }}
      REDIS_HOST: ${{ secrets.REDIS_HOST }}
      REDIS_PORT: ${{ secrets.REDIS_PORT }}
      MOMENTO_AUTH_TOKEN: ${{ secrets.MOMENTO_AUTH_TOKEN }}
      MOMENTO_API_KEY: ${{ secrets.MOMENTO_API_KEY }}
      QDRANT_API_KEY: ${{ secrets.QDRANT_API_KEY }}
      QDRANT_API_URL: ${{ secrets.QDRANT_API_URL }}
      CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
      GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      GOOGLE_CSE_ID: ${{ secrets.GOOGLE_CSE_ID }}

      # Azure OpenAI env vars
      AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
      AZURE_OPENAI_API_BASE: ${{ secrets.AZURE_OPENAI_API_BASE }}
      AZURE_OPENAI_API_VERSION: "2023-05-15"
      AZURE_OPENAI_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_NAME }}
      AZURE_OPENAI_MODEL_NAME: ${{ secrets.AZURE_GPT_MODEL_NAME }} 
      AZURE_OPENAI_MODEL_VERSION: ${{ secrets.AZURE_OPENAI_MODEL_VERSION }}
    steps:
    - name: Check out repository
      uses: actions/checkout@v3
    - name: Increase ulimit
      run: ulimit -n 4096
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11  # Replace with your desired Python version

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libmagic1
        sudo apt-get install -y poppler-utils tesseract-ocr

    - name: Load cached Poetry installation
      uses: actions/cache@v4
      with:
        path: ~/.local
        key: poetry-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install and configure Poetry
      uses: snok/install-poetry@v1
      with:
        virtualenvs-create: true
        virtualenvs-in-project: true
        installer-parallel: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v4
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install Poetry dependencies if not found in cache
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: |
        poetry --version
        echo "$HOME/.local/bin" >> $GITHUB_PATH
        python -m pip install --upgrade pip
        
        poetry install --no-root --sync \
          -E "lancedb momento meilisearch chromadb hf-embeddings unstructured pdf-parsers docx sql fastembed" \
          --with dev

    - name: Download NLTK data
      run: poetry run python -c "import nltk; nltk.download('punkt_tab')"

    - name: Dump dependencies to file
      run: pip freeze > requirements_github.txt

    - name: Upload dependencies file
      uses: actions/upload-artifact@v3
      with:
        name: github-dependencies
        path: requirements_github.txt


    - name: Run ALL tests with coverage (GPT-4o)
      id: first_test
      env:
        PYTEST_ADDOPTS: "-p no:logging"
      run: |
        poetry run coverage run --source=langroid  --parallel-mode \
          -m pytest -rf -vv --log-cli-level=INFO --show-capture=no -n auto --timeout=300 \
          --first-test-file=tests/main/test_llm.py \
          --first-test-file=tests/main/test_llm_async.py \
          --first-test-file=tests/main/test_task_inf_loop.py \
          --first-test-file=tests/main/test_task.py \
          --first-test-file=tests/main/test_lance_doc_chat_agent.py \
          tests/main tests/extras/test_hf_embeddings.py tests/extras/test_fastembed_embeddings.py
      continue-on-error: true


    - name: Retry FAILED tests ONLY with gpt-4 instead of gpt-4o
      id: second_test
      if: steps.first_test.outcome == 'failure'
      env:
        PYTEST_ADDOPTS: "-p no:logging"
      run: |
        poetry run coverage run --source=langroid  --parallel-mode \
          -m pytest --m gpt-4 -rf --show-capture=no  -n auto --timeout=300 \
          --first-test-file=tests/main/test_llm.py \
          --first-test-file=tests/main/test_llm_async.py \
          --first-test-file=tests/main/test_task_inf_loop.py \
          --first-test-file=tests/main/test_task.py \
          --first-test-file=tests/main/test_lance_doc_chat_agent.py \
          --lf --last-failed-no-failures none \
          tests/main tests/extras/test_hf_embeddings.py tests/extras/test_fastembed_embeddings.py

    - name: Combine coverage data
      run: poetry run coverage combine
      
    - name: Generate final coverage report from all runs
      run: poetry run coverage report

    - name: Generate XML coverage report
      run: poetry run coverage xml
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
      env:
        CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

