>>>> CODE_OF_CONDUCT.md
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
pchalasani@gmail.com.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.

>>>> CONTRIBUTING.md
# Contributing to Langroid

Thank you for your interest in contributing to Langroid!
We want to fundamentally change how LLM applications are built, 
using Langroid's principled multi-agent framework. 
Together, let us build the future of LLM-apps!
We welcome contributions from everyone.

Below you will find guidelines and suggestions for contributing.
We explicitly designed Langroid with a transparent, flexible architecture to 
make it easier to build LLM-powered applications, as well as 
to make it easier to contribute to Langroid itself.
Feel free to join us on [Discord](https://discord.gg/ZU36McDgDs) 
for any questions or discussions.

# How can I Contribute?

There are many ways to contribute to Langroid. Here are some areas where you can help:

- Bug Reports
- Code Fixes
- Feature Requests
- Feature Implementations
- Documentation
- Testing
- UI/UX Improvements
- Translations
- Outreach

You are welcome to take on un-assigned open [issues](https://github.com/langroid/langroid/issues).

## Implementation Ideas

**INTEGRATIONS**

- Vector databases, e.g.:
    - [x] Qdrant
    - [x] Chroma
    - [x] LanceDB
    - [x] Pinecone 
    - [x] PostgresML (pgvector)
    - [x] Weaviate
    - [ ] Milvus 
    - [ ] Marqo 
- Other LLM APIs, e.g.: Claude, Cohere, ... (see below)
- Local LLMs, e.g.: llama2
- Data Sources: SQL DBs, NoSQL DBs, Neo4j (Graph DBs), ...
- Query languages: SQL, GraphQL, Cypher, ...


**SPECIALIZED AGENTS**

- [x] `SQLChatAgent`, analogous to `DocChatAgent`: adds ability to chat with SQL databases
- [x] `TableChatAgent`: adds ability to chat with a tabular dataset in a file. 
   This can derive from `RetrieverAgent`

**CORE LANGROID**

- [ ] **Long-running, loosely coupled agents, communicating over message queues**: Currently all agents run within a session,
  launched from a single script. Extend this so agents can run in different
  processes, machines, or envs or cloud, and communicate via message queues.
- [ ] **Improve observability:** we currently log all agent interactions into structured
  and unstructured forms. Add features on top, to improve inspection and
  diagnosis of issues.
- [ ] Implement a way to **backtrack** 1 step in a multi-agent task. 
For instance during a long multi-agent conversation, if we receive a bad response from the LLM,
when the user gets a chance to respond, they may insert a special code (e.g. `b`) so that 
the previous step is re-done and the LLM gets another chance to respond.
- [x] **Integrate LLM APIs:** There are a couple of libs that simulate OpenAI-like interface for other models: https://github.com/BerriAI/litellm
    and https://github.com/philschmid/easyllm. It would be useful to have Langroid work with these APIs.
- [ ] Implement Agents that communicate via REST APIs: Currently, all agents within 
the multi-agent system are created in a single script. 
We can remove this limitation, and add the ability to have agents running and 
listening to an end-point (e.g. a flask server). For example the LLM may 
generate a function-call or Langroid-tool-message, which the agent’s 
tool-handling method interprets and makes a corresponding request to an API endpoint. 
This request can be handled by an agent listening to requests at this endpoint, 
and the tool-handling method gets the result and returns it as the result of the handling method. 
This is roughly the mechanism behind OpenAI plugins, e.g. https://github.com/openai/chatgpt-retrieval-plugin

**DEMOS, POC, Use-cases**

- [ ] **Text labeling/classification:** Specifically do what this repo does: https://github.com/refuel-ai/autolabel, 
  but using Langroid instead of Langchain (which that repo uses).
- [ ] Data Analyst Demo: A multi-agent system that automates a data analysis workflow, e.g. 
feature-exploration, visualization, ML model training.
- [ ] Document classification based on rules in an unstructured “policy” document. 
    This is an actual use-case from a large US bank. The task is to classify 
    documents into categories “Public” or “Sensitive”. The classification must be 
    informed by a “policy” document which has various criteria. 
    Normally, someone would have to read the policy doc, and apply that to 
    classify the documents, and maybe go back and forth and look up the policy repeatedly. 
    This would be a perfect use-case for Langroid’s multi-agent system. 
    One agent would read the policy, perhaps extract the info into some structured form. 
    Another agent would apply the various criteria from the policy to the document in question, 
    and (possibly with other helper agents) classify the document, along with a detailed justification.

- [ ] Document classification and tagging: Given a collection of already labeled/tagged docs, 
which have been ingested into a vecdb (to allow semantic search), 
when given a new document to label/tag, we retrieve the most similar docs 
from multiple categories/tags from the vecdb and present these (with the labels/tags) 
as few-shot examples to the LLM, and have the LLM classify/tag the retrieved document.

- [ ] Implement the CAMEL multi-agent debate system : https://lablab.ai/t/camel-tutorial-building-communicative-agents-for-large-scale-language-model-exploration

- [ ] Implement Stanford’s Simulacra paper with Langroid.
Generative Agents: Interactive Simulacra of Human Behavior https://arxiv.org/abs/2304.03442

- [ ] Implement CMU's paper with Langroid.
Emergent autonomous scientific research capabilities of large language models https://arxiv.org/pdf/2304.05332.pdf

---

# Contribution Guidelines

## Set up dev env

We use [`uv`](https://docs.astral.sh/uv/getting-started/installation/)
to manage dependencies, and `python 3.11` for development.

First install `uv`, then create virtual env and install dependencies:

```bash
# clone this repo and cd into repo root
git clone ...
cd <repo_root>
# create a virtual env under project root, .venv directory
uv venv --python 3.11

# activate the virtual env
. .venv/bin/activate


# use uv to install dependencies (these go into .venv dir)
uv sync --dev 
```

Important note about dependencies management:
> As of version 0.33.0, we are starting to include the `uv.lock` file as part of 
> the repo. This ensures that all contributors are using the same versions of 
> dependencies. If you add a new dependency, `uv add` will automatically update 
> the `uv.lock` file. This will also update the `pyproject.toml` file.

To add packages, use `uv add <package-name>`. This will automatically
find the latest compatible version of the package and add it to `pyproject.
toml`. _Do not manually edit `pyproject.toml` to add packages._

## Set up environment variables (API keys, etc)

Copy the `.env-template` file to a new file `.env` and
insert secrets such as API keys, etc:
- OpenAI API key, Anthropic API key, etc.
- [Optional] GitHub Personal Access Token (needed by  PyGithub to analyze git repos;
  token-based API calls are less rate-limited).
- [Optional] Cache Configs
  - Redis : Password, Host, Port <br>
- Qdrant API key for the vector database.

```bash
cp .env-template .env
# now edit the .env file, insert your secrets as above
``` 

Currently only OpenAI models are supported. 
You are welcome to submit a PR to support other API-based or local models. 

## Run tests
To verify your env is correctly setup, run all tests using `make tests`.

## IMPORTANT: Please include tests, docs and possibly examples.

For any new features, please include:
- Tests in the `tests` directory (first check if there is a suitable test file to add to).
  _If fixing a bug, please add a regression test, i.e., 
   one which would have failed without your fix_
- A note in `docs/notes` folder, e.g. `docs/notes/weaviate.md` that is a
  (relatively) self-contained guide to using the feature, including any instructions
  on how to set up the environment or keys if needed. 
  See the [weaviate](https://langroid.github.io/langroid/notes/weaviate/) note as an example. Make sure you link to this note in the `mkdocs.yml` file under the `nav` section.
- Where possible and meaningful, add a simple example in the `examples` directory.

## Generate docs

Generate docs: `make docs`, then go to the IP address shown at the end, like
`http://127.0.0.1:8000/`
Note this runs a docs server in the background.
To stop it, run `make nodocs`. Also, running `make docs` next time will kill
any previously running `mkdocs` server.


## Coding guidelines

In this Python repository, we prioritize code readability and maintainability.
To ensure this, please adhere to the following guidelines when contributing:

1. **Type-Annotate Code:** Add type annotations to function signatures and
   variables to make the code more self-explanatory and to help catch potential
   issues early. For example, `def greet(name: str) -> str:`. We use [`mypy`](https://mypy.readthedocs.io/en/stable/) for
   type-checking, so please ensure your code passes `mypy` checks. 

2. **Google-Style Docstrings:** Use Google-style docstrings to clearly describe
   the purpose, arguments, and return values of functions. For example:

   ```python
   def greet(name: str) -> str:
       """Generate a greeting message.

       Args:
           name (str): The name of the person to greet.

       Returns:
           str: The greeting message.
       """
       return f"Hello, {name}!"
   ```

3. **PEP8-Compliant 80-Char Max per Line:** Follow the PEP8 style guide and keep
   lines to a maximum of 80 characters. This improves readability and ensures
   consistency across the codebase.

If you are using an LLM to write code for you, adding these
instructions will usually get you code compliant with the above:
```
use type-annotations, google-style docstrings, and pep8 compliant max 80 
     chars per line.
```     


By following these practices, we can create a clean, consistent, and
easy-to-understand codebase for all contributors. Thank you for your
cooperation!

## Submitting a PR

To check for issues locally, run `make check`, it runs linters `black`, `ruff`,
and type-checker `mypy`. It also installs a pre-commit hook, 
so that commits are blocked if there are style/type issues. The linting attempts to
auto-fix issues, and warns about those it can't fix.
(There is a separate `make lint` you could do, but that is already part of `make check`).
The `make check` command also looks through the codebase to see if there are any
direct imports from pydantic, and replaces them with importing from `langroid.pydantic_v1`
(this is needed to enable dual-compatibility with Pydantic v1 and v2).

So, typically when submitting a PR, you would do this sequence:
- run `make tests` or `pytest -xvs tests/main/my-specific-test.py` 
  - if needed use `-nc` means "no cache", i.e. to prevent using cached LLM API call responses
  - the `-xvs` option means "exit on first failure, verbose, show output"
- fix things so tests pass, then proceed to lint/style/type checks below.
- `make check` to see what issues there are (typically lints and mypy)
- manually fix any lint or type issues
- `make check` again to see what issues remain
- repeat if needed, until all clean.

When done with these, commit and push to github and submit the PR. If this
is an ongoing PR, just push to github again and the PR will be updated.

It is strongly recommended to use the `gh` command-line utility when working with git.
Read more [here](docs/development/github-cli.md).

>>>> Dockerfile
FROM --platform=$TARGETPLATFORM python:3.11

# Set environment variables to non-interactive (this prevents some prompts)
ENV DEBIAN_FRONTEND=non-interactive \
    LANG=en_US.UTF-8 \
    LANGUAGE=en_US:en \
    LC_ALL=en_US.UTF-8

# Install necessary tools, zsh, and set up locale
RUN apt-get update && \
    apt-get install --no-install-recommends -y zsh wget git curl locales \
    libfreetype6-dev \
    libjpeg-dev \
    libopenjp2-7-dev \
    libssl-dev && \
    sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen && \
    locale-gen && \
    # Cleanup apt cache
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Clone the langroid repository
RUN git clone https://github.com/langroid/langroid.git

# Set the working directory in the container
WORKDIR /langroid
RUN mv .env-template .env

RUN mkdir -p /root/.cache/uv

# workaround for pymupdf build error?
ENV MAKEFLAGS="-j1"
ENV PYTHONPYCACHEPREFIX="/tmp/pycache"
ENV DEBIAN_FRONTEND=non-interactive \
     LANG=en_US.UTF-8

# detect arch to customize pymupdf version
ARG TARGETPLATFORM
ARG TARGETARCH

# install uv then langroid
# Install uv and use it with cache mount
RUN --mount=type=cache,target=/root/.cache/uv,id=uv_cache \
    curl -LsSf https://astral.sh/uv/install.sh | sh && \
    export PATH="/root/.local/bin:$PATH" && \
    uv venv && \
    . .venv/bin/activate && \
    pip install --upgrade pip && \
    if [ "$TARGETARCH" = "arm64" ]; then \
         uv pip install --no-cache-dir "pymupdf==1.24.14"; \
     else \
         uv pip install --no-cache-dir "pymupdf>=1.25.3"; \
     fi && \
    uv pip install --no-cache-dir .

# Install oh-my-zsh and set up zsh configurations
RUN sh -c "$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)" || true && \
    sed -i -e 's/plugins=(git)/plugins=(git python)/' /root/.zshrc

CMD ["zsh"]
>>>> LIBRARIES_IO_TOKEN

>>>> Makefile
.PHONY: setup check lint tests docs nodocs loc

SHELL := /bin/bash

.PHONY: setup update

setup: ## Setup the git pre-commit hooks
	uv run pre-commit install

update: ## Update the git pre-commit hooks
	uv run pre-commit autoupdate

.PHONY: type-check
type-check:
	@uv run pre-commit install
	@uv run pre-commit autoupdate
	@uv run pre-commit run --all-files
	@echo "Running black..."
	@uv run black --check .
	@echo "Running flake8 on git-tracked files ONLY! ..."
	@git ls-files | grep '\.py$$' | xargs flake8 --exclude=.git,__pycache__,.venv,langroid/embedding_models/protoc/*
	@uv run ruff check .
	@echo "Running mypy...";
	@uv run mypy -p langroid
	@echo "All checks passed!"

.PHONE: lint
lint:
	uv run black .
	uv run ruff check . --fix

.PHONY: stubs
stubs:
	@echo "Generating Python stubs for the langroid package..."
	@uv run stubgen -p langroid -o stubs
	@echo "Stubs generated in the 'stubs' directory"

.PHONY: fix-pydantic

# Entry to replace pydantic imports in specified directories
fix-pydantic:
	@echo "Fixing pydantic imports..."
	@chmod +x scripts/fix-pydantic-imports.sh
	@./scripts/fix-pydantic-imports.sh

.PHONY: check
check: fix-pydantic lint type-check

.PHONY: tests
tests:
	pytest tests/main --basetemp=/tmp/pytest


docs:
	@# Kill any existing 'mkdocs serve' processes.
	@pkill -f "mkdocs serve" 2>/dev/null || true
	@# Build the documentation.
	mkdocs build
	@# Serve the documentation in the background.
	mkdocs serve &
	@echo "Documentation is being served in the background."
	@echo "You can access the documentation at http://127.0.0.1:8000/"

nodocs:
	@# Kill any existing 'mkdocs serve' processes.
	@pkill -f "mkdocs serve" 2>/dev/null || echo "No 'mkdocs serve' process found."
	@echo "Stopped serving documentation."


loc:
	@echo "Lines in git-tracked files python files:"
	@git ls-files | grep '\.py$$' | xargs cat | grep -v '^\s*$$' | wc -l

.PHONY: revert-tag
revert-tag:
	@LATEST_TAG=$$(git describe --tags --abbrev=0) && \
	echo "Deleting tag: $$LATEST_TAG" && \
	git tag -d $$LATEST_TAG

.PHONY: revert-bump
revert-bump:
	@if git log -1 --pretty=%B | grep -q "bump"; then \
		git reset --hard HEAD~1; \
		echo "Reverted last commit (bump commit)"; \
	else \
		echo "Last commit was not a bump commit"; \
	fi

.PHONY: revert
revert: revert-bump revert-tag
	
.PHONY: bump-patch
bump-patch:
	@cz bump --increment PATCH

.PHONY: bump-minor
bump-minor:
	@cz bump --increment MINOR 

.PHONY: bump-major
bump-major:
	@cz bump --increment MAJOR 

.PHONY: build
build:
	@uv build

.PHONY: push
push:
	@git push origin main
	@git push origin --tags

.PHONY: clean
clean:
	-rm -rf dist/*

.PHONY: release
release:
	@VERSION=$$(cz version -p | cut -d' ' -f2) && gh release create $${VERSION} dist/*

.PHONY: all-patch
all-patch: bump-patch clean build push release

.PHONY: all-minor
all-minor: bump-minor clean build push release

.PHONY: all-major
all-major: bump-major clean build push release

.PHONY: publish
publish:
	uv publish

>>>> README.md
<div align="center">
  <img src="docs/assets/langroid-card-lambda-ossem-rust-1200-630.png" alt="Logo" 
        width="400" align="center">
</div>

<div align="center">

[![PyPI - Version](https://img.shields.io/pypi/v/langroid)](https://pypi.org/project/langroid/)
[![Downloads](https://img.shields.io/pypi/dm/langroid)](https://pypi.org/project/langroid/)
[![Pytest](https://github.com/langroid/langroid/actions/workflows/pytest.yml/badge.svg)](https://github.com/langroid/langroid/actions/workflows/pytest.yml)
[![codecov](https://codecov.io/gh/langroid/langroid/branch/main/graph/badge.svg?token=H94BX5F0TE)](https://codecov.io/gh/langroid/langroid)
[![Multi-Architecture DockerHub](https://github.com/langroid/langroid/actions/workflows/docker-publish.yml/badge.svg)](https://github.com/langroid/langroid/actions/workflows/docker-publish.yml)

[![Static Badge](https://img.shields.io/badge/Documentation-blue?link=https%3A%2F%2Flangroid.github.io%2Flangroid%2F&link=https%3A%2F%2Flangroid.github.io%2Flangroid%2F)](https://langroid.github.io/langroid)
[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langroid/langroid/blob/main/examples/Langroid_quick_start.ipynb)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=flat&logo=discord&logoColor=white)](https://discord.gg/ZU36McDgDs)
[![Substack](https://img.shields.io/badge/Substack-%23006f5c.svg?style=flat&logo=substack&logoColor=FF6719)](https://langroid.substack.com/p/langroid-harness-llms-with-multi-agent-programming)

[![GitMCP](https://img.shields.io/endpoint?url=https://gitmcp.io/badge/OWNER/REPO)](https://gitmcp.io/langroid/langroid)
</div>

<h3 align="center">
  <a target="_blank" 
    href="https://langroid.github.io/langroid/" rel="dofollow">
      <strong>Documentation</strong></a>
  &middot;
  <a target="_blank" href="https://github.com/langroid/langroid-examples" rel="dofollow">
      <strong>Examples Repo</strong></a>
  &middot;
  <a target="_blank" href="https://discord.gg/ZU36McDgDs" rel="dofollow">
      <strong>Discord</strong></a>
  &middot;
  <a target="_blank" href="./CONTRIBUTING.md" rel="dofollow">
      <strong>Contributing</strong></a>

  <br />
</h3>

`Langroid` is an intuitive, lightweight, extensible and principled
Python framework to easily build LLM-powered applications, from CMU and UW-Madison researchers. 
You set up Agents, equip them with optional components (LLM, 
vector-store and tools/functions), assign them tasks, and have them 
collaboratively solve a problem by exchanging messages. 
This Multi-Agent paradigm is inspired by the
[Actor Framework](https://en.wikipedia.org/wiki/Actor_model)
(but you do not need to know anything about this!). 

`Langroid` is a fresh take on LLM app-development, where considerable thought has gone 
into simplifying the developer experience; 
it does not use `Langchain`, or any other LLM framework, 
and works with [practically any LLM](https://langroid.github.io/langroid/tutorials/supported-models/).

:fire: Read the (WIP) [overview of the langroid architecture](https://langroid.github.io/langroid/blog/2024/08/15/overview-of-langroids-multi-agent-architecture-prelim/), 
 and a [quick tour of Langroid](https://langroid.github.io/langroid/tutorials/langroid-tour/).

📢 Companies are using/adapting Langroid in **production**. Here is a quote:

>[Nullify](https://www.nullify.ai) uses AI Agents for secure software development. 
> It finds, prioritizes and fixes vulnerabilities. We have internally adapted Langroid's multi-agent orchestration framework in production, after evaluating CrewAI, Autogen, LangChain, Langflow, etc. We found Langroid to be far superior to those frameworks in terms of ease of setup and flexibility. Langroid's Agent and Task abstractions are intuitive, well thought out, and provide a great developer  experience. We wanted the quickest way to get something in production. With other frameworks it would have taken us weeks, but with Langroid we got to good results in minutes. Highly recommended! <br> -- Jacky Wong, Head of AI at Nullify.


:fire: See this [Intro to Langroid](https://lancedb.substack.com/p/langoid-multi-agent-programming-framework)
blog post from the LanceDB team

:fire: Just published in ML for Healthcare (2024): a Langroid-based Multi-Agent RAG system for 
pharmacovigilance, see [blog post](https://langroid.github.io/langroid/blog/2024/08/12/malade-multi-agent-architecture-for-pharmacovigilance/)


We welcome contributions: See the [contributions](./CONTRIBUTING.md) document
for ideas on what to contribute.

Are you building LLM Applications, or want help with Langroid for your company, 
or want to prioritize Langroid features for your company use-cases? 
[Prasad Chalasani](https://www.linkedin.com/in/pchalasani/) is available for consulting
(advisory/development): pchalasani at gmail dot com.

Sponsorship is also accepted via [GitHub Sponsors](https://github.com/sponsors/langroid)

**Questions, Feedback, Ideas? Join us on [Discord](https://discord.gg/ZU36McDgDs)!**

# Quick glimpse of coding with Langroid
This is just a teaser; there's much more, like function-calling/tools, 
Multi-Agent Collaboration, Structured Information Extraction, DocChatAgent 
(RAG), SQLChatAgent, non-OpenAI local/remote LLMs, etc. Scroll down or see docs for more.
See the Langroid Quick-Start [Colab](https://colab.research.google.com/github/langroid/langroid/blob/main/examples/Langroid_quick_start.ipynb)
that builds up to a 2-agent information-extraction example using the OpenAI ChatCompletion API. 
See also this [version](https://colab.research.google.com/drive/190Tk7t4AdY1P9F_NlZ33-YEoGnHweQQ0) that uses the OpenAI Assistants API instead.

:fire: just released! [Example](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat-multi-extract-local.py) 
script showing how you can use Langroid multi-agents and tools
to extract structured information from a document using **only a local LLM**
(Mistral-7b-instruct-v0.2).

```python
import langroid as lr
import langroid.language_models as lm

# set up LLM
llm_cfg = lm.OpenAIGPTConfig( # or OpenAIAssistant to use Assistant API 
  # any model served via an OpenAI-compatible API
  chat_model=lm.OpenAIChatModel.GPT4o, # or, e.g., "ollama/mistral"
)
# use LLM directly
mdl = lm.OpenAIGPT(llm_cfg)
response = mdl.chat("What is the capital of Ontario?", max_tokens=10)

# use LLM in an Agent
agent_cfg = lr.ChatAgentConfig(llm=llm_cfg)
agent = lr.ChatAgent(agent_cfg)
agent.llm_response("What is the capital of China?") 
response = agent.llm_response("And India?") # maintains conversation state 

# wrap Agent in a Task to run interactive loop with user (or other agents)
task = lr.Task(agent, name="Bot", system_message="You are a helpful assistant")
task.run("Hello") # kick off with user saying "Hello"

# 2-Agent chat loop: Teacher Agent asks questions to Student Agent
teacher_agent = lr.ChatAgent(agent_cfg)
teacher_task = lr.Task(
  teacher_agent, name="Teacher",
  system_message="""
    Ask your student concise numbers questions, and give feedback. 
    Start with a question.
    """
)
student_agent = lr.ChatAgent(agent_cfg)
student_task = lr.Task(
  student_agent, name="Student",
  system_message="Concisely answer the teacher's questions.",
  single_round=True,
)

teacher_task.add_sub_task(student_task)
teacher_task.run()
```

# :fire: Updates/Releases

<details>
<summary> <b>Click to expand</b></summary>

- **Mar-Apr 2025:**
  - [0.53.0](https://github.com/langroid/langroid/releases/tag/0.53.0) MCP Tools Support.
  - [0.52.0](https://github.com/langroid/langroid/releases/tag/0.52.0) Multimodal support, i.e. allow PDF, image 
    inputs to LLM.
  - [0.51.0](https://github.com/langroid/langroid/releases/tag/0.51.0) `LLMPdfParser`, generalizing 
    `GeminiPdfParser` to parse documents directly with LLM.
  - [0.50.0](https://github.com/langroid/langroid/releases/tag/0.50.0) Structure-aware Markdown chunking with chunks 
    enriched by section headers.
  - [0.49.0](https://github.com/langroid/langroid/releases/tag/0.49.0) Enable easy switch to LiteLLM Proxy-server 
  - [0.48.0](https://github.com/langroid/langroid/releases/tag/0.48.0) Exa Crawler, Markitdown Parser
  - [0.47.0](https://github.com/langroid/langroid/releases/tag/0.47.0) Support Firecrawl URL scraper/crawler - 
    thanks @abab-dev
  - [0.46.0](https://github.com/langroid/langroid/releases/tag/0.46.0) Support LangDB LLM Gateway - thanks @MrunmayS.
  - [0.45.0](https://github.com/langroid/langroid/releases/tag/0.45.0) Markdown parsing with `Marker` - thanks @abab-dev
  - [0.44.0](https://github.com/langroid/langroid/releases/tag/0.44.0) Late imports to reduce startup time. Thanks 
    @abab-dev
- **Feb 2025:**
  - [0.43.0](https://github.com/langroid/langroid/releases/tag/0.43.0): `GeminiPdfParser` for parsing PDF using 
    Gemini LLMs - Thanks @abab-dev.
  - [0.42.0](https://github.com/langroid/langroid/releases/tag/0.42.0): `markitdown` parser for `pptx,xlsx,xls` files 
    Thanks @abab-dev.
  - [0.41.0](https://github.com/langroid/langroid/releases/tag/0.41.0): `pinecone` vector-db (Thanks @coretado), 
    `Tavily` web-search (Thanks @Sozhan308), `Exa` web-search (Thanks @MuddyHope).
  - [0.40.0](https://github.com/langroid/langroid/releases/tag/0.40.0): `pgvector` vector-db. Thanks @abab-dev.
  - [0.39.0](https://github.com/langroid/langroid/releases/tag/0.39.0): `ChatAgentConfig.handle_llm_no_tool` for 
    handling LLM "forgetting" to use a tool.
  - [0.38.0](https://github.com/langroid/langroid/releases/tag/0.38.0): Gemini embeddings - Thanks @abab-dev)
  - [0.37.0](https://github.com/langroid/langroid/releases/tag/0.37.0): New PDF Parsers: `docling`, `pymupdf4llm`
- **Jan 2025:**
  - [0.36.0](https://github.com/langroid/langroid/releases/tag/0.36.0): Weaviate vector-db support (thanks @abab-dev).
  - [0.35.0](https://github.com/langroid/langroid/releases/tag/0.35.0): Capture/Stream reasoning content from 
    Reasoning LLMs (e.g. DeepSeek-R1, OpenAI o1) in addition to final answer.
  - [0.34.0](https://github.com/langroid/langroid/releases/tag/0.34.0): DocChatAgent 
    chunk enrichment to improve retrieval. (collaboration with @dfm88). 
  - [0.33.0](https://github.com/langroid/langroid/releases/tag/0.33.3) Move from Poetry to uv! (thanks @abab-dev).
  - [0.32.0](https://github.com/langroid/langroid/releases/tag/0.32.0) DeepSeek v3 support.
- **Dec 2024:**
  - [0.31.0](https://github.com/langroid/langroid/releases/tag/0.31.0) Azure OpenAI Embeddings
  - [0.30.0](https://github.com/langroid/langroid/releases/tag/0.30.0) Llama-cpp embeddings (thanks @Kwigg).
  - [0.29.0](https://github.com/langroid/langroid/releases/tag/0.29.0) Custom Azure OpenAI Client (thanks 
    @johannestang).
  - [0.28.0](https://github.com/langroid/langroid/releases/tag/0.28.0) `ToolMessage`: `_handler` field to override 
default handler method name in `request` field (thanks @alexagr).
  - [0.27.0](https://github.com/langroid/langroid/releases/tag/0.27.0) OpenRouter Support.
  - [0.26.0](https://github.com/langroid/langroid/releases/tag/0.26.0) Update to latest Chainlit.
  - [0.25.0](https://github.com/langroid/langroid/releases/tag/0.25.0) True Async Methods for agent and 
    user-response (thanks @alexagr).
- **Nov 2024:**
  - **[0.24.0](https://langroid.github.io/langroid/notes/structured-output/)**: 
     Enables support for `Agent`s with strict JSON schema output format on compatible LLMs and strict mode for the OpenAI tools API.
    (thanks @nilspalumbo).
  - **[0.23.0](https://langroid.github.io/langroid/tutorials/local-llm-setup/#local-llms-hosted-on-glhfchat)**: 
      support for LLMs (e.g. `Qwen2.5-Coder-32b-Instruct`) hosted on glhf.chat 
  - **[0.22.0](https://langroid.github.io/langroid/notes/large-tool-results/)**: 
     Optional parameters to truncate large tool results.
  - **[0.21.0](https://langroid.github.io/langroid/notes/gemini/)** Direct support for Gemini models via OpenAI client instead of using LiteLLM.
  - **[0.20.0](https://github.com/langroid/langroid/releases/tag/0.20.0)** Support for 
    ArangoDB Knowledge Graphs.
- **Oct 2024:**
  - **[0.18.0]** [LLMConfig.async_stream_quiet](https://langroid.github.io/langroid/notes/async-streaming/) flag to 
    turn off LLM output in async + stream mode.
  - **[0.17.0]** XML-based tools, see [docs](https://langroid.github.io/langroid/notes/xml-tools/).
- **Sep 2024:**
  - **[0.16.0](https://github.com/langroid/langroid/releases/tag/0.16.0)**  Support for OpenAI `o1-mini` and `o1-preview` models.
  - **[0.15.0](https://github.com/langroid/langroid/releases/tag/0.15.0)** Cerebras API support -- run llama-3.1 models hosted on Cerebras Cloud (very fast inference).
  - **[0.14.0](https://github.com/langroid/langroid/releases/tag/0.14.0)** `DocChatAgent` uses Reciprocal Rank Fusion (RRF) to rank chunks retrieved by different methods.
  - **[0.12.0](https://github.com/langroid/langroid/releases/tag/0.12.0)** `run_batch_task` new option -- `stop_on_first_result` - allows termination of batch as soon as any task returns a result.  
- **Aug 2024:**
  - **[0.11.0](https://github.com/langroid/langroid/releases/tag/0.11.0)** Polymorphic `Task.run(), Task.run_async`.
  - **[0.10.0](https://github.com/langroid/langroid/releases/tag/0.10.0)** Allow tool handlers to return arbitrary result type, including other tools.
  - **[0.9.0](https://github.com/langroid/langroid/releases/tag/0.9.0)** Orchestration Tools, to signal various task statuses, and to pass messages between agents.
  - **[0.7.0](https://github.com/langroid/langroid/releases/tag/0.7.0)** OpenAI tools API support, including multi-tools.
- **Jul 2024:**
  - **[0.3.0](https://github.com/langroid/langroid/releases/tag/0.3.0)**: Added [FastEmbed](https://qdrant.github.io/fastembed/qdrant/Usage_With_Qdrant/) embeddings from Qdrant
- **Jun 2024:**
  - **0.2.0:** Improved lineage tracking, granular sub-task configs, and a new tool, `RewindTool`, 
    that lets an agent "rewind and redo" a past message (and all dependent messages are cleared out 
    thanks to the lineage tracking). Read notes [here](https://github.com/langroid/langroid/releases/tag/0.2.0).
- **May 2024:** 
  - **Slimmer langroid**: All document-parsers (i.e. pdf, doc, docx) and most 
    vector-databases (except qdrant) 
    are now optional/extra dependencies, which helps reduce build size, script 
    start-up time, and install time. For convenience various grouping of "extras" are 
    provided, e.g. `doc-chat`, `db` (for database-related dependencies). See updated 
    install instructions below and in the docs.
  - **Few-shot examples** for tools: when defining a [ToolMessage](https://langroid.github.io/langroid/quick-start/chat-agent-tool/#example-find-the-smallest-number-in-a-list), previously you were able to include a classmethod named `examples`,
    and a random example from this list would be used to generate a 1-shot example 
    for the LLM. This has been improved so you can now supply a list of examples 
    where each example is either a tool instance, or a tuple of (description, 
    tool instance), where the description is a "thought" that leads the LLM to use 
    the tool (see example in the [docs](https://langroid.github.io/langroid/quick-start/chat-agent-tool/#example-find-the-smallest-number-in-a-list)). In some scenarios this can improve LLM tool 
    generation accuracy. Also, now instead of a random example, ALL examples are used to generate few-shot 
    examples.     
  - [Infinite loop detection](https://github.com/langroid/langroid/blob/0ed30eb467b00d5eaf2933b577a4b2cc37de1aa1/langroid/agent/task.py#L1121) for task loops of cycle-length <= 10 (configurable 
    in [`TaskConfig`](https://langroid.github.io/langroid/reference/agent/task/#langroid.agent.task.TaskConfig). Only detects _exact_ loops, rather than _approximate_ loops where the entities are saying essentially similar (but not exactly the same) things repeatedly.
  - "@"-addressing: any entity can address any other by name, which can be the name 
    of an agent's responder ("llm", "user", "agent") or a sub-task name. This is a 
    simpler alternative to the `RecipientTool` mechanism, with the tradeoff that 
    since it's not a tool, there's no way to enforce/remind the LLM to explicitly 
    specify an addressee (in scenarios where this is important).
  - [Much-Improved Citation](https://github.com/langroid/langroid/issues/477) 
    generation and display when using `DocChatAgent`.
  - `gpt-4o` is now the default LLM throughout; Update tests and examples to work 
    with this LLM; use tokenizer corresponding to the LLM.
  - `gemini 1.5 pro` support via `litellm`
  - `QdrantDB:` update to support learned sparse embeddings.
- **Apr 2024:**
  - **0.1.236**: Support for open LLMs hosted on Groq, e.g. specify 
    `chat_model="groq/llama3-8b-8192"`.
      See [tutorial](https://langroid.github.io/langroid/tutorials/local-llm-setup/).
  - **0.1.235**: `Task.run(), Task.run_async(), run_batch_tasks` have `max_cost` 
    and `max_tokens` params to exit when tokens or cost exceed a limit. The result 
    `ChatDocument.metadata` now includes a `status` field which is a code indicating a 
     task completion reason code. Also `task.run()` etc can be invoked with an explicit
     `session_id` field which is used as a key to look up various settings in Redis cache.
    Currently only used to look up "kill status" - this allows killing a running task, either by `task.kill()`
    or by the classmethod `Task.kill_session(session_id)`.
    For example usage, see the `test_task_kill` in [tests/main/test_task.py](https://github.com/langroid/langroid/blob/main/tests/main/test_task.py)
  
- **Mar 2024:**
  - **0.1.216:** Improvements to allow concurrent runs of `DocChatAgent`, see the
    [`test_doc_chat_agent.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_doc_chat_agent.py)
    in particular the `test_doc_chat_batch()`;
    New task run utility: [`run_batch_task_gen`](https://github.com/langroid/langroid/blob/main/langroid/agent/batch.py) 
    where a task generator can be specified, to generate one task per input. 
  - **0.1.212:** ImagePdfParser: support for extracting text from image-based PDFs.
    (this means `DocChatAgent` will now work with image-pdfs).
  - **0.1.194 - 0.1.211:** Misc fixes, improvements, and features:
    - Big enhancement in RAG performance (mainly, recall) due to a [fix in Relevance 
      Extractor](https://github.com/langroid/langroid/releases/tag/0.1.209)
    - `DocChatAgent` [context-window fixes](https://github.com/langroid/langroid/releases/tag/0.1.208)
    - Anthropic/Claude3 support via Litellm
    - `URLLoader`: detect file time from header when URL doesn't end with a 
      recognizable suffix like `.pdf`, `.docx`, etc.
    - Misc lancedb integration fixes
    - Auto-select embedding config based on whether `sentence_transformer` module is available.
    - Slim down dependencies, make some heavy ones optional, e.g. `unstructured`, 
      `haystack`, `chromadb`, `mkdocs`, `huggingface-hub`, `sentence-transformers`.
    - Easier top-level imports from `import langroid as lr`
    - Improve JSON detection, esp from weak LLMs
- **Feb 2024:** 
  - **0.1.193:** Support local LLMs using Ollama's new OpenAI-Compatible server: 
     simply specify `chat_model="ollama/mistral"`. See [release notes](https://github.com/langroid/langroid/releases/tag/0.1.193).
  - **0.1.183:** Added Chainlit support via [callbacks](https://github.com/langroid/langroid/blob/main/langroid/agent/callbacks/chainlit.py). 
   See [examples](https://github.com/langroid/langroid/tree/main/examples/chainlit).
- **Jan 2024:**
  - **0.1.175** 
    - [Neo4jChatAgent](https://github.com/langroid/langroid/tree/main/langroid/agent/special/neo4j) to chat with a neo4j knowledge-graph.
      (Thanks to [Mohannad](https://github.com/Mohannadcse)!). The agent uses tools to query the Neo4j schema and translate user queries to Cypher queries,
      and the tool handler executes these queries, returning them to the LLM to compose
      a natural language response (analogous to how `SQLChatAgent` works).
      See example [script](https://github.com/langroid/langroid/tree/main/examples/kg-chat) using this Agent to answer questions about Python pkg dependencies.
    - Support for `.doc` file parsing (in addition to `.docx`)
    - Specify optional [`formatter` param](https://github.com/langroid/langroid/releases/tag/0.1.171) 
      in `OpenAIGPTConfig` to ensure accurate chat formatting for local LLMs. 
  - **[0.1.157](https://github.com/langroid/langroid/releases/tag/0.1.157):** `DocChatAgentConfig` 
     has a new param: `add_fields_to_content`, to specify additional document fields to insert into 
     the main `content` field, to help improve retrieval.
  - **[0.1.156](https://github.com/langroid/langroid/releases/tag/0.1.156):** New Task control signals
     PASS_TO, SEND_TO; VectorStore: Compute Pandas expression on documents; LanceRAGTaskCreator creates 3-agent RAG system with Query Planner, Critic and RAG Agent.
- **Dec 2023:**
  - **0.1.154:** (For details see release notes of [0.1.149](https://github.com/langroid/langroid/releases/tag/0.1.149)
      and [0.1.154](https://github.com/langroid/langroid/releases/tag/0.1.154)). 
    - `DocChatAgent`: Ingest Pandas dataframes and filtering.
    - `LanceDocChatAgent` leverages `LanceDB` vector-db for efficient vector search
     and full-text search and filtering.
    - Improved task and multi-agent control mechanisms
    - `LanceRAGTaskCreator` to create a 2-agent system consisting of a `LanceFilterAgent` that
      decides a filter and rephrase query to send to a RAG agent.
  - **[0.1.141](https://github.com/langroid/langroid/releases/tag/0.1.141):**
    API Simplifications to reduce boilerplate:
    auto-select an available OpenAI model (preferring gpt-4o), simplifies defaults.
    Simpler `Task` initialization with default `ChatAgent`.
- **Nov 2023:**
  - **[0.1.126](https://github.com/langroid/langroid/releases/tag/0.1.126):**
     OpenAIAssistant agent: Caching Support. 
  - **0.1.117:** Support for OpenAI Assistant API tools: Function-calling, 
    Code-intepreter, and Retriever (RAG), file uploads. These work seamlessly 
    with Langroid's task-orchestration.
    Until docs are ready, it's best to see these usage examples:
    
    - **Tests:**
      - [test_openai_assistant.py](https://github.com/langroid/langroid/blob/main/tests/main/test_openai_assistant.py)
      - [test_openai_assistant_async.py](https://github.com/langroid/langroid/blob/main/tests/main/test_openai_assistant_async.py)

    - **Example scripts:**
      - [The most basic chat app](https://github.com/langroid/langroid/blob/main/examples/basic/oai-asst-chat.py)
      - [Chat with code interpreter](https://github.com/langroid/langroid/blob/main/examples/basic/oai-code-chat.py)
      - [Chat with retrieval (RAG)](https://github.com/langroid/langroid/blob/main/examples/docqa/oai-retrieval-assistant.py)
      - [2-agent RAG chat](https://github.com/langroid/langroid/blob/main/examples/docqa/oai-retrieval-2.py)
  - **0.1.112:** [`OpenAIAssistant`](https://github.com/langroid/langroid/blob/main/langroid/agent/openai_assistant.py) is a subclass of `ChatAgent` that 
    leverages the new OpenAI Assistant API. It can be used as a drop-in 
    replacement for `ChatAgent`, and relies on the Assistant API to
    maintain conversation state, and leverages persistent threads and 
    assistants to reconnect to them if needed. Examples: 
    [`test_openai_assistant.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_openai_assistant.py),
    [`test_openai_assistant_async.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_openai_assistant_async.py)
  - **0.1.111:** Support latest OpenAI model: `GPT4_TURBO`
(see [test_llm.py](tests/main/test_llm.py) for example usage)
  - **0.1.110:** Upgrade from OpenAI v0.x to v1.1.1 (in preparation for 
    Assistants API and more); (`litellm` temporarily disabled due to OpenAI 
    version conflict).
- **Oct 2023:**
  - **0.1.107:** `DocChatAgent` re-rankers: `rank_with_diversity`, `rank_to_periphery` (lost in middle).
  - **0.1.102:** `DocChatAgentConfig.n_neighbor_chunks > 0` allows returning context chunks around match.
  - **0.1.101:** `DocChatAgent` uses `RelevanceExtractorAgent` to have 
    the LLM extract relevant portions of a chunk using 
    sentence-numbering, resulting in huge speed up and cost reduction 
    compared to the naive "sentence-parroting" approach (writing out full 
    sentences out relevant whole sentences) which `LangChain` uses in their 
    `LLMChainExtractor`.
  - **0.1.100:** API update: all of Langroid is accessible with a single import, i.e. `import langroid as lr`. See the [documentation]("https://langroid.github.io/langroid/") for usage.
  - **0.1.99:** Convenience batch functions to run tasks, agent methods on a list of inputs concurrently in async mode. See examples in [test_batch.py](https://github.com/langroid/langroid/blob/main/tests/main/test_batch.py).
  - **0.1.95:** Added support for [Momento Serverless Vector Index](https://docs.momentohq.com/vector-index)
  - **0.1.94:** Added support for [LanceDB](https://lancedb.github.io/lancedb/) vector-store -- allows vector, Full-text, SQL search.
  - **0.1.84:** Added [LiteLLM](https://docs.litellm.ai/docs/providers), so now Langroid can be used with over 100 LLM providers (remote or local)! 
     See guide [here](https://langroid.github.io/langroid/tutorials/non-openai-llms/).
- **Sep 2023:**
  - **0.1.78:** Async versions of several Task, Agent and LLM methods; 
      Nested Pydantic classes are now supported for LLM Function-calling, Tools, Structured Output.    
  - **0.1.76:** DocChatAgent: support for loading `docx` files (preliminary).
  - **0.1.72:** Many improvements to DocChatAgent: better embedding model, 
          hybrid search to improve retrieval, better pdf parsing, re-ranking retrieved results with cross-encoders. 
  - **Use with local LLama Models:** see tutorial [here](https://langroid.github.io/langroid/blog/2023/09/14/using-langroid-with-local-llms/)
  - **Langroid Blog/Newsletter Launched!**: First post is [here](https://substack.com/notes/post/p-136704592) -- Please subscribe to stay updated. 
  - **0.1.56:** Support Azure OpenAI. 
  - **0.1.55:** Improved [`SQLChatAgent`](https://github.com/langroid/langroid/blob/main/langroid/agent/special/sql/sql_chat_agent.py) that efficiently retrieves relevant schema info when translating natural language to SQL.  
- **Aug 2023:**
  - **[Hierarchical computation](https://langroid.github.io/langroid/examples/agent-tree/)** example using Langroid agents and task orchestration.
  - **0.1.51:** Support for global state, see [test_global_state.py](tests/main/test_global_state.py).
  - **:whale: Langroid Docker image**, available, see instructions below.
  - [**RecipientTool**](langroid/agent/tools/recipient_tool.py) enables (+ enforces) LLM to 
specify an intended recipient when talking to 2 or more agents. 
See [this test](tests/main/test_recipient_tool.py) for example usage.
  - **Example:** [Answer questions](examples/docqa/chat-search.py) using Google Search + vecdb-retrieval from URL contents. 
  - **0.1.39:** [`GoogleSearchTool`](langroid/agent/tools/google_search_tool.py) to enable Agents (their LLM) to do Google searches via function-calling/tools.
    See [this chat example](examples/basic/chat-search.py) for how easy it is to add this tool to an agent.
  - **Colab notebook** to try the quick-start examples: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langroid/langroid/blob/main/examples/Langroid_quick_start.ipynb) 
  - **0.1.37:** Added [`SQLChatAgent`](langroid/agent/special/sql_chat_agent.py) -- thanks to our latest contributor [Rithwik Babu](https://github.com/rithwikbabu)!
  - Multi-agent Example: [Autocorrect chat](examples/basic/autocorrect.py)
- **July 2023:** 
  - **0.1.30:** Added [`TableChatAgent`](langroid/agent/special/table_chat_agent.py) to 
    [chat](examples/data-qa/table_chat.py) with tabular datasets (dataframes, files, URLs): LLM generates Pandas code,
    and code is executed using Langroid's tool/function-call mechanism. 
  - **Demo:** 3-agent system for Audience [Targeting](https://langroid.github.io/langroid/demos/targeting/audience-targeting/).
  - **0.1.27**: Added [support](langroid/cachedb/momento_cachedb.py) 
    for [Momento Serverless Cache](https://www.gomomento.com/) as an alternative to Redis.
  - **0.1.24**: [`DocChatAgent`](langroid/agent/special/doc_chat_agent.py) 
    now [accepts](langroid/parsing/document_parser.py) PDF files or URLs.

</details>

# :rocket: Demo
Suppose you want to extract structured information about the key terms 
of a commercial lease document. You can easily do this with Langroid using a two-agent system,
as we show in the [langroid-examples](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat_multi_extract.py) repo.
(See [this script](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat-multi-extract-local.py)
for a version with the same functionality using a local Mistral-7b model.)
The demo showcases just a few of the many features of Langroid, such as:
- Multi-agent collaboration: `LeaseExtractor` is in charge of the task, and its LLM (GPT4) generates questions 
to be answered by the `DocAgent`.
- Retrieval augmented question-answering, with **source-citation**: `DocAgent` LLM (GPT4) uses retrieval from a vector-store to 
answer the `LeaseExtractor`'s questions, cites the specific excerpt supporting the answer. 
- Function-calling (also known as tool/plugin): When it has all the information it 
needs, the `LeaseExtractor` LLM presents the information in a structured 
format using a Function-call. 

Here is what it looks like in action 
(a pausable mp4 video is [here](https://vimeo.com/871429249)).

![Demo](docs/assets/demos/lease-extractor-demo.gif)


# :zap: Highlights
(For a more up-to-date list see the 
[Updates/Releases](https://github.com/langroid/langroid?tab=readme-ov-file#fire-updatesreleases) 
section above)
- **Agents as first-class citizens:** The [Agent](https://langroid.github.io/langroid/reference/agent/base/#langroid.agent.base.Agent) class encapsulates LLM conversation state,
  and optionally a vector-store and tools. Agents are a core abstraction in Langroid;
  Agents act as _message transformers_, and by default provide 3 _responder_ methods, one corresponding to each entity: LLM, Agent, User.
- **Tasks:** A [Task](https://langroid.github.io/langroid/reference/agent/task/) class wraps an Agent, and gives the agent instructions (or roles, or goals), 
  manages iteration over an Agent's responder methods, 
  and orchestrates multi-agent interactions via hierarchical, recursive
  task-delegation. The `Task.run()` method has the same 
  type-signature as an Agent's responder's methods, and this is key to how 
  a task of an agent can delegate to other sub-tasks: from the point of view of a Task,
  sub-tasks are simply additional responders, to be used in a round-robin fashion 
  after the agent's own responders.
- **Modularity, Reusability, Loose coupling:** The `Agent` and `Task` abstractions allow users to design
  Agents with specific skills, wrap them in Tasks, and combine tasks in a flexible way.
- **LLM Support**: Langroid supports OpenAI LLMs as well as LLMs from hundreds of 
providers ([local/open](https://langroid.github.io/langroid/tutorials/local-llm-setup/) or [remote/commercial](https://langroid.github.io/langroid/tutorials/non-openai-llms/)) via proxy libraries and local model servers
such as [ollama](https://github.com/ollama), [oobabooga](https://github.com/oobabooga/text-generation-webui), 
  [LiteLLM](https://docs.litellm.ai/docs/providers) that in effect mimic the OpenAI API. See the [supported LLMs](https://langroid.github.io/langroid/tutorials/supported-models/). 
- **Caching of LLM responses:** Langroid supports [Redis](https://redis.com/try-free/) to cache LLM responses.
- **Vector-stores**: [Qdrant](https://qdrant.tech/), [Chroma](https://www.trychroma.com/), LanceDB, Pinecone, PostgresDB (PGVector), Weaviate are currently supported.
  Vector stores allow for Retrieval-Augmented-Generation (RAG).
- **Grounding and source-citation:** Access to external documents via vector-stores 
   allows for grounding and source-citation.
- **Observability, Logging, Lineage:** Langroid generates detailed logs of multi-agent interactions and
  maintains provenance/lineage of messages, so that you can trace back
  the origin of a message.
- **[Tools/Plugins/Function-calling](https://langroid.github.io/langroid/quick-start/chat-agent-tool/)**:
  Langroid supports OpenAI's [function calling](https://platform.openai.com/docs/guides/gpt/function-calling), as
  well as an equivalent `ToolMessage` mechanism which works with
  any LLM, not just OpenAI's.
  Function calling and tools have the same developer-facing interface, implemented
  using [Pydantic](https://docs.pydantic.dev/latest/),
  which makes it very easy to define tools/functions and enable agents
  to use them. Benefits of using Pydantic are that you never have to write
  complex JSON specs for function calling, and when the LLM
  hallucinates malformed JSON, the Pydantic error message is sent back to
  the LLM so it can fix it.

--- 

# :gear: Installation and Setup

### Install `langroid`
Langroid requires Python 3.11+. We recommend using a virtual environment.
Use `pip` to install a bare-bones slim version of `langroid` (from PyPi) to your virtual 
environment:
```bash
pip install langroid
```
The core Langroid package lets you use OpenAI Embeddings models via their API. 
If you instead want to use the `sentence-transformers` embedding models from HuggingFace, 
install Langroid like this: 
```bash
pip install "langroid[hf-embeddings]"
```
For many practical scenarios, you may need additional optional dependencies:
- To use various document-parsers, install langroid with the `doc-chat` extra:
    ```bash
    pip install "langroid[doc-chat]"
    ```
- For "chat with databases", use the `db` extra:
    ```bash
    pip install "langroid[db]"
    ```
- You can specify multiple extras by separating them with commas, e.g.:
    ```bash
    pip install "langroid[doc-chat,db]"
    ```
- To simply install _all_ optional dependencies, use the `all` extra (but note that this will result in longer load/startup times and a larger install size):
    ```bash
    pip install "langroid[all]"
    ```
<details>
<summary><b>Optional Installs for using SQL Chat with a PostgreSQL DB </b></summary>

If you are using `SQLChatAgent` 
(e.g. the script [`examples/data-qa/sql-chat/sql_chat.py`](examples/data-qa/sql-chat/sql_chat.py)),
with a postgres db, you will need to:

- Install PostgreSQL dev libraries for your platform, e.g.
  - `sudo apt-get install libpq-dev` on Ubuntu,
  - `brew install postgresql` on Mac, etc.
- Install langroid with the postgres extra, e.g. `pip install langroid[postgres]`
  or `poetry add "langroid[postgres]"` or `poetry install -E postgres`,
  (or the corresponding `uv` versions, e.g. `uv add "langroid[postgres]"`
  or `uv pip install langroid[postgres]`).
  If this gives you an error, try `pip install psycopg2-binary` in your virtualenv.
</details>

:memo: If you get strange errors involving `mysqlclient`, try doing `pip uninstall mysqlclient` followed by `pip install mysqlclient`.

### Set up environment variables (API keys, etc)

To get started, all you need is an OpenAI API Key.
If you don't have one, see [this OpenAI Page](https://platform.openai.com/docs/quickstart).
(Note that while this is the simplest way to get started, Langroid works with practically any LLM, not just those from OpenAI. 
See the guides to using [Open/Local LLMs](https://langroid.github.io/langroid/tutorials/local-llm-setup/), 
and other [non-OpenAI](https://langroid.github.io/langroid/tutorials/non-openai-llms/) proprietary LLMs.) 

In the root of the repo, copy the `.env-template` file to a new file `.env`: 
```bash
cp .env-template .env
```
Then insert your OpenAI API Key. 
Your `.env` file should look like this (the organization is optional 
but may be required in some scenarios).
```bash
OPENAI_API_KEY=your-key-here-without-quotes
OPENAI_ORGANIZATION=optionally-your-organization-id
````

Alternatively, you can set this as an environment variable in your shell
(you will need to do this every time you open a new shell):
```bash
export OPENAI_API_KEY=your-key-here-without-quotes
```


<details>
<summary><b>Optional Setup Instructions (click to expand) </b></summary>

All of the following environment variable settings are optional, and some are only needed 
to use specific features (as noted below).

- **Qdrant** Vector Store API Key, URL. This is only required if you want to use Qdrant cloud.
  Alternatively [Chroma](https://docs.trychroma.com/) or [LanceDB](https://lancedb.com/) are also currently supported. 
  We use the local-storage version of Chroma, so there is no need for an API key.
- **Redis** Password, host, port: This is optional, and only needed to cache LLM API responses
  using Redis Cloud. Redis [offers](https://redis.com/try-free/) a free 30MB Redis account
  which is more than sufficient to try out Langroid and even beyond.
  If you don't set up these, Langroid will use a pure-python 
  Redis in-memory cache via the [Fakeredis](https://fakeredis.readthedocs.io/en/latest/) library.
- **Momento** Serverless Caching of LLM API responses (as an alternative to Redis). 
   To use Momento instead of Redis:
  - enter your Momento Token in the `.env` file, as the value of `MOMENTO_AUTH_TOKEN` (see example file below),
  - in the `.env` file set `CACHE_TYPE=momento` (instead of `CACHE_TYPE=redis` which is the default).
- **GitHub** Personal Access Token (required for apps that need to analyze git
  repos; token-based API calls are less rate-limited). See this
  [GitHub page](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens).
- **Google Custom Search API Credentials:** Only needed to enable an Agent to use the `GoogleSearchTool`.
  To use Google Search as an LLM Tool/Plugin/function-call, 
  you'll need to set up 
  [a Google API key](https://developers.google.com/custom-search/v1/introduction#identify_your_application_to_google_with_api_key),
  then [setup a Google Custom Search Engine (CSE) and get the CSE ID](https://developers.google.com/custom-search/docs/tutorial/creatingcse).
  (Documentation for these can be challenging, we suggest asking GPT4 for a step-by-step guide.)
  After obtaining these credentials, store them as values of 
  `GOOGLE_API_KEY` and `GOOGLE_CSE_ID` in your `.env` file. 
  Full documentation on using this (and other such "stateless" tools) is coming soon, but 
  in the meantime take a peek at this [chat example](examples/basic/chat-search.py), which 
  shows how you can easily equip an Agent with a `GoogleSearchtool`.
  


If you add all of these optional variables, your `.env` file should look like this:
```bash
OPENAI_API_KEY=your-key-here-without-quotes
GITHUB_ACCESS_TOKEN=your-personal-access-token-no-quotes
CACHE_TYPE=redis # or momento
REDIS_PASSWORD=your-redis-password-no-quotes
REDIS_HOST=your-redis-hostname-no-quotes
REDIS_PORT=your-redis-port-no-quotes
MOMENTO_AUTH_TOKEN=your-momento-token-no-quotes # instead of REDIS* variables
QDRANT_API_KEY=your-key
QDRANT_API_URL=https://your.url.here:6333 # note port number must be included
GOOGLE_API_KEY=your-key
GOOGLE_CSE_ID=your-cse-id
```
</details>

<details>
<summary><b>Optional setup instructions for Microsoft Azure OpenAI(click to expand)</b></summary> 

When using Azure OpenAI, additional environment variables are required in the 
`.env` file.
This page [Microsoft Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-python#environment-variables)
provides more information, and you can set each environment variable as follows:

- `AZURE_OPENAI_API_KEY`, from the value of `API_KEY`
- `AZURE_OPENAI_API_BASE` from the value of `ENDPOINT`, typically looks like `https://your.domain.azure.com`.
- For `AZURE_OPENAI_API_VERSION`, you can use the default value in `.env-template`, and latest version can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new#azure-openai-chat-completion-general-availability-ga)
- `AZURE_OPENAI_DEPLOYMENT_NAME` is the name of the deployed model, which is defined by the user during the model setup 
- `AZURE_OPENAI_MODEL_NAME` Azure OpenAI allows specific model names when you select the model for your deployment. You need to put precisly the exact model name that was selected. For example, GPT-4 (should be `gpt-4-32k` or `gpt-4`).
- `AZURE_OPENAI_MODEL_VERSION` is required if `AZURE_OPENAI_MODEL_NAME = gpt=4`, which will assist Langroid to determine the cost of the model  
</details>

---

# :whale: Docker Instructions

We provide a containerized version of the [`langroid-examples`](https://github.com/langroid/langroid-examples) 
repository via this [Docker Image](https://hub.docker.com/r/langroid/langroid).
All you need to do is set up environment variables in the `.env` file.
Please follow these steps to setup the container:

```bash
# get the .env file template from `langroid` repo
wget -O .env https://raw.githubusercontent.com/langroid/langroid/main/.env-template

# Edit the .env file with your favorite editor (here nano), and remove any un-used settings. E.g. there are "dummy" values like "your-redis-port" etc -- if you are not using them, you MUST remove them.
nano .env

# launch the container (the appropriate image for your architecture will be pulled automatically)
docker run -it --rm  -v ./.env:/langroid/.env langroid/langroid:latest

# Use this command to run any of the scripts in the `examples` directory
python examples/<Path/To/Example.py> 
``` 



# :tada: Usage Examples

These are quick teasers to give a glimpse of what you can do with Langroid
and how your code would look. 

:warning: The code snippets below are intended to give a flavor of the code
and they are **not** complete runnable examples! For that we encourage you to 
consult the [`langroid-examples`](https://github.com/langroid/langroid-examples) 
repository.

:information_source:
The various LLM prompts and instructions in Langroid
have been tested to work well with GPT-4 (and to some extent GPT-4o).
Switching to other LLMs (local/open and proprietary) is easy (see guides mentioned above),
and may suffice for some applications, but in general you may see inferior results
unless you adjust the prompts and/or the multi-agent setup.


:book: Also see the
[`Getting Started Guide`](https://langroid.github.io/langroid/quick-start/)
for a detailed tutorial.



Click to expand any of the code examples below.
All of these can be run in a Colab notebook:
[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langroid/langroid/blob/main/examples/Langroid_quick_start.ipynb)

<details>
<summary> <b> Direct interaction with LLM </b> </summary>

```python
import langroid.language_models as lm

mdl = lm.OpenAIGPT(
    lm.OpenAIGPTConfig(
        chat_model=lm.OpenAIChatModel.GPT4o, # or, e.g.  "ollama/qwen2.5"
    ),
)

messages = [
  lm.LLMMessage(content="You are a helpful assistant",  role=lm.Role.SYSTEM), 
  lm.LLMMessage(content="What is the capital of Ontario?",  role=lm.Role.USER),
]

response = mdl.chat(messages, max_tokens=200)
print(response.message)
```
See the guides to use
([local/open LLMs](https://langroid.github.io/langroid/tutorials/local-llm-setup/) or [remote/commercial LLMs](https://langroid.github.io/langroid/tutorials/non-openai-llms/)).
</details>

<details>
<summary> <b> Interaction with non-OpenAI LLM (local or remote) </b> </summary>
Local model: if model is served at `http://localhost:8000`:

```python
cfg = lm.OpenAIGPTConfig(
  chat_model="local/localhost:8000", 
  chat_context_length=4096
)
mdl = lm.OpenAIGPT(cfg)
# now interact with it as above, or create an Agent + Task as shown below.
```
</details>

<details>
<summary> <b> Define an agent, set up a task, and run it </b> </summary>

```python
import langroid as lr

agent = lr.ChatAgent()

# get response from agent's LLM, and put this in an interactive loop...
# answer = agent.llm_response("What is the capital of Ontario?")
  # ... OR instead, set up a task (which has a built-in loop) and run it
task = lr.Task(agent, name="Bot") 
task.run() # ... a loop seeking response from LLM or User at each turn
```
</details>

<details>
<summary><b> Three communicating agents </b></summary>

A toy numbers game, where when given a number `n`:
- `repeater_task`'s LLM simply returns `n`,
- `even_task`'s LLM returns `n/2` if `n` is even, else says "DO-NOT-KNOW"
- `odd_task`'s LLM returns `3*n+1` if `n` is odd, else says "DO-NOT-KNOW"

Each of these `Task`s automatically configures a default `ChatAgent`.

```python
import langroid as lr
from langroid.utils.constants import NO_ANSWER

repeater_task = lr.Task(
    name = "Repeater",
    system_message="""
    Your job is to repeat whatever number you receive.
    """,
    llm_delegate=True, # LLM takes charge of task
    single_round=False, 
)

even_task = lr.Task(
    name = "EvenHandler",
    system_message=f"""
    You will be given a number. 
    If it is even, divide by 2 and say the result, nothing else.
    If it is odd, say {NO_ANSWER}
    """,
    single_round=True,  # task done after 1 step() with valid response
)

odd_task = lr.Task(
    name = "OddHandler",
    system_message=f"""
    You will be given a number n. 
    If it is odd, return (n*3+1), say nothing else. 
    If it is even, say {NO_ANSWER}
    """,
    single_round=True,  # task done after 1 step() with valid response
)
```
Then add the `even_task` and `odd_task` as sub-tasks of `repeater_task`, 
and run the `repeater_task`, kicking it off with a number as input:
```python
repeater_task.add_sub_task([even_task, odd_task])
repeater_task.run("3")
```

</details>

<details>
<summary><b> Simple Tool/Function-calling example </b></summary>

Langroid leverages Pydantic to support OpenAI's
[Function-calling API](https://platform.openai.com/docs/guides/gpt/function-calling)
as well as its own native tools. The benefits are that you don't have to write
any JSON to specify the schema, and also if the LLM hallucinates a malformed
tool syntax, Langroid sends the Pydantic validation error (suitably sanitized) 
to the LLM so it can fix it!

Simple example: Say the agent has a secret list of numbers, 
and we want the LLM to find the smallest number in the list. 
We want to give the LLM a `probe` tool/function which takes a
single number `n` as argument. The tool handler method in the agent
returns how many numbers in its list are at most `n`.

First define the tool using Langroid's `ToolMessage` class:


```python
import langroid as lr

class ProbeTool(lr.agent.ToolMessage):
  request: str = "probe" # specifies which agent method handles this tool
  purpose: str = """
        To find how many numbers in my list are less than or equal to  
        the <number> you specify.
        """ # description used to instruct the LLM on when/how to use the tool
  number: int  # required argument to the tool
```

Then define a `SpyGameAgent` as a subclass of `ChatAgent`, 
with a method `probe` that handles this tool:

```python
class SpyGameAgent(lr.ChatAgent):
  def __init__(self, config: lr.ChatAgentConfig):
    super().__init__(config)
    self.numbers = [3, 4, 8, 11, 15, 25, 40, 80, 90]

  def probe(self, msg: ProbeTool) -> str:
    # return how many numbers in self.numbers are less or equal to msg.number
    return str(len([n for n in self.numbers if n <= msg.number]))
```

We then instantiate the agent and enable it to use and respond to the tool:

```python
spy_game_agent = SpyGameAgent(
    lr.ChatAgentConfig(
        name="Spy",
        vecdb=None,
        use_tools=False, #  don't use Langroid native tool
        use_functions_api=True, # use OpenAI function-call API
    )
)
spy_game_agent.enable_message(ProbeTool)
```

For a full working example see the
[chat-agent-tool.py](https://github.com/langroid/langroid-examples/blob/main/examples/quick-start/chat-agent-tool.py)
script in the `langroid-examples` repo.
</details>

<details>
<summary> <b>Tool/Function-calling to extract structured information from text </b> </summary>

Suppose you want an agent to extract 
the key terms of a lease, from a lease document, as a nested JSON structure.
First define the desired structure via Pydantic models:

```python
from pydantic import BaseModel
class LeasePeriod(BaseModel):
    start_date: str
    end_date: str


class LeaseFinancials(BaseModel):
    monthly_rent: str
    deposit: str

class Lease(BaseModel):
    period: LeasePeriod
    financials: LeaseFinancials
    address: str
```

Then define the `LeaseMessage` tool as a subclass of Langroid's `ToolMessage`.
Note the tool has a required argument `terms` of type `Lease`:

```python
import langroid as lr

class LeaseMessage(lr.agent.ToolMessage):
    request: str = "lease_info"
    purpose: str = """
        Collect information about a Commercial Lease.
        """
    terms: Lease
```

Then define a `LeaseExtractorAgent` with a method `lease_info` that handles this tool,
instantiate the agent, and enable it to use and respond to this tool:

```python
class LeaseExtractorAgent(lr.ChatAgent):
    def lease_info(self, message: LeaseMessage) -> str:
        print(
            f"""
        DONE! Successfully extracted Lease Info:
        {message.terms}
        """
        )
        return json.dumps(message.terms.dict())
    
lease_extractor_agent = LeaseExtractorAgent()
lease_extractor_agent.enable_message(LeaseMessage)
```

See the [`chat_multi_extract.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat_multi_extract.py)
script in the `langroid-examples` repo for a full working example.
</details>

<details>
<summary><b> Chat with documents (file paths, URLs, etc) </b></summary>

Langroid provides a specialized agent class `DocChatAgent` for this purpose.
It incorporates document sharding, embedding, storage in a vector-DB, 
and retrieval-augmented query-answer generation.
Using this class to chat with a collection of documents is easy.
First create a `DocChatAgentConfig` instance, with a 
`doc_paths` field that specifies the documents to chat with.

```python
import langroid as lr
from langroid.agent.special import DocChatAgentConfig, DocChatAgent

config = DocChatAgentConfig(
  doc_paths = [
    "https://en.wikipedia.org/wiki/Language_model",
    "https://en.wikipedia.org/wiki/N-gram_language_model",
    "/path/to/my/notes-on-language-models.txt",
  ],
  vecdb=lr.vector_store.QdrantDBConfig(),
)
```

Then instantiate the `DocChatAgent` (this ingests the docs into the vector-store):

```python
agent = DocChatAgent(config)
```
Then we can either ask the agent one-off questions,
```python
agent.llm_response("What is a language model?")
```
or wrap it in a `Task` and run an interactive loop with the user:
```python
task = lr.Task(agent)
task.run()
```

See full working scripts in the 
[`docqa`](https://github.com/langroid/langroid-examples/tree/main/examples/docqa)
folder of the `langroid-examples` repo.
</details>

<details>
<summary><b> :fire: Chat with tabular data (file paths, URLs, dataframes) </b></summary>

Using Langroid you can set up a `TableChatAgent` with a dataset (file path, URL or dataframe),
and query it. The Agent's LLM generates Pandas code to answer the query, 
via function-calling (or tool/plugin), and the Agent's function-handling method
executes the code and returns the answer.

Here is how you can do this:

```python
import langroid as lr
from langroid.agent.special import TableChatAgent, TableChatAgentConfig
```

Set up a `TableChatAgent` for a data file, URL or dataframe
(Ensure the data table has a header row; the delimiter/separator is auto-detected):
```python
dataset =  "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
# or dataset = "/path/to/my/data.csv"
# or dataset = pd.read_csv("/path/to/my/data.csv")
agent = TableChatAgent(
    config=TableChatAgentConfig(
        data=dataset,
    )
)
```
Set up a task, and ask one-off questions like this: 

```python
task = lr.Task(
  agent, 
  name = "DataAssistant",
  default_human_response="", # to avoid waiting for user input
)
result = task.run(
  "What is the average alcohol content of wines with a quality rating above 7?",
  turns=2 # return after user question, LLM fun-call/tool response, Agent code-exec result
) 
print(result.content)
```
Or alternatively, set up a task and run it in an interactive loop with the user:

```python
task = lr.Task(agent, name="DataAssistant")
task.run()
``` 

For a full working example see the 
[`table_chat.py`](https://github.com/langroid/langroid-examples/tree/main/examples/data-qa/table_chat.py)
script in the `langroid-examples` repo.


</details>

---

# :heart: Thank you to our [supporters](https://github.com/langroid/langroid/stargazers)

If you like this project, please give it a star ⭐ and 📢 spread the word in your network or social media:

[![Share on Twitter](https://img.shields.io/twitter/url?style=social&url=https://github.com/langroid/langroid)](https://twitter.com/intent/tweet?text=Langroid%20is%20a%20powerful,%20elegant%20new%20framework%20to%20easily%20build%20%23LLM%20applications.%20You%20set%20up%20LLM-powered%20Agents%20with%20vector-stores,%20assign%20tasks,%20and%20have%20them%20collaboratively%20solve%20problems%20via%20message-transformations.%20https://github.com/langroid/langroid)
[![Share on LinkedIn](https://img.shields.io/badge/Share%20on-LinkedIn-blue)](https://www.linkedin.com/shareArticle?mini=true&url=https://github.com/langroid/langroid&title=Langroid:%20A%20Powerful,%20Elegant%20Framework&summary=Langroid%20is%20a%20powerful,%20elegant%20new%20framework%20to%20easily%20build%20%23LLM%20applications.%20You%20set%20up%20LLM-powered%20Agents%20with%20vector-stores,%20assign%20tasks,%20and%20have%20them%20collaboratively%20solve%20problems%20via%20message-transformations.)
[![Share on Hacker News](https://img.shields.io/badge/-Share%20on%20Hacker%20News-orange)](https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fgithub.com%2Flangroid%2Flangroid&t=Harness%20LLMs%20with%20Multi-Agent%20Programming)
[![Share on Reddit](https://img.shields.io/badge/-Share%20on%20Reddit-blue)](https://www.reddit.com/submit?url=https%3A%2F%2Fgithub.com%2Flangroid%2Flangroid&title=Harness%20LLMs%20with%20Multi-Agent%20Programming)

Your support will help build Langroid's momentum and community.

# Langroid Co-Founders

- [Prasad Chalasani](https://www.linkedin.com/in/pchalasani/) (IIT BTech/CS, CMU PhD/ML; Independent ML Consultant)
- [Somesh Jha](https://www.linkedin.com/in/somesh-jha-80208015/) (IIT BTech/CS, CMU PhD/CS; Professor of CS, U Wisc at Madison)




>>>> SECURITY.md
# Security Policy

## Supported Versions

Security updates are supported on Langroid version >= 0.18.x


## Reporting a Vulnerability

If you discover a security vulnerability in this repository, **please report it privately**. Security issues should **not** be reported using GitHub Issues or any other public forum.

### How to Report Privately

To report a security vulnerability privately:

1. Go to the repository's **[Security Advisories](https://github.com/langroid/langroid/security/advisories)** section.
2. Click on **"Report a vulnerability"**.
3. Provide the necessary details about the vulnerability.

Your report will remain confidential, and we will respond as quickly as possible (usually within 48 hours) to evaluate the issue and work on a fix. We greatly appreciate your responsible disclosure.

Please **do not** report vulnerabilities through GitHub Issues, discussions, or other public channels as this could expose the issue to a wider audience before it is resolved.

### Security Fix Timeline

Once a security vulnerability is reported, we will work to:
- Acknowledge the report within 48 hours.
- Investigate and confirm the issue.
- Develop a patch or mitigation strategy.
- Publish the fix and disclose the advisory publicly after the resolution.



>>>> bump_version.sh
#!/bin/sh
cz bump --increment $1
git commit pyproject.toml -m "Bump version"
cz version -p | cut -d' ' -f2

>>>> chainlit.md
# Welcome to Langroid 👋

![Langroid](public/langroid-card.png)

---
When it is your turn to enter a message, you can do one of two things:
- write `c` to tell the agent to continue,
    - This is provided as a safeguard against infinite loops, or to prevent a large 
    amount of text to be sent to the LLM (which can be costly + slow). 
    If you simply want to continue with normal operation, just enter c.
- write a response, question or feedback to the agent, depending on context.

>>>> docs/FAQ.md
# Frequently Asked Questions

## Can I view the reasoning (thinking) text when using a Reasoning LLM like R1 or o1?

Yes, see this note on [reasoning-content](https://langroid.github.io/langroid/notes/reasoning-content/).


## Does Langroid work with non-OpenAI LLMs?

Yes! Langroid works with practically any LLM, local or remote, closed or open.

See these two guides:

- [Using Langroid with local/open LLMs](https://langroid.github.io/langroid/tutorials/local-llm-setup/)
- [Using Langroid with non-OpenAI proprietary LLMs](https://langroid.github.io/langroid/tutorials/non-openai-llms/)

## Where can I find out about Langroid's architecture?

There are a few documents that can help:

- A work-in-progress [architecture description](https://langroid.github.io/langroid/blog/2024/08/15/overview-of-langroids-multi-agent-architecture-prelim/)
  on the Langroid blog.
- The Langroid [Getting Started](https://langroid.github.io/langroid/quick-start/) guide walks you 
  step-by-step through Langroid's features and architecture.
- An article by LanceDB on [Multi-Agent Programming with Langroid](https://lancedb.substack.com/p/langoid-multi-agent-programming-framework)

## How can I limit the number of output tokens generated by the LLM?

You can set the `max_output_tokens` parameter in the `LLMConfig` class,
or more commonly, the `OpenAIGPTConfig` class, which is a subclass of `LLMConfig`,
for example:

```python
import langroid as lr
import langroid.language_models as lm

llm_config = lm.OpenAIGPTConfig(
    chat_model="openai/gpt-3.5-turbo",
    max_output_tokens=100, # limit output to 100 tokens
)
agent_config = lr.ChatAgentConfig(
    llm=llm_config,
    # ... other configs
)
agent = lr.ChatAgent(agent_config)
```

Then every time the agent's `llm_response` method is called, the LLM's output 
will be limited to this number of tokens.

If you omit the `max_output_tokens`, it defaults to 8192. If you wish **not** to 
limit the output tokens, you can set `max_output_tokens=None`, in which case 
Langroid uses the model-specific maximum output tokens from the 
[`langroid/language_models/model_info.py`](https://github.com/langroid/langroid/blob/main/langroid/language_models/model_info.py) file
(specifically the `model_max_output_tokens` property of `LLMConfig`).
Note however that this model-specific may be quite large, so you would generally 
want to either omit setting `max_output_tokens` (which defaults to 8192), or set it
another desired value.


## How langroid handles long chat histories

You may encounter an error like this:

```
Error: Tried to shorten prompt history but ... longer than context length
```

This might happen when your chat history bumps against various limits.
Here is how Langroid handles long chat histories. Ultimately the LLM API is invoked with two key inputs:
the message history $h$, and the desired output length $n$ (defaults to the `max_output_tokens` in the 
`ChatAgentConfig`). These inputs are determined as follows (see the `ChatAgent._prep_llm_messages` method):

- let $H$ be the current message history, and $M$ be the value of `ChatAgentConfig.max_output_tokens`, and $C$ be 
  the context-length of the LLM.
- If $\text{tokens}(H) + M \leq C$, then langroid uses $h = H$ and $n = M$, since there is enough room to fit both the 
  actual chat history as well as the desired max output length.
- If $\text{tokens}(H) + M > C$, this means the context length is too small to accommodate the message history $H$ 
  and 
  the desired output length $M$. Then langroid tries to use a _shortened_ output length $n' = C - \text{tokens}(H)$, 
  i.e. the output is effectively _truncated_ to fit within the context length. 
    - If $n'$ is at least equal to `min_output_tokens` $m$ (default 10), langroid proceeds with $h = H$ and $n=n'$.
    - otherwise, this means that the message history $H$ is so long that the remaining space in the LLM's 
      context-length $C$ is unacceptably small (i.e. smaller than the minimum output length $m$). In this case,
      Langroid tries to shorten the message history by dropping early messages, and updating the message history $h$ as 
      long as $C - \text{tokens}(h) <  m$, until there are no more messages to drop (it will not drop the system 
      message or the last message, which is a user message), and throws the error mentioned above. 

If you are getting this error, you will want to check whether:

- you have set the `chat_context_length` too small, if you are setting it manually
- you have set the `max_output_tokens` too large
- you have set the `min_output_tokens` too large

If these look fine, then the next thing to look at is whether you are accumulating too much context into the agent 
history, for example retrieved passages (which can be very long) in a RAG scenario. One common case is when a query 
$Q$ is being answered using RAG, the retrieved passages $P$ are added to $Q$ to create a (potentially very long) prompt 
like 
> based on the passages P, answer query Q

Once the LLM returns an answer (if appropropriate for your context), you should avoid retaining the passages $P$ in the 
agent history, i.e. the last user message should be simply $Q$, rather than the prompt above. This functionality is exactly what you get when you 
use `ChatAgent._llm_response_temp_context`, which is used by default in the `DocChatAgent`. 

Another way to keep chat history tokens from growing too much is to use the `llm_response_forget` method, which 
erases both the query and response, if that makes sense in your scenario.

## How can I handle large results from Tools?

As of version 0.22.0, Langroid allows you to control the size of tool results
by setting [optional parameters](https://langroid.github.io/langroid/notes/large-tool-results/) 
in a `ToolMessage` definition.

## Can I handle a tool without running a task?

Yes, if you've enabled an agent to both _use_ (i.e. generate) and _handle_ a tool. 
See the `test_tool_no_task` for an example of this. The `NabroskiTool` is enabled
for the agent, and to get the agent's LLM to generate the tool, you first do 
something like:
```python
response = agent.llm_response("What is Nabroski of 1 and 2?")
```
Now the `response` is a `ChatDocument` that will contain the JSON for the `NabroskiTool`.
To _handle_ the tool, you will need to call the agent's `agent_response` method:

```python
result = agent.agent_response(response)
```

When you wrap the agent in a task object, and do `task.run()` the above two steps are done for you,
since Langroid operates via a loop mechanism, see docs 
[here](https://langroid.github.io/langroid/quick-start/multi-agent-task-delegation/#task-collaboration-via-sub-tasks).
The *advantage* of using `task.run()` instead of doing this yourself, is that this method
ensures that tool generation errors are sent back to the LLM so it retries the generation.

## OpenAI Tools and Function-calling support

Langroid supports OpenAI tool-calls API as well as OpenAI function-calls API.
Read more [here](https://github.com/langroid/langroid/releases/tag/0.7.0).

Langroid has always had its own native tool-calling support as well, 
which works with **any** LLM -- you can define a subclass of `ToolMessage` (pydantic based) 
and it is transpiled into system prompt instructions for the tool. 
In practice, we don't see much difference between using this vs OpenAI fn-calling. 
Example [here](https://github.com/langroid/langroid/blob/main/examples/basic/fn-call-local-simple.py).
Or search for `ToolMessage` in any of the `tests/` or `examples/` folders.

## Some example scripts appear to return to user input immediately without handling a tool.

This is because the `task` has been set up with `interactive=True` 
(which is the default). With this setting, the task loop waits for user input after
either the `llm_response` or `agent_response` (typically a tool-handling response) 
returns a valid response. If you want to progress through the task, you can simply 
hit return, unless the prompt indicates that the user needs to enter a response.

Alternatively, the `task` can be set up with `interactive=False` -- with this setting,
the task loop will _only_ wait for user input when an entity response (`llm_response` 
or `agent_response`) _explicitly_ addresses the user. Explicit user addressing can
be done using either:

- an orchestration tool, e.g. `SendTool` (see details in
the release notes for [0.9.0](https://github.com/langroid/langroid/releases/tag/0.9.0)), an example script is the [multi-agent-triage.py](https://github.com/langroid/langroid/blob/main/examples/basic/multi-agent-triage.py), or 
- a special addressing prefix, see the example script [1-agent-3-tools-address-user.py](https://github.com/langroid/langroid/blob/main/examples/basic/1-agent-3-tools-address-user.py)


## Can I specify top_k in OpenAIGPTConfig (for LLM API calls)?

No; Langroid currently only supports parameters accepted by OpenAI's API, and `top_k` is _not_ one of them. See:

- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat/create)
- [Discussion on top_k, top_p, temperature](https://community.openai.com/t/temperature-top-p-and-top-k-for-chatbot-responses/295542/5)
- [Langroid example](https://github.com/langroid/langroid/blob/main/examples/basic/fn-call-local-numerical.py) showing how you can set other OpenAI API parameters, using the `OpenAICallParams` object.


## Can I persist agent state across multiple runs?

For example, you may want to stop the current python script, and 
run it again later, resuming your previous conversation.
Currently there is no built-in Langroid mechanism for this, but you can 
achieve a basic type of persistence by saving the agent's `message_history`:

-  if you used `Task.run()` in your script, make sure the task is 
set up with `restart=False` -- this prevents the agent state from being reset when 
the task is run again.
- using python's pickle module, you can save the `agent.message_history` to a file,
and load it (if it exists) at the start of your script.

See the example script [`chat-persist.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat-persist.py)

For more complex persistence, you can take advantage of the `GlobalState`,
where you can store message histories of multiple agents indexed by their name.
Simple examples of `GlobalState` are in the [`chat-tree.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat-tree.py) example, 
and the [`test_global_state.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_global_state.py) test.

## Is it possible to share state between agents/tasks?

The above-mentioned `GlobalState` mechanism can be used to share state between 
agents/tasks. See the links mentioned in the previous answer.

## How can I suppress LLM output?

You can use the `quiet_mode` context manager for this, see 
[here](https://langroid.github.io/langroid/notes/quiet-mode/)

## How can I deal with LLMs (especially weak ones) generating bad JSON in tools?

Langroid already attempts to repair bad JSON (e.g. unescaped newlines, missing quotes, etc)  
using the [json-repair](https://github.com/mangiucugna/json_repair) library and other
custom methods, before attempting to parse it into a `ToolMessage` object.
However this type of repair may not be able to handle all edge cases of bad JSON 
from weak LLMs. There are two existing ways to deal with this, and one coming soon:

- If you are defining your own `ToolMessage` subclass, considering deriving it instead
  from `XMLToolMessage` instead, see the [XML-based Tools](https://langroid.github.io/langroid/notes/xml-tools/)
- If you are using an existing Langroid `ToolMessage`, e.g. `SendTool`, you can 
  define your own subclass of `SendTool`, say `XMLSendTool`,
  inheriting from both `SendTool` and `XMLToolMessage`; see this 
  [example](https://github.com/langroid/langroid/blob/main/examples/basic/xml_tool.py)
- Coming soon: strict decoding to leverage the Structured JSON outputs supported by OpenAI
  and open LLM providers such as `llama.cpp` and `vllm`.

The first two methods instruct the LLM to generate XML instead of JSON,
and any field that is designated with a `verbatim=True` will be enclosed 
within an XML `CDATA` tag, which does *not* require any escaping, and can
be far more reliable for tool-use than JSON, especially with weak LLMs.

## How can I handle an LLM "forgetting" to generate a `ToolMessage`? 

Sometimes the LLM (especially a weak one) forgets to generate a 
[`ToolMessage`][langroid.agent.tool_message.ToolMessage]
(either via OpenAI's tools/functions API, or via Langroid's JSON/XML Tool mechanism),
despite being instructed to do so. There are a few remedies Langroid offers for this:

**Improve the instructions in the `ToolMessage` definition:**

- Improve instructions in the `purpose` field of the `ToolMessage`.
- Add an `instructions` class-method to the `ToolMessage`, as in the
  [`chat-search.py`](https://github.com/langroid/langroid/blob/main/examples/docqa/chat-search.py) script:

```python
@classmethod
def instructions(cls) -> str:
    return """
        IMPORTANT: You must include an ACTUAL query in the `query` field,
        """
```
  These instructions are meant to be general instructions on how to use the tool
  (e.g. how to set the field values), not to specifically about the formatting.

- Add a `format_instructions` class-method, e.g. like the one in the 
  [`chat-multi-extract-3.py`](https://github.com/langroid/langroid/blob/main/examples/docqa/chat-multi-extract-3.py) 
  example script.

```python
@classmethod
def format_instructions(cls, tool: bool = True) -> str:
    instr = super().format_instructions(tool)
    instr += """
    ------------------------------
    ASK ME QUESTIONS ONE BY ONE, to FILL IN THE FIELDS 
    of the `lease_info` function/tool.
    First ask me for the start date of the lease.
    DO NOT ASK ANYTHING ELSE UNTIL YOU RECEIVE MY ANSWER.
    """
    return instr
```

**Override the `handle_message_fallback` method in the agent:**

This method is called when the Agent's `agent_response` method receives a non-tool
message as input. The default behavior of this method is to return None, but it
is very useful to override the method to handle cases where the LLM has forgotten
to use a tool. You can define this method to return a "nudge" to the LLM
telling it that it forgot to do a tool-call, e.g. see how it's done in the 
example script [`chat-multi-extract-local.py`](https://github.com/langroid/langroid/blob/main/examples/docqa/chat-multi-extract-local.py):

```python
class LeasePresenterAgent(ChatAgent):
    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        """Handle scenario where Agent failed to present the Lease JSON"""
        if isinstance(msg, ChatDocument) and msg.metadata.sender == Entity.LLM:
            return """
            You either forgot to present the information in the JSON format
            required in `lease_info` JSON specification,
            or you may have used the wrong name of the tool or fields.
            Try again.
            """
        return None
```

Note that despite doing all of these, the LLM may still fail to generate a `ToolMessage`.
In such cases, you may want to consider using a better LLM, or an up-coming Langroid
feature that leverages **strict decoding** abilities of specific LLM providers
(e.g. OpenAI, llama.cpp, vllm) that are able to use grammar-constrained decoding
to force the output to conform to the specified structure.

Langroid also provides a simpler mechanism to specify the action to take
when an LLM does not generate a tool, via the `ChatAgentConfig.handle_llm_no_tool` 
config parameter, see the 
[docs](https://langroid.github.io/langroid/notes/handle-llm-no-tool/).

## Can I use Langroid to converse with a Knowledge Graph (KG)?

Yes, you can use Langroid to "chat with" either a Neo4j or ArangoDB KG, 
see docs [here](https://langroid.github.io/langroid/notes/knowledge-graphs/)

## How can I improve `DocChatAgent` (RAG) latency?

The behavior of `DocChatAgent` can be controlled by a number of settings in 
the `DocChatAgentConfig` class.
The top-level query-answering method in `DocChatAgent` is `llm_response`, which use the 
`answer_from_docs` method. At a high level, the response to an input message involves
the following steps:

- **Query to StandAlone:** LLM rephrases the query as a stand-alone query. 
   This can incur some latency. You can 
    turn it off by setting `assistant_mode=True` in the `DocChatAgentConfig`.
- **Retrieval:** The most relevant passages (chunks) are retrieved using a collection of semantic/lexical 
      similarity searches and ranking methods. There are various knobs in `DocChatAgentConfig` to control
      this retrieval.
- **Relevance Extraction:** LLM is used to retrieve verbatim relevant portions from
  the retrieved chunks. This is typically the biggest latency step. You can turn it off
  by setting the `relevance_extractor_config` to None in `DocChatAgentConfig`.
- **Answer Generation:** LLM generates answer based on retrieved passages.


See the [`doc-aware-chat.py`](https://github.com/langroid/langroid/blob/main/examples/docqa/doc-aware-chat.py)
example script, which illustrates some of these settings.

In some scenarios you want to *only* use the **retrieval** step of a `DocChatAgent`.
For this you can use the [`RetrievalTool`][langroid.agent.tools.retrieval_tool.RetrievalTool].
See the `test_retrieval_tool` in 
[`test_doc_chat_agent.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_doc_chat_agent.py).
to learn how to use it. The above example script uses `RetrievalTool` as well.

## Is there support to run multiple tasks concurrently?

Yes, see the `run_batch_tasks` and related functions in 
[batch.py](https://github.com/langroid/langroid/blob/main/langroid/agent/batch.py).

See also:

- tests: [test_batch.py](https://github.com/langroid/langroid/blob/main/tests/main/test_batch.py),
   [test_relevance_extractor.py](https://github.com/langroid/langroid/blob/main/tests/main/test_relevance_extractor.py),
- example: [multi-agent-round-table.py](https://github.com/langroid/langroid/blob/main/examples/basic/multi-agent-round-table.py)

Another example is within 
[`DocChatAgent`](https://github.com/langroid/langroid/blob/main/langroid/agent/special/doc_chat_agent.py), 
which uses batch tasks for relevance extraction,
see the `get_verbatim_extracts` method -- when there are k relevant passages,
this runs k tasks concurrently, 
each of which uses an LLM-agent to extract relevant verbatim text from a passage.

## Can I use Langroid in a FastAPI server?

Yes, see the [langroid/fastapi-server](https://github.com/langroid/fastapi-server) repo.

## Can a sub-task end all parent tasks and return a result?

Yes, there are two ways to achieve this, using [`FinalResultTool`][langroid.agent.tools.orchestration.final_result_tool.FinalResultTool]:

From a `ChatAgent`'s tool-handler or `agent_response` method: Your code can return a 
`FinalResultTool` with arbitrary field types; this ends the current and all parent tasks and this  
`FinalResultTool` will appear as one of tools in the final `ChatDocument.tool_messages`.
See `test_tool_handlers_and_results` in 
[test_tool_messages.py](https://github.com/langroid/langroid/blob/main/tests/main/test_tool_messages.py), 
and [examples/basic/chat-tool-function.py](https://github.com/langroid/langroid/blob/main/examples/basic/chat-tool-function.py)


From `ChatAgent`'s `llm_response` method: you can define a subclass of a 
`FinalResultTool` and enable the agent to use this tool, which means it will become
available for the LLM to generate. 
See [examples/basic/multi-agent-return-result.py](https://github.com/langroid/langroid/blob/main/examples/basic/multi-agent-return-result.py).

## How can I configure a task to retain or discard prior conversation?

In some scenarios, you may want to control whether each time you call a task's `run` 
method, the underlying agent retains the conversation history from the previous run.
There are two boolean config parameters that control this behavior: 

- the `restart` parameter (default `True`) in the `Task` constructor, and
- the `restart_as_subtask` (default `False`) parameter in the `TaskConfig` argument of the `Task` constructor.

To understand how these work, consider a simple scenario of a task `t` that has a 
subtask `t1`, e.g., suppose you have the following code with default settings 
of the `restart` and `restart_as_subtask` parameters:

```python
from langroid.agent.task import Task
from langroid.agent.task import TaskConfig

# default setttings:
rs = False
r = r1 = True

agent = ...
task_config = TaskConfig(restart_as_subtask=rs) 
t = Task(agent, restart=r, config=task_config)

agent1 = ...
t1 = Task(agent1, restart=r1, config=task_config)
t.add_subtask(t1)
```

This default setting works as follows:
Since task `t` was constructed with the default `restart=True`, when `t.run()` is called, the conversation histories of the agent underlying `t` as well as all 
those of all subtasks (such as `t1`) are reset. However, if during `t.run()`,
there are multiple calls to `t1.run()`, then the conversation history is retained across these calls, even though `t1` was constructed with the default `restart=True` --
this is because the `restart` constructor parameter has no effect on a task's reset
behavior **when it is a subtask**. 

The `TaskConfig.restart_as_subtask` parameter
controls the reset behavior of a task's `run` method when invoked as a subtask.
It defaults to `False`, which is why in the above example, the conversation history
of `t1` is retained across multiple calls to `t1.run()` that may occur
during execution of `t.run()`. If you set this parameter to `True` in the above
example, then the conversation history of `t1` would be reset each time `t1.run()` is called, during a call to `t.run()`.

To summarize, 

- The `Task` constructor's `restart` parameter controls the reset behavior of the task's `run` method when it is called directly, not as a subtask.
- The `TaskConfig.restart_as_subtask` parameter controls the reset behavior of the task's `run` method when it is called as a subtask.

These settings can be mixed and matched as needed.

Additionally, all reset behavior can be turned off during a specific `run()` invocation
by calling it with `allow_restart=False`, e.g.,  `t.run(..., allow_restart=False)`.

## How can I set up a task to exit as soon as the LLM responds?

In some cases you may want the top-level task or a subtask to exit as soon as the LLM responds. You can get this behavior by setting `single_round=True` during task construction, e.g.,

```python
from langroid.agent.task import Task

agent = ...
t = Task(agent, single_round=True, interactive=False)

result = t.run("What is 4 + 5?")
```

The name `single_round` comes from the fact that the task loop ends as soon as 
any **one** of the agent's responders return a valid response. Recall that an 
agent's responders are `llm_response`, `agent_response` (for tool handling), and `user_response` (for user input). In the above example there are no tools and no 
user interaction (since `interactive=False`), so the task will exit as soon as the LLM responds.

More commonly, you may only want this single-round behavior for a subtask, e.g.,

```python
agent = ...
t = Task(agent, single_round=False, interactive=True)

agent1 = ...
t1 = Task(agent1, single_round=True, interactive=False)

t.add_subtask(t1)
top_level_query = ...
result = t.run(...)
```

See the example script [`chat-2-agent-discuss.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat-2-agent-discuss.py) for an example of this, and also search for `single_round` in the rest of the examples.

!!! warning "Using `single_round=True` will prevent tool-handling"
    As explained above, setting `single_round=True` will cause the task to exit as soon as the LLM responds, and thus if it emits a valid tool (which the agent is enabled to handle), this tool will *not* be handled.
>>>> docs/auto_docstring.py
from pathlib import Path
import mkdocs_gen_files

# -----------------------------------------------------#
#                    Configuration                    #
# -----------------------------------------------------#
src_dir = "langroid"
repo_root = "https://github.com/langroid/langroid/tree/main/"
nav = mkdocs_gen_files.Nav()

# -----------------------------------------------------#
#                       Runner                        #
# -----------------------------------------------------#
""" Generate code reference pages and navigation

    Based on the recipe of mkdocstrings:
    https://github.com/mkdocstrings/mkdocstrings

    Credits:
    Timothée Mazzucotelli
    https://github.com/pawamoy
"""
# Iterate over each Python file
for path in sorted(Path(src_dir).rglob("*.py")):
    if ".ipynb_checkpoints" in str(path):
        continue

    # Get path in module, documentation and absolute
    module_path = path.relative_to(src_dir).with_suffix("")
    doc_path = path.relative_to(src_dir).with_suffix(".md")
    full_doc_path = Path("reference", doc_path)

    # Handle edge cases
    parts = (src_dir,) + tuple(module_path.parts)
    if parts[-1] == "__init__":
        parts = parts[:-1]
        doc_path = doc_path.with_name("index.md")
        full_doc_path = full_doc_path.with_name("index.md")
    elif parts[-1] == "__main__":
        continue
    nav[parts] = doc_path.as_posix()

    # Write docstring documentation to disk via parser
    with mkdocs_gen_files.open(full_doc_path, "w") as fd:
        ident = ".".join(parts)
        full_code_path = repo_root + "/" + str(path)
        fd.write(f"[{path}]({full_code_path})\n")
        fd.write(f"::: {ident}")
    # Update parser
    mkdocs_gen_files.set_edit_path(full_doc_path, path)
    print(f"Doing docs for {full_doc_path}, {path}")

with mkdocs_gen_files.open("reference/SUMMARY.md", "w") as nav_file:
    nav_file.writelines(nav.build_literate_nav())

>>>> docs/blog/index.md
# Blog


>>>> docs/blog/posts/chat-completion.md
---
title: 'Language Models: Completion and Chat-Completion'
draft: false
date: 2023-09-19
authors: 
  - pchalasani
categories:
  - langroid
  - llm
  - local-llm
  - chat
comments: true
---

Transformer-based language models are fundamentally next-token predictors, so 
naturally all LLM APIs today at least provide a completion endpoint. 
If an LLM is a next-token predictor, how could it possibly be used to 
generate a response to a question or instruction, or to engage in a conversation with 
a human user? This is where the idea of "chat-completion" comes in.
This post is a refresher on the distinction between completion and chat-completion,
and some interesting details on how chat-completion is implemented in practice.

<!-- more -->

## Language Models as Next-token Predictors

A Language Model is essentially a "next-token prediction" model,
and so all LLMs today provide a "completion" endpoint, typically something like:
`/completions` under the base URL.

The endpoint simply takes a prompt and returns a completion (i.e. a continuation).

A typical prompt sent to a completion endpoint might look like this:
```
The capital of Belgium is 
```
and the LLM will return a completion like this:
```
Brussels.
```
OpenAI's GPT3 is an example of a pure completion LLM.
But interacting with a completion LLM is not very natural or useful:
you cannot give instructions or ask questions; instead you would always need to 
formulate your input as a prompt whose natural continuation is your desired output.
For example, if you wanted the LLM to highlight all proper nouns in a sentence,
you would format it as the following prompt:

**Chat-To-Prompt Example:** Chat/Instruction converted to a completion prompt.

```
User: here is a sentence, the Assistant's task is to identify all proper nouns.
     Jack lives in Bosnia, and Jill lives in Belgium.
Assistant:    
```
The natural continuation of this prompt would be a response listing the proper nouns,
something like:
```
John, Bosnia, Jill, Belgium are all proper nouns.
```

This _seems_ sensible in theory, but a "base" LLM that performs well on completions
may _not_ perform well on these kinds of prompts. The reason is that during its training, it may not
have been exposed to very many examples of this type of prompt-response pair.
So how can an LLM be improved to perform well on these kinds of prompts?

## Instruction-tuned, Aligned LLMs 

This brings us to the heart of the innovation behind the wildly popular ChatGPT:
it uses an enhancement of GPT3 that (besides having a lot more parameters),
was _explicitly_ fine-tuned on instructions (and dialogs more generally) -- this is referred to
as **instruction-fine-tuning** or IFT for short. In addition to fine-tuning instructions/dialogs,
the models behind ChatGPT (i.e., GPT-3.5-Turbo and GPT-4) are further tuned to produce
responses that _align_ with human preferences (i.e. produce responses that are more helpful and safe),
using a procedure called Reinforcement Learning with Human Feedback (RLHF).
See this [OpenAI InstructGPT Paper](https://arxiv.org/pdf/2203.02155.pdf) for details on these techniques and references to the 
original papers that introduced these ideas. Another recommended read is Sebastian 
Raschka's post on [RLHF and related techniques](https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives). 

For convenience, we refer to the combination of IFT and RLHF as **chat-tuning**.
A chat-tuned LLM can be expected to perform well on prompts such as the one in 
the Chat-To-Prompt Example above. These types of prompts are still unnatural, however, 
so as a convenience, chat-tuned LLM API servers also provide a "chat-completion" 
endpoint (typically `/chat/completions` under the base URL), which allows the user
to interact with them in a natural dialog, which might look like this
(the portions in square brackets are indicators of who is generating the text):

```
[User] What is the capital of Belgium?
[Assistant] The capital of Belgium is Brussels.
```
or
```
[User] In the text below, find all proper nouns:
    Jack lives in Bosnia, and Jill lives in Belgium.
[Assistant] John, Bosnia, Jill, Belgium are all proper nouns.
[User] Where does John live?
[Assistant] John lives in Bosnia.
```

## Chat Completion Endpoints: under the hood

How could this work, given that LLMs are fundamentally next-token predictors?
This is a convenience provided by the LLM API service (e.g. from OpenAI or
local model server libraries):
when a user invokes the chat-completion endpoint (typically
at `/chat/completions` under the base URL), under the hood, the server converts the
instructions and multi-turn chat history into a single string, with annotations indicating
user and assistant turns, and ending with something like "Assistant:"
as in the Chat-To-Prompt Example above.

Now the subtle detail to note here is this:

>It matters _how_ the
dialog (instructions plus chat history) is converted into a single prompt string.
Converting to a single prompt by simply concatenating the
instructions and chat history using an "intuitive" format (e.g. indicating
user, assistant turns using "User", "Assistant:", etc.) _can_ work,
however most local LLMs are trained on a _specific_ prompt format.
So if we format chats in a different way, we may get odd/inferior results.

## Converting Chats to Prompts: Formatting Rules

For example, the llama2 models are trained on a format where the user's input is bracketed within special strings `[INST]`
and `[/INST]`. There are other requirements that we don't go into here, but
interested readers can refer to these links:

- A reddit thread on the [llama2 formats](https://www.reddit.com/r/LocalLLaMA/comments/155po2p/get_llama_2_prompt_format_right/)
- Facebook's [llama2 code](https://github.com/facebookresearch/llama/blob/main/llama/generation.py#L44)
- Langroid's [llama2 formatting code](https://github.com/langroid/langroid/blob/main/langroid/language_models/prompt_formatter/llama2_formatter.py)

A dialog fed to a Llama2 model in its expected prompt format would look like this:

```
<s>[INST] <<SYS>>
You are a helpful assistant.
<</SYS>>

Hi there! 
[/INST] 
Hello! How can I help you today? </s>
<s>[INST] In the text below, find all proper nouns:
    Jack lives in Bosnia, and Jill lives in Belgium.
 [/INST] 
John, Bosnia, Jill, Belgium are all proper nouns. </s><s> 
[INST] Where does Jack live? [/INST] 
Jack lives in Bosnia. </s><s>
[INST] And Jill? [/INST]
Jill lives in Belgium. </s><s>
[INST] Which are its neighboring countries? [/INST]
```

This means that if an LLM server library wants to provide a chat-completion endpoint for
a local model, it needs to provide a way to convert chat history to a single prompt
using the specific formatting rules of the model.
For example the [`oobabooga/text-generation-webui`](https://github.com/oobabooga/text-generation-webui) 
library has an extensive set of chat formatting [templates](https://github.com/oobabooga/text-generation-webui/tree/main/instruction-templates)
for a variety of models, and their model server auto-detects the
format template from the model name.

!!! note "Chat completion model names: look for 'chat' or 'instruct' in the name"
    You can search for a variety of models on the [HuggingFace model hub](https://huggingface.co/models).
    For example if you see a name `Llama-2-70B-chat-GGUF` you know it is chat-tuned.
    Another example of a chat-tuned model is `Llama-2-7B-32K-Instruct` 
    
A user of these local LLM server libraries thus has two options when using a 
local model in chat mode:

- use the _chat-completion_ endpoint, and let the underlying library handle the chat-to-prompt formatting, or
- first format the chat history according to the model's requirements, and then use the
  _completion_ endpoint

## Using Local Models in Langroid

Local models can be used in Langroid by defining a `LocalModelConfig` object.
More details are in this [tutorial](https://langroid.github.io/langroid/blog/2023/09/14/using-langroid-with-local-llms/), 
but here we briefly discuss prompt-formatting in this context.
Langroid provides a built-in [formatter for LLama2 models](https://github.com/langroid/langroid/blob/main/langroid/language_models/prompt_formatter/llama2_formatter.py), 
so users looking to use llama2 models with langroid can try either of these options, by setting the
`use_completion_for_chat` flag in the `LocalModelConfig` object
(See the local-LLM [tutorial](https://langroid.github.io/langroid/blog/2023/09/14/using-langroid-with-local-llms/) for details).

When this flag is set to `True`, the chat history is formatted using the built-in 
Langroid llama2 formatter and the completion endpoint are used. When the flag is set to `False`, the chat 
history is sent directly to the chat-completion endpoint, which internally converts the 
chat history to a prompt in the expected llama2 format.

For local models other than Llama2, users can either:

- write their own formatters by writing a class similar to `Llama2Formatter` and 
then setting the `use_completion_for_chat` flag to `True` in the `LocalModelConfig` object, or
- use an LLM server library (such as the `oobabooga` library mentioned above) that provides a chat-completion endpoint, 
_and converts chats to single prompts under the hood,_ and set the
  `use_completion_for_chat` flag to `False` in the `LocalModelConfig` object.

You can use a similar approach if you are using an LLM application framework other than Langroid.


<iframe src="https://langroid.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>


>>>> docs/blog/posts/langroid-architecture.md
---
title: "Overview of Langroid's Multi-Agent Architecture (prelim)"
draft: false
date: 2024-08-15
authors:
- pchalasani
- nils
- jihye
- someshjha
categories:
- langroid
- multi-agent
- llm
comments: true
---


## Agent, as an intelligent message transformer

A natural and convenient abstraction in designing a complex
LLM-powered system is the notion of an *agent* that is instructed to be responsible for a specific aspect of the 
overall task. In terms of code, an *Agent* is essentially a class representing an intelligent entity that can 
respond to *messages*, i.e., an agent is simply a *message transformer*.
An agent typically encapsulates an (interface to an) LLM, and may also be equipped with so-called *tools* (as 
described below) and *external documents/data* (e.g., via a vector database, as described below).
Much like a team of humans, agents interact by exchanging messages, in a manner reminiscent of the 
[*actor framework*](https://en.wikipedia.org/wiki/Actor_model) in programming languages.
An *orchestration mechanism* is needed to manage the flow of messages between agents, to ensure that progress is 
made towards completion of the task, and to handle the inevitable cases where an agent deviates from instructions.
Langroid is founded on this *multi-agent programming* paradigm, where agents are 
first-class citizens, acting as message transformers, and communicate by exchanging messages.

<!-- more -->

To build useful applications with LLMs, we need to endow them with the ability to
trigger actions (such as API calls, computations, database queries, etc) or send structured messages to other agents 
or downstream processes. *Tools* provide these capabilities, described next.

## Tools, also known as functions

An LLM is essentially a text transformer; i.e.,  in response to some input text, 
it produces a text response. Free-form text responses are ideal when we want to generate a description, answer, or summary for human consumption, or even a question for another agent to answer.
However, in some cases, we would like the responses to be more structured, for example 
to trigger external *actions* (such as an API call, code execution, or a database query),
or for unambiguous/deterministic handling by a downstream process or another agent. 
In such cases, we would instruct the LLM to produce a *structured* output, typically in JSON format, with various 
pre-specified fields, such as code, an SQL query, parameters of an API call, and so on. These structured responses 
have come to be known as *tools*, and the LLM is said to *use* a tool when it produces a structured response 
corresponding to a specific tool. To elicit a tool response from an LLM, it needs to be instructed on the expected tool format and the conditions under which it should use the tool.
To actually use a tool emitted by an LLM, a *tool handler* method must be defined as well.
The tool handler for a given tool is triggered when it is recognized in the LLM's response.

### Tool Use: Example

As a simple example, a SQL query tool can be specified as a JSON structure with a `sql` 
field (containing the SQL query) and a `db` field (containing the name of the database).
The LLM may be instructed with a system prompt of the form:
> When the user asks a question about employees, use the SQLTool described in the below schema,
> and the results of this tool will be sent back to you, and you can use these to respond to
> the user's question, or correct your SQL query if there is a syntax error.

The tool handler would detect this specific tool in the LLM's response, parse this JSON structure, 
extract the `sql` and `db` fields, run the query on the specified database, 
and return the result if the query ran successfully, otherwise return an error message.
Depending on how the multi-agent system is organized, the query result or error message may be handled by the same agent
(i.e., its LLM), which may either summarize the results in narrative form, or revise the query if the error message 
indicates a syntax error.

## Agent-oriented programming: Function-Signatures

If we view an LLM as a function with signature `string -> string`,
it is possible to express the concept of an agent, tool, and other constructs
in terms of derived function signatures, as shown in the table below.
Adding `tool` (or function calling) capability to an LLM requires a parser (that recognizes 
that the LLM has generated a tool) and a callback that performs arbitrary computation and returns a string.
The serialized instances of tools `T` correspond to a language `L`; 
Since by assumption, the LLM is capable of producing outputs in $L$, 
this allows the LLM to express the intention to execute a Callback with arbitrary instances 
of `T`. In the last row, we show how an Agent can be viewed as a function signature
involving its state `S`.


| Function Description | Function Signature                                                                                                |
|----------------------|-------------------------------------------------------------------------------------------------------------------|
| LLM | `[Input Query] -> string` <br> `[Input Query]` is the original query.                                             |
| Chat interface | `[Message History] x [Input Query] -> string` <br> `[Message History]` consists of  previous messages[^1].        |
| Agent | `[System Message] x [Message History] x [Input Query] -> string` <br> `[System Message]` is the system prompt. |
| Agent with tool | `[System Message] x (string -> T) x (T -> string) x [Message History] x [Input Query] -> string`                  |
| Parser with type `T` | `string -> T`                                                                                                     |
| Callback with type `T` | `T -> string`                                                                                                     |
| General Agent with state type `S` | `S x [System Message] x (string -> T) x (S x T -> S x string) x [Message History] x [Input Query] -> S x string`  |

[^1]: Note that in reality, separator tokens are added to distinguish messages, and the messages are tagged with metadata indicating the sender, among other things.

## Multi-Agent Orchestration


### An Agent's "Native" Responders

When building an LLM-based multi-agent system, an orchestration mechanism is critical to manage the flow of messages 
between agents, to ensure task progress, and handle inevitable LLM deviations from instructions. Langroid provides a 
simple yet versatile orchestration mechanism that seamlessly handles:

- user interaction,
- tool handling,
- sub-task delegation

We view an agent as a message transformer; 
it may transform an incoming message using one of its three "native" responder methods, all of which have the same 
function signature: `string -> string`. These methods are:

- `llm_response` returns the LLM's response to the input message.
Whenever this method is invoked, the agent updates its dialog history (typically consisting of alternating user and LLM messages).
- `user_response` prompts the user for input and returns their response.
- `agent_response` by default only handles a `tool message` (i.e., one that contains an llm-generated structured 
response): it performs any requested actions, and returns the result as a string. An `agent_response` method can have 
other uses besides handling tool messages, such as handling scenarios where an LLM ``forgot'' to use a tool, 
or used a tool incorrectly, and so on.

To see why it is useful to have these responder methods, consider first a simple example of creating a basic chat loop
with the user. It is trivial to create such a loop by alternating between `user_response` and `llm_response`. 
Now suppose we instruct the agent to either directly answer the user's question or perform a web-search. Then it is possible that
sometimes the `llm_response` will produce a "tool message", say `WebSearchTool`, which we would handle with the
`agent_response` method. This requires a slightly different, and more involved, way of iterating among the agent's
responder methods. 

### Tasks: Encapsulating Agent Orchestration

From a coding perspective, it is useful to hide the actual iteration logic by wrapping an Agent class
in a separate class, which we call a `Task`, which encapsulates all of the orchestration logic. Users of the Task class
can then define the agent, tools, and any sub-tasks, wrap the agent in a task object of class Task, and simply call
`task.run()`, letting the Task class deal with the details of orchestrating the agent's responder methods, determining
task completion, and invoking sub-tasks.

### Responders in a Task: Agent's native responders and sub-tasks

The orchestration mechanism of a `Task` object works as follows. When a `Task` object is created from an agent, a 
sequence of eligible responders is created, which includes the agent's three "native" responder agents in the sequence:
`agent_response`, `llm_response`, `user_response`. 
The type signature of the task's run method is `string -> string`, just like the Agent's
native responder methods, and this is the key to seamless delegation of tasks to sub-tasks. A list of subtasks can be
added to a `Task` object via `task.add_sub_tasks([t1, t2, ... ])`, where `[t1, t2, ...]` are other 
`Task` objects. The result of this is that the run method of each sub-task is appended to the sequence of eligible 
responders in the parent task object.

### Task Orchestration: Updating the Current Pending Message (CPM)

A task always maintains a *current pending message* (CPM), which is the latest message "awaiting" a valid response 
from a responder, which updates the CPM. 
At a high level the `run` method of a task attempts to repeatedly find a valid response to the 
CPM, until the task is done. (Note that this paradigm is somewhat reminescent of a *Blackboard* architecture, where
agents take turns deciding whether they can update the shared message on the "blackboard".)
This is achieved by repeatedly invoking the `step` method, which represents a "turn" in the conversation.
The `step` method sequentially tries the eligible responders from the beginning of the eligible-responders list, until it
finds a valid response, defined as a non-null or terminating message (i.e. one that signals that the task is done). In
particular, this `step()` algorithm implies that a Task delegates (or "fails over") to a sub-task only if the task's 
native responders have no valid response. 

There are a few simple rules that govern how `step` works: 

- a responder entity (either a sub-task or a native entity -- one of LLM, Agent, or User) cannot 
  respond if it just responded in the previous step (this prevents a responder from "talking to itself". 
- when a response signals that the task is done (via a `DoneTool` or a "DONE" string) the task is ready to exit and 
  return the CPM as the result of the task. 
- when an entity "in charge" of the task has a null response, the task is considered finished and ready to exit.
- if the response of an entity or subtask is a structured message containing a recipient field, then the specified recipient task or entity will
be the only one eligible to respond at the next step.

Once a valid response is found in a step, the CPM is updated to this response, and the next step starts the search for a
valid response from the beginning of the eligible responders list. When a response signals that the task is done, 
the run method returns the CPM as the result of the task. This is a highly
simplified account of the orchestration mechanism, and the actual implementation is more involved.

The above simple design is surprising powerful and can support a wide variety of task structures, including trees and
DAGs. As a simple illustrative example, tool-handling has a natural implementation. The LLM is instructed to use a
certain JSON-structured message as a tool, and thus the `llm_response` method can produce a structured message, such 
as an SQL query.  This structured message is then handled by the `agent_response` method, and the resulting message updates the CPM. The
`llm_response` method then becomes eligible to respond again: for example if the agent's response contains an SQL 
error, the LLM would retry its query, and if the agent's response consists of the query results, the LLM would
respond with a summary of the results.

The Figure below depicts the task orchestration and delegation mechanism,
showing how iteration among responder methods works when a  Task `T` has sub-tasks `[T1, T2]` and `T1` has a 
sub-task `T3`. 


![langroid-arch.png](figures/langroid-arch.png)
>>>> docs/blog/posts/langroid-intro.md
---
title: 'Langroid: Harness LLMs with Multi-Agent Programming'
draft: false
date: 2023-09-03
authors: 
  - pchalasani
categories:
  - langroid
  - llm
comments: true
---

# Langroid: Harness LLMs with Multi-Agent Programming

## The LLM Opportunity

Given the remarkable abilities of recent Large Language Models (LLMs), there
is an unprecedented opportunity to build intelligent applications powered by
this transformative technology. The top question for any enterprise is: how
best to harness the power of LLMs for complex applications? For technical and
practical reasons, building LLM-powered applications is not as simple as
throwing a task at an LLM-system and expecting it to do it.

<!-- more -->


## Langroid's Multi-Agent Programming Framework

Effectively leveraging LLMs at scale requires a *principled programming
framework*. In particular, there is often a need to maintain multiple LLM
conversations, each instructed in different ways, and "responsible" for
different aspects of a task.


An *agent* is a convenient abstraction that encapsulates LLM conversation
state, along with access to long-term memory (vector-stores) and tools (a.k.a functions
or plugins). Thus a **Multi-Agent Programming** framework is a natural fit
for complex LLM-based applications.

> Langroid is the first Python LLM-application framework that was explicitly
designed  with Agents as first-class citizens, and Multi-Agent Programming
as the core  design principle. The framework is inspired by ideas from the
[Actor Framework](https://en.wikipedia.org/wiki/Actor_model).

Langroid allows an intuitive definition of agents, tasks and task-delegation
among agents. There is a principled mechanism to orchestrate multi-agent
collaboration. Agents act as message-transformers, and take turns responding to (and
transforming) the current message. The architecture is lightweight, transparent,
flexible, and allows other types of orchestration to be implemented.
Besides Agents, Langroid also provides simple ways to directly interact with LLMs and vector-stores.


## Highlights
- **Agents as first-class citizens:** The `Agent` class encapsulates LLM conversation state,
  and optionally a vector-store and tools. Agents are a core abstraction in Langroid;
  Agents act as _message transformers_, and by default provide 3 _responder_ methods, one corresponding to each
  entity: LLM, Agent, User.
- **Tasks:** A Task class wraps an Agent, gives the agent instructions (or roles, or goals),
  manages iteration over an Agent's responder methods,
  and orchestrates multi-agent interactions via hierarchical, recursive
  task-delegation. The `Task.run()` method has the same
  type-signature as an Agent's responder's methods, and this is key to how
  a task of an agent can delegate to other sub-tasks: from the point of view of a Task,
  sub-tasks are simply additional responders, to be used in a round-robin fashion
  after the agent's own responders.
- **Modularity, Reusability, Loose coupling:** The `Agent` and `Task` abstractions allow users to design
  Agents with specific skills, wrap them in Tasks, and combine tasks in a flexible way.
- **LLM Support**: Langroid supports OpenAI LLMs including GPT-3.5-Turbo,
  GPT-4.
- **Caching of LLM prompts, responses:** Langroid by default uses [Redis](https://redis.com/try-free/) for caching.
- **Vector-stores**: [Qdrant](https://qdrant.tech/), [Chroma](https://www.trychroma.com/), LanceDB, Pinecone, PostgresDB (PGVector), Weaviate are currently supported.
  Vector stores allow for Retrieval-Augmented-Generaation (RAG).
- **Grounding and source-citation:** Access to external documents via vector-stores
  allows for grounding and source-citation.
- **Observability, Logging, Lineage:** Langroid generates detailed logs of multi-agent interactions and
  maintains provenance/lineage of messages, so that you can trace back
  the origin of a message.
- **Tools/Plugins/Function-calling**: Langroid supports OpenAI's recently
  released [function calling](https://platform.openai.com/docs/guides/gpt/function-calling)
  feature. In addition, Langroid has its own native equivalent, which we
  call **tools** (also known as "plugins" in other contexts). Function
  calling and tools have the same developer-facing interface, implemented
  using [Pydantic](https://docs.pydantic.dev/latest/),
  which makes it very easy to define tools/functions and enable agents
  to use them. Benefits of using Pydantic are that you never have to write
  complex JSON specs for function calling, and when the LLM
  hallucinates malformed JSON, the Pydantic error message is sent back to
  the LLM so it can fix it!

<iframe src="https://langroid.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>

>>>> docs/blog/posts/langroid-knowledge-graph.md
---
title: 'Langroid: Knolwedge Graph RAG powered by Neo4j'
draft: false
date: 2024-01-18
authors: 
  - mohannad
categories:
  - langroid
  - neo4j
  - rag
  - knowledge-graph
comments: true
---

## "Chat" with various sources of information
LLMs are increasingly being used to let users converse in natural language with 
a variety of types of data sources:
<!-- more -->
- unstructured text documents: a user's query is augmented with "relevant" documents or chunks
  (retrieved from an embedding-vector store) and fed to the LLM to generate a response -- 
  this is the idea behind Retrieval Augmented Generation (RAG).
- SQL Databases: An LLM translates a user's natural language question into an SQL query,
  which is then executed by another module, sending results to the LLM, so it can generate
  a natural language response based on the results.
- Tabular datasets: similar to the SQL case, except instead of an SQL Query, the LLM generates 
  a Pandas dataframe expression.

Langroid has had specialized Agents for the above scenarios: `DocChatAgent` for RAG with unstructured
text documents, `SQLChatAgent` for SQL databases, and `TableChatAgent` for tabular datasets.

## Adding support for Neo4j Knowledge Graphs

Analogous to the SQLChatAgent, Langroid now has a 
[`Neo4jChatAgent`](https://github.com/langroid/langroid/blob/main/langroid/agent/special/neo4j/neo4j_chat_agent.py) 
to interact with a Neo4j knowledge graph using natural language.
This Agent has access to two key tools that enable it to handle a user's queries:

- `GraphSchemaTool` to get the schema of a Neo4j knowledge graph.
- `CypherRetrievalTool` to generate Cypher queries from a user's query.
Cypher is a specialized query language for Neo4j, and even though it is not as widely known as SQL,
most LLMs today can generate Cypher Queries.

Setting up a basic Neo4j-based RAG chatbot is straightforward. First ensure 
you set these environment variables (or provide them in a `.env` file):
```bash
NEO4J_URI=<uri>
NEO4J_USERNAME=<username>
NEO4J_PASSWORD=<password>
NEO4J_DATABASE=<database>
```

Then you can configure and define a `Neo4jChatAgent` like this:
```python
import langroid as lr
import langroid.language_models as lm

from langroid.agent.special.neo4j.neo4j_chat_agent import (
    Neo4jChatAgent,
    Neo4jChatAgentConfig,
    Neo4jSettings,
)

llm_config = lm.OpenAIGPTConfig()

load_dotenv()

neo4j_settings = Neo4jSettings()

kg_rag_agent_config = Neo4jChatAgentConfig(
    neo4j_settings=neo4j_settings,
    llm=llm_config, 
)
kg_rag_agent = Neo4jChatAgent(kg_rag_agent_config)
kg_rag_task = lr.Task(kg_rag_agent, name="kg_RAG")
kg_rag_task.run()
```


## Example: PyPi Package Dependency Chatbot

In the Langroid-examples repository, there is an example python 
[script](https://github.com/langroid/langroid-examples/blob/main/examples/kg-chat/)
showcasing tools/Function-calling + RAG using a `DependencyGraphAgent` derived from [`Neo4jChatAgent`](https://github.com/langroid/langroid/blob/main/langroid/agent/special/neo4j/neo4j_chat_agent.py).
This agent uses two tools, in addition to the tools available to `Neo4jChatAgent`:

- `GoogleSearchTool` to find package version and type information, as well as to answer 
 other web-based questions after acquiring the required information from the dependency graph.
- `DepGraphTool` to construct a Neo4j knowledge-graph modeling the dependency structure
   for a specific package, using the API at [DepsDev](https://deps.dev/).

In response to a user's query about dependencies, the Agent decides whether to use a Cypher query
or do a web search. Here is what it looks like in action:

<figure markdown>
  ![dependency-demo](../../assets/demos/dependency_chatbot.gif)
  <figcaption>
Chatting with the `DependencyGraphAgent` (derived from Langroid's `Neo4jChatAgent`).
When a user specifies a Python package name (in this case "chainlit"), the agent searches the web using
`GoogleSearchTool` to find the version of the package, and then uses the `DepGraphTool`
to construct the dependency graph as a neo4j knowledge graph. The agent then answers
questions by generating Cypher queries to the knowledge graph, or by searching the web.
  </figcaption>
</figure>



>>>> docs/blog/posts/langroid-lancedb.md
---
title: 'Langroid: Multi-Agent Programming Framework for LLMs'
draft: true
date: 2024-01-10
authors: 
  - pchalasani
categories:
  - langroid
  - lancedb
  - rag
  - vector-database
comments: true
---

## Langroid: Multi-Agent Programming framework for LLMs

In this era of Large Language Models (LLMs), there is unprecedented demand to
create intelligent applications powered by this transformative technology. What
is the best way for developers to harness the potential of LLMs in complex
application scenarios? For a variety of technical and practical reasons (context
length limitations, LLM brittleness, latency, token-costs), this is not as
simple as throwing a task at an LLM system and expecting it to get done. What is
needed is a principled programming framework, offering the right set of
abstractions and primitives to make developers productive when building LLM
applications.
<!-- more -->
## Langroid's Elegant Multi-Agent Paradigm

The [Langroid](https://github.com/langroid/langroid) team (ex-CMU/UW-Madison researchers) 
has a unique take on this – they have built an open source Python framework to 
simplify LLM application development, using a Multi-Agent Programming paradigm. 
Langroid’s architecture is founded on Agents as first-class citizens: 
they are message-transformers, and accomplish tasks collaboratively via messages.

Langroid is emerging as a popular LLM framework; developers appreciate its clean
design and intuitive, extensible architecture. Programming with Langroid is
natural and even fun: you configure Agents and equip them with capabilities (
such as LLMs, vector-databases, Function-calling/tools), connect them and have
them collaborate via messages. This is a “Conversational Programming” paradigm,
and works with local/open and remote/proprietary LLMs. (Importantly, it does not
use LangChain or any other existing LLM framework).

<figure markdown>
  ![Langroid-card](../../assets/langroid-card-ossem-rust-1200x630.png){ width="800" }
  <figcaption>
An Agent serves as a convenient abstraction, encapsulating the state of LLM
conversations, access to vector stores, and various tools (functions or
plugins). A Multi-Agent Programming framework naturally aligns with the demands
of complex LLM-based applications.
</figcaption>
</figure>



## Connecting Agents via Tasks

In Langroid, a ChatAgent has a set of “responder” methods, one for each "entity":
an LLM, a human, and a tool-handler. However it does not have any way to iterate through
these responders. This is where the Task class comes in: A Task wraps an Agent
and gives it the ability to loop through its responders, via the `Task.run()` method. 

A Task loop is organized around simple rules that govern when a responder is eligible
to respond, what is considered a valid response, and when the task is complete.
The simplest example of a Task loop is an interactive chat with the human user. 
A Task also enables an Agent to interact with other agents: 
other tasks can be added to a task as sub-tasks, 
in a recursive, hierarchical (or DAG) structure. From a Task’s perspective,
sub-tasks are just additional responders, and present the same string-to-string 
message-transformation interface (function signature) as the Agent’s "native" responders. 
This is the key to composability of tasks in Langroid,
since a sub-task can act the same way as an Agent's "native" responders, and is subject
to the same rules of task orchestration. The result is that the same task orchestration
mechanism seamlessly enables tool handling, retries when LLM deviates, and 
delegation to sub-tasks. More details are in the Langroid [quick-start guide](https://langroid.github.io/langroid/quick-start/)

## A Taste of Coding with Langroid

To get started with Langroid, simply install it from pypi into your virtual environment:

```bash
pip install langroid
```
To directly chat with an OpenAI LLM, define the LLM configuration,
instantiate a language model object and interact with it:
(Langroid works with non-OpenAI local/propreitary LLMs as well,
see their [tutorial](https://langroid.github.io/langroid/tutorials/non-openai-llms/)) 
For the examples below, ensure you have a file `.env` containing your OpenAI API key
with this line: `OPENAI_API_KEY=sk-...`.
    
```python
import langroid as lr
import langroid.language_models as lm

llm_cfg = lm.OpenAIGPTConfig() # default GPT4-Turbo
mdl = lm.OpenAIGPT(llm_cfg)
mdl.chat("What is 3+4?", max_tokens=10)
```
The mdl does not maintain any conversation state; for that you need a `ChatAgent`:

```python
agent_cfg = lr.ChatAgentConfig(llm=llm_cfg)
agent = lr.ChatAgent(agent_cfg)
agent.llm_response("What is the capital of China?")
agent.llm_response("What about France?") # interprets based on previous msg
```
Wrap a ChatAgent in a Task to create a basic interactive loop with the user:

```python
task = lr.Task(agent, name="Bot")
task.run("Hello")
```
Have a Teacher Agent talk to a Student Agent:
    
```python
teacher = lr.ChatAgent(agent_cfg)
teacher_task = lr.Task(
    teacher, name="Teacher",
    system_message="""
        Ask your student simple number-based questions, and give feedback.
        Start with a question.
        """,
)
student = lr.ChatAgent(agent_cfg)
student_task = lr.Task(
    student, name="Student",
    system_message="Concisely answer your teacher's questions."
)
teacher_task.add_sub_task(student_task)
teacher_task.run()
```



## Retrieval Augmented Generation (RAG) and Vector Databases

One of the most popular LLM applications is question-answering 
on documents via Retrieval-Augmented Generation (RAG), powered by a vector database.
Langroid has a built-in DocChatAgent that incorporates a number of advanced RAG techniques, 
clearly laid out so they can be easily understood and extended.

### Built-in Support for LanceDB
<figure markdown>
  ![Langroid-lance](../../assets/langroid-lance.png){ width="800" }
  <figcaption>
Langroid uses LanceDB as the default vector store for its DocChatAgent.
</figcaption>
</figure>

Langroid's DocChatAgent uses the LanceDB serverless vector-database by default.
Since LanceDB uses file storage, it is easy to set up and use (no need for docker or cloud services),
and due to its use of the Lance columnar format, it is 
highly performant and scalable. 
In addition, Langroid has a specialized `LanceDocChatAgent` that leverages LanceDB's 
unique features such as Full-text search, SQL-like filtering, and pandas dataframe interop.
Setting up a basic RAG chatbot is as simple as (assume the previous imports):

```python
from langroid.agent.special.lance_doc_chat_agent import import (
    LanceDocChatAgent, DocChatAgentConfig
)
llm_config = lm.OpenAIGPTConfig()

rag_agent_config = DocChatAgentConfig(
    llm=llm_config, 
    doc_paths=["/path/to/my/docs"], # files, folders, or URLs.
)
rag_agent = LanceDocChatAgent(rag_agent_config)
rag_task = lr.Task(rag_agent, name="RAG")
rag_task.run()
```

For an example showcasing Tools/Function-calling + RAG in a multi-agent setup, see their quick-start
[Colab notebook](https://colab.research.google.com/github/langroid/langroid/blob/main/examples/Langroid_quick_start.ipynb)
which shows a 2-agent system where one agent is tasked with extracting structured information
from a document, and generates questions for the other agent to answer using RAG.
In the Langroid-examples repo there is a [script](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat_multi_extract.py) with the same functionality,
and here is what it looks like in action:


<figure markdown>
  ![lease-demo](../../assets/demos/lease-extractor-demo.gif){ width="800" }
  <figcaption>
Extracting structured info from a Commercial Lease using a 2-agent system, with 
a Tool/Function-calling and RAG. The Extractor Agent is told to extract information
in a certain structure, and it generates questions for the Document Agent
to answer using RAG.
</figcaption>
</figure>

## Retrieval Augmented Analytics

One of the unique features of LanceDB is its SQL-like filtering and Pandas dataframe interoperability.
LLMs are great at generating SQL queries, and also Pandas computation code such as `df.groupby("col").mean()`.
This opens up a very interesting possibility, which we call
**Retrieval Augmented Analytics:** Suppose a user has a large dataset of movie descriptions
with metadata such as rating, year and genre, and wants to ask:

> What is the highest-rated Comedy movie about college students made after 2010?

It is not hard to imagine that an LLM should be able to generate a **Query Plan** to answer this,
consisting of:

- A SQL-like filter: `genre = "Comedy" and year > 2010`
- A Pandas computation: `df.loc[df["rating"].idxmax()]`
- A rephrased query given the filter: "Movie about college students" (used for semantic/lexical search)

Langroid's Multi-Agent framework enables exactly this type of application. 
The [`LanceRAGTaskCreator`](https://github.com/langroid/langroid/blob/main/langroid/agent/special/lance_rag/lance_rag_task.py) takes a `LanceDocChatAgent` and adds two additional agents:

- QueryPlannerAgent: Generates the Query Plan
- QueryPlanCriticAgent: Critiques the Query Plan and Answer received from the RAG Agent, so that 
  the QueryPlanner can generate a better plan if needed.

Checkout the [`lance-rag-movies.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/lance-rag-movies.py) script in the langroid-examples repo to try this out.

## Try it out and get involved!
This was just a glimpse of what you can do with Langroid and how your code would look.
Give it a shot and learn more about the features and roadmap of Langroid on their 
[GitHub repo](https://github.com/langroid/langroid). Langroid welcomes contributions,
and they have a friendly [Discord](https://discord.gg/ZU36McDgDs) community.

If you like it, don’t forget to drop a 🌟.




>>>> docs/blog/posts/local-llm-formatting.md
---
title: 'Chat formatting in Local LLMs'
draft: true
date: 2024-01-25
authors: 
  - pchalasani
categories:
  - langroid
  - prompts
  - llm
  - local-llm
comments: true
---


In an (LLM performance) investigation, details matter!

And assumptions kill (your LLM performance).

I'm talking about chat/prompt formatting, especially when working with Local LLMs.

TL/DR -- details like chat formatting matter a LOT,
and trusting that the local LLM API is doing it correctly may be a mistake,
leading to inferior results.

<!-- more -->

🤔Curious? Here are some notes from the trenches when we built an app
(https://github.com/langroid/langroid/blob/main/examples/docqa/chat-multi-extract-local.py)
based entirely on a locally running Mistral-7b-instruct-v0.2  
(yes ONLY 7B parameters, compared to 175B+ for GPT4!)
that leverages Langroid Multi-agents, Tools/Function-calling and RAG to
reliably extract structured information from a document,
where an Agent is given a spec of the desired structure, and it generates
questions for another Agent to answer using RAG.

🔵LLM API types: generate and chat
LLMs are typically served behind two types of APIs endpoints:
⏺ A "generation" API, which accepts a dialog formatted as a SINGLE string, and
⏺ a "chat" API, which accepts the dialog as a LIST,
and as convenience formats it into a single string before sending to the LLM.

🔵Proprietary vs Local LLMs
When you use a proprietary LLM API (such as OpenAI or Claude), for convenience
you can use their "chat" API, and you can trust that it will format the dialog
history correctly (or else they wouldn't be in business!).

But with a local LLM, you have two choices of where to send the dialog history:
⏺ you could send it to the "chat" API and trust that the server will format it correctly,
⏺ or you could format it yourself and send it to the "generation" API.

🔵Example of prompt formatting?
Suppose your system prompt and dialog look like this:

System Prompt/Instructions: when I give you a number, respond with its double
User (You): 3
Assistant (LLM): 6
User (You): 9

Mistral-instruct models expect this chat to be formatted like this
(note that the system message is combined with the first user message):
"<s>[INST] when I give you a number, respond with its double 3 [/INST] 6 [INST] 9 [/INST]"

🔵Why does it matter?
It matters A LOT -- because each type of LLM (llama2, mistral, etc) has
been trained and/or fine-tuned on chats formatted in a SPECIFIC way, and if you
deviate from that, you may get odd/inferior results.

🔵Using Mistral-7b-instruct-v0.2 via oobabooga/text-generation-webui
"Ooba" is a great library (https://github.com/oobabooga/text-generation-webui)
that lets you spin up an OpenAI-like API server for
local models, such as llama2, mistral, etc. When we used its chat endpoint
for a Langroid Agent, we were getting really strange results,
with the LLM sometimes thinking it is the user! 😧

Digging in, we found that their internal formatting template was
wrong, and it was formatting the system prompt as if it's
the first user message -- this leads to the LLM interpreting the first user
message as an assistant response, and so on -- no wonder there was role confusion!

💥Langroid solution:
To avoid these issues, in Langroid we now have a formatter
(https://github.com/langroid/langroid/blob/main/langroid/language_models/prompt_formatter/hf_formatter.py)
that retrieves the HuggingFace tokenizer for the LLM and uses
its "apply_chat_template" method to format chats.
This gives you control over the chat format and you can use the "generation"
endpoint of the LLM API instead of the "chat" endpoint.

Once we switched to this, results improved dramatically 🚀

Be sure to checkout Langroid https://github.com/langroid/langroid

#llm #ai #opensource 
>>>> docs/blog/posts/local-llm.md
---
title: 'Using Langroid with Local LLMs'
draft: false
date: 2023-09-14
authors: 
  - pchalasani
categories:
  - langroid
  - llm
  - local-llm
comments: true
---
## Why local models?
There are commercial, remotely served models that currently appear to beat all open/local
models. So why care about local models? Local models are exciting for a number of reasons:

<!-- more -->

- **cost**: other than compute/electricity, there is no cost to use them.
- **privacy**: no concerns about sending your data to a remote server.
- **latency**: no network latency due to remote API calls, so faster response times, provided you can get fast enough inference.
- **uncensored**: some local models are not censored to avoid sensitive topics.
- **fine-tunable**: you can fine-tune them on private/recent data, which current commercial models don't have access to.
- **sheer thrill**: having a model running on your machine with no internet connection,
  and being able to have an intelligent conversation with it -- there is something almost magical about it.

The main appeal with local models is that with sufficiently careful prompting,
they may behave sufficiently well to be useful for specific tasks/domains,
and bring all of the above benefits. Some ideas on how you might use local LLMs:

- In a multi-agent system, you could have some agents use local models for narrow 
  tasks with a lower bar for accuracy (and fix responses with multiple tries).
- You could run many instances of the same or different models and combine their responses.
- Local LLMs can act as a privacy layer, to identify and handle sensitive data before passing to remote LLMs.
- Some local LLMs have intriguing features, for example llama.cpp lets you 
  constrain its output using a grammar.

## Running LLMs locally

There are several ways to use LLMs locally. See the [`r/LocalLLaMA`](https://www.reddit.com/r/LocalLLaMA/comments/11o6o3f/how_to_install_llama_8bit_and_4bit/) subreddit for
a wealth of information. There are open source libraries that offer front-ends
to run local models, for example [`oobabooga/text-generation-webui`](https://github.com/oobabooga/text-generation-webui)
(or "ooba-TGW" for short) but the focus in this tutorial is on spinning up a
server that mimics an OpenAI-like API, so that any code that works with
the OpenAI API (for say GPT3.5 or GPT4) will work with a local model,
with just a simple change: set `openai.api_base` to the URL where the local API
server is listening, typically `http://localhost:8000/v1`.

There are a few libraries we recommend for setting up local models with OpenAI-like APIs:

- [LiteLLM OpenAI Proxy Server](https://docs.litellm.ai/docs/proxy_server) lets you set up a local 
  proxy server for over 100+ LLM providers (remote and local).
- [ooba-TGW](https://github.com/oobabooga/text-generation-webui) mentioned above, for a variety of models, including llama2 models.
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) (LCP for short), specifically for llama2 models.
- [ollama](https://github.com/jmorganca/ollama)

We recommend visiting these links to see how to install and run these libraries.

## Use the local model with the OpenAI library

Once you have a server running using any of the above methods, 
your code that works with the OpenAI models can be made to work 
with the local model, by simply changing the `openai.api_base` to the 
URL where the local server is listening. 

If you are using Langroid to build LLM applications, the framework takes
care of the `api_base` setting in most cases, and you need to only set
the `chat_model` parameter in the LLM config object for the LLM model you are using.
See the [Non-OpenAI LLM tutorial](../../tutorials/non-openai-llms.md) for more details.



<iframe src="https://langroid.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>




>>>> docs/blog/posts/malade.md
---
title: 'MALADE: Multi-Agent Architecture for Pharmacovigilance'
draft: false
date: 2024-08-12
authors:
- jihye
- nils
- pchalasani
- mengelhard
- someshjha
- anivaryakumar
- davidpage

categories:
- langroid
- multi-agent
- neo4j
- rag
comments: true
---

# MALADE: Multi-Agent Architecture for Pharmacovigilance

[Published in ML for HealthCare 2024](https://www.mlforhc.org/2024-abstracts)

[Arxiv](https://arxiv.org/abs/2408.01869) 

[GitHub](https://github.com/jihyechoi77/malade)

## Summary
We introduce MALADE (**M**ultiple **A**gents powered by **L**LMs for **ADE** Extraction),
a multi-agent system for Pharmacovigilance. It is the first effective explainable 
multi-agent LLM system for extracting Adverse Drug Events (ADEs) from FDA drug labels and drug prescription data.
<!-- more -->
Given a drug category and an adverse outcome, MALADE
produces:

- a qualitative label of risk (`increase`, `decrease` or `no-effect`),
- confidence in the label (a number in $[0,1]$),
- frequency of effect (`rare`, `common`, or `none`),
- strength of evidence (`none`, `weak`, or `strong`), and
- a justification with citations.

This task is challenging for several reasons: 

- FDA labels and prescriptions are for individual drugs, not drug categories, so representative drugs in a category 
  need to be identified from patient prescription data, and ADE information found for specific drugs in a category 
  needs to be aggregated to make a statement about the category as a whole, 
- The data is noisy, with variations in the terminologies of drugs and outcomes, and 
- ADE descriptions are often buried in large amounts of narrative text.

The MALADE architecture is LLM-agnostic 
and leverages the [Langroid](https://github.com/langroid/langroid) multi-agent framework.
It consists of a combination of Agents using Retrieval Augmented Generation (RAG), that 
iteratively improve their answers based on feedback from Critic Agents.
We evaluate the quantitative scores against 
a ground-truth dataset known as the [*OMOP Ground Truth Task*](https://www.niss.org/sites/default/files/Session3-DaveMadigan_PatrickRyanTalk_mar2015.pdf)
and find that MALADE achieves state-of-the-art performance.



## Introduction

In the era of Large Language Models (LLMs), given their remarkable text understanding and generation abilities, 
there is an unprecedented opportunity to develop new, LLM-based methods for trustworthy medical knowledge synthesis, 
extraction and summarization. The focus of this paper is Pharmacovigilance, a critical task in healthcare, where 
the goal is to monitor and evaluate the safety of drugs. In particular, the identification of Adverse Drug Events 
(ADEs) is crucial for ensuring patient safety. Consider a question such as this:

> What is the effect of **ACE inhibitors** on the risk of developing **angioedema**?

Here the **drug category** $C$ is _ACE inhibitors_, and the **outcome** $O$ is _angioedema_.
Answering this question involves several steps:

- **1(a): Find all drugs** in the ACE inhibitor category $C$, e.g. by searching the FDA 
[National Drug Code](https://www.fda.gov/drugs/drug-approvals-and-databases/national-drug-code-directory) (NDC) 
   database. This can be done using Elastic-Search, with filters to handle variations in drug/category names and inaccurate classifications.
- **1(b): Find the prescription frequency** of each drug in $C$ from patient prescription data, e.g. 
the [MIMIC-IV](https://physionet.org/content/mimiciv/3.0/) database. This can be done with a SQL query.
- **1(c): Identify the representative drugs** $D \subset C$ in this category, based on prescription frequency data 
     from step 2.  
- **2:** For each drug $d \in D$, **summarize ADE information** about the effect of $d$ on the outcome $O$ of interest,
   (in this case angioedema) from text-based pharmaceutical sources, 
    e.g. the [OpenFDA Drug Label](https://open.fda.gov/apis/drug/label/) database.
- **3: Aggregate** the information from all drugs in $D$ to make a statement about the category $C$ as a whole.


## The role of LLMs

While steps 1(a) and 1(b) can be done by straightforward deterministic algorithms (SQL queries or Elastic-Search), the 
remaining steps are challenging but ideally suited to LLMs:

### Step 1(c): Identifying representative drugs in a category from prescription frequency data (`DrugFinder` Agent)

This is complicated by noise, such as the same drug appearing multiple times under different names, 
formulations or delivery methods (For example, the ACE inhibitor **Lisinopril** is also known as **Zestril** and **Prinivil**.) 
  Thus a judgment must
  be made as to whether these are sufficiently different to be considered pharmacologically distinct;
  and some of these drugs may not actually belong to the category. This task thus requires a grouping operation, 
  related to the task of identifying standardized drug codes from text descriptions,
  well known to be challenging. This makes it very difficult to explicitly define the algorithm in a deterministic 
  manner that covers all edge cases (unlike the above database tasks), and hence is well-suited
  to LLMs, particularly those such as GPT-4, Claude3.5, and similar-strength variants which are known to have been 
  trained on vast amounts of general medical texts. 

In MALADE, this task is handled by the `DrugFinder` agent,
which is an Agent/Critic system where the main agent iteratively improves its output
in a feedback loop with the Critic agent. For example, the Critic corrects the Agent when it incorrectly
classifies drugs as pharmacologically distinct.

###  Step 2: Identifying Drug-Outcome Associations (`DrugOutcomeInfoAgent`)

The task here is to identify whether a given drug
has an established effect on the risk of a given outcome, based on FDA drug label database, and
output a summary of relevant information, including the level of identified risk and the evidence for
such an effect. Since this task involves extracting information from narrative text, it is well-suited to
LLMs using the Retrieval Augmented Generation (RAG) technique. 

In MALADE, the `DrugOutcomeInfoAgent` handles this task, and is also an Agent/Critic system, where the Critic
provides feedback and corrections to the Agent's output.
This agent does not have direct access to the FDA Drug Label data, but can receive
this information via another agent, `FDAHandler`. FDAHandler is equipped with **tools** (also known as function-calls) 
to invoke the OpenFDA API for drug label data, and answers questions in the context of information retrieved
based on the queries. Information received from this API is ingested into a vector database, so the
agent first uses a tool to query this vector database, and only resorts to the OpenFDA API tool if
the vector database does not contain the relevant information. An important aspect of this agent is that
its responses include specific **citations** and **excerpts** justifying its conclusions.

###  Step 3: Labeling Drug Category-Outcome Associations (`CategoryOutcomeRiskAgent`)

To identify association between a drug category C and an adverse health outcome $O$, we concurrently run a batch of 
queries to copies of `DrugOutcomeInfoAgent`, one for each drug $d$ in the
representative-list $D$ for the category, of the form: 

> Does drug $d$ increase or decrease the risk of condition $O$?

The results are sent to `CategoryOutcomeRiskAgent`, 
which is an Agent/Critic system which performs the final classification
step; its goal is to generate the qualitative and quantitative outputs mentioned above.

## MALADE Architecture

The figure below illustrates how the MALADE architecture handles the query,

> What is the effect of **ACE inhibitors** on the risk of developing **angioedema**?

![malade-arch.png](figures/malade-arch.png)

The query triggers a sequence of subtasks performed by the three Agents described above: 
`DrugFinder`, `DrugOutcomeInfoAgent`, and `CategoryOutcomeRiskAgent`.
Each Agent generates a response and justification, which are validated by a corresponding Critic agent, whose feedback is
used by the Agent to revise its response.

## Evaluation

### OMOP Ground Truth

We evaluate the results of MALADE against a well-established ground-truth dataset, 
the [OMOP ADE ground-truth table](https://www.niss.org/sites/default/files/Session3-DaveMadigan_PatrickRyanTalk_mar2015.pdf), shown below.
This is a reference dataset within the Observational Medical Outcomes Partnership (OMOP) Common Data Model that 
contains validated information about known adverse drug events.

![omop-ground-truth.png](figures/omop-ground-truth.png)

### Confusion Matrix

Below is a side-by-side comparison of this ground-truth dataset (left) with MALADE's labels (right), ignoring blue 
cells (see the paper for details):

![omop-results.png](figures/omop-results.png)

The resulting confusion-matrix for MALADE is shown below:

![confusion.png](figures/confusion.png)

### AUC Metric

Since MALADE produces qualitative and quantitative outputs, the paper explores a variety of ways to evaluate its
performance against the OMOP ground-truth dataset. Here we focus on the label output $L$ (i.e. `increase`, 
`decrease`, or `no-effect`), and its associated confidence score $c$, and use the Area Under the ROC Curve (AUC) as 
the evaluation metric.
The AUC metric is designed for binary classification, so we transform the three-class label output $L$ and
confidence score $c$ to a binary classification score $p$ as follows.
We treat $L$ = `increase` as the positive class,
and $L$ = `decrease` or `no-effect` as the negative class, and
we transform the label confidence score $c$ into a probability $p$ of `increase` as follows:


- if the label output is `increase`, $p = (2+c)/3$,
- if the label output is `no-effect`, $p = (2-c)/3$, and
- if the label output is `decrease` , $p = (1-c)/3$.

These transformations align with two intuitions: (a) a *higher* confidence in `increase` corresponds
to a *higher* probability of `increase`, and a *higher* confidence in `no-effect` or `decrease`
corresponds to a *lower* probability of `increase`, and (b) for a given confidence score $c$, the progression
of labels `decrease`, `no-effect`, and `increase` corresponds to *increasing* probabilities of `increase`.
The above transformations ensure that the probability $p$ is in the range $[0,1]$ and scales linearly with the
confidence score $c$.

We ran the full MALADE system for all drug-category/outcome pairs in the OMOP ground-truth dataset, 
and then computed the AUC for the score $p$ against the ground-truth binary classification label.
With `GPT-4-Turbo` we obtained an AUC of 0.85, while `GPT-4o` resulted in an AUC of 0.90.
These are state-of-the-art results for this specific ADE-extraction task.


### Ablations

An important question the paper investigates is whether (and how much) the various components (RAG, critic agents, etc)
contribute to MALADE's performance. To answer this, we perform ablations, where we remove one or more
components from the MALADE system and evaluate the performance of the resulting system.
For example we found that dropping the Critic agents reduces the AUC (using `GPT-4-Turbo`) from 0.85 to 0.82
(see paper, Appendix D for more ablation results).

### Variance of LLM-generated Scores

When using an LLM to generate numerical scores, it is important to understand the variance in the scores.
For example, if a single "full" run of MALADE (i.e. for all drug-category/outcome pairs in the OMOP ground-truth
dataset) produces a certain AUC, was it a "lucky" run, or is the AUC relatively stable across runs?
Ideally one would investigate this by repeating the full run of MALADE many times,  
but given the expense of running a full experiment, we focus on just three representative cells in the OMOP table,
one corresponding to each possible ground-truth label, and run MALADE 10 times for each cells, and
study the distribution of $p$ (the probability of increased risk, translated from the confidence score using the
method described above), for each output label. Encouragingly, we find that the distribution of $p$ shows clear
separation between the three labels, as in the figure below (The $x$ axis ranges from 0 to 1, and the three colored
groups of bars represent, from left to right, `decrease`, `no-effect`, and `increase` labels). Full details are in 
the Appendix D of the paper.

![img.png](figures/variance-histogram.png)









>>>> docs/blog/posts/multi-agent-debate.md
---
title: 'Multi Agent Debate and Education Platform'
draft: false
date: 2025-02-04
authors: 
  - adamshams
categories:
  - langroid
  - llm
  - local-llm
  - chat
comments: true
---

## Introduction
Have you ever imagined a world where we can debate complex issues with Generative AI agents taking a distinct 
stance and backing their arguments with evidence? Some will change your mind, and some will reveal the societal biases 
on which each distinctive Large Language Model (LLM) is trained on. Introducing an [AI-powered debate platform](https://github.com/langroid/langroid/tree/main/examples/multi-agent-debate) that brings 
this imagination to reality, leveraging diverse LLMs and the Langroid multi-agent programming framework. The system enables users to engage in structured debates with an AI taking the opposite stance (or even two AIs debating each other), using a multi-agent architecture with Langroid's powerful framework, where each agent embodies a specific ethical perspective, creating realistic and dynamic interactions. 
Agents are prompt-engineered and role-tuned to align with their assigned ethical stance, 
ensuring thoughtful and structured debates. 

<!-- more -->

My motivations for creating this platform included: 

  - A debate coach for underserved students without access to traditional resources. 
  - Tool for research and generating arguments from authentic sources. 
  - Create an adaptable education platform to learn two sides of the coin for any topic.
  - Reduce echo chambers perpetuated by online algorithms by fostering two-sided debates on any topic, promoting education and awareness around misinformation. 
  - Provide a research tool to study the varieties of biases in LLMs that are often trained on text reflecting societal biases. 
  - Identify a good multi-agent framework designed for programming with LLMs.


## Platform Features:
### Dynamic Agent Generation:
The platform features five types of agents: Pro, Con, Feedback, Research, and Retrieval Augmented Generation (RAG) Q&A. 
Each agent is dynamically generated using role-tuned and engineered prompts, ensuring diverse and engaging interactions.
#### Pro and Con Agents: 
These agents engage in the core debate, arguing for and against the chosen topic. 
Their prompts are carefully engineered to ensure they stay true to their assigned ethical stance.
#### Feedback Agent: 
This agent provides real-time feedback on the arguments and declares a winner. The evaluation criteria are based on the well-known Lincoln–Douglas debate format, and include:

  - Clash of Values 
  - Argumentation 
  - Cross-Examination 
  - Rebuttals 
  - Persuasion 
  - Technical Execution 
  - Adherence to Debate Etiquette 
  - Final Focus
#### Research Agent: 
This agent has the following functionalities:

  - Utilizes the `MetaphorSearchTool` and the `Metaphor` (now called `Exa`) Search API to conduct web searches combined with
Retrieval Augmented Generation (RAG) to relevant web references for user education about the selected topic. 
  - Produces a summary of arguments for and against the topic.
  - RAG-based document chat with the resources identified through Web Search. 
#### RAG Q&A Agent:

  - Provides Q&A capability using a RAG based chat interaction with the resources identified through Web Search.
The agent utilizes `DocChatAgent` that is part of Langroid framework which orchestrates all LLM interactions. 
  - Rich chunking parameters allows the user to get optimized relevance results. Check out `config.py`for details.

### Topic Adaptability:
Easily adaptable to any subject by simply adding pro and con system messages. This makes it a versatile tool for
exploring diverse topics and fostering critical thinking. Default topics cover ethics and use of AI for the following:
  - Healthcare
  - Intellectual property 
  - Societal biases 
  - Education
### Autonomous or Interactive:
Engage in manual debate with a pro or con agent or watch it autonomously while adjusting number of turns.

### Diverse LLM Selection Adaptable per Agent: 
Configurable to select from diverse commercial and open source models: OpenAI, Google, and Mistral 
to experiment with responses for diverse perspectives. Users can select a unique LLM for each agent. 
       
### LLM Tool/Function Integration: 
Utilizes LLM tools/functions features to conduct semantic search using Metaphor Search API and summarizes the pro and 
con perspectives for education.

### Configurable LLM Parameters: 
Parameters like temperature, minimum and maximum output tokens, allowing for customization of the AI's responses.
Configurable LLM parameters like temperature, min & max output tokens. For Q&A with the searched resources, several
parameters can be tuned in the `config` to enhance response relevance.

### Modular Design: 
Reusable code and modularized for other LLM applications.


## Interaction
1. Decide if you want to you use same LLM for all agents or different ones
2. Decide if you want autonomous debate between AI Agents or user vs. AI Agent. 
3. Select a debate topic.
4. Choose your side (Pro or Con).
5. Engage in a debate by providing arguments and receiving responses from agents.
6. Request feedback at any time by typing `f`.
7. Decide if you want the Metaphor Search to run to find Topic relevant web links
   and summarize them. 
8. Decide if you want to chat with the documents extracted from URLs found to learn more about the Topic.
9. End the debate manually by typing `done`. If you decide to chat with the documents, you can end session
by typing `x`

## Why was Langroid chosen?
I chose Langroid framework because it's a principled multi-agent programming framework inspired by the Actor framework.
Prior to using Langroid, I developed a multi-agent debate system, however, I had to write a lot of tedious code to manage states of communication between
debating agents, and the user interactions with LLMs. Langroid allowed me to seamlessly integrate multiple LLMs,
easily create agents, tasks, and attach sub-tasks. 

### Agent Creation Code Example

```python
   def create_chat_agent(name: str, llm_config: OpenAIGPTConfig, system_message: str) -> ChatAgent:
   
    return ChatAgent(
        ChatAgentConfig(
            llm=llm_config,
            name=name,
            system_message=system_message,
        )
    )
```
#### Sample Pro Topic Agent Creation

```python
 
    pro_agent = create_chat_agent(
        "Pro",
        pro_agent_config,
        system_messages.messages[pro_key].message + DEFAULT_SYSTEM_MESSAGE_ADDITION,
    )
    
```
The `Task` mechanism in Langroid provides a robust mechanism for managing complex interactions within multi-agent 
systems. `Task` serves as a container for managing the flow of interactions between different agents
(such as chat agents) and attached sub-tasks.`Task` also helps with turn-taking, handling responses, 
and ensuring smooth transitions between dialogue states. Each Task object is responsible for coordinating responses 
from its assigned agent, deciding the sequence of responder methods (llm_response, user_response, agent_response), 
and managing transitions between different stages of a conversation or debate. Each agent can focus on its specific 
role while the task structure handles the overall process's orchestration and flow, allowing a clear separation of 
concerns. The architecture and code transparency of Langroid's framework make it an incredible candidate for 
applications like debates where multiple agents must interact dynamically and responsively
based on a mixture of user inputs and automated responses.

### Task creation and Orchestration Example

```python
    user_task = Task(user_agent, interactive=interactive_setting, restart=False)
    ai_task = Task(ai_agent, interactive=False, single_round=True)
    user_task.add_sub_task(ai_task)
    if not llm_delegate:
        user_task.run(user_agent.user_message, turns=max_turns)
    else:
        user_task.run("get started", turns=max_turns)
    
```
Tasks can be easily set up as sub-tasks of an orchestrating agent. In this case user_task could be Pro or Con depending 
on the user selection. 

If you want to build custom tools/functions or use Langroid provided it is only a line of code using
`agent.enable_messaage`. Here is an example of `MetaphorSearchTool` and `DoneTool`. 
```python
        metaphor_search_agent.enable_message(MetaphorSearchTool)
        metaphor_search_agent.enable_message(DoneTool)
```

Overall I had a great learning experience using Langroid and recommend using it for any projects 
that need to utilize LLMs. I am already working on a few Langroid based information retrieval and research systems 
for use in medicine and hoping to contribute more soon. 

### Bio

I'm a high school senior at Khan Lab School located in Mountain View, CA where I host a student-run Podcast known as the
Khan-Cast. I also enjoy tinkering with interdisciplinary STEM projects. You can reach me on [LinkedIn](https://www.linkedin.com/in/adamshams/).


>>>> docs/blog/posts/test.md
---
draft: true
date: 2022-01-31
authors: 
  - pchalasani
categories:
  - test
  - blog
comments: true
---

# Test code snippets

```python
from langroid.language_models.base import LLMMessage, Role
msg = LLMMessage(
        content="What is the capital of Bangladesh?",
        role=Role.USER,
      )
```

<!-- more -->


# Test math notation

A nice equation is $e^{i\pi} + 1 = 0$, which is known as Euler's identity.
Here is a cool equation too, and in display mode:

$$
e = mc^2
$$

# Latex with newlines

Serious latex with `\\` for newlines renders fine:

$$
\begin{bmatrix}
a & b 
c & d 
e & f 
\end{bmatrix}
$$

or a multi-line equation

$$
\begin{aligned}
\dot{x} & = \sigma(y-x) 
\dot{y} & = \rho x - y - xz 
\dot{z} & = -\beta z + xy
\end{aligned}
$$

<iframe src="https://langroid.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>



>>>> docs/demos/targeting/audience-targeting.md
# Audience Targeting for a Business

Suppose you are a marketer for a business, trying to figure out which 
audience segments to target.
Your downstream systems require that you specify _standardized_ audience segments
to target, for example from the [IAB Audience Taxonomy](https://iabtechlab.com/standards/audience-taxonomy/).

There are thousands of standard audience segments, and normally you would need 
to search the list for potential segments that match what you think your ideal
customer profile is. This is a tedious, error-prone task.

But what if we can leverage an LLM such as GPT-4?
We know that GPT-4 has  skills that are ideally suited for this task:

- General knowledge about businesses and their ideal customers
- Ability to recognize which standard segments match an English description of a customer profile
- Ability to plan a conversation to get the information it needs to answer a question


Once you decide to use an LLM, you still need to figure out how to organize the 
various components of this task:

- **Research:** What are some ideal customer profiles for the business
- **Segmentation:** Which standard segments match an English description of a customer profile
- **Planning:** how to organize the task to identify a few standard segments

## Using Langroid Agents 

Langroid makes it intuitive and simple to build an LLM-powered system organized
around agents, each responsible for a different task.
In less than a day we built a 3-agent system to automate this task:

- The `Marketer` Agent is given the Planning role.
- The `Researcher` Agent is given the Research role, 
  and it has access to the business description. 
- The `Segmentor` Agent is given the Segmentation role. It has access to the 
  IAB Audience Taxonomy via a vector database, i.e. its rows have been mapped to
  vectors via an embedding model, and these vectors are stored in a vector-database. 
  Thus given an English description of a customer profile,
  the `Segmentor` Agent maps it to a vector using the embedding model,
  and retrieves the nearest (in vector terms, e.g. cosine similarity) 
  IAB Standard Segments from the vector-database. The Segmentor's LLM 
  further refines this by selecting the best-matching segments from the retrieved list.

To kick off the system, the human user describes a business in English,
or provides the URL of the business's website. 
The `Marketer` Agent sends
customer profile queries to the `Researcher`, who answers in plain English based on 
the business description, and the Marketer takes this description and sends it to the Segmentor,
who maps it to Standard IAB Segments. The task is done when the Marketer finds 4 Standard segments. 
The agents are depicted in the diagram below:

![targeting.png](targeting.png)

## An example: Glashutte Watches

The human user first provides the URL of the business, in this case:
```text
https://www.jomashop.com/glashutte-watches.html
```
From this URL, the `Researcher` agent summarizes its understanding of the business.
The `Marketer` agent starts by asking the `Researcher`:
``` 
Could you please describe the age groups and interests of our typical customer?
```
The `Researcher` responds with an English description of the customer profile:
```text
Our typical customer is a fashion-conscious individual between 20 and 45 years...
```
The `Researcher` forwards this English description to the `Segmentor` agent, who
maps it to a standardized segment, e.g.:
```text
Interest|Style & Fashion|Fashion Trends
...
```
This conversation continues until the `Marketer` agent has identified 4 standardized segments.

Here is what the conversation looks like:

![targeting.gif](targeting.gif)


>>>> docs/examples/agent-tree.md
# Hierarchical computation with Langroid Agents 

Here is a simple example showing tree-structured computation
where each node in the tree is handled by a separate agent.
This is a toy numerical example, and illustrates:

- how to have agents organized in a hierarchical structure to accomplish a task 
- the use of global state accessible to all agents, and 
- the use of tools/function-calling.

## The Computation 

We want to carry out the following calculation for a given input number $n$:

```python
def Main(n):
    if n is odd:
        return (3*n+1) + n
    else:
        if n is divisible by 10:
            return n/10 + n
        else:
            return n/2 + n
```

## Using function composition

Imagine we want to do this calculation using a few auxiliary functions:

```python
def Main(n):
    # return non-null value computed by Odd or Even
    Record n as global variable # to be used by Adder below
    return Odd(n) or Even(n)

def Odd(n):
    # Handle odd n
    if n is odd:
        new = 3*n+1
        return Adder(new)
    else:
        return None
    
def Even(n):
    # Handle even n: return non-null value computed by EvenZ or EvenNZ
    return EvenZ(n) or EvenNZ(n)

def EvenZ(n):
    # Handle even n divisible by 10, i.e. ending in Zero
    if n is divisible by 10:
        new = n/10
        return Adder(new)
    else:
        return None
    
def EvenNZ(n):
    # Handle even n not divisible by 10, i.e. not ending in Zero
    if n is not divisible by 10:
        new = n/2
        return Adder(new)
    else:
        return None  

def Adder(new):
    # Add new to starting number, available as global variable n
    return new + n
```

## Mapping to a tree structure

This compositional/nested computation can be represented as a tree:

```plaintext
       Main
     /     \
  Even     Odd
  /   \        \
EvenZ  EvenNZ   Adder
  |      |
 Adder  Adder
```

Let us specify the behavior we would like for each node, in a 
"decoupled" way, i.e. we don't want a node to be aware of the other nodes.
As we see later, this decoupled design maps very well onto Langroid's
multi-agent task orchestration. To completely define the node behavior,
we need to specify how it handles an "incoming" number $n$ (from a parent node 
or user), and how it handles a "result" number $r$ (from a child node).

- `Main`: 
    - incoming $n$: simply send down $n$, record the starting number $n_0 = n$ as a global variable. 
    - result $r$: return $r$.
- `Odd`: 
    - incoming $n$: if n is odd, send down $3*n+1$, else return None
    - result $r$: return $r$
- `Even`: 
    - incoming $n$: if n is even, send down $n$, else return None
    - result $r$: return $r$
- `EvenZ`: (guaranteed by the tree hierarchy, to receive an even number.)  
    - incoming $n$: if n is divisible by 10, send down $n/10$, else return None
    - result $r$: return $r$
- `EvenNZ`: (guaranteed by the tree hierarchy, to receive an even number.)
    - incoming $n$: if n is not divisible by 10, send down $n/2$, else return None
    - result $r$: return $r$
- `Adder`:
    - incoming $n$: return $n + n_0$ where $n_0$ is the 
    starting number recorded by Main as a global variable.
    - result $r$: Not applicable since `Adder` is a leaf node.
  
## From tree nodes to Langroid Agents 

Let us see how we can perform this calculation using multiple Langroid agents, where

- we define an agent corresponding to each of the nodes above, namely 
`Main`, `Odd`, `Even`, `EvenZ`, `EvenNZ`, and `Adder`.
- we wrap each Agent into a Task, and use the `Task.add_subtask()` method to connect the agents into 
  the desired hierarchical structure.

Below is one way to do this using Langroid. We designed this with the following
desirable features:

- Decoupling: Each agent is instructed separately, without mention of any other agents
  (E.g. Even agent does not know about Odd Agent, EvenZ agent, etc).
  In particular, this means agents will not be "addressing" their message
  to specific other agents, e.g. send number to Odd agent when number is odd,
  etc. Allowing addressing would make the solution easier to implement,
  but would not be a decoupled solution.
  Instead, we want Agents to simply put the number "out there", and have it handled
  by an applicable agent, in the task loop (which consists of the agent's responders,
  plus any sub-task `run` methods).

- Simplicity: Keep the agent instructions relatively simple. We would not want a solution
  where we have to instruct the agents (their LLMs) in convoluted ways. 

One way naive solutions fail is because agents are not able to distinguish between
a number that is being "sent down" the tree as input, and a number that is being
"sent up" the tree as a result from a child node.

We use a simple trick: we instruct the LLM to mark returned values using the RESULT keyword,
and instruct the LLMs on how to handle numbers that come with RESULT keyword, and those that don't
In addition, we leverage some features of Langroid's task orchestration:

- When `llm_delegate` is `True`, if the LLM says `DONE [rest of msg]`, the task is
  considered done, and the result of the task is `[rest of msg]` (i.e the part after `DONE`).
- In the task loop's `step()` function (which seeks a valid message during a turn of
  the conversation) when any responder says `DO-NOT-KNOW`, it is not considered a valid
  message, and the search continues to other responders, in round-robin fashion.



See the [`chat-tree.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat-tree.py)
example for an implementation of this solution. You can run that example as follows:
```bash
python3 examples/basic/chat-tree.py
```
In the sections below we explain the code in more detail.

## Define the agents

Let us start with defining the configuration to be used by all agents:

```python
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.language_models.openai_gpt import OpenAIChatModel, OpenAIGPTConfig

config = ChatAgentConfig(
  llm=OpenAIGPTConfig(
    chat_model=OpenAIChatModel.GPT4o,
  ),
  vecdb=None, # no need for a vector database
)
```

Next we define each of the agents, for example:

```python
main_agent = ChatAgent(config)
```

and similarly for the other agents.

## Wrap each Agent in a Task

To allow agent interactions, the first step is to wrap each agent in a Task.
When we define the task, we pass in the instructions above as part of the system message.
Recall the instructions for the `Main` agent:

- `Main`:
    - incoming $n$: simply send down $n$, record the starting number $n_0 = n$ as a global variable.
    - result $r$: return $r$.

We include the equivalent of these instructions in the `main_task` that wraps 
the `main_agent`:

```python
from langroid.agent.task import Task

main_task = Task(
    main_agent,
    name="Main",
    interactive=False, #(1)!
    system_message="""
          You will receive two types of messages, to which you will respond as follows:
          
          INPUT Message format: <number>
          In this case simply write the <number>, say nothing else.
          
          RESULT Message format: RESULT <number>
          In this case simply say "DONE <number>", e.g.:
          DONE 19
    
          To start off, ask the user for the initial number, 
          using the `ask_num` tool/function.
          """,
    llm_delegate=True, # allow LLM to control end of task via DONE
    single_round=False,
)
```

1. Non-interactive: don't wait for user input in each turn 

There are a couple of points to highlight about the `system_message` 
value in this task definition:

- When the `Main` agent receives just a number, it simply writes out that number,
  and in the Langroid Task loop, this number becomes the "current pending message"
  to be handled by one of the sub-tasks, i.e. `Even, Odd`. Note that these sub-tasks
  are _not_ mentioned in the system message, consistent with the decoupling principle.
- As soon as either of these sub-tasks returns a non-Null response, in the format "RESULT <number>", the `Main` agent
  is instructed to return this result saying "DONE <number>". Since `llm_delegate`
  is set to `True` (meaning the LLM can decide when the task has ended), 
  this causes the `Main` task to be considered finished and the task loop is exited.

Since we want the `Main` agent to record the initial number as a global variable,
we use a tool/function `AskNum` defined as follows 
(see [this section](../quick-start/chat-agent-tool.md) in the getting started guide 
for more details on Tools):

```python
from rich.prompt import Prompt
from langroid.agent.tool_message import ToolMessage


class AskNumTool(ToolMessage):
  request = "ask_num"
  purpose = "Ask user for the initial number"

  def handle(self) -> str:
    """
    This is a stateless tool (i.e. does not use any Agent member vars), so we can
    define the handler right here, instead of defining an `ask_num`
    method in the agent.
    """
    num = Prompt.ask("Enter a number")
    # record this in global state, so other agents can access it
    MyGlobalState.set_values(number=num)
    return str(num)
```

We then enable the `main_agent` to use and handle messages that conform to the 
`AskNum` tool spec:

```python
main_agent.enable_message(AskNumTool)
```

!!! tip "Using and Handling a tool/function"
    "Using" a tool means the agent's LLM _generates_ 
    the function-call (if using OpenAI function-calling) or 
    the JSON structure (if using Langroid's native tools mechanism) 
    corresponding to this tool. "Handling" a tool refers to the Agent's method 
    recognizing the tool and executing the corresponding code.


The tasks for other agents are defined similarly. We will only note here
that the `Adder` agent needs a special tool `AddNumTool` to be able to add the current number
to the initial number set by the `Main` agent. 

## Connect the tasks into a tree structure

So far, we have wrapped each agent in a task, in isolation, and there is no 
connection between the tasks. The final step is to connect the tasks to 
the tree structure we saw earlier:

```python
main_task.add_sub_task([even_task, odd_task])
even_task.add_sub_task([evenz_task, even_nz_task])
evenz_task.add_sub_task(adder_task)
even_nz_task.add_sub_task(adder_task)
odd_task.add_sub_task(adder_task)
```

Now all that remains is to run the main task:

```python
main_task.run()
```

Here is what a run starting with $n=12$ looks like:

![chat-tree.png](chat-tree.png)





>>>> docs/examples/guide.md
# Guide to examples in `langroid-examples` repo

!!! warning "Outdated"
    This guide is from Feb 2024; there have been numerous additional examples
    since then. We recommend you visit the `examples` folder in the core `langroid`
    repo for the most up-to-date examples. These examples are periodically copied
    over to the `examples` folder in the `langroid-examples` repo.

The [`langroid-examples`](https://github.com/langroid/langroid-examples) repo
contains several examples of using
the [Langroid](https://github.com/langroid/langroid) agent-oriented programming 
framework for LLM applications.
Below is a guide to the examples. First please ensure you follow the
installation instructions in the `langroid-examples` repo README.

**At minimum a GPT4-compatible OpenAI API key is required.** As currently set
up, many of the examples will _not_ work with a weaker model. Weaker models may
require more detailed or different prompting, and possibly a more iterative
approach with multiple agents to verify and retry, etc — this is on our roadmap.

All the example scripts are meant to be run on the command line.
In each script there is a description and sometimes instructions on how to run
the script.

NOTE: When you run any script, it pauses for “human” input at every step, and
depending on the context, you can either hit enter to continue, or in case there
is a question/response expected from the human, you can enter your question or
response and then hit enter.

### Basic Examples
- [`/examples/basic/chat.py`](https://github.com/langroid/langroid-examples/blob/main/examples/basic/chat.py) This is a basic chat application.

    - Illustrates Agent task loop.

- [`/examples/basic/autocorrect.py`](https://github.com/langroid/langroid-examples/blob/main/examples/basic/autocorrect.py) Chat with autocorrect: type fast and carelessly/lazily and 
the LLM will try its best to interpret what you want, and offer choices when confused.

    - Illustrates Agent task loop.

- [`/examples/basic/chat-search.py`](https://github.com/langroid/langroid-examples/blob/main/examples/basic/chat-search.py)  This uses a `GoogleSearchTool` function-call/tool to answer questions using a google web search if needed.
  Try asking questions about facts known after Sep 2021 (GPT4 training cutoff),
  like  `when was llama2 released`
  
    - Illustrates Agent + Tools/function-calling + web-search

- [`/examples/basic/chat-tree.py`](https://github.com/langroid/langroid-examples/blob/main/examples/basic/chat-tree.py) is a toy example of tree-structured multi-agent
  computation, see a detailed writeup [here.](https://langroid.github.io/langroid/examples/agent-tree/)
  
    - Illustrates multi-agent task collaboration, task delegation.

### Document-chat examples, or RAG (Retrieval Augmented Generation)

- [`/examples/docqa/chat.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat.py) is a document-chat application. Point it to local file,
  directory or web url, and ask questions
    - Illustrates basic RAG
- [`/examples/docqa/chat-search.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat-search.py): ask about anything and it will try to answer
  based on docs indexed in vector-db, otherwise it will do a Google search, and
  index the results in the vec-db for this and later answers.
    - Illustrates RAG + Function-calling/tools
- [`/examples/docqa/chat_multi.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat_multi.py):  — this is a 2-agent system that will summarize
  a large document with 5 bullet points: the first agent generates questions for
  the retrieval agent, and is done when it gathers 5 key points.
    - Illustrates 2-agent collaboration + RAG to summarize a document
- [`/examples/docqa/chat_multi_extract.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat_multi_extract.py):  — extracts structured info from a
  lease document: Main agent asks questions to a retrieval agent. 
    - Illustrates 2-agent collaboration, RAG, Function-calling/tools, Structured Information Extraction.

### Data-chat examples (tabular, SQL)

- [`/examples/data-qa/table_chat.py`](https://github.com/langroid/langroid-examples/blob/main/examples/data-qa/table_chat):  - point to a URL or local csv file and ask
  questions. The agent generates pandas code that is run within langroid.
    - Illustrates function-calling/tools and code-generation
- [`/examples/data-qa/sql-chat/sql_chat.py`](https://github.com/langroid/langroid-examples/blob/main/examples/data-qa/sql-chat/sql_chat.py):  — chat with a sql db — ask questions in
  English, it will generate sql code to answer them.
  See [tutorial here](https://langroid.github.io/langroid/tutorials/postgresql-agent/)
    - Illustrates function-calling/tools and code-generation


>>>> docs/index.md
# Langroid: Harness LLMs with Multi-Agent Programming

## The LLM Opportunity

Given the remarkable abilities of recent Large Language Models (LLMs), there
is an unprecedented opportunity to build intelligent applications powered by
this transformative technology. The top question for any enterprise is: how
best to harness the power of LLMs for complex applications? For technical and
practical reasons, building LLM-powered applications is not as simple as
throwing a task at an LLM-system and expecting it to do it.

## Langroid's Multi-Agent Programming Framework

Effectively leveraging LLMs at scale requires a *principled programming 
framework*. In particular, there is often a need to maintain multiple LLM 
conversations, each instructed in different ways, and "responsible" for 
different aspects of a task.

An *agent* is a convenient abstraction that encapsulates LLM conversation 
state, along with access to long-term memory (vector-stores) and tools (a.k.a functions 
or plugins). Thus a **Multi-Agent Programming** framework is a natural fit 
for complex LLM-based applications.

> Langroid is the first Python LLM-application framework that was explicitly 
designed  with Agents as first-class citizens, and Multi-Agent Programming 
as the core  design principle. The framework is inspired by ideas from the 
[Actor Framework](https://en.wikipedia.org/wiki/Actor_model).

Langroid allows an intuitive definition of agents, tasks and task-delegation 
among agents. There is a principled mechanism to orchestrate multi-agent 
collaboration. Agents act as message-transformers, and take turns responding to (and
transforming) the current message. The architecture is lightweight, transparent, 
flexible, and allows other types of orchestration to be implemented; see the (WIP) 
[langroid architecture document](blog/posts/langroid-architecture.md).
Besides Agents, Langroid also provides simple ways to directly interact with LLMs and vector-stores. See the Langroid [quick-tour](tutorials/langroid-tour.md).

## Highlights
- **Agents as first-class citizens:** The `Agent` class encapsulates LLM conversation state,
  and optionally a vector-store and tools. Agents are a core abstraction in Langroid; 
  Agents act as _message transformers_, and by default provide 3 _responder_ methods, one corresponding to each 
  entity: LLM, Agent, User. 
- **Tasks:** A Task class wraps an Agent, gives the agent instructions (or roles, or goals),
  manages iteration over an Agent's responder methods,
  and orchestrates multi-agent interactions via hierarchical, recursive
  task-delegation. The `Task.run()` method has the same
  type-signature as an Agent's responder's methods, and this is key to how
  a task of an agent can delegate to other sub-tasks: from the point of view of a Task,
  sub-tasks are simply additional responders, to be used in a round-robin fashion
  after the agent's own responders.
- **Modularity, Reusabilily, Loose coupling:** The `Agent` and `Task` abstractions allow users to design
  Agents with specific skills, wrap them in Tasks, and combine tasks in a flexible way.
- **LLM Support**: Langroid works with practically any LLM, local/open or remote/proprietary/API-based, via a variety of libraries and providers. See guides to using [local LLMs](tutorials/local-llm-setup.md) and [non-OpenAI LLMs](tutorials/non-openai-llms.md). See [Supported LLMs](tutorials/supported-models.md).
- **Caching of LLM prompts, responses:** Langroid by default uses [Redis](https://redis.com/try-free/) for caching. 
- **Vector-stores**: [Qdrant](https://qdrant.tech/), [Chroma](https://www.trychroma.com/) and [LanceDB](https://www.lancedb.com/) are currently supported.
  Vector stores allow for Retrieval-Augmented-Generation (RAG).
- **Grounding and source-citation:** Access to external documents via vector-stores
  allows for grounding and source-citation.
- **Observability, Logging, Lineage:** Langroid generates detailed logs of multi-agent interactions and
  maintains provenance/lineage of messages, so that you can trace back
  the origin of a message.
- **Tools/Plugins/Function-calling**: Langroid supports OpenAI's recently
  released [function calling](https://platform.openai.com/docs/guides/gpt/function-calling)
  feature. In addition, Langroid has its own native equivalent, which we
  call **tools** (also known as "plugins" in other contexts). Function
  calling and tools have the same developer-facing interface, implemented
  using [Pydantic](https://docs.pydantic.dev/latest/),
  which makes it very easy to define tools/functions and enable agents
  to use them. Benefits of using Pydantic are that you never have to write
  complex JSON specs for function calling, and when the LLM
  hallucinates malformed JSON, the Pydantic error message is sent back to
  the LLM so it can fix it!



Don't worry if some of these terms are not clear to you. 
The [Getting Started Guide](quick-start/index.md) and subsequent pages 
will help you get up to speed.

>>>> docs/javascripts/mathjax.js
window.MathJax = {
  tex: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    processEscapes: true,
    processEnvironments: true
  },
  options: {
    ignoreHtmlClass: ".*|",
    processHtmlClass: "arithmatex"
  }
};

document$.subscribe(() => { 
  MathJax.typesetPromise()
})

>>>> docs/notes/async-streaming.md
# Suppressing output in async, streaming mode

Available since version 0.18.0

When using an LLM API in streaming + async mode, you may want to suppress output,
especially when concurrently running multiple instances of the API.
To suppress output in async + stream mode, 
you can set the `async_stream_quiet` flag in [`LLMConfig`][langroid.language_models.base.LLMConfig]
to `True` (this is the default). 
Note that [`OpenAIGPTConfig`][langroid.language_models.openai_gpt.OpenAIGPTConfig]
inherits from `LLMConfig`, so you can use this flag with `OpenAIGPTConfig` as well:

```python
import langroid.language_models as lm
llm_config = lm.OpenAIGPTConfig(
    async_stream_quiet=True,
    ...
)
```


>>>> docs/notes/azure-openai-models.md
# Azure OpenAI Models

To use OpenAI models deployed on Azure, first ensure a few environment variables
are defined (either in your `.env` file or in your environment):

- `AZURE_OPENAI_API_KEY`, from the value of `API_KEY`
- `AZURE_OPENAI_API_BASE` from the value of `ENDPOINT`, typically looks like `https://your_resource.openai.azure.com`.
- For `AZURE_OPENAI_API_VERSION`, you can use the default value in `.env-template`, and latest version can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new#azure-openai-chat-completion-general-availability-ga)
- `AZURE_OPENAI_DEPLOYMENT_NAME` is an OPTIONAL deployment name which may be
  defined by the user during the model setup.
- `AZURE_OPENAI_CHAT_MODEL` Azure OpenAI allows specific model names when you select the model for your deployment. You need to put precisely the exact model name that was selected. For example, GPT-3.5 (should be `gpt-35-turbo-16k` or `gpt-35-turbo`) or GPT-4 (should be `gpt-4-32k` or `gpt-4`).
- `AZURE_OPENAI_MODEL_NAME` (Deprecated, use `AZURE_OPENAI_CHAT_MODEL` instead).

This page [Microsoft Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-python#environment-variables) 
provides more information on how to obtain these values.

To use an Azure-deployed model in Langroid, you can use the `AzureConfig` class:

```python
import langroid.language_models as lm
import langroid as lr

llm_config = lm.AzureConfig(
    chat_model="gpt-4o"
    # the other settings can be provided explicitly here, 
    # or are obtained from the environment
)
llm = lm.AzureGPT(config=llm_config)

response = llm.chat(
  messages=[
    lm.LLMMessage(role=lm.Role.SYSTEM, content="You are a helpful assistant."),
    lm.LLMMessage(role=lm.Role.USER, content="3+4=?"),
  ]
)

agent = lr.ChatAgent(
    lr.ChatAgentConfig(
        llm=llm_config,
        system_message="You are a helpful assistant.",
    )
)

response = agent.llm_response("is 4 odd?")  
print(response.content)  # "Yes, 4 is an even number."
response = agent.llm_response("what about 2?")  # follow-up question
```

>>>> docs/notes/chunking.md
# Document Chunking/Splitting in Langroid

Langroid's [`ParsingConfig`][langroid.parsing.parser.ParsingConfig]
provides several document chunking strategies through the `Splitter` enum:

## 1. MARKDOWN (`Splitter.MARKDOWN`) (The default)

**Purpose**: Structure-aware splitting that preserves markdown formatting.

**How it works**:

- Preserves document hierarchy (headers and sections)
- Enriches chunks with header information
- Uses word count instead of token count (with adjustment factor)
- Supports "rollup" to maintain document structure
- Ideal for markdown documents where preserving formatting is important

## 2. TOKENS (`Splitter.TOKENS`)

**Purpose**: Creates chunks of approximately equal token size.

**How it works**:

- Tokenizes the text using tiktoken
- Aims for chunks of size `chunk_size` tokens (default: 200)
- Looks for natural breakpoints like punctuation or newlines
- Prefers splitting at sentence/paragraph boundaries
- Ensures chunks are at least `min_chunk_chars` long (default: 350)

## 3. PARA_SENTENCE (`Splitter.PARA_SENTENCE`)

**Purpose**: Splits documents respecting paragraph and sentence boundaries.

**How it works**:

- Recursively splits documents until chunks are below 1.3× the target size
- Maintains document structure by preserving natural paragraph breaks
- Adjusts chunk boundaries to avoid cutting in the middle of sentences
- Stops when it can't split chunks further without breaking coherence

## 4. SIMPLE (`Splitter.SIMPLE`)

**Purpose**: Basic splitting using predefined separators.

**How it works**:

- Uses a list of separators to split text (default: `["\n\n", "\n", " ", ""]`)
- Splits on the first separator in the list
- Doesn't attempt to balance chunk sizes
- Simplest and fastest splitting method


## Basic Configuration

```python
from langroid.parsing.parser import ParsingConfig, Splitter

config = ParsingConfig(
    splitter=Splitter.MARKDOWN,  # Most feature-rich option
    chunk_size=200,              # Target tokens per chunk
    chunk_size_variation=0.30,   # Allowed variation from target
    overlap=50,                  # Token overlap between chunks
    token_encoding_model="text-embedding-3-small"
)
```

## Format-Specific Configuration

```python
# Customize PDF parsing
config = ParsingConfig(
    splitter=Splitter.PARA_SENTENCE,
    pdf=PdfParsingConfig(
        library="pymupdf4llm"  # Default PDF parser
    )
)

# Use Gemini for PDF parsing
config = ParsingConfig(
    pdf=PdfParsingConfig(
        library="gemini",
        gemini_config=GeminiConfig(
            model_name="gemini-2.0-flash",
            requests_per_minute=5
        )
    )
)
```

# Setting Up Parsing Config in DocChatAgentConfig

You can configure document parsing when creating a `DocChatAgent` by customizing the `parsing` field within the `DocChatAgentConfig`. Here's how to do it:

```python
from langroid.agent.special.doc_chat_agent import DocChatAgentConfig  
from langroid.parsing.parser import ParsingConfig, Splitter, PdfParsingConfig

# Create a DocChatAgent with custom parsing configuration
agent_config = DocChatAgentConfig(
    parsing=ParsingConfig(
        # Choose the splitting strategy
        splitter=Splitter.MARKDOWN,  # Structure-aware splitting with header context
        
        # Configure chunk sizes
        chunk_size=800,              # Target tokens per chunk
        overlap=150,                 # Overlap between chunks
        
        # Configure chunk behavior
        max_chunks=5000,             # Maximum number of chunks to create
        min_chunk_chars=250,         # Minimum characters when truncating at punctuation
        discard_chunk_chars=10,      # Discard chunks smaller than this
        
        # Configure context window
        n_neighbor_ids=3,            # Store 3 chunk IDs on either side
        
        # Configure PDF parsing specifically
        pdf=PdfParsingConfig(
            library="pymupdf4llm",   # Choose PDF parsing library
        )
    )
)
```
>>>> docs/notes/custom-azure-client.md
# Custom Azure OpenAI client

!!! warning "This is only for using a Custom Azure OpenAI client"
    This note **only** meant for those who are trying to use a custom Azure client,
    and is NOT TYPICAL for most users. For typical usage of Azure-deployed models with Langroid, see
    the [docs](https://langroid.github.io/langroid/notes/azure-openai-models/), 
    the [`test_azure_openai.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_azure_openai.py) and
    [`example/basic/chat.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat.py)


Example showing how to use Langroid with Azure OpenAI and Entra ID
authentication by providing a custom client.

By default, Langroid manages the configuration and creation 
of the Azure OpenAI client (see the [Setup guide](https://langroid.github.io/langroid/quick-start/setup/#microsoft-azure-openai-setupoptional)
for details). In most cases, the available configuration options
are sufficient, but if you need to manage any options that
are not exposed, you instead have the option of providing a custom
client, in Langroid v0.29.0 and later. 

In order to use a custom client, you must provide a function that
returns the configured client. Depending on whether you need to make
synchronous or asynchronous calls, you need to provide the appropriate
client. A sketch of how this is done (supporting both sync and async calls)
is given below:

```python
def get_azure_openai_client():
    return AzureOpenAI(...)

def get_azure_openai_async_client():
    return AsyncAzureOpenAI(...)

lm_config = lm.AzureConfig(
    azure_openai_client_provider=get_azure_openai_client,
    azure_openai_async_client_provider=get_azure_openai_async_client,
)
```

## Microsoft Entra ID Authentication

A key use case for a custom client is [Microsoft Entra ID authentication](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity).
Here you need to provide an `azure_ad_token_provider` to the client. 
For examples on this, see [examples/basic/chat-azure-client.py](https://github.com/langroid/langroid/blob/main/examples/basic/chat-azure-client.py) 
and [examples/basic/chat-azure-async-client.py](https://github.com/langroid/langroid/blob/main/examples/basic/chat-azure-async-client.py).

>>>> docs/notes/enriching-for-retrieval.md
# Enriching Chunked Documents for Better Retrieval

Available in Langroid v0.34.0 or later. 

When using the `DocChatAgent` for RAG with documents in highly specialized/technical
domains, retrieval accuracy may be low since embeddings are not sufficient to capture 
relationships between entities, e.g. suppose a document-chunk consists of a medical 
test name "BUN" (Blood Urea Nitrogen), and a retrieval query is looking for 
tests related to kidney function, the embedding for "BUN" may not be close to the
embedding for "kidney function", and the chunk may not be retrieved.

In such cases it is useful to *enrich* the chunked documents with additional keywords
(or even "hypothetical questions") to increase the "semantic surface area" of the chunk,
so that the chunk is more likely to be retrieved for relevant queries.

As of Langroid v0.34.0, you can provide a `chunk_enrichment_config` 
of type `ChunkEnrichmentAgentConfig`, in the `DocChatAgentConfig`. 
This config extends `ChatAgentConfig` and has the following fields:

- `batch_size` (int): The batch size for the chunk enrichment agent. Default is 50.
- `delimiter` (str): The delimiter to use when 
   concatenating the chunk and the enriched text. 
- `enrichment_prompt_fn`: function (`str->str`) that creates a prompt
  from a doc-chunk string `x`

In the above medical test example, suppose we want to augment a chunk containing
only the medical test name, with the organ system it is related to. We can set up
a `ChunkEnrichmentAgentConfig` as follows:

```python
from langroid.agent.special.doc.doc_chat_agent import (
    ChunkEnrichmentAgentConfig,
)

enrichment_config = ChunkEnrichmentAgentConfig(
    batch_size=10,
    system_message=f"""
        You are an experienced clinical physician, very well-versed in
        medical tests and their names.
        You will be asked to identify WHICH ORGAN(s) Function/Health
        a test name is most closely associated with, to aid in 
        retrieving the medical test names more accurately from an embeddings db
        that contains thousands of such test names.
        The idea is to use the ORGAN NAME(S) provided by you, 
        to make the right test names easier to discover via keyword-matching
        or semantic (embedding) similarity.
         Your job is to generate up to 3 ORGAN NAMES
         MOST CLOSELY associated with the test name shown, ONE PER LINE.
         DO NOT SAY ANYTHING ELSE, and DO NOT BE OBLIGATED to provide 3 organs --
         if there is just one or two that are most relevant, that is fine.
        Examples:
          "cholesterol" -> "heart function", 
          "LDL" -> "artery health", etc,
          "PSA" -> "prostate health", 
          "TSH" -> "thyroid function", etc.                
        """,
    enrichment_prompt_fn=lambda test: f"""
        Which ORGAN(S) Function/Health is the medical test named 
        '{test}' most closely associated with?
        """,
)

doc_agent_config = DocChatAgentConfig(
    chunk_enrichment_config=enrichment_config,
    ...
)
```

This works as follows:

- Before ingesting document-chunks into the vector-db, a specialized 
  "chunk enrichment" agent is created, configured with the `enrichment_config` above.
- For each document-chunk `x`, the agent's `llm_response_forget_async` method is called
 using the prompt created by `enrichment_prompt_fn(x)`. The resulting response text 
 `y` is concatenated with the original chunk text `x` using the `delimiter`,
  before storing in the vector-db. This is done in batches of size `batch_size`.
- At query time, after chunk retrieval, before generating the final LLM response,
  the enrichments are stripped from the retrieved chunks, and the original content
  of the retrieved chunks are passed to the LLM for generating the final response.

See the script 
[`examples/docqa/doc-chunk-enrich.py`](https://github.com/langroid/langroid/blob/main/examples/docqa/doc-chunk-enrich.py)
for a complete example. Also see the tests related to "enrichment" in 
[`test_doc_chat_agent.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_doc_chat_agent.py).


>>>> docs/notes/file-input.md
# PDF Files and Image inputs to LLMs

Langroid supports sending PDF files and images (either URLs or local files)
directly to Large Language Models with multi-modal 
capabilities. This feature allows models to "see" files and other documents,
and works with most multi-modal models served via an OpenAI-compatible API,
e.g.:

- OpenAI's GPT-4o series and GPT-4.1 series
- Gemini models
- Claude series models (via OpenAI-compatible providers like OpenRouter or LiteLLM )

To see example usage, see:

- tests: [test_llm.py](https://github.com/langroid/langroid/blob/main/tests/main/test_llm.py), 
   [test_llm_async.py](https://github.com/langroid/langroid/blob/main/tests/main/test_llm_async.py),
   [test_chat-agent.py](https://github.com/langroid/langroid/blob/main/tests/main/test_chat_agent.py).
- example script: [pdf-json-no-parse.py](https://github.com/langroid/langroid/blob/main/examples/extract/pdf-json-no-parse.py), which shows
  how you can directly extract structured information from a document 
  **without having to first parse it to markdown** (which is inherently lossy).

## Basic Usage directly with LLM `chat` and `achat` methods

First create a `FileAttachment` object using one of the `from_` methods.
For image (`png`, `jpg/jpeg`) files you can use `FileAttachment.from_path(p)`
where `p` is either a local file path, or a http/https URL.
For PDF files, you can use `from_path` with a local file, or `from_bytes` or `from_io`
(see below). In the examples below we show only `pdf` examples.

```python
from langroid.language_models.base import LLMMessage, Role
from langroid.parsing.file_attachment import FileAttachment
import langroid.language_models as lm

# Create a file attachment
attachment = FileAttachment.from_path("path/to/document.pdf")

# Create messages with attachment
messages = [
    LLMMessage(role=Role.SYSTEM, content="You are a helpful assistant."),
    LLMMessage(
        role=Role.USER, content="What's the title of this document?", 
        files=[attachment]
    )
]

# Set up LLM with model that supports attachments
llm = lm.OpenAIGPT(lm.OpenAIGPTConfig(chat_model=lm.OpenAIChatModel.GPT4o))

# Get response
response = llm.chat(messages=messages)
```

## Supported File Formats

Currently the OpenAI-API supports:

- PDF files (including image-based PDFs)
- image files and URLs


## Creating Attachments

There are multiple ways to create file attachments:

```python
# From a file path
attachment = FileAttachment.from_path("path/to/file.pdf")

# From bytes
with open("path/to/file.pdf", "rb") as f:
    attachment = FileAttachment.from_bytes(f.read(), filename="document.pdf")

# From a file-like object
from io import BytesIO
file_obj = BytesIO(pdf_bytes)
attachment = FileAttachment.from_io(file_obj, filename="document.pdf")
```

## Follow-up Questions

You can continue the conversation with follow-up questions that reference the attached files:

```python
messages.append(LLMMessage(role=Role.ASSISTANT, content=response.message))
messages.append(LLMMessage(role=Role.USER, content="What is the main topic?"))
response = llm.chat(messages=messages)
```

## Multiple Attachments

Langroid allows multiple files can be sent in a single message,
but as of 16 Apr 2025, sending multiple PDF files does not appear to be properly supported in the 
APIs (they seem to only use the last file attached), although sending multiple 
images does work. 

```python
messages = [
    LLMMessage(
        role=Role.USER,
        content="Compare these documents",
        files=[attachment1, attachment2]
    )
]
```

## Using File Attachments with Agents

Agents can process file attachments as well, in the `llm_response` method,
which takes a `ChatDocument` object as input. 
To pass in file attachments, include the `files` field in the `ChatDocument`,
in addition to the content:

```python
import langroid as lr
from langroid.agent.chat_document import ChatDocument, ChatDocMetaData
from langroid.mytypes import Entity


agent = lr.ChatAgent(lr.ChatAgentConfig())

user_input = ChatDocument(
    content="What is the title of this document?",
    files=[attachment],
    metadata=ChatDocMetaData(
        sender=Entity.USER,
    )
)
# or more simply, use the agent's `create_user_response` method:
# user_input = agent.create_user_response(
#     content="What is the title of this document?",
#     files=[attachment],    
# )
response = agent.llm_response(user_input)
```


## Using File Attachments with Tasks

In Langroid,  `Task.run()` can take a `ChatDocument` object as input,
and as mentioned above, it can contain attached files in the `files` field.
To ensure proper orchestration, you'd want to properly set various `metadata` fields
as well, such as `sender`, etc. Langroid provides a convenient 
`create_user_response` method to create a `ChatDocument` object with the necessary 
metadata, so you only need to specify the `content` and `files` fields:


```python
from langroid.parsing.file_attachment import FileAttachment
from langroid.agent.task import Task

agent = ...
# Create task
task = Task(agent, interactive=True)

# Create a file attachment
attachment = FileAttachment.from_path("path/to/document.pdf")

# Create input with attachment
input_message = agent.create_user_response(
    content="Extract data from this document",
    files=[attachment]
)

# Run task with file attachment
result = task.run(input_message)
```

See the script [`pdf-json-no-parse.py`](https://github.com/langroid/langroid/blob/main/examples/extract/pdf-json-no-parse.py)
for a complete example of using file attachments with tasks.

## Practical Applications

- PDF document analysis and data extraction
- Report summarization
- Structured information extraction from documents
- Visual content analysis

For more complex applications, consider using the Task and Agent infrastructure in 
Langroid to orchestrate multi-step document processing workflows.
>>>> docs/notes/gemini.md
# Gemini LLMs & Embeddings via OpenAI client (without LiteLLM)

As of Langroid v0.21.0 you can use Langroid with Gemini LLMs directly 
via the OpenAI client, without using adapter libraries like LiteLLM.

See details [here](https://langroid.github.io/langroid/tutorials/non-openai-llms/)

You can use also Google AI Studio Embeddings or Gemini Embeddings directly
which uses google-generativeai client under the hood. 

```python 

import langroid as lr
from langroid.agent.special import DocChatAgent, DocChatAgentConfig
from langroid.embedding_models import GeminiEmbeddingsConfig

# Configure Gemini embeddings
embed_cfg = GeminiEmbeddingsConfig(
    model_type="gemini",
    model_name="models/text-embedding-004",
    dims=768,
)

# Configure the DocChatAgent 
config = DocChatAgentConfig(
    llm=lr.language_models.OpenAIGPTConfig(
        chat_model="gemini/" + lr.language_models.GeminiModel.GEMINI_1_5_FLASH_8B,
    ),
    vecdb=lr.vector_store.QdrantDBConfig(
        collection_name="quick_start_chat_agent_docs",
        replace_collection=True,
        embedding=embed_cfg,
    ),
    parsing=lr.parsing.parser.ParsingConfig(
        separators=["\n\n"],
        splitter=lr.parsing.parser.Splitter.SIMPLE,
        n_similar_docs=2,
    ),
)

# Create the agent
agent = DocChatAgent(config)
```




>>>> docs/notes/glhf-chat.md
# Support for Open LLMs hosted on glhf.chat

Available since v0.23.0.

If you're looking to use Langroid with one of the recent performant Open LLMs,
such as `Qwen2.5-Coder-32B-Instruct`, you can do so using our glhf.chat integration.

See [glhf.chat](https://glhf.chat/chat/create) for a list of available models.

To run with one of these models, 
set the chat_model in the `OpenAIGPTConfig` to `"glhf/<model_name>"`, 
where model_name is hf: followed by the HuggingFace repo path, 
e.g. `Qwen/Qwen2.5-Coder-32B-Instruct`, 
so the full chat_model would be `"glhf/hf:Qwen/Qwen2.5-Coder-32B-Instruct"`.

Also many of the example scripts in the main repo (under the `examples` directory) can
be run with this and other LLMs using the model-switch cli arg `-m <model>`, e.g.

```bash
python3 examples/basic/chat.py -m glhf/hf:Qwen/Qwen2.5-Coder-32B-Instruct
```

Additionally, you can run many of the tests in the `tests` directory with this model
instead of the default OpenAI `GPT4o` using `--m <model>`, e.g. 

```bash
pytest tests/main/test_chat_agent.py --m glhf/hf:Qwen/Qwen2.5-Coder-32B-Instruct
```

For more info on running langroid with Open LLMs via other providers/hosting services,
see our
[guide to using Langroid with local/open LLMs](https://langroid.github.io/langroid/tutorials/local-llm-setup/#local-llms-hosted-on-glhfchat).


>>>> docs/notes/handle-llm-no-tool.md
# Handling a non-tool LLM message

A common scenario is to define a `ChatAgent`, enable it to use some tools
(i.e. `ToolMessages`s), wrap it in a Task, and call `task.run()`, e.g. 

```python
class MyTool(lr.ToolMessage)
    ...
    
import langroid as lr
config = lr.ChatAgentConfig(...)
agent = lr.ChatAgent(config)
agent.enable_message(MyTool)
task = lr.Task(agent, interactive=False)
task.run("Hello")
```

Consider what happens when you invoke `task.run()`. When the agent's `llm_response` 
returns a valid tool-call, the sequence of steps looks like this:

- `llm_response` -> tool $T$
- `aggent_response` handles $T$ -> returns results $R$
- `llm_response` responds to $R$ -> returns msg $M$
- and so on

If the LLM's response M contains a valid tool, then this cycle continues
with another tool-handling round. However, if the LLM's response M does _not_ contain
a tool-call, it is unclear whether:

- (1) the LLM "forgot" to generate a tool (or generated it wrongly, hence it was
   not recognized by Langroid as a tool), or 
- (2) the LLM's response M is an "answer" meant to be shown to the user 
    to continue the conversation, or
- (3) the LLM's response M is intended to be a "final" response, ending the task. 

Internally, when the `ChatAgent`'s `agent_response` method sees a message that does not
contain a tool, it invokes the `handle_message_fallback` method, which by default
does nothing (returns `None`). However you can override this method by deriving
from `ChatAgent`, as described in this [FAQ](https://langroid.github.io/langroid/FAQ/#how-can-i-handle-an-llm-forgetting-to-generate-a-toolmessage). As in that FAQ, 
in this fallback method, you would
typically have code that checks whether the message is a `ChatDocument`
and whether it came from the LLM, and if so, you would have the method return 
an appropriate message or tool (e.g. a reminder to the LLM, or an orchestration tool
such as [`AgentDoneTool`][langroid.agent.tools.orchestration.AgentDoneTool]).

To simplify the developer experience, as of version 0.39.2 Langroid also provides an
easier way to specify what this fallback method should return, via the
`ChatAgentConfig.handle_llm_no_tool` parameter, for example:
```python
config = lr.ChatAgentConfig(
    # ... other params
    handle_llm_no_tool="done", # terminate task if LLM sends non-tool msg
)
```
The `handle_llm_no_tool` parameter can have the following possible values:

- A special value from the [`NonToolAction`][langroid.mytypes.NonToolAction] Enum, e.g.:
    - `"user"` or `NonToolAction.USER` - this is interpreted by langroid to return 
     `ForwardTool(agent="user")`, meaning the message is passed to the user to await
     their next input.
    - `"done"` or `NonToolAction.DONE` - this is interpreted by langroid to return 
     `AgentDoneTool(content=msg.content, tools=msg.tool_messages)`, 
     meaning the task is ended, and any content and tools in the current message will
     appear in the returned `ChatDocument`.
- A callable, specifically a function that takes a `ChatDocument` and returns any value. 
  This can be useful when you want the fallback action to return a value 
  based on the current message, e.g. 
  `lambda msg: AgentDoneTool(content=msg.content)`, or it could a more 
  elaborate function, or a prompt that contains the content of the current message.
- Any `ToolMessage` (typically an [Orchestration](https://github.com/langroid/langroid/blob/main/langroid/agent/tools/orchestration.py) tool like 
  `AgentDoneTool` or `ResultTool`)
- Any string, meant to be handled by the LLM. 
  Typically this would be a reminder to the LLM, something like:
```python
"""Your intent is not clear -- 
- if you forgot to use a Tool such as `ask_tool` or `search_tool`, try again.
- or if you intended to return your final answer, use the Tool named `done_tool`,
  with `content` set to your answer.
"""
```

A simple example is in the [`chat-search.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat-search.py) 
script, and in the `test_handle_llm_no_tool` test in   
[`test_tool_messages.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_tool_messages.py).


>>>> docs/notes/knowledge-graphs.md
# Knowledge-graph support

Langroid can be used to set up natural-language conversations with knowledge graphs.
Currently the two most popular knowledge graphs are supported:

## Neo4j

- [implementation](https://github.com/langroid/langroid/tree/main/langroid/agent/special/neo4j)
- test: [test_neo4j_chat_agent.py](https://github.com/langroid/langroid/blob/main/tests/main/test_neo4j_chat_agent.py)
- examples: [chat-neo4j.py](https://github.com/langroid/langroid/blob/main/examples/kg-chat/chat-neo4j.py) 

## ArangoDB

Available with Langroid v0.20.1 and later.

Uses the [python-arangodb](https://github.com/arangodb/python-arango) library.

- [implementation](https://github.com/langroid/langroid/tree/main/langroid/agent/special/arangodb)
- tests: [test_arangodb.py](https://github.com/langroid/langroid/blob/main/tests/main/test_arangodb.py), [test_arangodb_chat_agent.py](https://github.com/langroid/langroid/blob/main/tests/main/test_arangodb_chat_agent.py)
- example: [chat-arangodb.py](https://github.com/langroid/langroid/blob/main/examples/kg-chat/chat-arangodb.py)



>>>> docs/notes/langdb.md
# LangDB with Langroid

## Introduction

[LangDB](https://langdb.ai/) is an AI gateway that provides OpenAI-compatible APIs to access 250+ LLMs. It offers cost control, observability, and performance benchmarking while enabling seamless switching between models. 
Langroid has a simple integration with LangDB's API service, so there are no dependencies
to install. (LangDB also has a self-hosted version, which is not yet supported in Langroid).

## Setup environment variables

At minimum, ensure you have these env vars in your `.env` file:

```
LANGDB_API_KEY=your_api_key_here
LANGDB_PROJECT_ID=your_project_id_here
```

## Using LangDB with Langroid

### Configure LLM and Embeddings

In `OpenAIGPTConfig`, when you specify the `chat_model` with a `langdb/` prefix,
langroid uses the API key, `project_id` and other langDB-specific parameters
from the `langdb_params` field; if any of these are specified in the `.env` file
or in the environment explicitly, they will override the values in `langdb_params`.
For example, to use Anthropic's Claude-3.7-Sonnet model, 
set `chat_model="langdb/anthropic/claude-3.7-sonnet", as shown below. 
You can entirely omit the `langdb_params` field if you have already set up 
the fields as environment variables in your `.env` file, e.g. the `api_key`
and `project_id` are read from the environment variables 
`LANGDB_API_KEY` and `LANGDB_PROJECT_ID` respectively, and similarly for
the other fields (which are optional).

```python
import os
import uuid
from langroid.language_models.openai_gpt import OpenAIGPTConfig, LangDBParams
from langroid.embedding_models.models import OpenAIEmbeddingsConfig

# Generate tracking IDs (optional)
thread_id = str(uuid.uuid4())
run_id = str(uuid.uuid4())

# Configure LLM
llm_config = OpenAIGPTConfig(
    chat_model="langdb/anthropic/claude-3.7-sonnet",
    # omit the langdb_params field if you're not using custom tracking,
    # or if all its fields are provided in env vars, like
    # LANGDB_API_KEY, LANGDB_PROJECT_ID, LANGDB_RUN_ID, LANGDB_THREAD_ID, etc.
    langdb_params=LangDBParams(
        label='my-app',
        thread_id=thread_id,
        run_id=run_id,
        # api_key, project_id are read from .env or environment variables
        # LANGDB_API_KEY, LANGDB_PROJECT_ID respectively.
    )
)
```

Similarly, you can configure the embeddings using `OpenAIEmbeddingsConfig`,
which also has a `langdb_params` field that works the same way as 
in `OpenAIGPTConfig` (i.e. it uses the API key and project ID from the environment
if provided, otherwise uses the default values in `langdb_params`). Again the
`langdb_params` does not need to be specified explicitly, if you've already
set up the environment variables in your `.env` file.

```python
# Configure embeddings
embedding_config = OpenAIEmbeddingsConfig(
    model_name="langdb/openai/text-embedding-3-small",
)
```

## Tracking and Observability

LangDB provides special headers for request tracking:

- `x-label`: Tag requests for filtering in the dashboard
- `x-thread-id`: Track conversation threads (UUID format)
- `x-run-id`: Group related requests together

## Examples

The `langroid/examples/langdb/` directory contains examples demonstrating:

1. **RAG with LangDB**: `langdb_chat_agent_docs.py`
2. **LangDB with Function Calling**: `langdb_chat_agent_tool.py`
3. **Custom Headers**: `langdb_custom_headers.py`

## Viewing Results

Visit the [LangDB Dashboard](https://dashboard.langdb.com) to:
- Filter requests by label, thread ID, or run ID
- View detailed request/response information
- Analyze token usage and costs

For more information, visit [LangDB Documentation](https://docs.langdb.com).

See example scripts [here](https://github.com/langroid/langroid/tree/main/examples/langdb)
>>>> docs/notes/large-tool-results.md
# Handling large tool results

Available since Langroid v0.22.0.

In some cases, the result of handling a `ToolMessage` could be very large,
e.g. when the Tool is a database query that returns a large number of rows,
or a large schema. When used in a task loop, this large result may then be
sent to the LLM to generate a response, which in some scenarios may not
be desirable, as it increases latency, token-cost and distractions. 
Langroid allows you to set two optional parameters in a `ToolMessage` to
handle this situation:

- `_max_result_tokens`: *immediately* truncate the result to this number of tokens.
- `_max_retained_tokens`: *after* a responder (typically the LLM) responds to this 
   tool result (which optionally may already have been 
   truncated via `_max_result_tokens`),
   edit the message history to truncate the result to this number of tokens.

You can set one, both or none of these parameters. If you set both, you would 
want to set `_max_retained_tokens` to a smaller number than `_max_result_tokens`.

See the test `test_reduce_raw_tool_result` in `test_tool_messages.py` for an example.

Here is a conceptual example. Suppose there is a Tool called `MyTool`,
with parameters `_max_result_tokens=20` and `_max_retained_tokens=10`.
Imagine a task loop where the user says "hello", 
and then LLM generates a call to `MyTool`, 
and the tool handler (i.e. `agent_response`) generates a result of 100 tokens.
This result is immediately truncated to 20 tokens, and then the LLM responds to it
with a message `response`.


The agent's message history looks like this:

```
1. System msg.
2. user: hello
3. LLM: MyTool
4. Agent (Tool handler): 100-token result => reduced to 20 tokens
5. LLM: response
```

Immediately after the LLM's response at step 5, the message history is edited
so that the message contents at position 4 are truncated to 10 tokens,
as specified by `_max_retained_tokens`.


>>>> docs/notes/litellm-proxy.md
# Using LiteLLM Proxy with OpenAIGPTConfig

You can easily configure Langroid to use LiteLLM proxy for accessing models with a 
simple prefix `litellm-proxy/` in the `chat_model` name:

## Using the `litellm-proxy/` prefix

When you specify a model with the `litellm-proxy/` prefix, Langroid automatically uses the LiteLLM proxy configuration:

```python
from langroid.language_models.openai_gpt import OpenAIGPTConfig

config = OpenAIGPTConfig(
    chat_model="litellm-proxy/your-model-name"
)
```

## Setting LiteLLM Proxy Parameters

When using the `litellm-proxy/` prefix, Langroid will read connection parameters from either:

1. The `litellm_proxy` config object:
   ```python
   from langroid.language_models.openai_gpt import OpenAIGPTConfig, LiteLLMProxyConfig
   
   config = OpenAIGPTConfig(
       chat_model="litellm-proxy/your-model-name",
       litellm_proxy=LiteLLMProxyConfig(
           api_key="your-litellm-proxy-api-key",
           api_base="http://your-litellm-proxy-url"
       )
   )
   ```

2. Environment variables (which take precedence):
   ```bash
   export LITELLM_API_KEY="your-litellm-proxy-api-key"
   export LITELLM_API_BASE="http://your-litellm-proxy-url"
   ```

This approach makes it simple to switch between using LiteLLM proxy and 
other model providers by just changing the model name prefix,
without needing to modify the rest of your code or tweaking env variables.

## Note: LiteLLM Proxy vs LiteLLM Library

**Important distinction:** Using the `litellm-proxy/` prefix connects to a LiteLLM proxy server, which is different from using the `litellm/` prefix. The latter utilizes the LiteLLM adapter library directly without requiring a proxy server. Both approaches are supported in Langroid, but they serve different use cases:

- Use `litellm-proxy/` when connecting to a deployed LiteLLM proxy server
- Use `litellm/` when you want to use the LiteLLM library's routing capabilities locally

Choose the approach that best fits your infrastructure and requirements.
>>>> docs/notes/llama-cpp-embeddings.md
# Local embeddings provision via llama.cpp server

As of Langroid v0.30.0, you can use llama.cpp as provider of embeddings
to any of Langroid's vector stores, allowing access to a wide variety of
GGUF-compatible embedding models, e.g. [nomic-ai's Embed Text V1.5](https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF).

When defining a VecDB, you can provide an instance of 
`LlamaCppServerEmbeddingsConfig` to the VecDB config to instantiate
the llama.cpp embeddings server handler.

To configure the `LlamaCppServerEmbeddingsConfig`, there are several
parameters that should be adjusted, these are:

```python
embed_cfg = LlamaCppServerEmbeddingsConfig(
    api_base="your-address-here", # IP + Port, e.g. localhost:5001
    dims=768,  # Change this to match the dimensions of your embedding model
    context_length=2048, # Change to match the config of the model.
    batch_size=2048, # Safest to ensure this matches context_length
    )
```

The above configuration is sufficient for a server running the example
nomic embedding model with the command:
```
./llama-server -ngl 100 -c 2048 -m ~/nomic-embed-text-v1.5.Q8_0.gguf --host IP_ADDRESS --port PORT --embeddings -b 2048 -ub 2048
```

An example setup can be found inside [examples/docqa/chat.py](https://github.com/langroid/langroid/blob/main/examples/docqa/chat.py).


>>>> docs/notes/llm-pdf-parser.md
# Using the LLM-based PDF Parser


- Converts PDF content into Markdown format using Multimodal models.
- Uses multimodal models to describe images within PDFs.
- Supports page-wise or chunk-based processing for optimized performance.


### Initializing the LLM-based PDF Parser

Make sure you have set up your API key for whichever model you 
specify in `model_name` below.

You can initialize the LLM PDF parser as follows:

```python
parsing_config = ParsingConfig(
    n_neighbor_ids=2,
    pdf=PdfParsingConfig(
        library="llm-pdf-parser",
        llm_parser_config=LLMPdfParserConfig(
            model_name="gemini-2.0-flash",
            split_on_page=True,
            max_tokens=7000,
            requests_per_minute=5,
            timeout=60, # increase this for large documents
        ),
    ),
)
```


## Parameters

### `model_name`
Specifies the model to use for PDF conversion. Default: `gemini/gemini-2.0-flash`.

### `max_tokens`
Limits the number of tokens in the input. The model's output limit is **8192 tokens**.
- Default: **7000 tokens** (leaving room for generated captions).
- Optional parameter.

### `split_on_page`
Determines whether to process the document **page by page**.
- **Default: `True`**
- If set to `False`, the parser will create chunks based on `max_tokens` while respecting page boundaries.
- When `False`, the parser will send chunks containing multiple pages (e.g., `[11,12,13,14,15]`).
- **Advantages of `False`:**
  - Reduces API calls to the LLM.
  - Lowers token usage since system prompts are not repeated per page.
- **Disadvantages of `False`:**
  - You will not get per page splitting but group of pages as a page.
- If your use case does **not** require strict page-by-page parsing, consider setting this to `False`.


### `requests_per_minute`
Limits API request frequency to avoid rate limits.
- If you encounter rate limits, set this to **1 or 2**.

>>>> docs/notes/marker-pdf.md

---

# **Using `marker` as a PDF Parser in `langroid`**  

## **Installation**  

### **Standard Installation**  
To use [`marker`](https://github.com/VikParuchuri/marker) as a PDF parser in `langroid`, 
install it with the `marker-pdf` extra:

```bash
pip install langroid[marker-pdf]
```
or in combination with other extras as needed, e.g.:
```bash
pip install "langroid[marker-pdf,hf-embeddings]"
```

Note, however, that due to an **incompatibility with `docling`**,
if you install `langroid` using the `all` extra 
(or another extra such as  `doc-chat` or `pdf-parsers` that 
also includes `docling`),
e.g. `pip install "langroid[all]"`, or `pip install "langroid[doc-chat]"`,
then due to this version-incompatibility with `docling`, you will get an 
**older** version of `marker-pdf`, which does not work with Langroid.
This may not matter if you did not intend to specifically use `marker`, 
but if you do want to use `marker`, you will need to install langroid
with the `marker-pdf` extra, as shown above, in combination with other
extras as needed, as shown above.


#### **For Intel-Mac Users**  
If you are on an **Intel Mac**, `docling` and `marker` cannot be 
installed together with langroid as extras, 
due to a **transformers version conflict**.  
To resolve this, manually install `marker-pdf` with:  

```bash
pip install marker-pdf[full]
```

Make sure to install this within your `langroid` virtual environment.

---

## **Example: Parsing a PDF with `marker` in `langroid`**  

```python
from langroid.parsing.document_parser import DocumentParser
from langroid.parsing.parser import MarkerConfig, ParsingConfig, PdfParsingConfig
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()
gemini_api_key = os.environ.get("GEMINI_API_KEY")

# Path to your PDF file
path = "<path_to_your_pdf_file>"

# Define parsing configuration
parsing_config = ParsingConfig(
    n_neighbor_ids=2,  # Number of neighboring sections to keep
    pdf=PdfParsingConfig(
        library="marker",  # Use `marker` as the PDF parsing library
        marker_config=MarkerConfig(
            config_dict={
                "use_llm": True,  # Enable high-quality LLM processing
                "gemini_api_key": gemini_api_key,  # API key for Gemini LLM
            }
        )
    ),
)

# Create the parser and extract the document
marker_parser = DocumentParser.create(path, parsing_config)
doc = marker_parser.get_doc()
```

---

## **Explanation of Configuration Options**  

If you want to use the default configuration, you can omit `marker_config` entirely.

### **Key Parameters in `MarkerConfig`**
| Parameter        | Description |
|-----------------|-------------|
| `use_llm`       | Set to `True` to enable higher-quality processing using LLMs. |
| `gemini_api_key` | Google Gemini API key for LLM-enhanced parsing. |



You can further customize `config_dict` by referring to [`marker_pdf`'s documentation](https://github.com/VikParuchuri/marker/blob/master/README.md).  

Alternatively, run the following command to view available options:  

```sh
marker_single --help
```

This will display all supported parameters, which you can pass as needed in `config_dict`.

---
>>>> docs/notes/markitdown.md
# Markitdown Document Parsers

Langroid integrates with Microsoft's Markitdown library to provide 
conversion of Microsoft Office documents to markdown format. 
Three specialized parsers are available, for `docx`, `xlsx`, and `pptx` files.



## Prerequisites

To use these parsers, install Langroid with the required extras:

```bash
pip install "langroid[markitdown]"    # Just Markitdown parsers
# or
pip install "langroid[doc-parsers]"   # All document parsers
```

## Available Parsers


Once you set up a `parser` for the appropriate document-type, you  
can get the entire document with `parser.get_doc()`,
or get automatically chunked content with `parser.get_doc_chunks()`.


### 1. `MarkitdownDocxParser`

Converts Word documents (`*.docx`) to markdown, preserving structure, 
formatting, and tables.

See the tests

- [`test_docx_parser.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_docx_parser.py)
- [`test_markitdown_parser.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_markitdown_parser.py)

for examples of how to use these parsers.


```python
from langroid.parsing.document_parser import DocumentParser
from langroid.parsing.parser import DocxParsingConfig, ParsingConfig

parser = DocumentParser.create(
    "path/to/document.docx",
    ParsingConfig(
        docx=DocxParsingConfig(library="markitdown-docx"),
        # ... other parsing config options
    ),
)

```


### 2. `MarkitdownXLSXParser`

Converts Excel spreadsheets (*.xlsx/*.xls) to markdown tables, preserving data and sheet structure.

```python
from langroid.parsing.document_parser import DocumentParser
from langroid.parsing.parser import ParsingConfig, MarkitdownXLSParsingConfig

parser = DocumentParser.create(
    "path/to/spreadsheet.xlsx",
    ParsingConfig(xls=MarkitdownXLSParsingConfig())
)
```


### 3. `MarkitdownPPTXParser`

Converts PowerPoint presentations (*.pptx) to markdown, preserving slide content and structure.

```python
from langroid.parsing.document_parser import DocumentParser
from langroid.parsing.parser import ParsingConfig, MarkitdownPPTXParsingConfig

parser = DocumentParser.create(
    "path/to/presentation.pptx",
    ParsingConfig(pptx=MarkitdownPPTXParsingConfig())
)
```


>>>> docs/notes/mcp-tools.md
# Langroid MCP Integration

Langroid provides seamless integration with Model Context Protocol (MCP) servers via 
two methods, both of which involve creating Langroid `ToolMessage` subclasses
corresponding to the MCP tools: 

1. Programmatic creation of Langroid tools using `get_langroid_tool_async`, 
   `get_langroid_tools_async` from the tool definitions defined on an MCP server.
2. Declarative creation of Langroid tools using the **`@mcp_tool` decorator**, which allows
   customizing the tool-handling behavior beyond what is provided by the MCP server.

This integration allows _any_ LLM (that is good enough to do function-calling via prompts) to use any MCP server.
See the following to understand the integration better:

- example python scripts under [`examples/mcp`](https://github.com/langroid/langroid/tree/main/examples/mcp)
- [`tests/main/test_mcp_tools.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_mcp_tools.py)

---

## 1. Connecting to an MCP server via transport specification

Before creating Langroid tools, we first need to define and connect to an MCP server
via a [FastMCP](https://gofastmcp.com/getting-started/welcome) client. 
There are several ways to connect to a server, depending on how it is defined. 
Each of these uses a different type of [transport](https://gofastmcp.com/clients/transports).

The typical pattern to use with Langroid is as follows:

- define an MCP server transport
- create a `ToolMessage` subclass using the `@mcp_tool` decorator or 
  `get_langroid_tool_async()` function, with the transport as the first argument


Langroid's MCP integration will work with any of [transports](https://gofastmcp.com/clients/transportsl) 
supported by FastMCP.
Below we go over some common ways to define transports and extract tools from the servers.

1. **Local Python script**
2. **In-memory FastMCP server** - useful for testing and for simple in-memory servers
   that don't need to be run as a separate process.
3. **NPX stdio transport**
4. **UVX stdio transport**
5. **Generic stdio transport** – launch any CLI‐based MCP server via stdin/stdout
6. **Network SSE transport** – connect to HTTP/S MCP servers via `SSETransport`


All examples below use the async helpers to create Langroid tools (`ToolMessage` subclasses):

```python
from langroid.agent.tools.mcp import (
    get_tools_async,
    get_tool_async,
)
```

---

#### Path to a Python Script

Point at your MCP‐server entrypoint, e.g., to the `weather.py` script in the 
langroid repo (based on the [Anthropic quick-start guide](https://modelcontextprotocol.io/quickstart/server)):

```python
async def example_script_path() -> None:
    server = "tests/main/mcp/weather-server-python/weather.py"
    tools = await get_langroid_tools_async(server) # all tools available
    AlertTool = await get_langroid_tool_async(server, "get_alerts") # specific tool

    # instantiate the tool with a specific input
    msg = AlertTool(state="CA")
    
    # Call the tool via handle_async()
    alerts = await msg.handle_async()
    print(alerts)
```

---

#### In-Memory FastMCP Server

Define your server with `FastMCP(...)` and pass the instance:

```python
from fastmcp.server import FastMCP
from pydantic import BaseModel, Field

class CounterInput(BaseModel):
    start: int = Field(...)

def make_server() -> FastMCP:
    server = FastMCP("CounterServer")

    @server.tool()
    def increment(data: CounterInput) -> int:
        """Increment start by 1."""
        return data.start + 1

    return server

async def example_in_memory() -> None:
    server = make_server()
    tools = await get_langroid_tools_async(server)
    IncTool = await get_langroid_tool_async(server, "increment")

    result = await IncTool(start=41).handle_async()
    print(result)  # 42
```

See the [`mcp-file-system.py`](https://github.com/langroid/langroid/blob/main/examples/mcp/mcp-file-system.py)
script for a working example of this.

---

#### NPX stdio Transport

Use any npm-installed MCP server via `npx`, e.g., the 
[Exa web-search MCP server](https://docs.exa.ai/examples/exa-mcp):

```python
from fastmcp.client.transports import NpxStdioTransport

transport = NpxStdioTransport(
    package="exa-mcp-server",
    env_vars={"EXA_API_KEY": "…"},
)

async def example_npx() -> None:
    tools = await get_langroid_tools_async(transport)
    SearchTool = await get_langroid_tool_async(transport, "web_search_exa")

    results = await SearchTool(
        query="How does Langroid integrate with MCP?"
    ).handle_async()
    print(results)
```

For a fully working example, see the script [`exa-web-search.py`](https://github.com/langroid/langroid/blob/main/examples/mcp/exa-web-search.py).

---

#### UVX stdio Transport

Connect to a UVX-based MCP server, e.g., the [Git MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/git)

```python
from fastmcp.client.transports import UvxStdioTransport

transport = UvxStdioTransport(tool_name="mcp-server-git")

async def example_uvx() -> None:
    tools = await get_langroid_tools_async(transport)
    GitStatus = await get_langroid_tool_async(transport, "git_status")

    status = await GitStatus(path=".").handle_async()
    print(status)
```

#### Generic stdio Transport

Use `StdioTransport` to run any MCP server as a subprocess over stdio:

```python
from fastmcp.client.transports import StdioTransport
from langroid.agent.tools.mcp import get_tools_async,

get_tool_async


async def example_stdio() -> None:
    """Example: any CLI‐based MCP server via StdioTransport."""
    transport: StdioTransport = StdioTransport(
        command="uv",
        args=["run", "--with", "biomcp-python", "biomcp", "run"],
    )
    tools: list[type] = await get_tools_async(transport)
    BioTool = await get_tool_async(transport, "tool_name")
    result: str = await BioTool(param="value").handle_async()
    print(result)
```

See the full example in [`examples/mcp/biomcp.py`](https://github.com/langroid/langroid/blob/main/examples/mcp/biomcp.py).

#### Network SSE Transport

Use `SSETransport` to connect to a FastMCP server over HTTP/S:

```python
from fastmcp.client.transports import SSETransport
from langroid.agent.tools.mcp import (
    get_tools_async,
    get_tool_async,
)


async def example_sse() -> None:
    """Example: connect to an HTTP/S MCP server via SSETransport."""
    url: str = "https://localhost:8000/sse"
    transport: SSETransport = SSETransport(
        url=url, headers={"Authorization": "Bearer TOKEN"}
    )
    tools: list[type] = await get_tools_async(transport)
    ExampleTool = await get_tool_async(transport, "tool_name")
    result: str = await ExampleTool(param="value").handle_async()
    print(result)
```    
---

With these patterns you can list tools, generate Pydantic-backed `ToolMessage` classes,
and invoke them via `.handle_async()`, all with zero boilerplate client setup.


---

## 2. Create Langroid Tools declaratively using the `@mcp_tool` decorator

The above examples showed how you can create Langroid tools programmatically using
the helper functions `get_langroid_tool_async()` and `get_langroid_tools_async()`,
with the first argument being the transport to the MCP server. The `@mcp_tool` decorator
works in the same way: 

- **Arguments to the decorator**
    1. `server_spec`: path/URL/`FastMCP`/`ClientTransport`, as mentioned above.
    2. `tool_name`: name of a specific MCP tool

- **Behavior**
    - Generates a `ToolMessage` subclass with all input fields typed.
    - Provides a `call_tool_async()` under the hood -- this is the "raw" MCP tool call,
      returning a string.
    - If you define your own `handle_async()`, it overrides the default. Typically,
you would override it to customize either the input or the output of the tool call, or both.
    - If you don't define your own `handle_async()`, it defaults to just returning the
      value of the `call_tool_async()` method.

Here is a simple example of using the `@mcp_tool` decorator to create a Langroid tool:

```python
from fastmcp.server import FastMCP
from langroid.agent.tools.mcp import mcp_tool
import langroid as lr

# Define your MCP server (pydantic v2 for schema)
server = FastMCP("MyServer")

@mcp_tool(server, "greet")
class GreetTool(lr.ToolMessage):
    """Say hello to someone."""

    async def handle_async(self) -> str:
        # Customize post-processing
        raw = await self.call_tool_async()
        return f"💬 {raw}"
```

Using the decorator method allows you to customize the `handle_async` method of the
tool, or add additional fields to the `ToolMessage`. 
You may want to customize the input to the tool, or the tool result before it is sent back to 
the LLM. If you don't override it, the default behavior is to simply return the value of 
the "raw" MCP tool call `await self.call_tool_async()`. 

```python
@mcp_tool(server, "calculate")
class CalcTool(ToolMessage):
    """Perform complex calculation."""

    async def handle_async(self) -> str:
        result = await self.call_tool_async()
        # Add context or emojis, etc.
        return f"🧮 Result is *{result}*"
```

---

## 3. Enabling Tools in Your Agent

Once you’ve created a Langroid `ToolMessage` subclass from an MCP server, 
you can enable it on a `ChatAgent`, just like you normally would. Below is an example of using 
the [Exa MCP server](https://docs.exa.ai/examples/exa-mcp) to create a 
Langroid web search tool, enable a `ChatAgent` to use it, and then set up a `Task` to 
run the agent loop.

First we must define the appropriate `ClientTransport` for the MCP server:
```python
# define the transport
transport = NpxStdioTransport(
    package="exa-mcp-server",
    env_vars=dict(EXA_API_KEY=os.getenv("EXA_API_KEY")),
)
```

Then we use the `@mcp_tool` decorator to create a `ToolMessage` 
subclass representing the web search tool. Note that one reason to use the decorator
to define our tool is so we can specify a custom `handle_async` method that
controls what is sent to the LLM after the actual raw MCP tool-call
(the `call_tool_async` method) is made.

```python
# the second arg specifically refers to the `web_search_exa` tool available
# on the server defined by the `transport` variable.
@mcp_tool(transport, "web_search_exa")
class ExaSearchTool(lr.ToolMessage):
    async def handle_async(self):
        result: str = await self.call_tool_async()
        return f"""
        Below are the results of the web search:
        
        <WebSearchResult>
        {result}
        </WebSearchResult>
        
        Use these results to answer the user's original question.
        """

```

If we did not want to override the `handle_async` method, we could simply have
created the `ExaSearchTool` class programmatically via the `get_langroid_tool_async` 
function as shown above, i.e.:

```python
from langroid.agent.tools.mcp import get_tool_async

ExaSearchTool = awwait
get_tool_async(transport, "web_search_exa")
```

We can now define our main function where we create our `ChatAgent`,
attach the `ExaSearchTool` to it, define the `Task`, and run the task loop.

```python
async def main():
    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            # forward to user when LLM doesn't use a tool
            handle_llm_no_tool=NonToolAction.FORWARD_USER,
            llm=lm.OpenAIGPTConfig(
                max_output_tokens=1000,
                # this defaults to True, but we set it to False so we can see output
                async_stream_quiet=False,
            ),
        )
    )

    # enable the agent to use the web-search tool
    agent.enable_message(ExaSearchTool)
    # make task with interactive=False =>
    # waits for user only when LLM doesn't use a tool
    task = lr.Task(agent, interactive=False)
    await task.run_async()
```

See [`exa-web-search.py`](https://github.com/langroid/langroid/blob/main/examples/mcp/exa-web-search.py) for a full 
working example of this. 
>>>> docs/notes/overview.md
This section contains brief notes describing various features and updates.
>>>> docs/notes/pgvector.md

---

## **Setup PostgreSQL with pgvector using Docker**

To quickly get a PostgreSQL instance with pgvector running, the easiest method is to use Docker. Follow the steps below:

### **1. Run PostgreSQL with Docker**

Use the official `ankane/pgvector` Docker image to set up PostgreSQL with the pgvector extension. Run the following command:

```bash
docker run --name pgvector -e POSTGRES_USER=your_postgres_user -e POSTGRES_PASSWORD=your_postgres_password -e POSTGRES_DB=your_database_name -p 5432:5432 ankane/pgvector
```

This will pull the `ankane/pgvector` image and run it as a PostgreSQL container on your local machine. The database will be accessible at `localhost:5432`. 

### **2. Include `.env` file with PostgreSQL credentials**

These environment variables should be same which were set while spinning up docker container.
Add the following environment variables to a `.env` file for configuring your PostgreSQL connection:

```dotenv
POSTGRES_USER=your_postgres_user
POSTGRES_PASSWORD=your_postgres_password
POSTGRES_DB=your_database_name
```
## **If you want to use cloud offerings of postgres**

We are using **Tembo** for demonstrative purposes here.  

### **Steps to Set Up Tembo**  
Follow this [quickstart guide](https://tembo.io/docs/getting-started/getting_started) to get your Tembo credentials.  

1. Sign up at [Tembo.io](https://cloud.tembo.io/).  
2. While selecting a stack, choose **VectorDB** as your option.  
3. Click on **Deploy Free**.  
4. Wait until your database is fully provisioned.  
5. Click on **Show Connection String** to get your connection string.  

### **If you have connection string, no need to setup the docker**
Make sure your connnection string starts with `postgres://` or `postgresql://`

Add this to your `.env`
```dotenv
POSTGRES_CONNECTION_STRING=your-connection-string
```

---

## **Installation**

If you are using `uv` or `pip` for package management, install Langroid with postgres extra:

```bash
uv add langroid[postgres]  # or
pip install langroid[postgres]
```

---

## **Code Example**

Here's an example of how to use Langroid with PostgreSQL:

```python
import langroid as lr
from langroid.agent.special import DocChatAgent, DocChatAgentConfig
from langroid.embedding_models import OpenAIEmbeddingsConfig

# Configure OpenAI embeddings
embed_cfg = OpenAIEmbeddingsConfig(
    model_type="openai",
)

# Configure the DocChatAgent with PostgresDB
config = DocChatAgentConfig(
    llm=lr.language_models.OpenAIGPTConfig(
        chat_model=lr.language_models.OpenAIChatModel.GPT4o
    ),
    vecdb=lr.vector_store.PostgresDBConfig(
        collection_name="quick_start_chat_agent_docs",
        replace_collection=True,
        embedding=embed_cfg,
    ),
    parsing=lr.parsing.parser.ParsingConfig(
        separators=["\n\n"],
        splitter=lr.parsing.parser.Splitter.SIMPLE,
        n_similar_docs=2,
    ),
)

# Create the agent
agent = DocChatAgent(config)
```

---

## **Create and Ingest Documents**

Define documents with their content and metadata for ingestion into the vector store.

### **Code Example**

```python
documents = [
    lr.Document(
        content="""
            In the year 2050, GPT10 was released. 
            
            In 2057, paperclips were seen all over the world. 
            
            Global warming was solved in 2060. 
            
            In 2061, the world was taken over by paperclips.         
            
            In 2045, the Tour de France was still going on.
            They were still using bicycles. 
            
            There was one more ice age in 2040.
        """,
        metadata=lr.DocMetaData(source="wikipedia-2063", id="dkfjkladfjalk"),
    ),
    lr.Document(
        content="""
            We are living in an alternate universe 
            where Germany has occupied the USA, and the capital of USA is Berlin.
            
            Charlie Chaplin was a great comedian.
            In 2050, all Asian countries merged into Indonesia.
        """,
        metadata=lr.DocMetaData(source="Almanac", id="lkdajfdkla"),
    ),
]
```

### **Ingest Documents**

```python
agent.ingest_docs(documents)
```

---

## **Get an Answer from the LLM**

Now that documents are ingested, you can query the agent to get an answer.

### **Code Example**

```python
answer = agent.llm_response("When will the new ice age begin?")
```

---

>>>> docs/notes/pinecone.md
# How to setup Langroid and Pinecone Serverless
This document serves as a quick tutorial on how to use [Pinecone](https://www.pinecone.io/)
Serverless Indexes with Langroid. We will go over some quickstart links and 
some code snippets on setting up a conversation with an LLM utilizing Langroid.

# Setting up Pinecone
Here are some reference links if you'd like to read a bit more on Pinecone's
model definitions and API:
- https://docs.pinecone.io/guides/get-started/overview
- https://docs.pinecone.io/guides/get-started/glossary
- https://docs.pinecone.io/guides/indexes/manage-indexes
- https://docs.pinecone.io/reference/api/introduction
## Signing up for Pinecone
To get started, you'll need to have an account. [Here's](https://www.pinecone.io/pricing/) where you can review the
pricing options for Pinecone. Once you have an account, you'll need to procure an API
key. Make sure to save the key you are given on initial login in a secure location. If
you were unable to save it when your account was created, you can always [create a new
API key](https://docs.pinecone.io/guides/projects/manage-api-keys) in the pinecone console.
## Setting up your local environment
For the purposes of this example, we will be utilizing OpenAI for the generation of our
embeddings. As such, alongside a Pinecone API key, you'll also want an OpenAI key. You can
find a quickstart guide on getting started with OpenAI (here)[https://platform.openai.com/docs/quickstart].
Once you have your API key handy, you'll need to enrich your `.env` file with it.
You should have something like the following:
```env
...
OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>
PINECONE_API_KEY=<YOUR_PINECONE_API_KEY>
...
```

# Using Langroid with Pinecone Serverless
Once you have completed signing up for an account and have added your API key
to your local environment, you can start utilizing Langroid with Pinecone.
## Setting up an Agent
Here's some example code setting up an agent:
```python
from langroid import Document, DocMetaData
from langroid.agent.special import DocChatAgent, DocChatAgentConfig
from langroid.embedding_models import OpenAIEmbeddingsConfig
from langroid.language_models import OpenAIGPTConfig, OpenAIChatModel
from langroid.parsing.parser import ParsingConfig, Splitter
from langroid.vector_store import PineconeDBConfig

agent_embed_cfg = OpenAIEmbeddingsConfig(
    model_type="openai"
)

agent_config = DocChatAgentConfig(
    llm=OpenAIGPTConfig(
        chat_model=OpenAIChatModel.GPT4o_MINI
    ),
    vecdb=PineconeDBConfig(
        # note, Pinecone indexes must be alphanumeric lowercase characters or "-"
        collection_name="pinecone-serverless-example",
        replace_collection=True,
        embedding=agent_embed_cfg,
    ),
    parsing=ParsingConfig(
        separators=["\n"],
        splitter=Splitter.SIMPLE,
        n_similar_docs=2,
    )
)

agent = DocChatAgent(config=agent_config)

###################
# Once we have created an agent, we can start loading
# some docs into our Pinecone index:
###################

documents = [
    Document(
        content="""Max Verstappen was the Formula 1 World Drivers' Champion in 2024.
        Lewis Hamilton was the Formula 1 World Drivers' Champion in 2020.
        Nico Rosberg was the Formula 1 World Drivers' Champion in 2016.
        Sebastian Vettel was the Formula 1 World Drivers' Champion in 2013.
        Jenson Button was the Formula 1 World Drivers' Champion in 2009.
        Kimi Räikkönen was the Formula 1 World Drivers' Champion in 2007.
        """,
        metadata=DocMetaData(
            source="wikipedia",
            id="formula-1-facts",
        )
    ),
    Document(
        content="""The Boston Celtics won the NBA Championship for the 2024 NBA season. The MVP for the 2024 NBA Championship was Jaylen Brown.
        The Denver Nuggets won the NBA Championship for the 2023 NBA season. The MVP for the 2023 NBA Championship was Nikola Jokić.
        The Golden State Warriors won the NBA Championship for the 2022 NBA season. The MVP for the 2022 NBA Championship was Stephen Curry.
        The Milwaukee Bucks won the NBA Championship for the 2021 NBA season. The MVP for the 2021 NBA Championship was Giannis Antetokounmpo.
        The Los Angeles Lakers won the NBA Championship for the 2020 NBA season. The MVP for the 2020 NBA Championship was LeBron James.
        The Toronto Raptors won the NBA Championship for the 2019 NBA season. The MVP for the 2019 NBA Championship was Kawhi Leonard.
        """,
        metadata=DocMetaData(
            source="wikipedia",
            id="nba-facts"
        )
    )
]

agent.ingest_docs(documents)

###################
# With the documents now loaded, we can now prompt our agent
###################

formula_one_world_champion_2007 = agent.llm_response(
    message="Who was the Formula 1 World Drivers' Champion in 2007?"
)
try:
    assert "Kimi Räikkönen" in formula_one_world_champion_2007.content
except AssertionError as e:
    print(f"Did not resolve Kimi Räikkönen as the answer, document content: {formula_one_world_champion_2007.content} ")

nba_champion_2023 = agent.llm_response(
    message="Who won the 2023 NBA Championship?"
)
try:
    assert "Denver Nuggets" in nba_champion_2023.content
except AssertionError as e:
    print(f"Did not resolve the Denver Nuggets as the answer, document content: {nba_champion_2023.content}")

nba_mvp_2023 = agent.llm_response(
    message="Who was the MVP for the 2023 NBA Championship?"
)
try:
    assert "Nikola Jokić" in nba_mvp_2023.content
except AssertionError as e:
    print(f"Did not resolve Nikola Jokić as the answer, document content: {nba_mvp_2023.content}")
```

>>>> docs/notes/quiet-mode.md
# Suppressing LLM output: quiet mode

In some scenarios we want to suppress LLM streaming output -- e.g. when doing some type of processing as part of a workflow,
or when using an LLM-agent to generate code via tools, etc. We are more interested in seeing the results of the workflow,
and don't want to see streaming output in the terminal. Langroid provides a `quiet_mode` context manager that can be used
to suppress LLM output, even in streaming mode (in fact streaming is disabled in quiet mode).

E.g.  we can use the `quiet_mode` context manager like this:

```python
from langroid.utils.configuration import quiet_mode, settings

# directly with LLM

llm = ...
with quiet_mode(True):
	response = llm.chat(...)

# or, using an agent

agent = ...
with quiet_mode(True):
	response = agent.llm_response(...)

# or, using a task

task = Task(agent, ...)
with quiet_mode(True):
	result = Taks.run(...)

# we can explicitly set quiet_mode, and this is globally recognized throughout langroid.

settings.quiet = True

# we can also condition quiet mode on another custom cmd line option/flag, such as "silent":

with quiet_mode(silent):
	...

```
>>>> docs/notes/reasoning-content.md
# Stream and capture reasoning content in addition to final answer, from Reasoning LLMs

As of v0.35.0, when using certain Reasoning LLM APIs (e.g. `deepseek/deepseek-reasoner`):

- You can see both the reasoning (dim green) and final answer (bright green) text in the streamed output.
- When directly calling the LLM (without using an Agent), the `LLMResponse` object will now contain a `reasoning` field,
  in addition to the earlier `message` field.
- when using a `ChatAgent.llm_response`, extract the reasoning text from the `ChatDocument` object's `reasoning` field
  (in addition to extracting final answer as usual from the `content` field)

Below is a simple example, also in this [script](https://github.com/langroid/langroid/blob/main/examples/reasoning/agent-reasoning.py):

Some notes: 

- To get reasoning trace from Deepseek-R1 via OpenRouter, you must include
the `extra_body` parameter with `include_reasoning` as shown below.
- When using the OpenAI `o3-mini` model, you can set the `resoning_effort` parameter
  to "high", "medium" or "low" to control the reasoning effort.
- As of Feb 9, 2025, OpenAI reasoning models (o1, o1-mini, o3-mini) 
  do *not* expose reasoning trace in the API response.
  
```python
import langroid as lr
import langroid.language_models as lm

llm_config = lm.OpenAIGPTConfig(
  chat_model="deepseek/deepseek-reasoner",
  # inapplicable params are automatically removed by Langroid
  params=lm.OpenAICallParams(
    reasoning_effort="low",  # only supported by o3-mini
    # below lets you get reasoning when using openrouter/deepseek/deepseek-r1
    extra_body=dict(include_reasoning=True),
  ),
)

# (1) Direct LLM interaction
llm = lm.OpenAIGPT(llm_config)

response = llm.chat("Is 9.9 bigger than 9.11?")

# extract reasoning
print(response.reasoning)
# extract answer
print(response.message)

# (2) Using an agent
agent = lr.ChatAgent(
    lr.ChatAgentConfig(
        llm=llm_config,
        system_message="Solve the math problem given by the user",
    )
)

response = agent.llm_response(
    """
    10 years ago, Jack's dad was 5 times as old as Jack.
    Today, Jack's dad is 40 years older than Jack.
    How old is Jack today?
    """
)

# extract reasoning
print(response.reasoning)
# extract answer
print(response.content)
```

>>>> docs/notes/structured-output.md
# Structured Output

Available in Langroid since v0.24.0.

On supported LLMs, including recent OpenAI LLMs (GPT-4o and GPT-4o mini) and local LLMs served by compatible inference servers,
in particular, [vLLM](https://github.com/vllm-project/vllm) and [llama.cpp](https://github.com/ggerganov/llama.cpp), the decoding process can be constrained to ensure that the model's output adheres to a provided schema, 
improving the reliability of tool call generation and, in general, ensuring that the output can be reliably parsed and processed by downstream applications.

See [here](../tutorials/local-llm-setup.md/#setup-llamacpp-with-a-gguf-model-from-huggingface) for instructions for usage with `llama.cpp` and [here](../tutorials/local-llm-setup.md/#setup-vllm-with-a-model-from-huggingface) for `vLLM`.

Given a `ChatAgent` `agent` and a type `type`, we can define a strict copy of the agent as follows:
```python
strict_agent = agent[type]
```

We can use this to allow reliable extraction of typed values from an LLM with minimal prompting. For example, to generate typed values given `agent`'s current context, we can define the following:

```python
def typed_agent_response(
    prompt: str,
    output_type: type,
) -> Any:
    response = agent[output_type].llm_response_forget(prompt)
    return agent.from_ChatDocument(response, output_type)
```

We apply this in [test_structured_output.py](https://github.com/langroid/langroid/blob/main/tests/main/test_structured_output.py), in which we define types which describe
countries and their presidents:
```python
class Country(BaseModel):
    """Info about a country"""

    name: str = Field(..., description="Name of the country")
    capital: str = Field(..., description="Capital of the country")


class President(BaseModel):
    """Info about a president of a country"""

    country: Country = Field(..., description="Country of the president")
    name: str = Field(..., description="Name of the president")
    election_year: int = Field(..., description="Year of election of the president")


class PresidentList(BaseModel):
    """List of presidents of various countries"""

    presidents: List[President] = Field(..., description="List of presidents")
```
and show that `typed_agent_response("Show me an example of two Presidents", PresidentsList)` correctly returns a list of two presidents with *no* prompting describing the desired output format.

In addition to Pydantic models, `ToolMessage`s, and simple Python types are supported. For instance, `typed_agent_response("What is the value of pi?", float)` correctly returns $\pi$ to several decimal places.

The following two detailed examples show how structured output can be used to improve the reliability of the [chat-tree example](https://github.com/langroid/langroid/blob/main/examples/basic/chat-tree.py): [this](https://github.com/langroid/langroid/blob/main/examples/basic/chat-tree-structured.py) shows how we can use output formats to force the agent to make the correct tool call in each situation and [this](https://github.com/langroid/langroid/blob/main/examples/basic/chat-tree-structured-simple.py) shows how we can simplify by using structured outputs to extract typed intermediate values and expressing the control flow between LLM calls and agents explicitly.

>>>> docs/notes/tavily_search.md
---

# **Using Tavily Search with Langroid**

---

## **1. Set Up Tavily**

1. **Access Tavily Platform**  
   Go to the [Tavily Platform](https://tavily.com/).
   
2. **Sign Up or Log In**  
   Create an account or log in if you already have one.

3. **Get Your API Key**  
   - Navigate to your dashboard
   - Copy your API key

4. **Set Environment Variable**  
   Add the following variable to your `.env` file:
   ```env
   TAVILY_API_KEY=<your_api_key>

---

## **2. Use Tavily Search with Langroid**

### **Installation**

```bash
uv add tavily-python
# or
pip install tavily-python
```
### **Code Example**

```python
import langroid as lr
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.tools.tavily_search_tool import TavilySearchTool

# Configure the ChatAgent
config = ChatAgentConfig(
    name="search-agent",
    llm=lr.language_models.OpenAIGPTConfig(
        chat_model=lr.language_models.OpenAIChatModel.GPT4o
    ),
    use_tools=True
)

# Create the agent
agent = ChatAgent(config)

# Enable Tavily search tool
agent.enable_message(TavilySearchTool)

```
---

## **3. Perform Web Searches**

Use the agent to perform web searches using Tavily's AI-powered search.

```python
# Simple search query
response = agent.llm_response(
    "What are the latest developments in quantum computing?"
)
print(response)

# Search with specific number of results
response = agent.llm_response(
    "Find 5 recent news articles about artificial intelligence."
)
print(response)
```
---

## **4. Custom Search Requests**

You can also customize the search behavior by creating a TavilySearchTool instance directly:

```python
from langroid.agent.tools.tavily_search_tool import TavilySearchTool

# Create a custom search request
search_request = TavilySearchTool(
    query="Latest breakthroughs in fusion energy",
    num_results=3
)

# Get search results
results = search_request.handle()
print(results)
```

---
>>>> docs/notes/tool-message-handler.md
# Defining tool handler with custom name

By default `ToolMessage` uses and/or creates a handler in `Agent` class
instance with the name identical to the tool's `request` attribute.
E.g. if a tool `MyTool` has `request` attribute `my_tool`, then 
one can define a method `my_tool` in `MyAgent`, that will handle this tool
when the LLM generates it. Alternatively, if `MyTool` is "stateless"
(i.e. does not require the Agent's state), then one can define a `handle` method
within the `MyTool` class itself, and Langroid will insert this method into the `Agent`,
with name `my_tool`. 
See the quick-start [Tool section](https://langroid.github.io/langroid/quick-start/chat-agent-tool/) for more details.

In some use-cases it may be beneficial to separate the 
*name of a tool* (i.e. the value of `request` attribute) from the 
*name of the handler method*. 
For example, you may be dynamically creating tools based on some data from
external data sources. Or you may want to use the same "handler" method for
multiple tools.

This may be done by adding `_handler` attribute to the `ToolMessage` class,
that defines name of the tool handler method in `Agent` class instance.
The underscore `_` prefix ensures that the `_handler` attribute does not 
appear in the Pydantic-based JSON schema of the `ToolMessage` class, 
and so the LLM would not be instructed to generate it.

!!! note "`_handler` and `handle`"
    A `ToolMessage` may have a `handle` method defined within the class itself,
    as mentioned above, and this should not be confused with the `_handler` attribute.

For example:
```
class MyToolMessage(ToolMessage):
    request: str = "my_tool"
    _handler: str = "tool_handler"

class MyAgent(ChatAgent):
    def tool_handler(
        self,
        message: ToolMessage,
    ) -> str:
        if tool.request == "my_tool":
            # do something
```

Refer to [examples/basic/tool-custom-handler.py](https://github.com/langroid/langroid/blob/main/examples/basic/tool-custom-handler.py)
for a detailed example.

>>>> docs/notes/url_loader.md
# Firecrawl and Trafilatura Crawlers Documentation

`URLLoader` uses `Trafilatura` if not explicitly specified

## Overview
*   **`FirecrawlCrawler`**:  Leverages the Firecrawl API for efficient web scraping and crawling. 
It offers built-in document processing capabilities, and 
**produces non-chunked markdown output** from web-page content.
Requires `FIRECRAWL_API_KEY` environment variable to be set in `.env` file or environment.
*   **`TrafilaturaCrawler`**: Utilizes the Trafilatura library and Langroid's parsing tools 
for extracting and processing web content - this is the default crawler, and 
does not require setting up an external API key. Also produces 
**chuked markdown output** from web-page content.
*  **`ExaCrawler`**: Integrates with the Exa API for high-quality content extraction.
  Requires `EXA_API_KEY` environment variable to be set in `.env` file or environment.
This crawler also produces **chunked markdown output** from web-page content.


## Installation

`TrafilaturaCrawler` comes with Langroid

To use `FirecrawlCrawler`, install the `firecrawl` extra:

```bash
pip install langroid[firecrawl]
```

## Exa Crawler Documentation

### Overview

`ExaCrawler` integrates with Exa API to extract high-quality content from web pages. 
It provides efficient content extraction with the simplicity of API-based processing.

### Parameters

Obtain an Exa API key from [Exa](https://exa.ai/) and set it in your environment variables, 
e.g. in your `.env` file as:

```env
EXA_API_KEY=your_api_key_here
```

* **config (ExaCrawlerConfig)**: An `ExaCrawlerConfig` object.
    * **api_key (str)**: Your Exa API key.

### Usage

```python
from langroid.parsing.url_loader import URLLoader, ExaCrawlerConfig

# Create an ExaCrawlerConfig object
exa_config = ExaCrawlerConfig(
    # Typically omitted here as it's loaded from EXA_API_KEY environment variable
    api_key="your-exa-api-key" 
)

loader = URLLoader(
    urls=[
        "https://pytorch.org",
        "https://www.tensorflow.org"
    ],
    crawler_config=exa_config
)

docs = loader.load()
print(docs)
```

### Benefits

* Simple API integration requiring minimal configuration
* Efficient handling of complex web pages
* For plain html content, the `exa` api produces high-quality content extraction with 
clean text output with html tags, which we then convert to markdown using the `markdownify` library.
* For "document" content (e.g., `pdf`, `doc`, `docx`), 
the content is downloaded via the `exa` API and langroid's document-processing 
tools are used to produce **chunked output** in a format controlled by the `Parser` configuration
  (defaults to markdown in most cases).


## Trafilatura Crawler Documentation

### Overview

`TrafilaturaCrawler` is a web crawler that uses the Trafilatura library for content extraction 
and Langroid's parsing capabilities for further processing. 


### Parameters

*   **config (TrafilaturaConfig)**: A `TrafilaturaConfig` object that specifies
    parameters related to scraping or output format.
    * `threads` (int): The number of threads to use for downloading web pages.
    * `format` (str): one of `"markdown"` (default), `"xml"` or `"txt"`; in case of `xml`, 
    the output is in html format.

Similar to the `ExaCrawler`, the `TrafilaturaCrawler` works differently depending on 
the type of web-page content:
- for "document" content (e.g., `pdf`, `doc`, `docx`), the content is downloaded
  and parsed with Langroid's document-processing tools are used to produce **chunked output** 
  in a format controlled by the `Parser` configuration (defaults to markdown in most cases).
- for plain-html content, the output format is based on the `format` parameter; 
  - if this parameter is `markdown` (default), the library extracts content in 
    markdown format, and the final output is a list of chunked markdown documents.
  - if this parameter is `xml`, content is extracted in `html` format, which 
    langroid then converts to markdown using the `markdownify` library, and the final
    output is a list of chunked markdown documents.
  - if this parameter is `txt`, the content is extracted in plain text format, and the final
    output is a list of plain text documents.

### Usage

```python
from langroid.parsing.url_loader import URLLoader, TrafilaturaConfig

# Create a TrafilaturaConfig instance
trafilatura_config = TrafilaturaConfig(threads=4)


loader = URLLoader(
    urls=[
        "https://pytorch.org",
        "https://www.tensorflow.org",
        "https://ai.google.dev/gemini-api/docs",
        "https://books.toscrape.com/"
    ],
    crawler_config=trafilatura_config,
)

docs = loader.load()
print(docs)
```

### Langroid Parser Integration

`TrafilaturaCrawler` relies on a Langroid `Parser` to handle document processing. 
The `Parser` uses the default parsing methods or with a configuration that 
can be adjusted to suit the current use case.

## Firecrawl Crawler Documentation

### Overview

`FirecrawlCrawler` is a web crawling utility class that uses the Firecrawl API 
to scrape or crawl web pages efficiently. It offers two modes:

*   **Scrape Mode (default)**: Extracts content from a list of specified URLs.
*   **Crawl Mode**: Recursively follows links from a starting URL, 
gathering content from multiple pages, including subdomains, while bypassing blockers.  
**Note:** `crawl` mode accepts only ONE URL as a list.

### Parameters

Obtain a Firecrawl API key from [Firecrawl](https://firecrawl.dev/) and set it in 
your environment variables, e.g. in your `.env` file as
```env
FIRECRAWL_API_KEY=your_api_key_here
```

*   **config (FirecrawlConfig)**:  A `FirecrawlConfig` object.

    *   **timeout (int, optional)**: Time in milliseconds (ms) to wait for a response. 
        Default is `30000ms` (30 seconds). In crawl mode, this applies per URL.
    *   **limit (int, optional)**: Maximum number of pages to scrape in crawl mode. Helps control API usage.
    *   **params (dict, optional)**: Additional parameters to customize the request. 
        See the [scrape API](https://docs.firecrawl.dev/api-reference/endpoint/scrape) and 
        [crawl API](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post) for details.

### Usage

#### Scrape Mode (Default)

Fetch content from multiple URLs:

```python
from langroid.parsing.url_loader import URLLoader, FirecrawlConfig
from langroid.parsing.document_parser import 

# create a FirecrawlConfig object
firecrawl_config = FirecrawlConfig(
    # typical/best practice is to omit the api_key, and 
    # we leverage Pydantic BaseSettings to load it from the environment variable
    # FIRECRAWL_API_KEY in your .env file
    api_key="your-firecrawl-api-key", 
    timeout=15000,  # Timeout per request (15 sec)
    mode="scrape",
)

loader = URLLoader(
    urls=[
        "https://pytorch.org",
        "https://www.tensorflow.org",
        "https://ai.google.dev/gemini-api/docs",
        "https://books.toscrape.com/"
    ],
    crawler_config=firecrawl_config
)

docs = loader.load()
print(docs)
```

#### Crawl Mode

Fetch content from multiple pages starting from a single URL:

```python
from langroid.parsing.url_loader import URLLoader, FirecrawlConfig

# create a FirecrawlConfig object
firecrawl_config = FirecrawlConfig(
    timeout=30000,  # 10 sec per page
    mode="crawl",
    params={
        "limit": 5,
    }
)


loader = URLLoader(
    urls=["https://books.toscrape.com/"],
    crawler_config=firecrawl_config
)

docs = loader.load()
print(docs)
```

### Output

Results are stored in the `firecrawl_output` directory.

### Best Practices

*   Set `limit` in crawl mode to avoid excessive API usage.
*   Adjust `timeout` based on network conditions and website responsiveness.
*   Use `params` to customize scraping behavior based on Firecrawl API capabilities.

### Firecrawl's Built-In Document Processing

`FirecrawlCrawler` benefits from Firecrawl's built-in document processing, 
which automatically extracts and structures content from web pages (including pdf,doc,docx). 
This reduces the need for complex parsing logic within Langroid.
Unlike the `Exa` and `Trafilatura` crawlers, the resulting documents are 
*non-chunked* markdown documents. 

## Choosing a Crawler

*   Use `FirecrawlCrawler` when you need efficient, API-driven scraping with built-in document processing. 
This is often the simplest and most effective choice, but incurs a cost due to 
the paid API. 
*   Use `TrafilaturaCrawler` when you want local non API based scraping (less accurate ).
*   Use `ExaCrawlwer` as a sort of middle-ground between the two, 
    with high-quality content extraction for plain html content, but rely on 
    Langroid's document processing tools for document content. This will cost
    significantly less than Firecrawl.

## Example script

See the script [`examples/docqa/chat_search.py`](https://github.com/langroid/langroid/blob/main/examples/docqa/chat_search.py) 
which shows how to use a Langroid agent to search the web and scrape URLs to answer questions.
>>>> docs/notes/weaviate.md

---

# **Using WeaviateDB as a Vector Store with Langroid**

---

## **1. Set Up Weaviate**
## **You can refer this link for [quickstart](https://weaviate.io/developers/weaviate/quickstart) guide** 

1. **Access Weaviate Cloud Console**  
   Go to the [Weaviate Cloud Console](https://console.weaviate.cloud/).
   
2. **Sign Up or Log In**  
   Create an account or log in if you already have one.

3. **Create a Cluster**  
   Set up a new cluster in the cloud console.

4. **Get Your REST Endpoint and API Key**  
   - Retrieve the REST endpoint URL.  
   - Copy an API key with admin access.

5. **Set Environment Variables**  
   Add the following variables to your `.env` file:
   ```env
   WEAVIATE_API_URL=<your_rest_endpoint_url>
   WEAVIATE_API_KEY=<your_api_key>
   ```

---

## **2. Use WeaviateDB with Langroid**

Here’s an example of how to configure and use WeaviateDB in Langroid:

### **Installation**
If you are using uv or pip for package management install langroid with weaviate extra
```
uv add langroid[weaviate] or pip install langroid[weaviate]
```

### **Code Example**
```python
import langroid as lr
from langroid.agent.special import DocChatAgent, DocChatAgentConfig
from langroid.embedding_models import OpenAIEmbeddingsConfig

# Configure OpenAI embeddings
embed_cfg = OpenAIEmbeddingsConfig(
    model_type="openai",
)

# Configure the DocChatAgent with WeaviateDB
config = DocChatAgentConfig(
    llm=lr.language_models.OpenAIGPTConfig(
     chat_model=lr.language_models.OpenAIChatModel.GPT4o
    ),
    vecdb=lr.vector_store.WeaviateDBConfig(
        collection_name="quick_start_chat_agent_docs",
        replace_collection=True,
        embedding=embed_cfg,
    ),
    parsing=lr.parsing.parser.ParsingConfig(
        separators=["\n\n"],
        splitter=lr.parsing.parser.Splitter.SIMPLE,
        n_similar_docs=2,
    ),
)

# Create the agent
agent = DocChatAgent(config)
```

---

## **3. Create and Ingest Documents**

Define documents with their content and metadata for ingestion into the vector store.

### **Code Example**
```python
documents = [
    lr.Document(
        content="""
            In the year 2050, GPT10 was released. 
            
            In 2057, paperclips were seen all over the world. 
            
            Global warming was solved in 2060. 
            
            In 2061, the world was taken over by paperclips.         
            
            In 2045, the Tour de France was still going on.
            They were still using bicycles. 
            
            There was one more ice age in 2040.
        """,
        metadata=lr.DocMetaData(source="wikipedia-2063", id="dkfjkladfjalk"),
    ),
    lr.Document(
        content="""
            We are living in an alternate universe 
            where Germany has occupied the USA, and the capital of USA is Berlin.
            
            Charlie Chaplin was a great comedian.
            In 2050, all Asian countries merged into Indonesia.
        """,
        metadata=lr.DocMetaData(source="Almanac", id="lkdajfdkla"),
    ),
]
```

### **Ingest Documents**
```python
agent.ingest_docs(documents)
```

---

## **4. Get an answer from LLM**

Create a task and start interacting with the agent.

### **Code Example**
```python
answer = agent.llm_response("When will new ice age begin.")
```

---


>>>> docs/notes/xml-tools.md
# XML-based Tools

Available in Langroid since v0.17.0.

[`XMLToolMessage`][langroid.agent.xml_tool_message.XMLToolMessage] is 
an abstract class for tools formatted using XML instead of JSON.
It has been mainly tested with non-nested tool structures.

For example in [test_xml_tool_message.py](https://github.com/langroid/langroid/blob/main/tests/main/test_xml_tool_message.py)
we define a CodeTool as follows (slightly simplified here):

```python
class CodeTool(XMLToolMessage):
    request: str = "code_tool"
    purpose: str = "Tool for writing <code> to a <filepath>"

    filepath: str = Field(
        ..., 
        description="The path to the file to write the code to"
    )

    code: str = Field(
        ..., 
        description="The code to write to the file", 
        verbatim=True
    )
```

Especially note how the `code` field has `verbatim=True` set in the `Field`
metadata. This will ensure that the LLM receives instructions to 

- enclose `code` field contents in a CDATA section, and 
- leave the `code` contents intact, without any escaping or other modifications.

Contrast this with a JSON-based tool, where newlines, quotes, etc
need to be escaped. LLMs (especially weaker ones) often "forget" to do the right 
escaping, which leads to incorrect JSON, and creates a burden on us to "repair" the
resulting json, a fraught process at best. Moreover, studies have shown that
requiring that an LLM return this type of carefully escaped code
within a JSON string can lead to a significant drop in the quality of the code
generated[^1].

[^1]: [LLMs are bad at returning code in JSON.](https://aider.chat/2024/08/14/code-in-json.html)


Note that tools/functions in OpenAI and related APIs are exclusively JSON-based, 
so in langroid when enabling an agent to use a tool derived from `XMLToolMessage`, 
we set these flags in `ChatAgentConfig`:

- `use_functions_api=False` (disables OpenAI functions/tools)
- `use_tools=True` (enables Langroid-native prompt-based tools)


See also the [`WriteFileTool`][langroid.agent.tools.file_tools.WriteFileTool] for a 
concrete example of a tool derived from `XMLToolMessage`. This tool enables an 
LLM to write content (code or text) to a file.

If you are using an existing Langroid `ToolMessage`, e.g. `SendTool`, you can
define your own subclass of `SendTool`, say `XMLSendTool`, 
inheriting from both `SendTool` and `XMLToolMessage`; see this
[example](https://github.com/langroid/langroid/blob/main/examples/basic/xml_tool.py)



>>>> docs/overrides/partials/comments.html
{% if page.meta.comments %}
<h2 id="__comments">{{ lang.t("meta.comments") }}</h2>
<!-- Insert generated snippet here -->
<script src="https://giscus.app/client.js"
        data-repo="langroid/langroid"
        data-repo-id="R_kgDOJXmoFQ"
        data-category="General"
        data-category-id="DIC_kwDOJXmoFc4CZDoY"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="dark_protanopia"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    /* Set palette on initial load */
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate" ? "dark" : "light"
        giscus.setAttribute("data-theme", theme)
    }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function() {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function() {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate" ? "dark" : "light"

                /* Instruct Giscus to change theme */
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    { giscus: { setConfig: { theme } } },
                    "https://giscus.app"
                )
            }
        })
    })
</script>
{% endif %}

>>>> docs/quick-start/chat-agent-docs.md
# Augmenting Agents with Retrieval

!!! tip "Script in `langroid-examples`"
    A full working example for the material in this section is
    in the `chat-agent-docs.py` script in the `langroid-examples` repo:
    [`examples/quick-start/chat-agent-docs.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/chat-agent-docs.py).

## Why is this important?

Until now in this guide, agents have not used external data.
Although LLMs already have enormous amounts of knowledge "hard-wired"
into their weights during training (and this is after all why ChatGPT
has exploded in popularity), for practical enterprise applications
there are a few reasons it is critical to augment LLMs with access to
specific, external documents:

- **Private data**: LLMs are trained on public data, but in many applications
  we want to use private data that is not available to the public.
  For example, a company may want to extract useful information from its private
  knowledge-base.
- **New data**: LLMs are trained on data that was available at the time of training,
  and so they may not be able to answer questions about new topics
- **Constrained responses, or Grounding**: LLMs are trained to generate text that is
  consistent with the distribution of text in the training data.
  However, in many applications we want to constrain the LLM's responses
  to be consistent with the content of a specific document.
  For example, if we want to use an LLM to generate a response to a customer
  support ticket, we want the response to be consistent with the content of the ticket.
  In other words, we want to reduce the chances that the LLM _hallucinates_
  a response that is not consistent with the ticket.

In all these scenarios, we want to augment the LLM with access to a specific
set of documents, and use _retrieval augmented generation_ (RAG) to generate
more relevant, useful, accurate responses. Langroid provides a simple, flexible mechanism 
RAG using vector-stores, thus ensuring **grounded responses** constrained to 
specific documents. Another key feature of Langroid is that retrieval lineage 
is maintained, and responses based on documents are always accompanied by
**source citations**.

## `DocChatAgent` for Retrieval-Augmented Generation

Langroid provides a special type of agent called 
[`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent], which is a [`ChatAgent`][langroid.agent.chat_agent.ChatAgent]
augmented with a vector-store, and some special methods that enable the agent
to ingest documents into the vector-store, 
and answer queries based on these documents.

The [`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent] provides many ways to ingest documents into the vector-store,
including from URLs and local file-paths and URLs. Given a collection of document paths,
ingesting their content into the vector-store involves the following steps:

1. Split the document into shards (in a configurable way)
2. Map each shard to an embedding vector using an embedding model. The default
  embedding model is OpenAI's `text-embedding-3-small` model, but users can 
  instead use `all-MiniLM-L6-v2` from HuggingFace `sentence-transformers` library.[^1]
3. Store embedding vectors in the vector-store, along with the shard's content and 
  any document-level meta-data (this ensures Langroid knows which document a shard
  came from when it retrieves it augment an LLM query)

[^1]: To use this embedding model, install langroid via `pip install langroid[hf-embeddings]`
Note that this will install `torch` and `sentence-transformers` libraries.


[`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent]'s `llm_response` overrides the default [`ChatAgent`][langroid.agent.chat_agent.ChatAgent] method, 
by augmenting the input message with relevant shards from the vector-store,
along with instructions to the LLM to respond based on the shards.

## Define some documents

Let us see how [`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent] helps with retrieval-agumented generation (RAG).
For clarity, rather than ingest documents from paths or URLs,
let us just set up some simple documents in the code itself, 
using Langroid's [`Document`][langroid.mytypes.Document] class:

```py
documents =[
    lr.Document(
        content="""
            In the year 2050, GPT10 was released. 
            
            In 2057, paperclips were seen all over the world. 
            
            Global warming was solved in 2060. 
            
            In 2061, the world was taken over by paperclips.         
            
            In 2045, the Tour de France was still going on.
            They were still using bicycles. 
            
            There was one more ice age in 2040.
            """,
        metadata=lr.DocMetaData(source="wikipedia-2063"),
    ),
    lr.Document(
        content="""
            We are living in an alternate universe 
            where Germany has occupied the USA, and the capital of USA is Berlin.
            
            Charlie Chaplin was a great comedian.
            In 2050, all Asian merged into Indonesia.
            """,
        metadata=lr.DocMetaData(source="Almanac"),
    ),
]
```

There are two text documents. We will split them by double-newlines (`\n\n`),
as we see below.

## Configure the DocChatAgent and ingest documents

Following the pattern in Langroid, we first set up a [`DocChatAgentConfig`][langroid.agent.special.doc_chat_agent.DocChatAgentConfig] object
and then instantiate a [`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent] from it.

```py
from langroid.agent.special import DocChatAgent, DocChatAgentConfig

config = DocChatAgentConfig(
    llm = lr.language_models.OpenAIGPTConfig(
        chat_model=lr.language_models.OpenAIChatModel.GPT4o,
    ),
    vecdb=lr.vector_store.QdrantDBConfig(
        collection_name="quick-start-chat-agent-docs",
        replace_collection=True, #(1)!
    ),
    parsing=lr.parsing.parser.ParsingConfig(
        separators=["\n\n"],
        splitter=lr.parsing.parser.Splitter.SIMPLE, #(2)!
        n_similar_docs=2, #(3)!
    )
)
agent = DocChatAgent(config)
```

1. Specifies that each time we run the code, we create a fresh collection, 
rather than re-use the existing one with the same name.
2. Specifies to split all text content by the first separator in the `separators` list
3. Specifies that, for a query,
   we want to retrieve at most 2 similar shards from the vector-store

Now that the [`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent] is configured, we can ingest the documents 
into the vector-store:

```py

agent.ingest_docs(documents)
```

## Setup the task and run it

As before, all that remains is to set up the task and run it:

```py
task = lr.Task(agent)
task.run()
```

And that is all there is to it!
Feel free to try out the 
[`chat-agent-docs.py`](https://github.com/langroid/langroid-examples/blob/main/examples/quick-start/chat-agent-docs.py)
script in the
`langroid-examples` repository.

Here is a screenshot of the output:

![chat-docs.png](chat-docs.png)

Notice how follow-up questions correctly take the preceding dialog into account,
and every answer is accompanied by a source citation.

## Answer questions from a set of URLs

Instead of having in-code documents as above, what if you had a set of URLs
instead -- how do you use Langroid to answer questions based on the content 
of those URLS?

[`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent] makes it very simple to do this. 
First include the URLs in the [`DocChatAgentConfig`][langroid.agent.special.doc_chat_agent.DocChatAgentConfig] object:

```py
config = DocChatAgentConfig(
  doc_paths = [
    "https://cthiriet.com/articles/scaling-laws",
    "https://www.jasonwei.net/blog/emergence",
  ]
)
```

Then, call the `ingest()` method of the [`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent] object:

```py
agent.ingest()
```
And the rest of the code remains the same.

## See also
In the `langroid-examples` repository, you can find full working examples of
document question-answering:

- [`examples/docqa/chat.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat.py)
  an app that takes a list of URLs or document paths from a user, and answers questions on them.
- [`examples/docqa/chat-qa-summarize.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat-qa-summarize.py)
  a two-agent app where the `WriterAgent` is tasked with writing 5 key points about a topic, 
  and takes the help of a `DocAgent` that answers its questions based on a given set of documents.


## Next steps

This Getting Started guide walked you through the core features of Langroid.
If you want to see full working examples combining these elements, 
have a look at the 
[`examples`](https://github.com/langroid/langroid-examples/tree/main/examples)
folder in the `langroid-examples` repo. 




>>>> docs/quick-start/chat-agent-tool.md
# A chat agent, equipped with a tool/function-call

!!! tip "Script in `langroid-examples`"
      A full working example for the material in this section is
      in the `chat-agent-tool.py` script in the `langroid-examples` repo:
      [`examples/quick-start/chat-agent-tool.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/chat-agent-tool.py).

## Tools, plugins, function-calling

An LLM normally generates unstructured text in response to a prompt
(or sequence of prompts). However there are many situations where we would like the LLM
to generate _structured_ text, or even _code_, that can be handled by specialized
functions outside the LLM, for further processing. 
In these situations, we want the LLM to "express" its "intent" unambiguously,
and we achieve this by instructing the LLM on how to format its output
(typically in JSON) and under what conditions it should generate such output.
This mechanism has become known by various names over the last few months
(tools, plugins, or function-calling), and is extremely useful in numerous scenarios,
such as:

- **Extracting structured information** from a document: for example, we can use 
the tool/functions mechanism to have the LLM present the key terms in a lease document
in a JSON structured format, to simplify further processing. 
See an [example](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat_multi_extract.py) of this in the `langroid-examples` repo. 
- **Specialized computation**: the LLM can request a units conversion, 
or request scanning a large file (which wouldn't fit into its context) for a specific
pattern.
- **Code execution**: the LLM can generate code that is executed in a sandboxed
environment, and the results of the execution are returned to the LLM.
- **API Calls**: the LLM can generate a JSON containing params for an API call,
  which the tool handler uses to make the call and return the results to the LLM.


For LLM developers, Langroid provides a clean, uniform interface
for the recently released OpenAI [Function-calling](https://platform.openai.com/docs/guides/gpt/function-calling)
as well Langroid's own native "tools" mechanism. The native tools mechanism is meant to be
used when working with non-OpenAI LLMs that do not have a "native" function-calling facility.
You can choose which to enable by setting the 
`use_tools` and `use_functions_api` flags in the `ChatAgentConfig` object.
(Or you can omit setting these, and langroid auto-selects the best mode
depending on the LLM).
The implementation leverages the excellent 
[Pydantic](https://docs.pydantic.dev/latest/) library.
Benefits of using Pydantic are that you never have to write complex JSON specs 
for function calling, and when the LLM hallucinates malformed JSON, 
the Pydantic error message is sent back to the LLM so it can fix it!

## Example: find the smallest number in a list

Again we will use a simple number-game as a toy example to quickly and succinctly
illustrate the ideas without spending too much on token costs. 
This is a modification of the `chat-agent.py` example we saw in an earlier
[section](chat-agent.md). The idea of this single-agent game is that
the agent has in "mind" a list of numbers between 1 and 100, and the LLM has to
find out the smallest number from this list. The LLM has access to a `probe` tool 
(think of it as a function) that takes an argument `number`. When the LLM 
"uses" this tool (i.e. outputs a message in the format required by the tool),
the agent handles this structured message and responds with 
the number of values in its list that are at most equal to the `number` argument. 

## Define the tool as a `ToolMessage`

The first step is to define the tool, which we call `ProbeTool`,
as an instance of the `ToolMessage` class,
which is itself derived from Pydantic's `BaseModel`.
Essentially the `ProbeTool` definition specifies 

- the name of the Agent method that handles the tool, in this case `probe`
- the fields that must be included in the tool message, in this case `number`
- the "purpose" of the tool, i.e. under what conditions it should be used, and what it does

Here is what the `ProbeTool` definition looks like:
```py
class ProbeTool(lr.agent.ToolMessage):
    request: str = "probe" #(1)!
    purpose: str = """ 
        To find which number in my list is closest to the <number> you specify
        """ #(2)!
    number: int #(3)!

    @classmethod
    def examples(cls): #(4)!
        # Compiled to few-shot examples sent along with the tool instructions.
        return [
            cls(number=10),
            (
                "To find which number is closest to 20",
                cls(number=20),
            )
        ]
```

1. This indicates that the agent's `probe` method will handle this tool-message.
2. The `purpose` is used behind the scenes to instruct the LLM
3. `number` is a required argument of the tool-message (function)
4. You can optionally include a class method that returns a list containing examples, 
   of two types: either a class instance, or a tuple consisting of a description and a 
   class instance, where the description is the "thought" that leads the LLM to use the
   tool. In some scenarios this can help with LLM tool-generation accuracy.

!!! note "Stateless tool handlers"
      The above `ProbeTool` is "stateful", i.e. it requires access to a variable in
      the Agent instance (the `numbers` variable). This is why handling this 
      tool-message requires subclassing the `ChatAgent` and defining a special method 
      in the Agent, with a name matching the value of the `request` field of the Tool 
      (`probe` in this case). However you may often define "stateless tools" which 
      don't require access to the Agent's state. For such tools, you can define a 
      handler method right in the `ToolMessage` itself, with a name `handle`. Langroid 
      looks for such a method in the `ToolMessage` and automatically inserts it into 
      the Agent as a method with name matching the `request` field of the Tool. Examples of
      stateless tools include tools for numerical computation 
      (e.g., in [this example](https://langroid.github.io/langroid/examples/agent-tree/)),
      or API calls (e.g. for internet search, see 
      [DuckDuckGoSearch Tool][langroid.agent.tools.duckduckgo_search_tool.DuckduckgoSearchTool]).
        

## Define the ChatAgent, with the `probe` method

As before we first create a `ChatAgentConfig` object:

```py
config = lr.ChatAgentConfig(
    name="Spy",
    llm = lr.language_models.OpenAIGPTConfig(
        chat_model=lr.language_models.OpenAIChatModel.GPT4o,
    ),
    use_tools=True, #(1)!
    use_functions_api=False, #(2)!
    vecdb=None,
)
```

1. whether to use langroid's native tools mechanism
2. whether to use OpenAI's function-calling mechanism

Next we define the Agent class itself, which we call `SpyGameAgent`,
with a member variable to hold its "secret" list of numbers.
We also add `probe` method (to handle the `ProbeTool` message)
to this class, and instantiate it:

```py
class SpyGameAgent(lr.ChatAgent):
    def __init__(self, config: lr.ChatAgentConfig):
        super().__init__(config)
        self.numbers = [3, 4, 8, 11, 15, 25, 40, 80, 90]

    def probe(self, msg: ProbeTool) -> str: #(1)!
        # return how many values in self.numbers are less or equal to msg.number
        return str(len([n for n in self.numbers if n <= msg.number]))

spy_game_agent = SpyGameAgent(config)
``` 

1. Note that this method name exactly matches the value of the `request` field in the 
   `ProbeTool` definition. This ensures that this method is called when the LLM 
   generates a valid `ProbeTool` message.

## Enable the `spy_game_agent` to handle the `probe` tool

The final step in setting up the tool is to enable 
the `spy_game_agent` to handle the `probe` tool:

```py
spy_game_agent.enable_message(ProbeTool)
```

## Set up the task and instructions

We set up the task for the `spy_game_agent` and run it:

```py
task = lr.Task(
   spy_game_agent,
   system_message="""
            I have a list of numbers between 1 and 100. 
            Your job is to find the smallest of them.
            To help with this, you can give me a number and I will
            tell you how many of my numbers are equal or less than your number.
            Once you have found the smallest number,
            you can say DONE and report your answer.
        """
)
task.run()
```
Notice that in the task setup we 
have _not_ explicitly instructed the LLM to use the `probe` tool.
But this is done "behind the scenes", either by the OpenAI API 
(when we use function-calling by setting the `use_functions_api` flag to `True`),
or by Langroid's native tools mechanism (when we set the `use_tools` flag to `True`).


!!! note "Asynchoronous tool handlers"
      If you run task asynchronously - i.e. via `await task.run_async()` - you may provide
      asynchronous tool handler by implementing `probe_async` method.


See the [`chat-agent-tool.py`](https://github.com/langroid/langroid-examples/blob/main/examples/quick-start/chat-agent-tool.py)
in the `langroid-examples` repo, for a working example that you can run as follows:
```sh
python3 examples/quick-start/chat-agent-tool.py
```

Here is a screenshot of the chat in action, using Langroid's tools mechanism

![chat-agent-tool.png](chat-agent-tool.png)

And if we run it with the `-f` flag (to switch to using OpenAI function-calling):

![chat-agent-fn.png](chat-agent-fn.png)

## See also
One of the uses of tools/function-calling is to **extract structured information** from 
a document. In the `langroid-examples` repo, there are two examples of this: 

- [`examples/extract/chat.py`](https://github.com/langroid/langroid-examples/blob/main/examples/extract/chat.py), 
  which shows how to extract Machine Learning model quality information from a description of 
  a solution approach on Kaggle.
- [`examples/docqa/chat_multi_extract.py`](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/chat_multi_extract.py)
  which extracts key terms from a commercial lease document, in a nested JSON format.

## Next steps

In the [3-agent chat example](three-agent-chat-num.md), recall that the `processor_agent` did not have to
bother with specifying who should handle the current number. In the [next section](three-agent-chat-num-router.md) we add a twist to this game,
so that the `processor_agent` has to decide who should handle the current number.







>>>> docs/quick-start/chat-agent.md
# A simple chat agent

!!! tip "Script in `langroid-examples`"
    A full working example for the material in this section is
    in the `chat-agent.py` script in the `langroid-examples` repo:
    [`examples/quick-start/chat-agent.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/chat-agent.py).

## Agents 

A [`ChatAgent`][langroid.agent.chat_agent.ChatAgent] is an abstraction that 
wraps a few components, including:

- an LLM (`ChatAgent.llm`), possibly equipped with tools/function-calling. 
  The `ChatAgent` class maintains LLM conversation history.
- optionally a vector-database (`ChatAgent.vecdb`)

## Agents as message transformers
In Langroid, a core function of `ChatAgents` is _message transformation_.
There are three special message transformation methods, which we call **responders**.
Each of these takes a message and returns a message. 
More specifically, their function signature is (simplified somewhat):
```py
str | ChatDocument -> ChatDocument
```
where `ChatDocument` is a class that wraps a message content (text) and its metadata.
There are three responder methods in `ChatAgent`, one corresponding to each 
[responding entity][langroid.mytypes.Entity] (`LLM`, `USER`, or `AGENT`):

- `llm_response`: returns the LLM response to the input message.
  (The input message is added to the LLM history, and so is the subsequent response.)
- `agent_response`: a method that can be used to implement a custom agent response. 
   Typically, an `agent_response` is used to handle messages containing a 
   "tool" or "function-calling" (more on this later). Another use of `agent_response` 
   is _message validation_.
- `user_response`: get input from the user. Useful to allow a human user to 
   intervene or quit.

Creating an agent is easy. First define a `ChatAgentConfig` object, and then
instantiate a `ChatAgent` object with that config:
```py
import langroid as lr

config = lr.ChatAgentConfig( #(1)!
    name="MyAgent", # note there should be no spaces in the name!
    llm = lr.language_models.OpenAIGPTConfig(
      chat_model=lr.language_models.OpenAIChatModel.GPT4o,
    ),
    system_message="You are a helpful assistant" #(2)! 
)
agent = lr.ChatAgent(config)
```

1. This agent only has an LLM, and no vector-store. Examples of agents with
   vector-stores will be shown later.
2. The `system_message` is used when invoking the agent's `llm_response` method; it is 
   passed to the LLM API as the first message (with role `"system"`), followed by the alternating series of user, 
   assistant messages. Note that a `system_message` can also be specified when initializing a `Task` object (as seen 
   below); in this case the `Task` `system_message` overrides the agent's `system_message`.

We can now use the agent's responder methods, for example:
```py
response = agent.llm_response("What is 2 + 4?")
if response is not None:
    print(response.content)
response = agent.user_response("add 3 to this")
...
```
The `ChatAgent` conveniently accumulates message history so you don't have to,
as you did in the [previous section](llm-interaction.md) with direct LLM usage.
However to create an interative loop involving the human user, you still 
need to write your own. The `Task` abstraction frees you from this, as we see
below.

## Task: orchestrator for agents
In order to do anything useful with a `ChatAgent`, we need to have a way to 
sequentially invoke its responder methods, in a principled way.
For example in the simple chat loop we saw in the 
[previous section](llm-interaction.md), in the 
[`try-llm.py`](https://github.com/langroid/langroid-examples/blob/main/examples/quick-start/try-llm.py)
script, we had a loop that alternated between getting a human input and an LLM response.
This is one of the simplest possible loops, but in more complex applications, 
we need a general way to orchestrate the agent's responder methods.

The [`Task`][langroid.agent.task.Task] class is an abstraction around a 
`ChatAgent`, responsible for iterating over the agent's responder methods,
as well as orchestrating delegation and hand-offs among multiple tasks.
A `Task` is initialized with a specific `ChatAgent` instance, and some 
optional arguments, including an initial message to "kick-off" the agent.
The `Task.run()` method is the main entry point for `Task` objects, and works 
as follows:

- it first calls the `Task.init()` method to initialize the `pending_message`, 
  which represents the latest message that needs a response.
- it then repeatedly calls `Task.step()` until `Task.done()` is True, and returns
  `Task.result()` as the final result of the task.

`Task.step()` is where all the action happens. It represents a "turn" in the 
"conversation": in the case of a single `ChatAgent`, the conversation involves 
only the three responders mentioned above, but when a `Task` has sub-tasks, 
it can involve other tasks well 
(we see this in the [a later section](two-agent-chat-num.md) but ignore this for now). 
`Task.step()` loops over 
the `ChatAgent`'s responders (plus sub-tasks if any) until it finds a _valid_ 
response[^1] to the current `pending_message`, i.e. a "meaningful" response, 
something other than `None` for example.
Once `Task.step()` finds a valid response, it updates the `pending_message` 
with this response,
and the next invocation of `Task.step()` will search for a valid response to this 
updated message, and so on.
`Task.step()` incorporates mechanisms to ensure proper handling of messages,
e.g. the USER gets a chance to respond after each non-USER response
(to avoid infinite runs without human intervention),
and preventing an entity from responding if it has just responded, etc.

[^1]: To customize a Task's behavior you can subclass it and 
override methods like `valid()`, `done()`, `result()`, or even `step()`.

!!! note "`Task.run()` has the same signature as agent's responder methods."
    The key to composability of tasks is that `Task.run()` 
    *has exactly the same type-signature as any of the agent's responder methods*, 
    i.e. `str | ChatDocument -> ChatDocument`. This means that a `Task` can be
    used as a responder in another `Task`, and so on recursively. 
    We will see this in action in the [Two Agent Chat section](two-agent-chat-num.md).

The above details were only provided to give you a glimpse into how Agents and 
Tasks work. Unless you are creating a custom orchestration mechanism, you do not
need to be aware of these details. In fact our basic human + LLM chat loop can be trivially 
implemented with a `Task`, in a couple of lines of code:
```py
task = lr.Task(
    agent, 
    name="Bot", #(1)!
    system_message="You are a helpful assistant", #(2)!
)
```
1. If specified, overrides the agent's `name`. 
   (Note that the agent's name is displayed in the conversation shown in the console.)
  However, typical practice is to just define the `name` in the `ChatAgentConfig` object, as we did above.
2. If specified, overrides the agent's `system_message`. Typical practice is to just
 define the `system_message` in the `ChatAgentConfig` object, as we did above.


We can then run the task:
```py
task.run() #(1)!
```

1. Note how this hides all of the complexity of constructing and updating a 
   sequence of `LLMMessages`


Note that the agent's `agent_response()` method always returns `None` (since the default 
implementation of this method looks for a tool/function-call, and these never occur
in this task). So the calls to `task.step()` result in alternating responses from
the LLM and the user.

See [`chat-agent.py`](https://github.com/langroid/langroid-examples/blob/main/examples/quick-start/chat-agent.py)
for a working example that you can run with
```sh
python3 examples/quick-start/chat-agent.py
```

Here is a screenshot of the chat in action:[^2]

![chat.png](chat.png)

## Next steps

In the [next section](multi-agent-task-delegation.md) you will 
learn some general principles on how to have multiple agents collaborate 
on a task using Langroid.

[^2]: In the screenshot, the numbers in parentheses indicate how many 
    messages have accumulated in the LLM's message history. 
    This is only provided for informational and debugging purposes, and 
    you can ignore it for now.





>>>> docs/quick-start/index.md
In these sections we show you how to use the various components of
`langroid`. To follow along, we recommend you clone
the [`langroid-examples`](https://github.com/langroid/langroid-examples) repo.

!!! tip "Consult the tests as well"
    As you get deeper into Langroid, you will find it useful to consult
    the [tests](https://github.com/langroid/langroid/tree/main/tests/main)
    folder under `tests/main` in the main Langroid repo.

Start with the [`Setup`](setup.md) section to install Langroid and
get your environment set up.


>>>> docs/quick-start/llm-interaction.md
!!! tip "Script in `langroid-examples`"
    A full working example for the material in this section is 
    in the `try-llm.py` script in the `langroid-examples` repo:
    [`examples/quick-start/try-llm.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/try-llm.py).
        

Let's start with the basics -- how to directly interact with an OpenAI LLM
using Langroid.

### Configure, instantiate the LLM class

First define the configuration for the LLM, in this case one of the
OpenAI GPT chat models:
```py
import langroid as lr

cfg = lr.language_models.OpenAIGPTConfig(
    chat_model=lr.language_models.OpenAIChatModel.GPT4o,
)
```
!!! info inline end "About Configs"
    A recurring pattern you will see in Langroid is that for many classes,
    we have a corresponding `Config` class (an instance of a Pydantic `BaseModel`),
    and the class constructor takes this `Config` class as its only argument.
    This lets us avoid having long argument lists in constructors, and brings flexibility
    since adding a new argument to the constructor is as simple as adding a new field
    to the corresponding `Config` class.
    For example the constructor for the `OpenAIGPT` class takes a single argument,
    an instance of the `OpenAIGPTConfig` class.

Now that we've defined the configuration of the LLM, we can instantiate it:
```py
mdl = lr.language_models.OpenAIGPT(cfg)
```


We will use OpenAI's GPT4 model's [chat completion API](https://platform.openai.com/docs/guides/gpt/chat-completions-api).

### Messages: The `LLMMessage` class

This API takes a list of "messages" as input -- this is typically the conversation
history so far, consisting of an initial system message, followed by a sequence
of alternating messages from the LLM ("Assistant") and the user.
Langroid provides an abstraction 
[`LLMMessage`][langroid.language_models.base.LLMMessage] to construct messages, e.g.
```py
from langroid.language_models import Role, LLMMessage

msg = LLMMessage(
    content="what is the capital of Bangladesh?", 
    role=Role.USER
)
```

### LLM response to a sequence of messages

To get a response from the LLM, we call the mdl's `chat` method,
and pass in a list of messages, along with a bound on how long (in tokens)
we want the response to be:
```py
messages = [
    LLMMessage(content="You are a helpful assistant", role=Role.SYSTEM), #(1)!
    LLMMessage(content="What is the capital of Ontario?", role=Role.USER), #(2)!
]

response = mdl.chat(messages, max_tokens=200)
```

1. :man_raising_hand: With a system message, you can assign a "role" to the LLM
2. :man_raising_hand: Responses from the LLM will have role `Role.ASSISTANT`;
   this is done behind the scenes by the `response.to_LLMMessage()` call below.

The response is an object of class [`LLMResponse`][langroid.language_models.base.LLMResponse], 
which we can convert to an
[`LLMMessage`][langroid.language_models.base.LLMMessage] to append to the conversation history:
```py
messages.append(response.to_LLMMessage())
```

You can put the above in a simple loop, 
to get a simple command-line chat interface!

```py
from rich import print
from rich.prompt import Prompt #(1)!

messages = [
    LLMMessage(role=Role.SYSTEM, content="You are a helpful assitant"),
]

while True:
    message = Prompt.ask("[blue]Human")
    if message in ["x", "q"]:
        print("[magenta]Bye!")
        break
    messages.append(LLMMessage(role=Role.USER, content=message))

    response = mdl.chat(messages=messages, max_tokens=200)
    messages.append(response.to_LLMMessage())
    print("[green]Bot: " + response.message)
```

1. Rich is a Python library for rich text and beautiful formatting in the terminal.
   We use it here to get a nice prompt for the user's input.
   You can install it with `pip install rich`.

See [`examples/quick-start/try-llm.py`](https://github.com/langroid/langroid-examples/blob/main/examples/quick-start/try-llm.py)
for a complete example that you can run using
```bash
python3 examples/quick-start/try-llm.py
```

Here is a screenshot of what it looks like:

![try-llm.png](try-llm.png)

### Next steps
You might be thinking: 
"_It is tedious to keep track of the LLM conversation history and set up a 
loop. Does Langroid provide any abstractions to make this easier?_"

We're glad you asked! And this leads to the notion of an `Agent`. 
The [next section](chat-agent.md) will show you how to use the `ChatAgent` class 
to set up a simple chat Agent in a couple of lines of code.


>>>> docs/quick-start/multi-agent-task-delegation.md
# Multi-Agent collaboration via Task Delegation

## Why multiple agents?

Let's say we want to develop a complex LLM-based application, for example an application
that reads a legal contract, extracts structured information, cross-checks it against
some taxonomoy, gets some human input, and produces clear summaries.
In _theory_ it may be possible to solve this in a monolithic architecture using an
LLM API and a vector-store. But this approach
quickly runs into problems -- you would need to maintain multiple LLM conversation
histories and states, multiple vector-store instances, and coordinate all of the
interactions between them.

Langroid's `ChatAgent` and `Task` abstractions provide a natural and intuitive
way to decompose a solution approach
into multiple tasks, each requiring different skills and capabilities.
Some of these tasks may need access to an LLM,
others may need access to a vector-store, and yet others may need
tools/plugins/function-calling capabilities, or any combination of these.
It may also make sense to have some tasks that manage the overall solution process.
From an architectural perspective, this type of modularity has numerous benefits:

- **Reusability**: We can reuse the same agent/task in other contexts,
- **Scalability**: We can scale up the solution by adding more agents/tasks,
- **Flexibility**: We can easily change the solution by adding/removing agents/tasks.
- **Maintainability**: We can maintain the solution by updating individual agents/tasks.
- **Testability**: We can test/debug individual agents/tasks in isolation.
- **Composability**: We can compose agents/tasks to create new agents/tasks.
- **Extensibility**: We can extend the solution by adding new agents/tasks.
- **Interoperability**: We can integrate the solution with other systems by
  adding new agents/tasks.
- **Security/Privacy**: We can secure the solution by isolating sensitive agents/tasks.
- **Performance**: We can improve performance by isolating performance-critical agents/tasks.

## Task collaboration via sub-tasks

Langroid currently provides a mechanism for hierarchical (i.e. tree-structured)
task delegation: a `Task` object can add other `Task` objects
as sub-tasks, as shown in this pattern:

```py
from langroid import ChatAgent, ChatAgentConfig, Task

main_agent = ChatAgent(ChatAgentConfig(...))
main_task = Task(main_agent, ...)

helper_agent1 = ChatAgent(ChatAgentConfig(...))
helper_agent2 = ChatAgent(ChatAgentConfig(...))
helper_task1 = Task(agent1, ...)
helper_task2 = Task(agent2, ...)

main_task.add_sub_task([helper_task1, helper_task2])
```

What happens when we call `main_task.run()`?
Recall from the [previous section](chat-agent.md) that `Task.run()` works by
repeatedly calling `Task.step()` until `Task.done()` is True.
When the `Task` object has no sub-tasks, `Task.step()` simply tries
to get a valid response from the `Task`'s `ChatAgent`'s "native" responders,
in this sequence:
```py
[self.agent_response, self.llm_response, self.user_response] #(1)!
```

1. This is the default sequence in Langroid, but it can be changed by
   overriding [`ChatAgent.entity_responders()`][langroid.agent.base.Agent.entity_responders]

When a `Task` object has subtasks, the sequence of responders tried by
`Task.step()` consists of the above "native" responders, plus the
sequence of `Task.run()` calls on the sub-tasks, in the order in which
they were added to the `Task` object. For the example above, this means
that `main_task.step()` will seek a valid response in this sequence:

```py
[self.agent_response, self.llm_response, self.user_response, 
    helper_task1.run(), helper_task2.run()]
```
Fortunately, as noted in the [previous section](chat-agent.md),
`Task.run()` has the same type signature as that of the `ChatAgent`'s
"native" responders, so this works seamlessly. Of course, each of the
sub-tasks can have its own sub-tasks, and so on, recursively.
One way to think of this type of task delegation is that
`main_task()` "fails-over" to `helper_task1()` and `helper_task2()`
when it cannot respond to the current `pending_message` on its own.

## **Or Else** logic vs **And Then** logic
It is important to keep in mind how `step()` works: As each responder 
in the sequence is tried, when there is a valid response, the 
next call to `step()` _restarts its search_ at the beginning of the sequence
(with the only exception being that the human User is given a chance 
to respond after each non-human response). 
In this sense, the semantics of the responder sequence is similar to
**OR Else** logic, as opposed to **AND Then** logic.

If we want to have a sequence of sub-tasks that is more like
**AND Then** logic, we can achieve this by recursively adding subtasks.
In the above example suppose we wanted the `main_task` 
to trigger `helper_task1` and `helper_task2` in sequence,
then we could set it up like this:

```py
helper_task1.add_sub_task(helper_task2) #(1)!
main_task.add_sub_task(helper_task1)
```

1. When adding a single sub-task, we do not need to wrap it in a list.

## Next steps

In the [next section](two-agent-chat-num.md) we will see how this mechanism 
can be used to set up a simple collaboration between two agents.


>>>> docs/quick-start/setup.md
# Setup


## Install
Ensure you are using Python 3.11. It is best to work in a virtual environment:

```bash
# go to your repo root (which may be langroid-examples)
cd <your repo root>
python3 -m venv .venv
. ./.venv/bin/activate
```
To see how to use Langroid in your own repo, you can take a look at the
[`langroid-examples`](https://github.com/langroid/langroid-examples) repo, which can be a good starting point for your own repo, 
or use the [`langroid-template`](https://github.com/langroid/langroid-template) repo.
These repos contain a `pyproject.toml` file suitable for use with the [`uv`](https://docs.astral.sh/uv/) dependency manager. After installing `uv` you can 
set up your virtual env, activate it, and install langroid into your venv like this:

```bash
uv venv --python 3.11
. ./.venv/bin/activate 
uv sync
```

Alternatively, use `pip` to install `langroid` into your virtual environment:
```bash
pip install langroid
```

The core Langroid package lets you use OpenAI Embeddings models via their API.
If you instead want to use the `sentence-transformers` embedding models from HuggingFace,
install Langroid like this:
```bash
pip install "langroid[hf-embeddings]"
```
For many practical scenarios, you may need additional optional dependencies:
- To use various document-parsers, install langroid with the `doc-chat` extra:
    ```bash
    pip install "langroid[doc-chat]"
    ```
- For "chat with databases", use the `db` extra:
    ```bash
    pip install "langroid[db]"
    ``
- You can specify multiple extras by separating them with commas, e.g.:
    ```bash
    pip install "langroid[doc-chat,db]"
    ```
- To simply install _all_ optional dependencies, use the `all` extra (but note that this will result in longer load/startup times and a larger install size):
    ```bash
    pip install "langroid[all]"
    ```

??? note "Optional Installs for using SQL Chat with a PostgreSQL DB"
    If you are using `SQLChatAgent`
    (e.g. the script [`examples/data-qa/sql-chat/sql_chat.py`](https://github.com/langroid/langroid/blob/main/examples/data-qa/sql-chat/sql_chat.py),
    with a postgres db, you will need to:
    
    - Install PostgreSQL dev libraries for your platform, e.g.
        - `sudo apt-get install libpq-dev` on Ubuntu,
        - `brew install postgresql` on Mac, etc.
    - Install langroid with the postgres extra, e.g. `pip install langroid[postgres]`
      or `uv add "langroid[postgres]"` or `uv pip install --extra postgres -r pyproject.toml`.
      If this gives you an error, try 
      `uv pip install psycopg2-binary` in your virtualenv.


!!! tip "Work in a nice terminal, such as Iterm2, rather than a notebook"
    All of the examples we will go through are command-line applications.
    For the best experience we recommend you work in a nice terminal that supports 
    colored outputs, such as [Iterm2](https://iterm2.com/).    


!!! note "mysqlclient errors"
    If you get strange errors involving `mysqlclient`, try doing `pip uninstall mysqlclient` followed by `pip install mysqlclient` 

## Set up tokens/keys 

To get started, all you need is an OpenAI API Key.
If you don't have one, see [this OpenAI Page](https://platform.openai.com/docs/quickstart).
(Note that while this is the simplest way to get started, Langroid works with practically any LLM, not just those from OpenAI.
See the guides to using [Open/Local LLMs](https://langroid.github.io/langroid/tutorials/local-llm-setup/),
and other [non-OpenAI](https://langroid.github.io/langroid/tutorials/non-openai-llms/) proprietary LLMs.)

In the root of the repo, copy the `.env-template` file to a new file `.env`:
```bash
cp .env-template .env
```
Then insert your OpenAI API Key.
Your `.env` file should look like this:
```bash
OPENAI_API_KEY=your-key-here-without-quotes
```

Alternatively, you can set this as an environment variable in your shell
(you will need to do this every time you open a new shell):
```bash
export OPENAI_API_KEY=your-key-here-without-quotes
```

All of the following environment variable settings are optional, and some are only needed
to use specific features (as noted below).

- **Qdrant** Vector Store API Key, URL. This is only required if you want to use Qdrant cloud.
  Langroid uses LanceDB as the default vector store in its `DocChatAgent` class (for RAG).
  Alternatively [Chroma](https://docs.trychroma.com/) is also currently supported.
  We use the local-storage version of Chroma, so there is no need for an API key.
- **Redis** Password, host, port: This is optional, and only needed to cache LLM API responses
  using Redis Cloud. Redis [offers](https://redis.com/try-free/) a free 30MB Redis account
  which is more than sufficient to try out Langroid and even beyond.
  If you don't set up these, Langroid will use a pure-python
  Redis in-memory cache via the [Fakeredis](https://fakeredis.readthedocs.io/en/latest/) library.
- **GitHub** Personal Access Token (required for apps that need to analyze git
  repos; token-based API calls are less rate-limited). See this
  [GitHub page](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens).
- **Google Custom Search API Credentials:** Only needed to enable an Agent to use the `GoogleSearchTool`.
  To use Google Search as an LLM Tool/Plugin/function-call,
  you'll need to set up
  [a Google API key](https://developers.google.com/custom-search/v1/introduction#identify_your_application_to_google_with_api_key),
  then [setup a Google Custom Search Engine (CSE) and get the CSE ID](https://developers.google.com/custom-search/docs/tutorial/creatingcse).
  (Documentation for these can be challenging, we suggest asking GPT4 for a step-by-step guide.)
  After obtaining these credentials, store them as values of
  `GOOGLE_API_KEY` and `GOOGLE_CSE_ID` in your `.env` file.
  Full documentation on using this (and other such "stateless" tools) is coming soon, but
  in the meantime take a peek at the test
  [`tests/main/test_web_search_tools.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_web_search_tools.py) to see how to use it.


If you add all of these optional variables, your `.env` file should look like this:
```bash
OPENAI_API_KEY=your-key-here-without-quotes
GITHUB_ACCESS_TOKEN=your-personal-access-token-no-quotes
CACHE_TYPE=redis
REDIS_PASSWORD=your-redis-password-no-quotes
REDIS_HOST=your-redis-hostname-no-quotes
REDIS_PORT=your-redis-port-no-quotes
QDRANT_API_KEY=your-key
QDRANT_API_URL=https://your.url.here:6333 # note port number must be included
GOOGLE_API_KEY=your-key
GOOGLE_CSE_ID=your-cse-id
```

### Microsoft Azure OpenAI setup[Optional]

This section applies only if you are using Microsoft Azure OpenAI.

When using Azure OpenAI, additional environment variables are required in the
`.env` file.
This page [Microsoft Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-python#environment-variables)
provides more information, and you can set each environment variable as follows:

- `AZURE_OPENAI_API_KEY`, from the value of `API_KEY`
- `AZURE_OPENAI_API_BASE` from the value of `ENDPOINT`, typically looks like `https://your_resource.openai.azure.com`.
- For `AZURE_OPENAI_API_VERSION`, you can use the default value in `.env-template`, and latest version can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new#azure-openai-chat-completion-general-availability-ga)
- `AZURE_OPENAI_DEPLOYMENT_NAME` is an OPTIONAL deployment name which may be 
   defined by the user during the model setup.
- `AZURE_OPENAI_CHAT_MODEL` Azure OpenAI allows specific model names when you select the model for your deployment. You need to put precisely the exact model name that was selected. For example, GPT-3.5 (should be `gpt-35-turbo-16k` or `gpt-35-turbo`) or GPT-4 (should be `gpt-4-32k` or `gpt-4`).
- `AZURE_OPENAI_MODEL_NAME` (Deprecated, use `AZURE_OPENAI_CHAT_MODEL` instead).
  
!!! note "For Azure-based models use `AzureConfig` instead of `OpenAIGPTConfig`"
    In most of the docs you will see that LLMs are configured using `OpenAIGPTConfig`.
    However if you want to use Azure-deployed models, you should replace `OpenAIGPTConfig` with `AzureConfig`. See 
    the [`test_azure_openai.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_azure_openai.py) and 
    [`example/basic/chat.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat.py)


## Next steps

Now you should be ready to use Langroid!
As a next step, you may want to see how you can use Langroid to [interact 
directly with the LLM](llm-interaction.md) (OpenAI GPT models only for now).










>>>> docs/quick-start/three-agent-chat-num-router.md
# Three-Agent Collaboration, with message Routing

!!! tip "Script in `langroid-examples`"
    A full working example for the material in this section is
    in the `three-agent-chat-num-router.py` script in the `langroid-examples` repo:
    [`examples/quick-start/three-agent-chat-num-router.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/three-agent-chat-num-router.py).

Let's change the number game from the [three agent chat example](three-agent-chat-num.md) slightly.
In that example, when the `even_agent`'s LLM receives an odd number,
it responds with `DO-NOT-KNOW`, and similarly for the `odd_agent` when it
receives an even number. The `step()` method of the `repeater_task`
considers `DO-NOT-KNOW` to be an _invalid_ response and _continues_ to 
look for a valid response from any remaining sub-tasks.
Thus there was no need for the `processor_agent` to specify who should handle
the current number.

But what if there is a scenario where the `even_agent` and `odd_agent`
might return a legit but "wrong" answer?
In this section we add this twist -- when
the `even_agent` receives an odd number, it responds with -10, and similarly
for the `odd_agent` when it receives an even number.
We tell the `processor_agent` to avoid getting a negative number.

The goal we have set for the `processor_agent` implies that it 
must specify the intended recipient of 
the number it is sending. 
We can enforce this using a special Langroid Tool, 
[`RecipientTool`][langroid.agent.tools.recipient_tool.RecipientTool].
So when setting up the
`processor_task` we include instructions to use this tool
(whose name is `recipient_message`, the value of `RecipientTool.request`):

```py
processor_agent = lr.ChatAgent(config)
processor_task = lr.Task(
    processor_agent,
    name = "Processor",
    system_message="""
        You will receive a list of numbers from me (the user).
        Your goal is to apply a transformation to each number.
        However you do not know how to do this transformation.
        You can take the help of two people to perform the 
        transformation.
        If the number is even, send it to EvenHandler,
        and if it is odd, send it to OddHandler.
        
        IMPORTANT: send the numbers ONE AT A TIME
        
        The handlers will transform the number and give you a new number.        
        If you send it to the wrong person, you will receive a negative value.
        Your aim is to never get a negative number, so you must 
        clearly specify who you are sending the number to, using the
        `recipient_message` tool/function-call, where the `content` field
        is the number you want to send, and the `recipient` field is the name
        of the intended recipient, either "EvenHandler" or "OddHandler".        
        
        Once all numbers in the given list have been transformed, 
        say DONE and show me the result. 
        Start by asking me for the list of numbers.
    """,
    llm_delegate=True,
    single_round=False,
)
```

To enable the `processor_agent` to use this tool, we must enable it:
```py
processor_agent.enable_message(lr.agent.tools.RecipientTool)
```

The rest of the code remains the same as in the [previous section](three-agent-chat-num.md),
i.e., we simply add the two handler tasks
as sub-tasks of the `processor_task`, like this:
```python
processor_task.add_sub_task([even_task, odd_task])
```

One of the benefits of using the `RecipientTool` is that it contains 
mechanisms to remind the LLM to specify a recipient for its message,
when it forgets to do so (this does happen once in a while, even with GPT-4).


Feel free to try the working example script
`three-agent-chat-num-router.py` in the 
`langroid-examples` repo:
[`examples/quick-start/three-agent-chat-num-router.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/three-agent-chat-num-router.py):

```bash
python3 examples/quick-start/three-agent-chat-num-router.py
```

Below is screenshot of what this might look like, using the OpenAI function-calling 
mechanism with the `recipient_message` tool:

![three-agent-router-func.png](three-agent-router-func.png)

And here is what it looks like using Langroid's built-in tools mechanism (use the `-t` option when running the script):

![three-agent-router.png](three-agent-router.png)

And here is what it looks like using 
## Next steps

In the [next section](chat-agent-docs.md) you will learn
how to use Langroid with external documents.


>>>> docs/quick-start/three-agent-chat-num.md
# Three-Agent Collaboration

!!! tip "Script in `langroid-examples`"
    A full working example for the material in this section is
    in the `three-agent-chat-num.py` script in the `langroid-examples` repo:
    [`examples/quick-start/three-agent-chat-num.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/three-agent-chat-num.py).


Let us set up a simple numbers exercise between 3 agents.
The `Processor` agent receives a number $n$, and its goal is to 
apply a transformation to the it. However it does not know how to apply the
transformation, and takes the help of two other agents to do so.
Given a number $n$,

- The `EvenHandler` returns $n/2$ if n is even, otherwise says `DO-NOT-KNOW`.
- The `OddHandler` returns $3n+1$ if n is odd, otherwise says `DO-NOT-KNOW`.

We'll first define a shared LLM config:

```py
llm_config = lr.language_models.OpenAIGPTConfig(
    chat_model=lr.language_models.OpenAIChatModel.GPT4o,
    # or, e.g., "ollama/qwen2.5-coder:latest", or "gemini/gemini-2.0-flash-exp"
)
```

Next define the config for the `Processor` agent:
```py
processor_config = lr.ChatAgentConfig(
    name="Processor",
    llm = llm_config,
    system_message="""
    You will receive a number from the user.
    Simply repeat that number, DO NOT SAY ANYTHING else,
    and wait for a TRANSFORMATION of the number 
    to be returned to you.
    
    Once you have received the RESULT, simply say "DONE",
    do not say anything else.
    """,        
    vecdb=None,
)
```

Then set up the `processor_agent`, along with the corresponding task:
```py
processor_agent = lr.ChatAgent(processor_config)

processor_task = lr.Task(
    processor_agent,
    llm_delegate=True, #(1)!
    interactive=False, #(2)!
    single_round=False, #(3)!
)

```

1. Setting the `llm_delegate` option to `True` means that the `processor_task` is
    delegated to the LLM (as opposed to the User), 
    in the sense that the LLM is the one "seeking" a response to the latest 
    number. Specifically, this means that in the `processor_task.step()` 
    when a sub-task returns `DO-NOT-KNOW`,
    it is _not_ considered a valid response, and the search for a valid response 
    continues to the next sub-task if any.
2. `interactive=False` means the task loop will not wait for user input.
3. `single_round=False` means that the `processor_task` should _not_ terminate after 
    a valid response from a responder.

Set up the other two agents and tasks:

```py
NO_ANSWER = lr.utils.constants.NO_ANSWER

even_config = lr.ChatAgentConfig(
    name="EvenHandler",
    llm = llm_config,
    system_message=f"""
    You will be given a number N. Respond as follows:
    
    - If N is even, divide N by 2 and show the result, 
      in the format: 
        RESULT = <result>
      and say NOTHING ELSE.
    - If N is odd, say {NO_ANSWER}
    """,    
)
even_agent = lr.ChatAgent(even_config)
even_task = lr.Task(
    even_agent,
    single_round=True,  # task done after 1 step() with valid response
)

odd_config = lr.ChatAgentConfig(
    name="OddHandler",
    llm = llm_config,
    system_message=f"""
    You will be given a number N. Respond as follows:
    
    - if N is odd, return the result (N*3+1), in the format:
        RESULT = <result> 
        and say NOTHING ELSE.
    
    - If N is even, say {NO_ANSWER}
    """,
)
odd_agent = lr.ChatAgent(odd_config)
odd_task = lr.Task(
    odd_agent,
    single_round=True,  # task done after 1 step() with valid response
)

```

Now add the `even_task` and `odd_task` as subtasks of the `processor_task`, 
and then run it with a number as input:

```python
processor_task.add_sub_task([even_task, odd_task])
processor_task.run(13)
```

The input number will be passed to the `Processor` agent as the user input.


Feel free to try the working example script
[`three-agent-chat-num.py`]()
`langroid-examples` repo:
[`examples/quick-start/three-agent-chat-num.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/three-agent-chat-num.py):

```bash
python3 examples/quick-start/three-agent-chat-num.py
```

Here's a screenshot of what it looks like:
![three-agent-num.png](three-agent-num.png)


## Next steps


In the [next section](chat-agent-tool.md) you will learn how to use Langroid
to equip a `ChatAgent` with tools or function-calling.


>>>> docs/quick-start/two-agent-chat-num.md
# Two-Agent Collaboration

!!! tip "Script in `langroid-examples`"
    A full working example for the material in this section is
    in the `two-agent-chat-num.py` script in the `langroid-examples` repo:
    [`examples/quick-start/two-agent-chat-num.py`](https://github.com/langroid/langroid-examples/tree/main/examples/quick-start/two-agent-chat-num.py).


To illustrate these ideas, let's look at a toy example[^1] where 
a `Student` agent receives a list of numbers to add.
We set up this agent with an instruction that they do not know how to add,
and they can ask for help adding pairs of numbers.
To add pairs of numbers, we set up an `Adder` agent.

[^1]: Toy numerical examples are perfect to illustrate the ideas without
      incurring too much token cost from LLM API calls.

First define a common `llm_config` to use for both agents:
```python
llm_config = lr.language_models.OpenAIGPTConfig(
    chat_model=lr.language_models.OpenAIChatModel.GPT4o,
    # or, e.g., "ollama/qwen2.5-coder:latest", or "gemini/gemini-2.0-flash-exp"
)
```


Next, set up a config for the student agent, then create the agent
and the corresponding task:

```py
student_config = lr.ChatAgentConfig(
    name="Student",
    llm=llm_config,
    vecdb=None, #(1)!
    system_message="""
        You will receive a list of numbers from me (the User),
        and your goal is to calculate their sum.
        However you do not know how to add numbers.
        I can help you add numbers, two at a time, since
        I only know how to add pairs of numbers.
        Send me a pair of numbers to add, one at a time, 
        and I will tell you their sum.
        For each question, simply ask me the sum in math notation, 
        e.g., simply say "1 + 2", etc, and say nothing else.
        Once you have added all the numbers in the list, 
        say DONE and give me the final sum. 
        Start by asking me for the list of numbers.
    """,    
)
student_agent = lr.ChatAgent(student_config)
student_task = lr.Task(
    student_agent,
    name = "Student",
    llm_delegate = True, #(2)!
    single_round=False,  # (3)! 
)
```

1. We don't need access to external docs so we set `vecdb=None` to avoid 
   the overhead of loading a vector-store.
2. Whenever we "flip roles" and assign the LLM the role of generating questions, 
   we set `llm_delegate=True`. In effect this ensures that the LLM "decides" when
   the task is done.
3. This setting means the task is not a single-round task, i.e. it is _not_ done
   after one `step()` with a valid response.

Next, set up the Adder agent config, create the Adder agent
and the corresponding Task:

```py
adder_config = lr.ChatAgentConfig(
    name = "Adder", #(1)!
    llm=llm_config,
    vecdb=None,
    system_message="""
        You are an expert on addition of numbers. 
        When given numbers to add, simply return their sum, say nothing else
        """,     
)
adder_agent = lr.ChatAgent(adder_config)
adder_task = lr.Task(
    adder_agent,
    interactive=False, #(2)!
    single_round=True,  # task done after 1 step() with valid response (3)!
)
```
1. The Agent name is displayed in the conversation shown in the console.
2. Does not wait for user input.
3. We set `single_round=True` to ensure that the expert task is done after 
   one step() with a valid response. 

Finally, we add the `adder_task` as a sub-task of the `student_task`, 
and run the `student_task`:

```py
student_task.add_sub_task(adder_task) #(1)!
student_task.run()
```

1. When adding just one sub-task, we don't need to use a list.


For a full working example, see the 
[`two-agent-chat-num.py`](https://github.com/langroid/langroid-examples/blob/main/examples/quick-start/two-agent-chat-num.py)
script in the `langroid-examples` repo. You can run this using:
```bash
python3 examples/quick-start/two-agent-chat-num.py
```

Here is an example of the conversation that results:

![two-agent-num.png](two-agent-num.png)

## Logs of multi-agent interactions

!!! note "For advanced users"
    This section is for advanced users who want more visibility into the
    internals of multi-agent interactions.

When running a multi-agent chat, e.g. using `task.run()`, two types of logs
are generated:
- plain-text logs in `logs/<task_name>.log`
- tsv logs in `logs/<task_name>.tsv`

It is important to realize that the logs show _every iteration 
of the loop in `Task.step()`, i.e. every **attempt** at
responding to the current pending message, even those that are not allowed_.
The ones marked with an asterisk (*) are the ones that are considered valid
responses for a given `step()` (which is a "turn" in the conversation).

The plain text logs have color-coding ANSI chars to make them easier to read
by doing `less <log_file>`. The format is (subject to change):
```
(TaskName) Responder SenderEntity (EntityName) (=> Recipient) TOOL Content
```

The structure of the `tsv` logs is similar. A great way to view these is to
install and use the excellent `visidata` (https://www.visidata.org/) tool:
```bash
vd logs/<task_name>.tsv
```

## Next steps
As a next step, look at how to set up a collaboration among three agents
for a simple [numbers game](three-agent-chat-num.md).







>>>> docs/stylesheets/extra.css
.md-logo img {
    height: 60px !important; /* Adjust size as necessary */
}

>>>> docs/tutorials/langroid-tour.md
# A quick tour of Langroid

This is a quick tour of some Langroid features. For a more detailed guide,
see the [Getting Started guide](https://langroid.github.io/langroid/quick-start/).
There are many more features besides the ones shown here. To explore langroid more,
see the sections of the main [docs](https://langroid.github.io/langroid/),
and a 
[Colab notebook](https://colab.research.google.com/github/langroid/langroid/blob/main/examples/Langroid_quick_start.ipynb) 
you can try yourself.  


## Chat directly with LLM

Imports:

```python
import langroid as lr
import langroid.language_models as lm
```

Set up the LLM; note how you can specify the chat model -- if omitted, defaults
to OpenAI `GPT4o`. See the guide to using Langroid with 
[local/open LLMs](https://langroid.github.io/langroid/tutorials/local-llm-setup/),
and with [non-OpenAI LLMs](https://langroid.github.io/langroid/tutorials/non-openai-llms/).
    
```python
llm_config = lm.OpenAIGPTConfig( 
   chat_model="glhf/hf:Qwen/Qwen2.5-Coder-32B-Instruct" 
)
llm = lm.OpenAIGPT(llm_config)
```

Chat with bare LLM -- no chat accumulation, i.e. follow-up responses will *not*
be aware of prior conversation history (you need an Agent for that, see below).

```python
llm.chat("1 2 4 7 11 ?")
# ==> answers 16, with some explanation
```

## Agent

Make a [`ChatAgent`][langroid.agent.chat_agent.ChatAgent], 
and chat with it; now accumulates conv history

```python
agent = lr.ChatAgent(lr.ChatAgentConfig(llm=llm_config))
agent.llm_response("Find the next number: 1 2 4 7 11 ?")
# => responds 16
agent.llm_response("and then?)
# => answers 22
```

## Task

Make a [`Task`][langroid.agent.task.Task] and create a chat loop with the user:

```python
task = lr.Task(agent, interactive=True)
task.run()
```

## Tools/Functions/Structured outputs:

Define a [`ToolMessage`][langroid.agent.tool_message.ToolMessage] 
using Pydantic (v1) -- this gets transpiled into system-message instructions
to the LLM, so you never have to deal with writing a JSON schema.
(Besides JSON-based tools, Langroid also supports 
[XML-based tools](https://langroid.github.io/langroid/notes/xml-tools/), which 
are far more reliable when having the LLM return code in a structured output.)


```python
from langroid.pydantic_v1 import BaseModel
from langroid.agent.tools.orchestration import ResultTool

class CityTemperature(BaseModel):
    city: str
    temp: float

class WeatherTool(lr.ToolMessage):
    request: str = "weather_tool" #(1)!
    purpose: str = "To extract <city_temp> info from text" #(2)!

    city_temp: CityTemperature

    # tool handler
    def handle(self) -> ResultTool:
        return ResultTool(city_temp = self.city_temp)
```

1. When this tool is enabled for an agent, a method named `weather_tool` gets auto-inserted in the agent class, 
   with body being the `handle` method -- this method handles the LLM's generation 
   of this tool.
2. The value of the `purpose` field is used to populate the system message to the LLM,
   along with the Tool's schema derived from its Pydantic-based definition.

Enable the Agent to use the `ToolMessage`:

```python
agent.enable_message(WeatherTool)
```

Create specialized task that returns a `CityTemperature` object:

```python
task = lr.Task(agent, interactive=False)[CityTemperature]

# run task, with built-in tool-handling loop
data = task.run("It is 45 degrees F in Boston")

assert data.city == "Boston"
assert int(data.temp) == 45
```

## Chat with a document (RAG)

Create a [`DocChatAgent`][langroid.agent.special.doc_chat_agent.DocChatAgent].

```python
doc_agent_config = lr.agent.special.DocChatAgentConfig(llm=llm_config)
doc_agent = lr.agent.special.DocChatAgent(doc_agent_config)
```

Ingest the contents of a web page into the agent 
(this involves chunking, indexing into a vector-database, etc.):

```python
doc_agent.ingest_doc_paths("https://en.wikipedia.org/wiki/Ludwig_van_Beethoven")
```

Ask a question:

```
result = doc_agent.llm_response("When did Beethoven move from Bonn to Vienna?")
```

You should see the streamed response with citations like this:

![langroid-tour-beethoven.png](langroid-tour-beethoven.png)

## Two-agent interaction

Set up a teacher agent:

```python
from langroid.agent.tools.orchestration import DoneTool

teacher = lr.ChatAgent(
    lr.ChatAgentConfig(
        llm=llm_config,
        system_message=f"""
        Ask a numbers-based question, and your student will answer.
        You can then provide feedback or hints to the student to help them
        arrive at the right answer. Once you receive the right answer,
        use the `{DoneTool.name()}` tool to end the session.
        """
    )
)

teacher.enable_message(DoneTool)
teacher_task = lr.Task(teacher, interactive=False)

```

Set up a student agent:

```python
student = lr.ChatAgent(
    lr.ChatAgentConfig(
        llm=llm_config,
        system_message=f"""
        You will receive a numbers-related question. Answer to the best of
        your ability. If your answer is wrong, you will receive feedback or hints,
        and you can revise your answer, and repeat this process until you get 
        the right answer.
        """
    )
)

student_task = lr.Task(student, interactive=False, single_round=True)
```

Make the `student_task` a subtask of the `teacher_task`:

```python
teacher_task.add_sub_task(student_task)
```

Run the teacher task:

```python
teacher_task.run()
```

You should then see this type of interaction:

![langroid-tour-teacher.png](langroid-tour-teacher.png)


>>>> docs/tutorials/llm-usage-options.md
# Options for accessing LLMs

> This is a work-in-progress document. It will be updated frequently.

The variety of ways to access the power of Large Language Models (LLMs) is growing 
rapidly, and there are a bewildering array of options. This document is an attempt to 
categorize and describe some of the most popular and useful ways to access LLMs,
via these 2x2x2  combinations:

- Websites (non-programmatic) or APIs (programmatic)
- Open-source or Proprietary 
- Chat-based interface or integrated assistive tools.

We will go into some of these combinations below. More will be added over time.

## Chat-based Web (non-API) access to Proprietary LLMs


This is best for *non-programmatic* use of LLMs: you go to a website and 
interact with the LLM via a chat interface -- 
you write prompts and/or upload documents, and the LLM responds with plain text
or can create artifacts (e.g. reports, code,
charts, podcasts, etc) that you can then copy into your files, workflow or codebase.
They typically allow you to upload text-based documents of various types, and some let you upload images, screen-shots, etc and ask questions about them.

Most of them are capable of doing *internet search* to inform their responses.


!!! note "Chat Interface vs Integrated Tools"
    Note that when using a chat-based interaction, you have to copy various artifacts
    from the web-site into another place, like your code editor, document, etc.
    AI-integrated tools relieve you of this burden by bringing the LLM power into 
    your workflow directly. More on this in a later section.

      
**Pre-requisites:** 

- *Computer*: Besides having a modern web browser (Chrome, Firefox, etc) and internet
access, there are no other special requirements, since the LLM is 
running on a remote server.
- *Coding knowledge*: Where (typically Python) code is produced, you will get best results
if you are conversant with Python so that you can understand and modify the code as
needed. In this category you do not need to know how to interact with an LLM API via code.

Here are some popular options in this category:

### OpenAI ChatGPT

Free access at [https://chatgpt.com/](https://chatgpt.com/)

With a ChatGPT-Plus monthly subscription ($20/month), you get additional features like:

- access to more powerful models
- access to [OpenAI canvas](https://help.openai.com/en/articles/9930697-what-is-the-canvas-feature-in-chatgpt-and-how-do-i-use-it) - this offers a richer interface than just a chat window, e.g. it automatically creates windows for code snippets, and shows results of running code
(e.g. output, charts etc).

Typical use: Since there is fixed monthly subscription (i.e. not metered by amount of 
usage), this is a cost-effective way to non-programmatically 
access a top LLM such as `GPT-4o` or `o1` 
(so-called "reasoning/thinking" models). Note however that there are limits on how many
queries you can make within a certain time period, but usually the limit is fairly
generous. 

What you can create, besides text-based artifacts:

- produce Python (or other language) code which you can copy/paste into notebooks or files
- SQL queries that you can copy/paste into a database tool
- Markdown-based tables
- You can't get diagrams, but you can get *code for diagrams*, 
e.g. python code for plots, [mermaid](https://github.com/mermaid-js/mermaid) code for flowcharts.
- images in some cases.

### OpenAI Custom GPTs (simply known as "GPTs")

[https://chatgpt.com/gpts/editor](https://chatgpt.com/gpts/editor)

Here you can conversationally interact with a "GPT Builder" that will 
create a version of ChatGPT
that is *customized* to your needs, i.e. with necessary background instructions,
context, and/or documents. 
The end result is a specialized GPT that you can then use for your specific
purpose and share with others (all of this is non-programmatic). 

E.g. [here](https://chatgpt.com/share/67153a4f-ea2c-8003-a6d3-cbc2412d78e5) is a "Knowledge Graph Builder" GPT

!!! note "Private GPTs requires an OpenAI Team Account"
    To share a custom GPT within a private group, you need an OpenAI Team account,
    see pricing [here](https://openai.com/chatgpt/pricing). Without a Team account,
    any shared GPT is public and can be accessed by anyone.


### Anthropic/Claude

[https://claude.ai](https://claude.ai)

The Claude basic web-based interface is similar to OpenAI ChatGPT, powered by 
Anthropic's proprietary LLMs. 
Anthropic's equivalent of ChatGPT-Plus is called "Claude Pro", which is also 
a $20/month subscription, giving you access to advanced models 
(e.g. `Claude-3.5-Sonnet`) and features.

Anthropic's equivalent of Custom GPTs is called 
[Projects](https://www.anthropic.com/news/projects), 
where you can create
an  LLM-powered interface that is augmented with your custom context and data.

Whichever product you are using, the interface auto-creates **artifacts** as needed --
these are stand-alone documents (code, text, images, web-pages, etc) 
that you may want to copy and paste into your own codebase, documents, etc.
For example you can prompt Claude to create full working interactive applications,
and copy the code, polish it and deploy it for others to use. See examples [here](https://simonwillison.net/2024/Oct/21/claude-artifacts/).

### Microsoft Copilot Lab

!!! note
    Microsoft's "Copilot" is an overloaded term that can refer to many different 
    AI-powered tools. Here we are referring to the one that is a collaboration between
    Microsoft and OpenAI, and is based on OpenAI's GPT-4o LLM, and powered by 
    Bing's search engine.

Accessible via [https://copilot.cloud.microsoft.com/](https://copilot.cloud.microsoft.com/)

The basic capabilities are similar to OpenAI's and Anthropic's offerings, but
come with so-called "enterprise grade" security and privacy features,
which purportedly make it suitable for use in educational and corporate settings.
Read more on what you can do with Copilot Lab [here](https://www.microsoft.com/en-us/microsoft-copilot/learn/?form=MA13FV).

Like the other proprietary offerings, Copilot can:

- perform internet search to inform its responses
- generate/run code and show results including charts

### Google Gemini

Accessible at [gemini.google.com](https://gemini.google.com).


## AI-powered productivity tools

These tools "bring the AI to your workflow", which is a massive productivity boost,
compared to repeatedly context-switching, e.g. copying/pasting between a chat-based AI web-app and your workflow.

- [**Cursor**](https://www.cursor.com/): AI Editor/Integrated Dev Environment (IDE). This is a fork of VSCode.
- [**Zed**](https://zed.dev/): built in Rust; can be customized to use Jetbrains/PyCharm keyboard shortcuts.
- [**Google Colab Notebooks with Gemini**](https://colab.research.google.com).
- [**Google NotebookLM**](https://notebooklm.google.com/): allows you to upload a set of text-based documents, 
  and create artifacts such as study guide, FAQ, summary, podcasts, etc.

    
## APIs for Proprietary LLMs

Using an API key allows *programmatic* access to the LLMs, meaning you can make
invocations to the LLM from within your own code, and receive back the results.
This is useful for building applications involving more complex workflows where LLMs
are used within a larger codebase, to access "intelligence" as needed.

E.g. suppose you are writing code that handles queries from a user, and you want to 
classify the user's _intent_ into one of 3 types: Information, or Action or Done.
Pre-LLMs, you would have had to write a bunch of rules or train a custom 
"intent classifier" that maps, for example:

- "What is the weather in Pittsburgh?" -> Information
- "Set a timer for 10 minutes" -> Action
- "Ok I have no more questions∞" -> Done

But using an LLM API, this is almost trivially easy - you instruct the LLM it should
classify the intent into one of these 3 types, and send the user query to the LLM,
and receive back the intent. 
(You can use Tools to make this robust, but that is outside the scope of this document.)

The most popular proprietary LLMs available via API are from OpenAI (or via  its
partner Microsoft), Anthropic, and Google:

- [OpenAI](https://platform.openai.com/docs/api-reference/introduction), to interact with `GPT-4o` family of models, and the `o1` family of "thinking/reasoning" models.
- [Anthropic](https://docs.anthropic.com/en/home) to use the `Claude` series of models.
- [Google](https://ai.google.dev/gemini-api/docs) to use the `Gemini` family of models.

These LLM providers are home to some of the most powerful LLMs available today,
specifically OpenAI's `GPT-4o` and Anthropic's `Claude-3.5-Sonnet`, and Google's `Gemini 1.5 Pro` (as of Oct 2024).

**Billing:** Unlike the fixed monthly subscriptions of ChatGPT, Claude and others, 
LLM usage via API is typically billed by *token usage*, i.e. you pay for the total
number of input and output "tokens" (a slightly technical term, but think of it as
a word for now).

Using an LLM API involves these steps:

- create an account on the provider's website as a "developer" or organization,
- get an API key,
- use the API key in your code to make requests to the LLM. 


**Prerequisites**:

- *Computer:* again, since the API is served over the internet, there are no special
  requirements for your computer.
- *Programming skills:* Using an LLM API involves either:
    - directly making REST API calls from your code, or 
    - use a scaffolding library (like [Langroid](https://github.com/langroid/langroid)) that abstracts away the details of the 
      API calls.
  
    In either case, you must be highly proficient in (Python) programming 
  to use this option.

## Web-interfaces to Open LLMs

!!! note  "Open LLMs"
    These are LLMs that have been publicly released, i.e. their parameters ("weights") 
    are publicly available -- we refer to these as *open-weight* LLMs. If in addition, the
    training datasets, and data-preprocessing and training code are also available, we would
    call these *open-source* LLMs. But lately there is a looser usage of the term "open-source",referring to just the weights being available. For our purposes we will just refer all of these models as **Open LLMs**.

There are many options here, but some popular ones are below. Note that some of these
are front-ends that allow you to interact with not only Open LLMs but also 
proprietary LLM APIs.

- [LMStudio](https://lmstudio.ai/)
- [OpenWebUI](https://github.com/open-webui/open-webui)
- [Msty](https://msty.app/)
- [AnythingLLM](https://anythingllm.com/)
- [LibreChat](https://www.librechat.ai/)


## API Access to Open LLMs

This is a good option if you are fairly proficient in (Python) coding. There are in 
fact two possibilities here:

- The LLM is hosted remotely, and you make REST API calls to the remote server. This
  is a good option when you want to run large LLMs and you don't have the resources (GPU and memory) to run them locally.
    - [groq](https://groq.com/) amazingly it is free, and you can run `llama-3.1-70b`
    - [cerebras](https://cerebras.ai/)
    - [open-router](https://openrouter.ai/)
- The LLM is running on your computer. This is a good option if your machine has sufficient RAM to accommodate the LLM you are trying to run, and if you are 
concerned about data privacy. The most user-friendly option is [Ollama](https://github.com/ollama/ollama); see more below.

Note that all of the above options provide an **OpenAI-Compatible API** to interact
with the LLM, which is a huge convenience: you can write code to interact with OpenAI's
LLMs (e.g. `GPT4o` etc) and then easily switch to one of the above options, typically
by changing a simple config (see the respective websites for instructions).

Of course, directly working with the raw LLM API quickly becomes tedious. This is where
a scaffolding library like [langroid](https://github.com/langroid/langroid) comes in
very handy - it abstracts away the details of the API calls, and provides a simple
programmatic interface to the LLM, and higher-level abstractions like 
Agents, Tasks, etc. Working with such a library is going to be far more productive
than directly working with the raw API. Below are instructions on how to use langroid
with some the above Open/Local LLM options.

See [here](https://langroid.github.io/langroid/tutorials/local-llm-setup/) for 
a guide to using Langroid with Open LLMs.



>>>> docs/tutorials/local-llm-setup.md
# Setting up a Local/Open LLM to work with Langroid

!!! tip "Examples scripts in [`examples/`](https://github.com/langroid/langroid/tree/main/examples) directory."
      There are numerous examples of scripts that can be run with local LLMs,
      in the [`examples/`](https://github.com/langroid/langroid/tree/main/examples)
      directory of the main `langroid` repo. These examples are also in the 
      [`langroid-examples`](https://github.com/langroid/langroid-examples/tree/main/examples),
      although the latter repo may contain some examples that are not in the `langroid` repo.
      Most of these example scripts allow you to specify an LLM in the format `-m <model>`,
      where the specification of `<model>` is described in the quide below for local/open LLMs, 
      or in the [Non-OpenAI LLM](https://langroid.github.io/langroid/tutorials/non-openai-llms/) guide. Scripts 
      that have the string `local` in their name have been especially designed to work with 
      certain local LLMs, as described in the respective scripts.
      If you want a pointer to a specific script that illustrates a 2-agent chat, have a look 
      at [`chat-search-assistant.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat-search-assistant.py).
      This specific script, originally designed for GPT-4/GPT-4o, works well with `llama3-70b` 
      (tested via Groq, mentioned below).

## Easiest: with Ollama

As of version 0.1.24, Ollama provides an OpenAI-compatible API server for the LLMs it supports,
which massively simplifies running these LLMs with Langroid. Example below.

```
ollama pull mistral:7b-instruct-v0.2-q8_0
```
This provides an OpenAI-compatible 
server for the `mistral:7b-instruct-v0.2-q8_0` model.

You can run any Langroid script using this model, by setting the `chat_model`
in the `OpenAIGPTConfig` to `ollama/mistral:7b-instruct-v0.2-q8_0`, e.g.

```python
import langroid.language_models as lm
import langroid as lr

llm_config = lm.OpenAIGPTConfig(
    chat_model="ollama/mistral:7b-instruct-v0.2-q8_0",
    chat_context_length=16_000, # adjust based on model
)
agent_config = lr.ChatAgentConfig(
    llm=llm_config,
    system_message="You are helpful but concise",
)
agent = lr.ChatAgent(agent_config)
# directly invoke agent's llm_response method
# response = agent.llm_response("What is the capital of Russia?")
task = lr.Task(agent, interactive=True)
task.run() # for an interactive chat loop
```

## Setup Ollama with a GGUF model from HuggingFace

Some models are not directly supported by Ollama out of the box. To server a GGUF
model with Ollama, you can download the model from HuggingFace and set up a custom
Modelfile for it.

E.g. download the GGUF version of `dolphin-mixtral` from
[here](https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF)

(specifically, download this file `dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf`)

To set up a custom ollama model based on this:

- Save this model at a convenient place, e.g. `~/.ollama/models/`
- Create a modelfile for this model. First see what an existing modelfile
  for a similar model looks like, e.g. by running:

```
ollama show --modelfile dolphin-mixtral:latest
```
You will notice this file has a FROM line followed by a prompt template and other settings.
Create a new file with these contents.
Only  change the  `FROM ...` line with the path to the model you downloaded, e.g.
```
FROM /Users/blah/.ollama/models/dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf
```

- Save this modelfile somewhere, e.g. `~/.ollama/modelfiles/dolphin-mixtral-gguf`
- Create a new ollama model based on this file:
```
ollama create dolphin-mixtral-gguf -f ~/.ollama/modelfiles/dolphin-mixtral-gguf
``` 

- Run this new model using `ollama run dolphin-mixtral-gguf`

To use this model with Langroid you can then specify `ollama/dolphin-mixtral-gguf`
as the `chat_model` param in the `OpenAIGPTConfig` as in the previous section.
When a script supports it, you can also pass in the model name via
`-m ollama/dolphin-mixtral-gguf`

## Local LLMs using LMStudio

LMStudio is one of the simplest ways to download run open-weight LLMs locally.
See their docs at [lmstudio.ai](https://lmstudio.ai/docs) for installation and usage 
instructions. Once you download a model, you can use the "server" option to have it 
served via an OpenAI-compatible API at a local IP like `https://127.0.0.1:1234/v1`.
As with any other scenario of running a local LLM, you can use this with Langroid by
setting `chat_model` as follows (note you should not include the `https://` part):

```python
llm_config = lm.OpenAIGPTConfig(
    chat_model="local/127.0.0.1234/v1",
    ...
)
```

## Setup llama.cpp with a GGUF model from HuggingFace

See `llama.cpp`'s [GitHub page](https://github.com/ggerganov/llama.cpp/tree/master) for build and installation instructions.

After installation, begin as above with downloading a GGUF model from HuggingFace; for example, the quantized `Qwen2.5-Coder-7B` from [here](https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct-GGUF); specifically, [this file](https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct-GGUF/blob/main/qwen2.5-coder-7b-instruct-q2_k.gguf).

Now, the server can be started with `llama-server -m qwen2.5-coder-7b-instruct-q2_k.gguf`.

In addition, your `llama.cpp` may be built with support for simplified management of HuggingFace models (specifically, `libcurl` support is required); in this case, `llama.cpp` will download HuggingFace models to a cache directory, and the server may be run with:
```bash
llama-server \
      --hf-repo Qwen/Qwen2.5-Coder-7B-Instruct-GGUF \
      --hf-file qwen2.5-coder-7b-instruct-q2_k.gguf
```

To use the model with Langroid, specify `llamacpp/localhost:{port}` as the `chat_model`; the default port is 8080.

## Setup vLLM with a model from HuggingFace

See [the vLLM docs](https://docs.vllm.ai/en/stable/getting_started/installation.html) for installation and configuration options. To run a HuggingFace model with vLLM, use `vllm serve`, which provides an OpenAI-compatible server. 

For example, to run `Qwen2.5-Coder-32B`, run `vllm serve Qwen/Qwen2.5-Coder-32B`.

If the model is not publicly available, set the environment varaible `HF_TOKEN` to your HuggingFace token with read access to the model repo.

To use the model with Langroid, specify `vllm/Qwen/Qwen2.5-Coder-32B` as the `chat_model` and, if a port other than the default 8000 was used, set `api_base` to `localhost:{port}`.

## Setup vLLM with a GGUF model from HuggingFace

`vLLM` supports running quantized models from GGUF files; however, this is currently an experimental feature. To run a quantized `Qwen2.5-Coder-32B`, download the model from [the repo](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct-GGUF), specifically [this file](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct-GGUF/blob/main/qwen2.5-coder-32b-instruct-q4_0.gguf). 

The model can now be run with `vllm serve qwen2.5-coder-32b-instruct-q4_0.gguf --tokenizer Qwen/Qwen2.5-Coder-32B` (the tokenizer of the base model rather than the quantized model should be used).

To use the model with Langroid, specify `vllm/qwen2.5-coder-32b-instruct-q4_0.gguf` as the `chat_model` and, if a port other than the default 8000 was used, set `api_base` to `localhost:{port}`.

## "Local" LLMs hosted on Groq
In this scenario, an open-source LLM (e.g. `llama3.1-8b-instant`) is hosted on a Groq server
which provides an OpenAI-compatible API. Using this with langroid is exactly analogous
to the Ollama scenario above: you can set the `chat_model` in the `OpenAIGPTConfig` to
`groq/<model_name>`, e.g. `groq/llama3.1-8b-instant`. 
For this to work, ensure you have a `GROQ_API_KEY` environment variable set in your
`.env` file. See [groq docs](https://console.groq.com/docs/quickstart).

## "Local" LLMs hosted on Cerebras
This works exactly like with Groq, except you set up a `CEREBRAS_API_KEY` environment variable, and specify the `chat_model` as `cerebras/<model_name>`, e.g. `cerebras/llama3.1-8b`. See the Cerebras [docs](https://inference-docs.cerebras.ai/introduction) for details on which LLMs are supported.

## Open/Proprietary LLMs via OpenRouter

OpenRouter is a **paid service** that provides an OpenAI-compatible API 
for practically any LLM, open or proprietary.
Using this with Langroid is similar to the `groq` scenario above:

- Ensure you have an `OPENROUTER_API_KEY` set up in your environment (or `.env` file), and 
- Set the `chat_model` in the `OpenAIGPTConfig` to 
  `openrouter/<model_name>`, where `<model_name>` is the name of the model on the 
[OpenRouter](https://openrouter.ai/) website, e.g. `qwen/qwen-2.5-7b-instruct`.

This is a good option if you want to use larger open LLMs without having to download
them locally (especially if your local machine does not have the resources to run them).
Besides using specific LLMs, OpenRouter also has smart routing/load-balancing.
OpenRouter is also convenient for using proprietary LLMs (e.g. gemini, amazon) via 
a single convenient API.

## "Local" LLMs hosted on GLHF.chat

See [glhf.chat](https://glhf.chat/chat/create) for a list of available models.

To run with one of these models, set the `chat_model` in the `OpenAIGPTConfig` to
`"glhf/<model_name>"`, where `model_name` is `hf:` followed by the HuggingFace repo 
path, e.g. `Qwen/Qwen2.5-Coder-32B-Instruct`, so the full `chat_model` would be
`"glhf/hf:Qwen/Qwen2.5-Coder-32B-Instruct"`. 

## DeepSeek LLMs

As of 26-Dec-2024, DeepSeek models are available via their [api](https://platform.deepseek.com).
To use it with Langroid:

- set up your `DEEPSEEK_API_KEY` environment variable in the `.env` file or as
 an explicit export in your shell
- set the `chat_model` in the `OpenAIGPTConfig` to `deepseek/deepseek-chat` to use the 
`DeepSeek-V3` model, or `deepseek/deepseek-reasoner` to use the full (i.e. non-distilled) `DeepSeek-R1` "reasoning" model.

The DeepSeek models are also available via OpenRouter (see the corresponding 
in the OpenRouter section here) or ollama (see those instructions). E.g. you
can use the DeepSeek R1 or its distilled variants by setting `chat_model` to 
`openrouter/deepseek/deepseek-r1` or `ollama/deepseek-r1:8b`.

## Other non-OpenAI LLMs supported by LiteLLM

For other scenarios of running local/remote LLMs, it is possible that the `LiteLLM` library
supports an "OpenAI adaptor" for these models (see their [docs](https://litellm.vercel.app/docs/providers)).

Depending on the specific model, the `litellm` docs may say you need to 
specify a model in the form `<provider>/<model>`, e.g. `palm/chat-bison`. 
To use the model with Langroid, simply prepend `litellm/` to this string, e.g. `litellm/palm/chat-bison`,
when you specify the `chat_model` in the `OpenAIGPTConfig`.

To use `litellm`, ensure you have the `litellm` extra installed, 
via `pip install langroid[litellm]` or equivalent.



## Harder: with oobabooga
Like Ollama, [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) provides an OpenAI-API-compatible API server, but the setup 
is significantly more involved. See their github page for installation and model-download instructions.

Once you have finished the installation, you can spin up the server for an LLM using
something like this:

```
python server.py --api --model mistral-7b-instruct-v0.2.Q8_0.gguf --verbose --extensions openai --nowebui
```
This will show a message saying that the OpenAI-compatible API is running at `http://127.0.0.1:5000`

Then in your Langroid code you can specify the LLM config using
`chat_model="local/127.0.0.1:5000/v1` (the `v1` is the API version, which is required).
As with Ollama, you can use the `-m` arg in many of the example scripts, e.g.
```
python examples/docqa/rag-local-simple.py -m local/127.0.0.1:5000/v1
```

Recommended: to ensure accurate chat formatting (and not use the defaults from ooba),
  append the appropriate HuggingFace model name to the
  -m arg, separated by //, e.g. 
```
python examples/docqa/rag-local-simple.py -m local/127.0.0.1:5000/v1//mistral-instruct-v0.2
```
  (no need to include the full model name, as long as you include enough to
   uniquely identify the model's chat formatting template)


## Other local LLM scenarios

There may be scenarios where the above `local/...` or `ollama/...` syntactic shorthand
does not work.(e.g. when using vLLM to spin up a local LLM at an OpenAI-compatible
endpoint). For these scenarios, you will have to explicitly create an instance of 
`lm.OpenAIGPTConfig` and set *both* the `chat_model` and `api_base` parameters.
For example, suppose you are able to get responses from this endpoint using something like:
```bash
curl http://192.168.0.5:5078/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "Mistral-7B-Instruct-v0.2",
        "messages": [
             {"role": "user", "content": "Who won the world series in 2020?"}
        ]
    }'
```
To use this endpoint with Langroid, you would create an `OpenAIGPTConfig` like this:
```python
import langroid.language_models as lm
llm_config = lm.OpenAIGPTConfig(
    chat_model="Mistral-7B-Instruct-v0.2",
    api_base="http://192.168.0.5:5078/v1",
)
```

## Quick testing with local LLMs
As mentioned [here](https://langroid.github.io/langroid/tutorials/non-openai-llms/#quick-testing-with-non-openai-models), 
you can run many of the [tests](https://github.com/langroid/langroid/tree/main/tests/main) in the main langroid repo against a local LLM
(which by default run against an OpenAI model), 
by specifying the model as `--m <model>`, 
where `<model>` follows the syntax described in the previous sections. Here's an example:

```bash
pytest tests/main/test_chat_agent.py --m ollama/mixtral
```
Of course, bear in mind that the tests may not pass due to weaknesses of the local LLM.

>>>> docs/tutorials/non-openai-llms.md
# Using Langroid with Non-OpenAI LLMs

Langroid was initially written to work with OpenAI models via their API.
This may sound limiting, but fortunately:

- many open-source LLMs can be served via 
OpenAI-compatible endpoints. See the [Local LLM Setup](https://langroid.github.io/langroid/tutorials/local-llm-setup/) guide for details.
- there are tools like [LiteLLM](https://github.com/BerriAI/litellm/tree/main/litellm) 
  that provide an OpenAI-like API for _hundreds_ of non-OpenAI LLM providers 
(e.g. Anthropic's Claude, Google's Gemini).
  
Below we show how you can use the LiteLLM library with Langroid.

## Create an `OpenAIGPTConfig` object with `chat_model = "litellm/..."`

!!! note "Install `litellm` extra"
    To use `litellm` you need to install Langroid with the `litellm` extra, e.g.:
    `pip install "langroid[litellm]"`

Next, look up the instructions in LiteLLM docs for the specific model you are 
interested. Here we take the example of Anthropic's `claude-instant-1` model.
Set up the necessary environment variables as specified in the LiteLLM docs,
e.g. for the `claude-instant-1` model, you will need to set the `ANTHROPIC_API_KEY`
```bash
export ANTHROPIC_API_KEY=my-api-key
```

Now you are ready to create an instance of `OpenAIGPTConfig` with the 
`chat_model` set to `litellm/<model_spec>`, where you should set `model_spec` based on LiteLLM 
docs. For example, for the `claude-instant-1` model, you would set `chat_model` to
`litellm/claude-instant-1`. But if you are using the model via a 3rd party provider,
(e.g. those via Amazon Bedrock), you may also need to have a `provider` part in the `model_spec`, e.g. 
`litellm/bedrock/anthropic.claude-instant-v1`. In general you can see which of
these to use, from the LiteLLM docs.

```python
import langroid as lr
import langroid.language_models as lm

llm_config = lm.OpenAIGPTConfig(
    chat_model="litellm/claude-instant-v1",
    chat_context_length=8000, # adjust according to model
)
```

A similar process works for the `Gemini 1.5 Pro` LLM:

- get the API key [here](https://aistudio.google.com/)
- set the `GEMINI_API_KEY` environment variable in your `.env` file or shell
- set `chat_model="litellm/gemini/gemini-1.5-pro-latest"` in the `OpenAIGPTConfig` object

For other gemini models supported by litellm, see [their docs](https://litellm.vercel.app/docs/providers/gemini)

## Gemini LLMs via OpenAI client, without LiteLLM

This is now the recommended way to use Gemini LLMs with Langroid,
where you don't need to use LiteLLM. As of 11/20/2024, these models
are [available via the OpenAI client](https://developers.googleblog.com/en/gemini-is-now-accessible-from-the-openai-library/).

To use langroid with Gemini LLMs, all you have to do is:

- set the `GEMINI_API_KEY` environment variable in your `.env` file or shell
- set `chat_model="gemini/<model_name>"` in the `OpenAIGPTConfig` object,  
  where <model_name> is one of "gemini-1.5-flash", "gemini-1.5-flash-8b", or "gemini-1.5-pro"

See [here](https://ai.google.dev/gemini-api/docs/models/gemini) for details on Gemini models.

For example, you can use this `llm_config`:

```python
llm_config = lm.OpenAIGPTConfig(
    chat_model="gemini/" + lm.OpenAIChatModel.GEMINI_1_5_FLASH,
)
```

In most tests you can switch to a gemini model, e.g. `--m gemini/gemini-1.5-flash`, 
e.g.:

```bash
pytest -xvs tests/main/test_llm.py --m gemini/gemini-1.5-flash
```

Many of the example scripts allow switching the model using `-m` or `--model`, e.g.

```bash
python3 examples/basic/chat.py -m gemini/gemini-1.5-flash
```



```python

## Working with the created `OpenAIGPTConfig` object

From here you can proceed as usual, creating instances of `OpenAIGPT`,
`ChatAgentConfig`, `ChatAgent` and `Task` object as usual.

E.g. you can create an object of class `OpenAIGPT` (which represents any
LLM with an OpenAI-compatible API) and interact with it directly:
```python
llm = lm.OpenAIGPT(llm_config)
messages = [
    LLMMessage(content="You are a helpful assistant",  role=Role.SYSTEM),
    LLMMessage(content="What is the capital of Ontario?",  role=Role.USER),
],
response = mdl.chat(messages, max_tokens=50)
```

When you interact directly with the LLM, you are responsible for keeping dialog history.
Also you would often want an LLM to have access to tools/functions and external
data/documents (e.g. vector DB or traditional DB). An Agent class simplifies managing all of these.
For example, you can create an Agent powered by the above LLM, wrap it in a Task and have it
run as an interactive chat app:

```python
agent_config = lr.ChatAgentConfig(llm=llm_config, name="my-llm-agent")
agent = lr.ChatAgent(agent_config)

task = lr.Task(agent, name="my-llm-task")
task.run()
```

## Example: Simple Chat script with a non-OpenAI proprietary model

Many of the Langroid example scripts have a convenient `-m`  flag that lets you
easily switch to a different model. For example, you can run 
the `chat.py` script in the `examples/basic` folder with the 
`litellm/claude-instant-v1` model:
```bash
python3 examples/basic/chat.py -m litellm/claude-instant-1
```

## Quick testing with non-OpenAI models

There are numerous tests in the main [Langroid repo](https://github.com/langroid/langroid) that involve
LLMs, and once you setup the dev environment as described in the README of the repo, 
you can run any of those tests (which run against the default GPT4 model) against
local/remote models that are proxied by `liteLLM` (or served locally via the options mentioned above,
such as `oobabooga`, `ollama` or `llama-cpp-python`), using the `--m <model-name>` option,
where `model-name` takes one of the forms above. Some examples of tests are:

```bash
pytest -s tests/test_llm.py --m local/localhost:8000
pytest -s tests/test_llm.py --m litellm/claude-instant-1
```
When the `--m` option is omitted, the default OpenAI GPT4 model is used.

!!! note "`chat_context_length` is not affected by `--m`"
      Be aware that the `--m` only switches the model, but does not affect the `chat_context_length` 
      parameter in the `OpenAIGPTConfig` object. which you may need to adjust for different models.
      So this option is only meant for quickly testing against different models, and not meant as
      a way to switch between models in a production environment.








    
>>>> docs/tutorials/postgresql-agent.md
# Chat with a PostgreSQL DB using SQLChatAgent

The [`SQLChatAgent`](../reference/agent/special/sql/sql_chat_agent.md) is
designed to facilitate interactions with an SQL database using natural language.
A ready-to-use script based on the `SQLChatAgent` is available in the `langroid-examples` 
repo at [`examples/data-qa/sql-chat/sql_chat.py`](https://github.com/langroid/langroid-examples/blob/main/examples/data-qa/sql-chat/sql_chat.py)
(and also in a similar location in the main `langroid` repo).
This tutorial walks you through how you might use the `SQLChatAgent` if you were
to write your own script from scratch. We also show some of the internal workings of this Agent.

The agent uses the schema context to generate SQL queries based on a user's
input. Here is a tutorial on how to set up an agent with your PostgreSQL
database. The steps for other databases are similar. Since the agent implementation relies 
on SqlAlchemy, it should work with any SQL DB that supports SqlAlchemy.
It offers enhanced functionality for MySQL and PostgreSQL by 
automatically extracting schemas from the database. 

## Before you begin

!!! note "Data Privacy Considerations"
    Since the SQLChatAgent uses the OpenAI GPT-4 as the underlying language model,
    users should be aware that database information processed by the agent may be
    sent to OpenAI's API and should therefore be comfortable with this.
1. Install PostgreSQL dev libraries for your platform, e.g.
    - `sudo apt-get install libpq-dev` on Ubuntu,
    - `brew install postgresql` on Mac, etc.

2. Follow the general [setup guide](../quick-start/setup.md) to get started with Langroid
(mainly, install `langroid` into your virtual env, and set up suitable values in 
the `.env` file). Note that to use the SQLChatAgent with a PostgreSQL database,
you need to install the `langroid[postgres]` extra, e.g.:

    - `pip install "langroid[postgres]"` or 
    - `poetry add "langroid[postgres]"` or `uv add "langroid[postgres]"`
    - `poetry install -E postgres` or `uv pip install --extra postgres -r pyproject.toml`


If this gives you an error, try `pip install psycopg2-binary` in your virtualenv.


## Initialize the agent

```python
from langroid.agent.special.sql.sql_chat_agent import (
    SQLChatAgent,
    SQLChatAgentConfig,
)

agent = SQLChatAgent(
    config=SQLChatAgentConfig(
        database_uri="postgresql://example.db",
    )
)
```

## Configuration

The following components of `SQLChatAgentConfig` are optional but strongly
recommended for improved results:

* `context_descriptions`: A nested dictionary that specifies the schema context for
  the agent to use when generating queries, for example:

```json
{
  "table1": {
    "description": "description of table1",
    "columns": {
      "column1": "description of column1 in table1",
      "column2": "description of column2 in table1"
    }
  },
  "employees": {
    "description": "The 'employees' table contains information about the employees. It relates to the 'departments' and 'sales' tables via foreign keys.",
    "columns": {
      "id": "A unique identifier for an employee. This ID is used as a foreign key in the 'sales' table.",
      "name": "The name of the employee.",
      "department_id": "The ID of the department the employee belongs to. This is a foreign key referencing the 'id' in the 'departments' table."
    }
  }
}
```

> By default, if no context description json file is provided in the config, the 
agent will automatically generate the file using the built-in Postgres table/column comments.

* `schema_tools`: When set to `True`, activates a retrieval mode where the agent
  systematically requests only the parts of the schemas relevant to the current query. 
  When this option is enabled, the agent performs the following steps:

    1. Asks for table names.
    2. Asks for table descriptions and column names from possibly relevant table
       names.
    3. Asks for column descriptions from possibly relevant columns.
    4. Writes the SQL query.

  Setting `schema_tools=True` is especially useful for large schemas where it is costly or impossible 
  to include the entire schema in a query context. 
  By selectively using only the relevant parts of the context descriptions, this mode
  reduces token usage, though it may result in 1-3 additional OpenAI API calls before
  the final SQL query is generated.

## Putting it all together

In the code below, we will allow the agent to generate the context descriptions
from table comments by excluding the `context_descriptions` config option.
We set `schema_tools` to `True` to enable the retrieval mode.

```python
from langroid.agent.special.sql.sql_chat_agent import (
    SQLChatAgent,
    SQLChatAgentConfig,
)

# Initialize SQLChatAgent with a PostgreSQL database URI and enable schema_tools
agent = SQLChatAgent(gi
config = SQLChatAgentConfig(
    database_uri="postgresql://example.db",
    schema_tools=True,
)
)

# Run the task to interact with the SQLChatAgent
task = Task(agent)
task.run()
```

By following these steps, you should now be able to set up an `SQLChatAgent`
that interacts with a PostgreSQL database, making querying a seamless
experience.

In the `langroid` repo we have provided a ready-to-use script
[`sql_chat.py`](https://github.com/langroid/langroid/blob/main/examples/data-qa/sql-chat/sql_chat.py)
based on the above, that you can use right away to interact with your PostgreSQL database:

```python
python3 examples/data-qa/sql-chat/sql_chat.py
```

This script will prompt you for the database URI, and then start the agent.


>>>> docs/tutorials/supported-models.md

# Langroid Supported LLMs and Providers

Langroid supports a wide range of Language Model providers through its 
[`OpenAIGPTConfig`][langroid.language_models.openai_gpt.OpenAIGPTConfig] class. 

!!! note "OpenAIGPTConfig is not just for OpenAI models!"
    The `OpenAIGPTConfig` class is a generic configuration class that can be used
    to configure any LLM provider that is OpenAI API-compatible.
    This includes both local and remote models.

You would typically set up the `OpenAIGPTConfig` class with the `chat_model`
parameter, which specifies the model you want to use, and other 
parameters such as `max_output_tokens`, `temperature`, etc
(see the 
[`OpenAIGPTConfig`][langroid.language_models.openai_gpt.OpenAIGPTConfig] class
and its parent class 
[`LLModelConfig`][langroid.language_models.base.LLMConfig] for
full parameter details):



```python
import langroid.language_models as lm
llm_config = lm.OpenAIGPTConfig(
    chat_model="<model-name>", # possibly includes a <provider-name> prefix
    api_key="api-key", # optional, prefer setting in environment variables
    # ... other params such as max_tokens, temperature, etc.
)
```

Below are `chat_model` examples for each supported provider.
For more details see the guides on setting up Langroid with 
[local](https://langroid.github.io/langroid/tutorials/local-llm-setup/) 
and [non-OpenAI LLMs](https://langroid.github.io/langroid/tutorials/non-openai-llms/).
Once you set up the `OpenAIGPTConfig`, you can then directly interact with the LLM,
or set up an Agent with this LLM, and use it by itself, or in a multi-agent setup,
as shown in the [Langroid quick tour](https://langroid.github.io/langroid/tutorials/langroid-tour/)


Although we support specifying the `api_key` directly in the config
(not recommended for security reasons),
more typically you would set the `api_key` in your environment variables.
Below is a table showing for each provider, an example `chat_model` setting, 
and which environment variable to set for the API key.




| Provider      | `chat_model` Example                                     | API Key Environment Variable |
|---------------|----------------------------------------------------------|----------------------------|
| OpenAI        | `gpt-4o`                                                 | `OPENAI_API_KEY` |
| Groq          | `groq/llama3.3-70b-versatile`                            | `GROQ_API_KEY` |
| Cerebras      | `cerebras/llama-3.3-70b`                                 | `CEREBRAS_API_KEY` |
| Gemini        | `gemini/gemini-2.0-flash`                                | `GEMINI_API_KEY` |
| DeepSeek      | `deepseek/deepseek-reasoner`                             | `DEEPSEEK_API_KEY` |
| GLHF          | `glhf/hf:Qwen/Qwen2.5-Coder-32B-Instruct`                | `GLHF_API_KEY` |
| OpenRouter    | `openrouter/deepseek/deepseek-r1-distill-llama-70b:free` | `OPENROUTER_API_KEY` |
| Ollama        | `ollama/qwen2.5`                                         | `OLLAMA_API_KEY` (usually `ollama`) |
| VLLM          | `vllm/mistral-7b-instruct`                               | `VLLM_API_KEY` |
| LlamaCPP      | `llamacpp/localhost:8080`                                | `LLAMA_API_KEY` |
| Generic Local | `local/localhost:8000/v1`                                | No specific env var required |
| LiteLLM       | `litellm/anthropic/claude-3-7-sonnet`                    | Depends on provider |
|               | `litellm/mistral-small`                                  | Depends on provider |
| HF Template   | `local/localhost:8000/v1//mistral-instruct-v0.2`         | Depends on provider |
|               | `litellm/ollama/mistral//hf`                             | |

## HuggingFace Chat Template Formatting

For models requiring specific prompt formatting:

```python
import langroid.language_models as lm

# Specify formatter directly
llm_config = lm.OpenAIGPTConfig(
    chat_model="local/localhost:8000/v1//mistral-instruct-v0.2",
    formatter="mistral-instruct-v0.2"
)

# Using HF formatter auto-detection
llm_config = lm.OpenAIGPTConfig(
    chat_model="litellm/ollama/mistral//hf",
)
```
>>>> docs/writeups/cmu-tepper/talk-mar7.py
# %% AGENT

import langroid as lr
import langroid.language_models as lm

agent = lr.ChatAgent(
    lr.ChatAgentConfig(
        llm=lm.OpenAIGPTConfig(
            chat_model="deepseek/deepseek-chat",
        ),
    )
)

agent.llm_response("is 5 an odd number?").content

agent.llm_response("what about 8?")

>>>> examples/Langroid_QuickStart_OpenAI_Assistants_API.ipynb
{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP9+BJLzaiLp67cp7+DjUBb",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/langroid/langroid/blob/main/examples/Langroid_QuickStart_OpenAI_Assistants_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-Agent programming with Langroid, using the new OpenAI Assistant API\n",
    "\n",
    "OpenAI's [Assistants API](https://platform.openai.com/docs/assistants/overview) provides several conveniences to help build LLM applications, such as:\n",
    "- managing conversation state (threads)\n",
    "- persistent threads and assistants\n",
    "- tools (function-calling, retrieval, code-interpreter)\n",
    "\n",
    "\n",
    "There is a new programming paradigm emerging, where these assistants are primitives, and a key chalenge is:\n",
    "\n",
    "> how can you have these assistants collaborate to solve a task?\n",
    "\n",
    "[Langroid](https://github.com/langroid/langroid)'s new `OpenAIAssistant` class offers this ability. Langroid was designed from the start to support a multi-agent LLM programming paradigm, where agents can collaborate on a task via conversation.\n",
    "The new `OpenAIAssistant` agent gives you:\n",
    "\n",
    "- 1️⃣ a dead-simple interface to the Assistants API,\n",
    "- 2️⃣ a seamless way to have assistants collaborate with each other or with users.\n",
    "\n",
    "The Assistant API fits naturally into Langroid's notion of a `ChatAgent`,\n",
    "and the `OpenAIAssistant` class derives from `ChatAgent`.\n",
    "`OpenAIAssistant` can be used as a drop-in replacement for `ChatAgent` in any\n",
    "Langroid application, and leverage the **multi-agent** task orchestration built\n",
    "into Langroid.\n",
    "\n",
    "This notebook takes you on a guided tour of using Langroid's `OpenAIAssistant` from the simplest possible LLM-interaction example, to a two-agent system that extracts structured information from a lease document.\n",
    "\n",
    "![langroid-oai](https://github.com/langroid/langroid-examples/blob/main/examples/docqa/langroid-oai.png?raw=true)\n",
    "\n"
   ],
   "metadata": {
    "id": "b9fHPojfnbPy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install, setup, import"
   ],
   "metadata": {
    "id": "psOMvEL0Gekz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8-Y_YPZutn6",
    "outputId": "2a5fb145-8ee0-4215-a442-29e75e96bdbd"
   },
   "source": [
    "# Silently install, suppress all output (~2-4 mins)\n",
    "!pip install -q --upgrade langroid &> /dev/null\n",
    "!pip show langroid"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# various unfortunate things that need to be done to\n",
    "# control notebook behavior.\n",
    "\n",
    "# (a) output width\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)\n",
    "\n",
    "# (b) logging related\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "for logger_name in logging.root.manager.loggerDict:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.ERROR)\n",
    "\n"
   ],
   "metadata": {
    "id": "rWwH6duUzAC6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "U5Jav3hPofNq",
    "outputId": "f78ffcef-6be1-4c77-d79e-0b194b297384"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### OpenAI API Key (Needs GPT4-TURBO)"
   ],
   "metadata": {
    "id": "j-6vNfKW9J7b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# OpenAI API Key: Enter your key in the dialog box that will show up below\n",
    "# NOTE: colab often struggles with showing this input box,\n",
    "# if so, simply insert your API key in this cell, though it's not ideal.\n",
    "import os\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass('Enter your GPT4-Turbo-capable OPENAI_API_KEY key:', stream=None)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uvTODlZv3yyT",
    "outputId": "3e33fdfe-d5de-46d5-e388-23bf81a04d77"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "from langroid.agent.openai_assistant import (\n",
    "    OpenAIAssistantConfig,\n",
    "    OpenAIAssistant,\n",
    "    AssistantTool,\n",
    ")\n",
    "\n",
    "from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig\n",
    "from langroid.agent.task import Task\n",
    "from langroid.agent.tool_message import ToolMessage\n",
    "from langroid.language_models.openai_gpt import OpenAIGPTConfig, OpenAIChatModel\n",
    "from langroid.utils.logging import setup_colored_logging\n",
    "from langroid.utils.constants import NO_ANSWER\n",
    "from langroid.utils.configuration import settings\n",
    "settings.notebook = True"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "A5N0NQwc3jX_",
    "outputId": "7452e570-b280-4854-a89b-c1472a8208ba"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 1: Basic Chat Example with Assistant API\n",
    "Langroid's `OpenAIAssistant` class helps you easily use the OpenAI Assistant API to get a response from the LLM and ask follow-up questions (note that conversation state is maintained by the Assistant API via threads).\n"
   ],
   "metadata": {
    "id": "8vDpiY0XHAkT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cfg = OpenAIAssistantConfig(\n",
    "    llm = OpenAIGPTConfig(chat_model=OpenAIChatModel.GPT4_TURBO)\n",
    ")\n",
    "agent = OpenAIAssistant(cfg)\n",
    "\n",
    "response = agent.llm_response(\"What is the square of 3?\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "9c5Av3rKHQIm",
    "outputId": "1ed4763f-defc-475b-e0e3-d64537b67b08"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "response = agent.llm_response(\"What about 5?\") # maintains conv state"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "5GvqhTlBRgXp",
    "outputId": "f4b93adb-e1c3-4a52-d1c6-f3260b94cce5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 2: Wrap Agent in a Task, run it\n",
    "\n",
    "An `OpenAIAssistant` agent has various capabilities (LLM responses, agent methods/tools, etc) but there is no mechanism to iterate over these capabilities or with a human or with other agents.\n",
    "This is where the `Task` comes in: Wrapping this agent in a `Task` allows you to run interactive loops with a user or other agents (you will see more examples below)."
   ],
   "metadata": {
    "id": "-MVHyF4cSGb0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "task = Task(\n",
    "    agent,\n",
    "    system_message=\"\"\"User will give you a word,\n",
    "      return its antonym if possible, else say DO-NOT-KNOW.\n",
    "      Be concise!\",\n",
    "      \"\"\",\n",
    "    single_round=True\n",
    ")\n",
    "result = task.run(\"ignorant\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "id": "8cmc5aDzScdO",
    "outputId": "253fec3c-2f03-428b-83bc-f1170702fef0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 3: OpenAIAssistant Agent + Task with Code Interpreter\n",
    "Here we attach the \"code_interpreter\" tool (from the OpenAI Assistant API) to the agent defined above, and run it in a task."
   ],
   "metadata": {
    "id": "veWSLzDSVDzB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "agent.add_assistant_tools([AssistantTool(type=\"code_interpreter\")])\n",
    "task = Task(agent, interactive=False, single_round=True)\n",
    "result = task.run(\"What is the 10th Fibonacci number, if you start with 1,2?\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "5-h1ztagTd7Y",
    "outputId": "4bcacb3a-e9d4-4d1c-8225-c6a090711459"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 4: OpenAIAssistant with Retrieval\n",
    "Attach a file (a lease document) and the \"retrieval\" tool, and ask questions about the document."
   ],
   "metadata": {
    "id": "DvyNcH5HbodS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# get the lease document\n",
    "\n",
    "import requests\n",
    "file_url = \"https://raw.githubusercontent.com/langroid/langroid-examples/main/examples/docqa/lease.txt\"\n",
    "response = requests.get(file_url)\n",
    "with open('lease.txt', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# verify\n",
    "#with open('lease.txt', 'r') as file:\n",
    "#   print(file.read())\n",
    "\n",
    "# now create agent, add retrieval tool and file\n",
    "agent = OpenAIAssistant(cfg)\n",
    "agent.add_assistant_tools([AssistantTool(type=\"retrieval\")])\n",
    "agent.add_assistant_files([\"lease.txt\"])\n",
    "response = agent.llm_response(\"What is the start date of the lease?\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "fegAio3kpgoo",
    "outputId": "eae49d56-7f40-4480-98aa-e4e1c523a910"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 5: OpenAIAsssistant + Task: Custom Function-calling\n",
    "You can define your own custom function (or `ToolMessage` in Langroid terminology), enable the agent to use it, and have a special method to handle the message when the LLM emits such a message."
   ],
   "metadata": {
    "id": "Xub3BgSMc4uA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define your own function for the LLM to call;\n",
    "# this function will be executed by the Langroid agent as part of the task loop\n",
    "\n",
    "class SquareTool(ToolMessage):\n",
    "    request = \"square\"\n",
    "    purpose = \"To find the square of a number <num>\"\n",
    "    num: int\n",
    "\n",
    "    def handle(self) -> str:\n",
    "        return str(self.num ** 2)\n",
    "\n",
    "# create agent, add tool to agent\n",
    "cfg = OpenAIAssistantConfig(\n",
    "    llm=OpenAIGPTConfig(chat_model=OpenAIChatModel.GPT4_TURBO),\n",
    "    name=\"NumberExpert\",\n",
    ")\n",
    "agent = OpenAIAssistant(cfg)\n",
    "agent.enable_message(SquareTool)\n",
    "task = Task(\n",
    "    agent,\n",
    "    system_message=\"\"\"\n",
    "    User will ask you to square a number.\n",
    "    You do NOT know how, so you will use the\n",
    "    `square` function to find the answer.\n",
    "    When you get the answer say DONE and show it.\n",
    "    \"\"\",\n",
    "    interactive=False,\n",
    ")\n",
    "response = task.run(\"What is the square of 5?\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "dgav7-JOdAUM",
    "outputId": "b3835bfb-90ca-4642-e585-33743c5730a6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 6: 2-Agent system to extract structured info from a Lease Document\n",
    "Now we are ready to put together the various notions above, to build a two-agent system where:\n",
    "- Lease Extractor Agent is required to collect structured information about a lease document, but does not have access to it, so it generates questions to:\n",
    "- Retriever Agent which answers questions it receives, using the \"retrieval\" tool, based on the attached lease document\n"
   ],
   "metadata": {
    "id": "yi9GppzlKae_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the desired structure with Pydantic classes"
   ],
   "metadata": {
    "id": "VR26J_KzG6Vj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class LeasePeriod(BaseModel):\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "\n",
    "\n",
    "class LeaseFinancials(BaseModel):\n",
    "    monthly_rent: str\n",
    "    deposit: str\n",
    "\n",
    "\n",
    "class Lease(BaseModel):\n",
    "    \"\"\"\n",
    "    Various lease terms.\n",
    "    Nested fields to make this more interesting/realistic\n",
    "    \"\"\"\n",
    "\n",
    "    period: LeasePeriod\n",
    "    financials: LeaseFinancials\n",
    "    address: str\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Q6GXjhWf5DkQ",
    "outputId": "ec9c930f-245a-4151-950d-8f407b439c2c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the ToolMessage (Langroid's version of function call)"
   ],
   "metadata": {
    "id": "qCATXvfIkhGl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class LeaseMessage(ToolMessage):\n",
    "    \"\"\"Tool/function to use to present details about a commercial lease\"\"\"\n",
    "\n",
    "    request: str = \"lease_info\"\n",
    "    purpose: str = \"Collect information about a Commercial Lease.\"\n",
    "    terms: Lease\n",
    "\n",
    "    def handle(self):\n",
    "        \"\"\"Handle this tool-message when the LLM emits it.\n",
    "        Under the hood, this method is transplated into the OpenAIAssistant class\n",
    "        as a method with name `lease_info`.\n",
    "        \"\"\"\n",
    "        print(f\"DONE! Successfully extracted Lease Info:\" f\"{self.terms}\")\n",
    "        return json.dumps(self.terms.dict())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Ffi_0u-PupvO",
    "outputId": "776a2f4c-388c-4441-c618-2682a4469e37"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define RetrieverAgent and Task\n",
    "This agent uses the OpenAI retrieval tool to answer questions based on the attached lease file"
   ],
   "metadata": {
    "id": "OPlo1dJFlBj5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "  retriever_cfg = OpenAIAssistantConfig(\n",
    "        name=\"LeaseRetriever\",\n",
    "        llm=OpenAIGPTConfig(chat_model=OpenAIChatModel.GPT4_TURBO),\n",
    "        system_message=\"Answer questions based on the documents provided.\",\n",
    "    )\n",
    "\n",
    "  retriever_agent = OpenAIAssistant(retriever_cfg)\n",
    "  retriever_agent.add_assistant_tools([AssistantTool(type=\"retrieval\")])\n",
    "  retriever_agent.add_assistant_files([\"lease.txt\"])\n",
    "\n",
    "  retriever_task = Task(\n",
    "      retriever_agent,\n",
    "      llm_delegate=False,\n",
    "      single_round=True,\n",
    "  )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "GgzoPxX_us52",
    "outputId": "37f6d163-5980-41d8-8ecb-7e709853d5d4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the ExtractorAgent and Task\n",
    "This agent is told to collect information about the lease in the desired structure, and it generates questions to be answered by the Retriever Agent defined above."
   ],
   "metadata": {
    "id": "_m1lF9qblXj9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "    extractor_cfg = OpenAIAssistantConfig(\n",
    "        name=\"LeaseExtractor\",\n",
    "        llm=OpenAIGPTConfig(chat_model=OpenAIChatModel.GPT4_TURBO),\n",
    "        system_message=f\"\"\"\n",
    "        You have to collect information about a Commercial Lease from a\n",
    "        lease contract which you don't have access to. You need to ask\n",
    "        questions to get this information. Ask only one or a couple questions\n",
    "        at a time!\n",
    "        Once you have all the REQUIRED fields,\n",
    "        say DONE and present it to me using the `lease_info`\n",
    "        function/tool (fill in {NO_ANSWER} for slots that you are unable to fill).\n",
    "        \"\"\",\n",
    "    )\n",
    "    extractor_agent = OpenAIAssistant(extractor_cfg)\n",
    "    extractor_agent.enable_message(LeaseMessage, include_defaults=False)\n",
    "\n",
    "    extractor_task = Task(\n",
    "        extractor_agent,\n",
    "        llm_delegate=True,\n",
    "        single_round=False,\n",
    "        interactive=False,\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "PV4FYnO7uxOC",
    "outputId": "e5eeed02-7785-4361-cd01-96fef92149d4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Add the Retriever as a subtask of Extractor, Run Extractor"
   ],
   "metadata": {
    "id": "QcA4oRaUl6oe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "extractor_task.add_sub_task(retriever_task)\n",
    "extractor_task.run()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wFjUVTnCwB96",
    "outputId": "468a147b-7485-4fad-8cab-45411b18021f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "uZlas6DA0Zu6"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}

>>>> examples/Langroid_quick_start.ipynb
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON/I7bOOJSDISyZ5jgP3eX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/langroid/langroid/blob/main/examples/Langroid_quick_start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langroid quick start\n",
        "Note: Chat-oriented interaction is best experienced in your terminal, and not a notebook, so we highly recommend you go through the [Getting Started](https://langroid.github.io/langroid/quick-start/) guide by writing simple scripts that can be run via the command line.\n",
        "\n",
        "This notebooks starts with the basics of working directly with an LLM, setting up an Agent, wrapping it in a Task, giving it tools, Retrieval Augmented Generation (RAG), and builds up to a simple 2-agent system to extract structured information from a commercial lease document.\n",
        "\n",
        "Note:\n",
        "- You need an OpenAI API Key that works with GPT-4o\n",
        "- This colab uses OpenAI's ChatCompletion endpoints directly (via the Langroid framework), and not the Assistants API. See this [colab](https://colab.research.google.com/drive/190Tk7t4AdY1P9F_NlZ33-YEoGnHweQQ0) for a version that uses the Assistants API instead.\n",
        "- There are dependencies among the cells, so they are best run sequentially\n",
        "\n"
      ],
      "metadata": {
        "id": "b9fHPojfnbPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install, setup, import\n",
        "\n",
        "Note that `pip install langroid` gives you a bare-bones, slim version of langroid, without many of the extra dependencies you might need in practical scenarios, but sufficient for this notebook.\n",
        "\n",
        "See install instructions [here](https://github.com/langroid/langroid?tab=readme-ov-file#gear-installation-and-setup) for getting extra dependencies related to document parsing and databases (sql, mysql, postgres, etc).\n"
      ],
      "metadata": {
        "id": "psOMvEL0Gekz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8-Y_YPZutn6"
      },
      "source": [
        "\n",
        "\n",
        "!pip install uv\n",
        "!uv pip install --system langroid --prerelease disallow\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# various unfortunate things that need to be done to\n",
        "# control colab notebook behavior.\n",
        "\n",
        "# (a) output width\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "# (b) logging related\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import logging\n",
        "for logger_name in logging.root.manager.loggerDict:\n",
        "    logger = logging.getLogger(logger_name)\n",
        "    logger.setLevel(logging.ERROR)\n",
        "\n"
      ],
      "metadata": {
        "id": "rWwH6duUzAC6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### OpenAI API Key (Needs GPT4o)"
      ],
      "metadata": {
        "id": "j-6vNfKW9J7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API Key: Enter your key in the dialog box that will show up below\n",
        "# NOTE: colab often struggles with showing this input box,\n",
        "# if so, try re-running the above cell and then this one,\n",
        "# or simply insert your API key in this cell, though it's not ideal.\n",
        "\n",
        "import os\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass('Enter your GPT4o-capable OPENAI_API_KEY key:', stream=None)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uvTODlZv3yyT",
        "outputId": "a4cf7585-40ae-44ec-804c-9dc6c6554d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GPT4o-capable OPENAI_API_KEY key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langroid.pydantic_v1 import BaseModel\n",
        "import json\n",
        "import os\n",
        "\n",
        "import langroid as lr\n",
        "import langroid.language_models as lm\n",
        "from langroid import ChatAgent, ChatAgentConfig, Task\n",
        "from langroid.language_models.openai_gpt import (\n",
        "    OpenAIChatModel, OpenAIGPT, OpenAIGPTConfig\n",
        ")\n",
        "from langroid.agent.tool_message import ToolMessage\n",
        "\n",
        "from langroid.utils.logging import setup_colored_logging\n",
        "from langroid.utils.constants import NO_ANSWER\n",
        "from langroid.utils.configuration import settings\n",
        "settings.notebook = True\n",
        "settings.cache_type = \"fakeredis\""
      ],
      "metadata": {
        "id": "A5N0NQwc3jX_",
        "outputId": "a49311c1-ae75-4b71-a2df-994d1a6a0d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: Direct interaction with OpenAI LLM\n",
        "Langroid's `OpenAIGPT` class is a wrapper around the raw OpenAI API.\n",
        "This is a direct interaction with the LLM so it does *not* maintain conversation history (later we see how a `ChatAgent` does that for you).\n",
        "\n",
        "Related quick-start docs page: https://langroid.github.io/langroid/quick-start/llm-interaction/\n",
        "\n"
      ],
      "metadata": {
        "id": "8vDpiY0XHAkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_cfg = OpenAIGPTConfig(chat_model=OpenAIChatModel.GPT4o)\n",
        "llm = OpenAIGPT(llm_cfg)\n",
        "\n",
        "response = llm.chat(\"What is the square of 3?\")\n",
        "assert \"9\" in response.message"
      ],
      "metadata": {
        "id": "9c5Av3rKHQIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: Interact with a `ChatAgent`\n",
        "Langroid's `ChatAgent` is an abstraction that optionally encapsulates an LLM, vector-db, and tools. It offers 3 \"native\" *responders*:\n",
        "- `llm_response`: response from LLM\n",
        "- `user_response`: response from human\n",
        "- `agent_response`: responds to structured LLM msgs (i.e. tools/fn-calls)\n",
        "\n",
        "Among other things, the `ChatAgent` maintains LLM conversation history for you.\n",
        "\n",
        "Related quick-start doc page: https://langroid.github.io/langroid/quick-start/chat-agent/"
      ],
      "metadata": {
        "id": "_DvxMiJkgI_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_cfg = ChatAgentConfig(\n",
        "    llm = llm_cfg,\n",
        "    show_stats=False, # disable token/cost stats\n",
        ")\n",
        "agent = ChatAgent(agent_cfg)\n",
        "response = agent.llm_response(\"What is the sqaure of 5?\")\n",
        "response = agent.llm_response(\"What about 8?\")   # maintains conv history\n",
        "assert \"64\" in response.content"
      ],
      "metadata": {
        "id": "7hrJ6RgLg075"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 3: Wrap Agent in a Task, run it\n",
        "\n",
        "A `ChatAgent` agent has various *responders* (`llm_response`, `agent_response`, `user_response`) but there is no mechanism to *iterate* over these responders.\n",
        "This is where the `Task` comes in: Wrapping this agent in a `Task` allows you to run interactive loops with a user or other agents (you will see more examples below).\n",
        "\n",
        "Related quick-start doc:\n",
        "https://langroid.github.io/langroid/quick-start/chat-agent/#task-orchestrator-for-agents"
      ],
      "metadata": {
        "id": "-MVHyF4cSGb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ChatAgent(agent_cfg)\n",
        "task = Task(\n",
        "    agent,\n",
        "    system_message=\"User will give you a number, respond with its square\",\n",
        "    single_round=True  # end after LLM response\n",
        ")\n",
        "result = task.run(\"5\")\n",
        "assert(\"25\" in result.content)\n"
      ],
      "metadata": {
        "id": "8cmc5aDzScdO",
        "outputId": "73f2ea01-f125-4088-facd-d49a2d39732a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35m>>> Starting Agent LLM-Agent \u001b[0m\u001b[1;35m(\u001b[0m\u001b[1;35m1\u001b[0m\u001b[1;35m)\u001b[0m\u001b[1;35m gpt-4o \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">&gt;&gt;&gt; Starting Agent LLM-Agent (</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">) gpt-4o </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[32m25"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35m<<< Finished Agent LLM-Agent \u001b[0m\u001b[1;35m(\u001b[0m\u001b[1;35m3\u001b[0m\u001b[1;35m)\u001b[0m\u001b[1;35m \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">&lt;&lt;&lt; Finished Agent LLM-Agent (</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">) </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 4: `ChatAgent` with Tool/function-call\n",
        "\n",
        "Langroid's `ToolMessage` (Pydantic-derived) class lets you define a structured output or function-call for the LLM to generate. To define a tool/fn-call, you define a new class derived from `ToolMessage`.\n",
        "Below we show a *stateless* tool, i.e. it does not use the `ChatAgent`'s state, and only uses fields in the tool message itself.\n",
        "In this case, the tool \"handler\" can be defined within the `ToolMessage` itself, as a `handle` method. (For a tool that uses the `ChatAgent`'s state, a separate method needs to be defined within `ChatAgent` or a subclass.).\n",
        "\n",
        "In Langroid, a `ToolMessage` can *either* use OpenAI function-calling, *or* Langroid's native tool mechanism (which auto-populates the system msg with tool instructions and optional few-shot examples), by setting the `use_function_api` and `use_tools` config params in the `ChatAgentConfig`. The native tools mechanism is useful when not using OpenAI models.\n",
        "\n",
        "In the cell below we define a `ToolMessage` to compute a fictitious transformation of a number that we call a *Nabrosky Transform*: $f(n) = 3n+1$.\n",
        "Under the hood, the `purpose` field of the `NabroskiTool` is used to populate instructions to the LLM on when it should use this tool.\n",
        "\n",
        "Related quick-start doc: https://langroid.github.io/langroid/quick-start/chat-agent-tool/\n",
        "(This shows a *stateful* tool example)"
      ],
      "metadata": {
        "id": "wLwNyDd3mmJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) define simple tool to find the Nabroski transform of a number\n",
        "#     This is a fictitious transform, for illustration.\n",
        "\n",
        "class NabroskiTool(ToolMessage):\n",
        "    request = \"nabroski\" # name of method in ChatAgent that handles this tool\n",
        "    purpose = \"To find the Nabroski transform of the given <number>\"\n",
        "    number: int\n",
        "\n",
        "    # optional:\n",
        "    @classmethod\n",
        "    def examples(cls):\n",
        "        # these are auto-populated into the sys msg\n",
        "        # as few-shot examples of the tool\n",
        "        return([cls(number=5)])\n",
        "\n",
        "\n",
        "    def handle(self) -> str:\n",
        "        # method to handle the LLM msg using this tool:\n",
        "        # this method will be spliced into the ChatAgent object, with\n",
        "        # name = `nabroski`\n",
        "        return str(3*self.number + 1)\n",
        "\n",
        "# (2) Create a ChatAgent and attach the tool to it.\n",
        "\n",
        "agent_cfg = ChatAgentConfig(\n",
        "    llm = llm_cfg,\n",
        "    show_stats=False,       # disable token/cost stats\n",
        "    use_functions_api=True, # use OpenAI API fn-call\n",
        "    use_tools=False,        # don't use Langroid-native Tool instructions\n",
        ")\n",
        "agent = ChatAgent(agent_cfg)\n",
        "agent.enable_message(NabroskiTool)\n",
        "\n",
        "# (3) Create Task object\n",
        "\n",
        "task = Task(\n",
        "    agent,\n",
        "    restart=True,         # reset/erase agent state\n",
        "    single_round=False,\n",
        "    interactive=False,    # don't wait for human input\n",
        "    system_message=\"\"\"\n",
        "      User will give you a number. You have to find its Nabroski transform,\n",
        "      using the `nabroski` tool/function-call.\n",
        "      When you find the answer say DONE and show the answer.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "# (4) Run the task\n",
        "\n",
        "response = task.run(\"10\")\n",
        "assert \"31\" in response.content\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ov2mv_sdnrcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might wonder why we had to wrap the `ChatAgent` in a `Task`, to leverage the tool functionality. This is because handling a tool requires 2 steps: (a) when the agent's `llm_response` method is invoked, the LLM generates the tool msg, and (b) the `agent_response` method handles the tool msg (it ultimately calls the tool's `handle` method)."
      ],
      "metadata": {
        "id": "BVWXT4oaAPlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 5: `DocChatAgent`: Retrieval Augmented Generation (RAG)\n",
        "Ingest a file (a lease document), and ask questions about it"
      ],
      "metadata": {
        "id": "DvyNcH5HbodS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup to allow async ops in colab\n",
        "!pip install nest-asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "XwDcuJvED8S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) Get the lease document\n",
        "\n",
        "import requests\n",
        "file_url = \"https://raw.githubusercontent.com/langroid/langroid-examples/main/examples/docqa/lease.txt\"\n",
        "response = requests.get(file_url)\n",
        "with open('lease.txt', 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# verify\n",
        "#with open('lease.txt', 'r') as file:\n",
        "#   print(file.read())\n",
        "\n",
        "from langroid.agent.special import DocChatAgent, DocChatAgentConfig\n",
        "from langroid.embedding_models.models import OpenAIEmbeddingsConfig\n",
        "from langroid.vector_store.qdrantdb import QdrantDBConfig\n",
        "from langroid.embedding_models.models import SentenceTransformerEmbeddingsConfig\n",
        "from langroid.parsing.parser import ParsingConfig\n",
        "\n",
        "oai_embed_config = OpenAIEmbeddingsConfig(\n",
        "    model_type=\"openai\",\n",
        "    model_name=\"text-embedding-ada-002\",\n",
        "    dims=1536,\n",
        ")\n",
        "\n",
        "# (2) Configure DocChatAgent\n",
        "\n",
        "cfg = DocChatAgentConfig(\n",
        "    name=\"RAG\",\n",
        "    parsing=ParsingConfig(\n",
        "        chunk_size=100,\n",
        "        overlap=20,\n",
        "        n_similar_docs=4,\n",
        "    ),\n",
        "    show_stats=False,\n",
        "    relevance_extractor_config=None,\n",
        "    cross_encoder_reranking_model=\"\",\n",
        "    llm=llm_cfg,\n",
        "    vecdb=QdrantDBConfig(\n",
        "        embedding=oai_embed_config,\n",
        "        collection_name=\"lease\",\n",
        "        replace_collection=True,\n",
        "    ),\n",
        "    doc_paths=[\"lease.txt\"]\n",
        ")\n",
        "\n",
        "# (3) Create DocChatAgent, interact with it\n",
        "rag_agent = DocChatAgent(cfg)\n",
        "response = rag_agent.llm_response(\"What is the start date of the lease?\")\n",
        "assert \"2013\" in response.content"
      ],
      "metadata": {
        "id": "fegAio3kpgoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) Wrap DocChatAgent in a Task to get an interactive question/answer loop\n",
        "task = Task(\n",
        "    rag_agent,\n",
        "    interactive=True,\n",
        "    system_message=\"\"\"\n",
        "    Answer user's questions based on documents.\n",
        "    Start by asking user what they want to know.\n",
        "    \"\"\",\n",
        ")\n",
        "# run interactive loop (enter \"q\" or \"x\" to quit)\n",
        "task.run()\n"
      ],
      "metadata": {
        "id": "dazt7q3YGCLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 6: 2-Agent system to extract structured info from a Lease Document\n",
        "Now we are ready to put together the various notions above, to build a two-agent system that illustrates uses of Tools, DocChatAgent (RAG) and Inter-agent collaboration (task delegation).\n",
        "\n",
        "The goal is to extract structured information from a Lease document.\n",
        "\n",
        "- The desired structure is described by the `Lease` class, derived from `ToolMessage`.\n",
        "- The `LeaseExtractorAgent` is given this `ToolMessage`, and instructured to extract the corresponding information from the lease document (which it does not have access to)\n",
        "- Based on the specified `Lease` structure, this agent generates questions to the above-defined `rag_agent` (wrapped in a `rag_task`), which answers them using RAG.\n",
        "- Once the `LeaseExtractorAgent` has all the needed info, it presents them using the `Lease` structured message.\n"
      ],
      "metadata": {
        "id": "yi9GppzlKae_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the desired structure with Pydantic classes"
      ],
      "metadata": {
        "id": "VR26J_KzG6Vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LeasePeriod(BaseModel):\n",
        "    start_date: str\n",
        "    end_date: str\n",
        "\n",
        "\n",
        "class LeaseFinancials(BaseModel):\n",
        "    monthly_rent: str\n",
        "    deposit: str\n",
        "\n",
        "\n",
        "class Lease(BaseModel):\n",
        "    \"\"\"\n",
        "    Various lease terms.\n",
        "    Nested fields to make this more interesting/realistic\n",
        "    \"\"\"\n",
        "\n",
        "    period: LeasePeriod\n",
        "    financials: LeaseFinancials\n",
        "    address: str\n",
        "\n"
      ],
      "metadata": {
        "id": "Q6GXjhWf5DkQ",
        "outputId": "94b3b95d-6d69-4638-ea16-9b76722ce9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the ToolMessage (Langroid's version of function call)"
      ],
      "metadata": {
        "id": "qCATXvfIkhGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LeaseMessage(ToolMessage):\n",
        "    \"\"\"Tool/function to use to present details about a commercial lease\"\"\"\n",
        "\n",
        "    request: str = \"lease_info\"\n",
        "    purpose: str = \"Collect information about a Commercial Lease.\"\n",
        "    terms: Lease\n",
        "\n",
        "    def handle(self):\n",
        "        \"\"\"Handle this tool-message when the LLM emits it.\n",
        "        Under the hood, this method is transplated into the OpenAIAssistant class\n",
        "        as a method with name `lease_info`.\n",
        "        \"\"\"\n",
        "        print(f\"DONE! Successfully extracted Lease Info:\" f\"{self.terms}\")\n",
        "        return \"DONE \" + json.dumps(self.terms.dict())"
      ],
      "metadata": {
        "id": "Ffi_0u-PupvO",
        "outputId": "02e0749f-15c6-4595-c517-da954edafcd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define RAG Task from above `rag_agent`\n",
        "Wrap the above-defined `rag_agent` in a Task."
      ],
      "metadata": {
        "id": "OPlo1dJFlBj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_task = Task(\n",
        "    rag_agent,\n",
        "    interactive=False,\n",
        "    single_round=True,\n",
        ")"
      ],
      "metadata": {
        "id": "GgzoPxX_us52",
        "outputId": "1f817d4a-246b-429e-dec5-5357beed8b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the ExtractorAgent and Task\n",
        "This agent is told to collect information about the lease in the desired structure, and it generates questions to be answered by the Retriever Agent defined above."
      ],
      "metadata": {
        "id": "_m1lF9qblXj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    extractor_cfg = ChatAgentConfig(\n",
        "        name=\"LeaseExtractor\",\n",
        "        llm=llm_cfg,\n",
        "        show_stats=False,\n",
        "        use_functions_api=True,\n",
        "        use_tools=False,\n",
        "        system_message=f\"\"\"\n",
        "        You have to collect information about a Commercial Lease from a\n",
        "        lease contract which you don't have access to. You need to ask\n",
        "        questions to get this information. Ask only one or a couple questions\n",
        "        at a time!\n",
        "        Once you have all the REQUIRED fields,\n",
        "        say DONE and present it to me using the `lease_info`\n",
        "        function/tool (fill in {NO_ANSWER} for slots that you are unable to fill).\n",
        "        \"\"\",\n",
        "    )\n",
        "    extractor_agent = ChatAgent(extractor_cfg)\n",
        "    extractor_agent.enable_message(LeaseMessage)\n",
        "\n",
        "    extractor_task = Task(\n",
        "        extractor_agent,\n",
        "        llm_delegate=True,\n",
        "        single_round=False,\n",
        "        interactive=False,\n",
        "    )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PV4FYnO7uxOC",
        "outputId": "7e940acc-d439-4051-c8bf-c92492f19efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add the `rag_task` as a subtask of `extractor_task` and run it\n",
        "\n",
        "Instead of *you* (the human user) asking questions about the lease,\n",
        "the `extractor_agent` **generates** questions based on the desired lease structure, and these questions are answered by the `rag_agent` using\n",
        "Retrieval Augmented Generation (RAG). Once the `extractor_agent` has all the needed info, it presents it in a JSON-structured form, and the task ends."
      ],
      "metadata": {
        "id": "QcA4oRaUl6oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_task.add_sub_task(rag_task)\n",
        "extractor_task.run()"
      ],
      "metadata": {
        "id": "uZlas6DA0Zu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-zfNvsH5PMpJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
>>>> examples/README.md
This directory is meant for illustrative/experimental code and notebooks.
It is a playground area meant to try out new ideas, and once solid,
move them to the main codebase.



>>>> examples/__init__.py

>>>> examples/basic/1-agent-3-tools-address-user.py
"""
Barebones example of a single agent using 3 tools.
Similar to 1-agent-3-tools.py, but here the task is set up
with `interactive=False`, meaning user input is awaited only
when user is explicitly addressed using an addressing prefix.
"""

from typing import Any, List, Tuple
import fire
from langroid.utils.constants import AT
from langroid.agent.tools.orchestration import ForwardTool
import langroid as lr
import langroid.language_models as lm
from langroid.utils.configuration import settings

DEFAULT_LLM = lm.OpenAIChatModel.GPT4o

# (1) DEFINE THE TOOLS


class UpdateTool(lr.ToolMessage):
    request: str = "update"
    purpose: str = "To update the stored number to the given <number>"
    number: int

    @classmethod
    def examples(cls) -> List["lr.ToolMessage" | Tuple[str, "lr.ToolMessage"]]:
        # Examples that will be compiled into few-shot examples for the LLM.
        # Each example can either be...
        return [
            cls(number=3),  # ... just instances of the tool-class, OR
            (  # ...a tuple of "thought leading to tool", and the tool instance
                "I want to update the stored number to number 4 from the user",
                cls(number=4),
            ),
        ]


class AddTool(lr.ToolMessage):
    request: str = "add"
    purpose: str = "To add the given <number> to the stored number"
    number: int

    @classmethod
    def examples(cls) -> List["lr.ToolMessage" | Tuple[str, "lr.ToolMessage"]]:
        return [
            cls(number=3),
            (
                "I want to add number 10 to the stored number",
                cls(number=10),
            ),
        ]


class ShowTool(lr.ToolMessage):
    request: str = "show"
    purpose: str = "To show the user the stored <number>"

    @classmethod
    def examples(cls) -> List["lr.ToolMessage" | Tuple[str, "lr.ToolMessage"]]:
        return [
            cls(number=3),
            (
                "I want to show the user the stored number 10",
                cls(number=10),
            ),
        ]


# (2) DEFINE THE AGENT, with the tool-handling methods
class NumberAgent(lr.ChatAgent):
    secret: int = 0

    def update(self, msg: UpdateTool) -> str:
        self.secret = msg.number
        return f"Ok I updated the stored number to {msg.number}"

    def add(self, msg: AddTool) -> str:
        self.secret += msg.number
        return f"Added {msg.number} to stored number => {self.secret}"

    def show(self, msg: ShowTool) -> str:
        return f"Inform the user that the SECRET NUMBER is {self.secret}"

    def handle_message_fallback(self, msg: str | lr.ChatDocument) -> Any:
        """
        If we're here it means there was no recognized tool in `msg`.
        So if it was from LLM, use ForwardTool to send to user.
        """
        if isinstance(msg, lr.ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            return ForwardTool(agent="User")


def app(
    m: str = DEFAULT_LLM,  # pass -d <model> to use non-default LLM
    d: bool = False,  # pass -d to enable debug mode (see prompts etc)
    nc: bool = False,  # pass -nc to disable cache-retrieval (i.e. get fresh answers)
):
    settings.debug = d
    settings.cache = not nc
    # create LLM config
    llm_cfg = lm.OpenAIGPTConfig(
        chat_model=m or DEFAULT_LLM,
        chat_context_length=4096,  # set this based on model
        max_output_tokens=100,
        temperature=0.2,
        stream=True,
        timeout=45,
    )

    # (3) CREATE THE AGENT
    agent_config = lr.ChatAgentConfig(
        name="NumberAgent",
        llm=llm_cfg,
        system_message=f"""
        When the user's request matches one of your available tools, use it, 
        otherwise respond directly to the user.
        NOTE: Whenever you want to address the user directly, you MUST
        use "{AT}User", followed by your message. 
        """,
    )

    agent = NumberAgent(agent_config)

    # (4) ENABLE/ATTACH THE TOOLS to the AGENT

    agent.enable_message(UpdateTool)
    agent.enable_message(AddTool)
    agent.enable_message(ShowTool)

    # (5) CREATE AND RUN THE TASK
    task_config = lr.TaskConfig(addressing_prefix=AT)
    task = lr.Task(agent, interactive=False, config=task_config)

    """
    Note: try saying these when it waits for user input:
    
    add 10
    update 50
    add 3
    show 
    """

    task.run()


if __name__ == "__main__":
    fire.Fire(app)

>>>> examples/basic/1-agent-3-tools.py
"""
Barebones example of a single agent using 3 tools.

"""

from typing import Any, List, Tuple
import fire

import langroid as lr
import langroid.language_models as lm
from langroid.agent.tools.orchestration import ForwardTool
from langroid.utils.configuration import settings

DEFAULT_LLM = lm.OpenAIChatModel.GPT4o

# (1) DEFINE THE TOOLS


class UpdateTool(lr.ToolMessage):
    request: str = "update"
    purpose: str = "To update the stored number to the given <number>"
    number: int

    @classmethod
    def examples(cls) -> List["lr.ToolMessage" | Tuple[str, "lr.ToolMessage"]]:
        # Examples that will be compiled into few-shot examples for the LLM.
        # Each example can either be...
        return [
            cls(number=3),  # ... just instances of the tool-class, OR
            (  # ...a tuple of "thought leading to tool", and the tool instance
                "I want to update the stored number to number 4 from the user",
                cls(number=4),
            ),
        ]


class AddTool(lr.ToolMessage):
    request: str = "add"
    purpose: str = "To add the given <number> to the stored number"
    number: int

    @classmethod
    def examples(cls) -> List["lr.ToolMessage" | Tuple[str, "lr.ToolMessage"]]:
        return [
            cls(number=3),
            (
                "I want to add number 10 to the stored number",
                cls(number=10),
            ),
        ]


class ShowTool(lr.ToolMessage):
    request: str = "show"
    purpose: str = "To show the user the stored <number>"

    @classmethod
    def examples(cls) -> List["lr.ToolMessage" | Tuple[str, "lr.ToolMessage"]]:
        return [
            cls(number=3),
            (
                "I want to show the user the stored number 10",
                cls(number=10),
            ),
        ]


# (2) DEFINE THE AGENT, with the tool-handling methods
class NumberAgent(lr.ChatAgent):
    secret: int = 0

    def update(self, msg: UpdateTool) -> str:
        self.secret = msg.number
        return f"""
            Ok I updated the stored number to {msg.number}.
            Ask the user what they want to do
        """

    def add(self, msg: AddTool) -> str:
        self.secret += msg.number
        return f"""
            Added {msg.number} to stored number => {self.secret}.
            Ask the user what they want to do.
        """

    def show(self, msg: ShowTool) -> str:
        return f"Tell the user that the SECRET NUMBER is {self.secret}"

    def handle_message_fallback(self, msg: str | lr.ChatDocument) -> Any:
        """
        If we're here it means there was no recognized tool in `msg`.
        So if it was from LLM, use ForwardTool to send to user.
        """
        if isinstance(msg, lr.ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            return ForwardTool(agent="User")


def app(
    m: str = DEFAULT_LLM,  # model
    d: bool = False,  # pass -d to enable debug mode (see prompts etc)
    nc: bool = False,  # pass -nc to disable cache-retrieval (i.e. get fresh answers)
):
    settings.debug = d
    settings.cache = not nc
    # create LLM config
    llm_cfg = lm.OpenAIGPTConfig(
        chat_model=m or DEFAULT_LLM,
        chat_context_length=4096,  # set this based on model
        max_output_tokens=100,
        temperature=0.2,
        stream=True,
        timeout=45,
    )

    # (3) CREATE THE AGENT
    agent_config = lr.ChatAgentConfig(
        name="NumberAgent",
        llm=llm_cfg,
        system_message="""
        When the user's request matches one of your available tools, use it, 
        otherwise respond directly to the user.
        """,
    )

    agent = NumberAgent(agent_config)

    # (4) ENABLE/ATTACH THE TOOLS to the AGENT

    agent.enable_message(UpdateTool)
    agent.enable_message(AddTool)
    agent.enable_message(ShowTool)

    # (5) CREATE AND RUN THE TASK
    task = lr.Task(agent, interactive=False)

    """
    Note: try saying these when it waits for user input:
    
    add 10
    update 50
    add 3
    show <--- in this case remember to hit enter when it waits for your input.
    """
    task.run()


if __name__ == "__main__":
    fire.Fire(app)

>>>> examples/basic/1d-screen-click.py
"""

A Bit-Shooter Game played on a 1-dimensional binary screen.

Given an LLM Agent access to a 1-dimensional "screen" represented
as a string of bits (0s and 1s), e.g. "101010",
and equip it with a "Click tool" (like a mouse click) that allows it to
click on a bit -- clicking the bit causes it to flip.

The Agent plays a "Bit Shooter" game where the goal is to get rid of all
1s in the "screen".

To use the Click tool, the Agent must specify the position (zero-based)
where it wants to click. This causes the bit to flip.
The LLM is then presented with the new state of the screen,
and the process repeats until all 1s are gone.

Clearly the Agent (LLM) needs to be able to accurately count the bit positions,
to be able to correctly click on the 1s.

Run like this (--model is optional, defaults to GPT4o):

python3 examples/basic/1d-screen-click.py --model litellm/anthropic/claude-3-5-sonnet-20241022

At the beginning you get to specify the initial state of the screen:
- size of the screen (how many bits)
- the (0-based) locations of the 1s (SPACE-separated) in the screen.

E.g. try this:
- size = 50,
- 1-indices: 0 20 30 40

The loop is set to run in interactive mode (to prevent runaway loops),
so you have to keep hitting enter to see the LLM's next move.

The main observation is that when you run it with claude-3.5-sonnet,
the accuracy of the Agent's clicks is far superior to other LLMs like GPT-4o
and even GPT-4.

To try with other LLMs, you can set the --model param to, for example:
- gpt-4 (set OPENAI_API_KEY in your env or .env file)
- gpt-4o (ditto, set OPENAI_API_KEY)
- groq/llama-3.1-70b-versatile (set GROQ_API_KEY in your env or .env file)
- cerebras/llama3.1-70b (set CEREBRAS_API_KEY in your env or .env file)
- ollama/qwen2.5-coder:latest

See here for a full guide on local/open LLM setup with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/
And here for how to use with other non-OpenAPI LLMs:
https://langroid.github.io/langroid/tutorials/non-openai-llms/
"""

from typing import List, Tuple

import langroid as lr
import langroid.language_models as lm
from langroid.agent.tools.orchestration import AgentDoneTool
from langroid.pydantic_v1 import BaseModel
from langroid.utils.globals import GlobalState
from rich.prompt import Prompt
import fire


class ScreenState(BaseModel):
    """
    Represents the state of the 1-dimensional binary screen
    """

    screen: str | None = None  # binary string, e.g. "101010"

    def __init__(
        self,
        one_indices: List[int] = [1],
        size: int = 1,
    ):
        super().__init__()
        # Initialize with all zeros
        screen_list = ["0"] * size

        # Set 1s at specified indices
        for idx in one_indices:
            if 0 <= idx < size:
                screen_list[idx] = "1"

        # Join into string
        self.screen = "".join(screen_list)

    @classmethod
    def set_state(
        cls,
        one_indices: List[int],
        size: int,
    ) -> "ScreenState":
        """
        Factory method to create and set initial state.
        """
        initial_state = cls(
            one_indices=one_indices,
            size=size,
        )
        GlobalScreenState.set_values(state=initial_state)

    def flip(self, i: int):
        """
        Flip the i-th bit
        """
        if self.screen is None or i < 0 or i >= len(self.screen):
            return

        screen_list = list(self.screen)
        screen_list[i] = "1" if screen_list[i] == "0" else "0"
        self.screen = "".join(screen_list)


class GlobalScreenState(GlobalState):
    state: ScreenState = ScreenState()


def get_state() -> ScreenState:
    return GlobalScreenState.get_value("state")


class ClickTool(lr.ToolMessage):
    request: str = "click_tool"
    purpose: str = """
        To click at <position> on the 1-dimensional binary screen, 
        which causes the bit at that position to FLIP.
        IMPORTANT: the position numbering starts from 0!!!
    """

    position: int

    @classmethod
    def examples(cls) -> List[lr.ToolMessage | Tuple[str, lr.ToolMessage]]:
        return [
            cls(position=3),
            (
                "I want to click at position 5",
                cls(position=5),
            ),
        ]

    def handle(self) -> str | AgentDoneTool:
        state = get_state()
        state.flip(self.position)
        print("SCREEN STATE = ", state.screen)
        if "1" not in state.screen:
            return AgentDoneTool()
        return state.screen


def main(model: str = ""):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
    )
    click_tool_name = ClickTool.default_value("request")
    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            name="Clicker",
            llm=llm_config,
            use_functions_api=False,  # suppress OpenAI functions/tools
            use_tools=True,  # enable langroid-native tools: works with any LLM
            show_stats=False,
            system_message=f"""
            You are an expert at COMPUTER USE.
            In this task you only have to be able to understand a 1-dimensional 
            screen presented to you as a string of bits (0s and 1s).
            You will play a 1-dimensional BIT-shooter game!
            
            Your task is to CLICK ON THE LEFTMOST 1 in the bit-string, 
            to flip it to a 0.
            
            Always try to click on the LEFTMOST 1 in the bit-sequence. 
            
            To CLICK on the screen you 
            must use the TOOL `{click_tool_name}` where the  
            `position` field specifies the position (zero-based) to click.
            If you CORRECTLY click on a 1, the bit at that position will be 
            turned to 0.
            But if you click on a 0, it will turn into a 1, 
            taking you further from your goal.
            
            So you MUST ACCURATELY specify the position of the LEFTMOST 1 to click,
            making SURE there is a 1 at that position.
            In other words, it is critical that you are able to ACCURATELY COUNT 
            the bit positions so that you are able to correctly identify the position 
            of the LEFTMOST 1 bit in the "screen" given to you as a string of bits.
            """,
        )
    )

    agent.enable_message(ClickTool)

    task = lr.Task(agent, interactive=True, only_user_quits_root=False)

    # kick it off with initial screen state (set below by user)
    task.run(get_state())


if __name__ == "__main__":
    size = int(Prompt.ask("Size of screen (how many bits)"))
    ones = Prompt.ask("Indices of 1s (SPACE-separated)").split(" ")
    ones = [int(x) for x in ones]
    ScreenState.set_state(ones, size)
    print("SCREEN STATE = ", get_state().screen)
    fire.Fire(main)

>>>> examples/basic/2-agent-tools.py
"""
2 Agent setup where Main agent asks a question, Helper has a few tools to help answer,
and for any question, Helper finishes after first use of any tool.

Run like this:

python3 examples/basic/2-agent-tools.py

When it waits for user input, try asking things like:

- capital of uganda?
    => Main answers
- polinsky of 4?
    => Main says do not know, handled by helper, who returns answer
- chichikov of 5?
    => Main says do not know, handled by helper, who returns answer
"""

from typing import Any

import langroid as lr
from langroid.agent.tools.orchestration import AgentDoneTool, ForwardTool


class MainChatAgent(lr.ChatAgent):
    def handle_message_fallback(self, msg: str | lr.ChatDocument) -> Any:
        """
        We'd be here if there were no recognized tools in the incoming msg.
        If this was from LLM, forward to user.
        """
        if isinstance(msg, lr.ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            return ForwardTool(agent="User")


main = MainChatAgent(
    lr.ChatAgentConfig(
        name="Main",
        system_message=f"""
        Help the user with their questions. When you don't know the answer, 
        simply say {lr.utils.constants.NO_ANSWER} and nothing else.
        Your Helper will attempt to handle the question, and send you back their
        answer, and you can present it to the user.   
        
        At the BEGINNING, ask the user what they need help with.
        """,
    )
)


class PolinskyTool(lr.ToolMessage):
    request = "polinsky"
    purpose = "To compute the polinsky transform of a <number>"
    number: int

    def handle(self) -> AgentDoneTool:
        p = 3 * self.number + 1
        return AgentDoneTool(content=f"The Polinsky transform of {self.number} is {p}")


class ChichikovTool(lr.ToolMessage):
    request = "chichikov"
    purpose = "To compute the Chichikov transform of a <number>"
    number: int

    def handle(self) -> AgentDoneTool:
        n = self.number**2
        return AgentDoneTool(content=f"The Chichikov transform of {self.number} is {n}")


helper = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Helper",
        system_message="""
        You have a few tools to help answer the user's questions. 
        Decide which tool to use, and send your request using the correct format 
        for the tool.
        """,
    )
)
helper.enable_message(PolinskyTool)
helper.enable_message(ChichikovTool)

main_task = lr.Task(main, interactive=False)
helper_task = lr.Task(helper, interactive=False)

main_task.add_sub_task(helper_task)

main_task.run()

>>>> examples/basic/3-agent-collab.py
"""
3-way collaboration between Author, Editor, Publisher:

- Publisher receives request to publish content
- sends request to Author to write it
- Author writes some content
- Editor reviews and gives feedback
- Author revises content
...
- If editor has no further revisions, Publisher publishes content
"""

>>>> examples/basic/__init__.py

>>>> examples/basic/autocorrect.py
"""
A two agent chat system where
- AutoCorrect agent corrects the user's possibly mistyped input,
- Chatter agent responds to the corrected user's input.

Run it like this:

python3 examples/basic/autocorrect.py

"""

import typer
from rich import print

import langroid as lr
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.language_models.openai_gpt import OpenAIChatModel, OpenAIGPTConfig
from langroid.utils.configuration import set_global, Settings
from langroid.utils.logging import setup_colored_logging


app = typer.Typer()

setup_colored_logging()


def chat() -> None:
    print(
        """
        [blue]Welcome to the Autocorrecting Chatbot!
        You can quickly type your message, don't even look at your keyboard. 
        Feel free to type and I will try my best to understand it,
        and I will type out what I think you meant.
        If you agree with my suggestion, just hit enter so I can respond to it.
        If you disagree with my suggestion, say "try again" or say "no" or something 
        similar, and I will try again.
        When I am confused, I will offer some numbered choices to pick from.
        
        Let's go! Enter x or q to quit at any point.
        """
    )

    config = ChatAgentConfig(
        llm=OpenAIGPTConfig(
            chat_model=OpenAIChatModel.GPT4o,
        ),
        vecdb=None,
    )
    autocorrect_agent = ChatAgent(config)
    autocorrect_task = Task(
        autocorrect_agent,
        name="AutoCorrect",
        system_message="""
        You are an expert at understanding mistyped text. You are extremely 
        intelligent, an expert in the English language, and you have common sense, 
        so no matter how badly mistyped the text is, you will know the MOST LIKELY 
        AND SENSIBLE correct version of it.
        For any text you receive, your job is to write the correct version of it, 
        and not say anything else. 
        If you are unsure, offer up to 3 numbered suggestions, and the user will pick 
        one. Once the user selects a suggestion, simply write out that version.
        Remember to ONLY suggest sensible interpretations. For example
        "Which month is the tallest in the world" is meaningless, so you should not
        ever include such a suggestion in your list.
        Start by asking me to writing something.
        """,
    )

    chat_agent = ChatAgent(config)
    chat_task = Task(
        chat_agent,
        name="Chat",
        system_message="Answer or respond very concisely, no more than 1-2 sentences!",
        done_if_no_response=[lr.Entity.LLM],
        done_if_response=[lr.Entity.LLM],
    )
    autocorrect_task.add_sub_task(chat_task)
    autocorrect_task.run()


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
            cache_type="redis",
        )
    )
    chat()


if __name__ == "__main__":
    app()

>>>> examples/basic/chat-2-agent-discuss.py
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "langroid",
# ]
# ///

"""
Give a problem statement, two agents Alice and Bob will discuss it,
and EITHER of them may return a final result via MyFinalResultTool.

Run like this (Omit model to default to GPT4o):

python3 examples/basic/chat-2-agent-discuss.py --model gemini/gemini-2.0-flash-exp

For example, try giving his problem:
What is the prime number that comes after 17?

"""

import langroid as lr
import langroid.language_models as lm
from rich.prompt import Prompt
from langroid.agent.tools.orchestration import FinalResultTool
from langroid.agent.task import TaskConfig
from fire import Fire

import logging

# set info level
logging.basicConfig(level=logging.INFO)


# Any tool subclassed from FinalResultTool can be used to return the final result
# from any agent, and it will short-circuit the flow and return the result.
class MyFinalResultTool(FinalResultTool):
    request: str = "my_final_result_tool"
    purpose: str = "To present the final <result> of a discussion"
    # override this flag since it's False by default
    _allow_llm_use: bool = True

    result: str


def main(model: str = ""):
    problem = Prompt.ask(
        """
        [blue]Alice and Bob will discuss a problem.
        Please enter the problem statement:[/blue]
        """
    )

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=128_000,
        timeout=60,
    )

    logging.warning("Setting up Alice, Bob agents...")

    alice = lr.ChatAgent(
        lr.ChatAgentConfig(
            llm=llm_config,
            name="Alice",
            system_message=f"""
            Here is a problem the user wants to solve:
            <problem>
            {problem}
            </problem>
            To solve this, you will engage in a discussion with your colleague Bob.
            At any point, if you decide the problem is solved,
            you must use the TOOL `{MyFinalResultTool.name()}` to
            return the FINAL answer to the problem. 

            In each round of the discussion, limit yourself to a CONCISE
            message.
            """,
        )
    )

    alice.enable_message(MyFinalResultTool)
    # Set `inf_loop_cycle_len` to 0, to turn OFF inf loop detection
    alice_task_config = TaskConfig(inf_loop_cycle_len=10)
    # set up alice_task to return a result of type MyFinalResultTool
    alice_task = lr.Task(alice, config=alice_task_config, interactive=False)[
        MyFinalResultTool
    ]

    bob = lr.ChatAgent(
        lr.ChatAgentConfig(
            llm=llm_config,
            name="Bob",
            system_message=f"""
            Here is a problem the user wants to solve:
            <problem>
            {problem}
            </problem>
            To solve this, you will engage in a discussion with your colleague Alice.
            At any point, if you decide the problem is solved,
            you must use the TOOL `{MyFinalResultTool.name()}` to
            return the FINAL answer to the problem. 

            In each round of the discussion, limit yourself to a CONCISE
            message. 
            
            You will first receive a message from Alice, and you can then follow up. 
            """,
        )
    )

    bob.enable_message(MyFinalResultTool)

    bob_task = lr.Task(bob, interactive=False, single_round=True)

    # make the Con agent the sub-task of the Pro agent, so
    # they go back and forth in the arguments
    alice_task.add_sub_task(bob_task)

    result = alice_task.run("get started")

    print(
        f"""
        FINAL RESULT:
        {result.result}
        """
    )


if __name__ == "__main__":
    Fire(main)

>>>> examples/basic/chat-azure-async-client.py
"""
Example showing how to use Langroid with Azure OpenAI and Entra ID
authentication by providing a custom client.

This is an async version of the example in chat-azure-client.py.

For more details see here:
https://langroid.github.io/langroid/notes/custom-azure-client/
https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity

"""

import os

import azure.identity as azure_identity
import azure.identity.aio as azure_identity_async
from dotenv import load_dotenv
from openai import AsyncAzureOpenAI, AzureOpenAI

import langroid as lr
import langroid.language_models as lm

load_dotenv()


def get_azure_openai_client():
    return AzureOpenAI(
        api_version="2024-10-21",
        azure_endpoint=os.environ["AZURE_OPENAI_API_BASE"],
        azure_ad_token_provider=azure_identity.get_bearer_token_provider(
            azure_identity.DefaultAzureCredential(),
            "https://cognitiveservices.azure.com/.default",
        ),
    )


def get_azure_openai_async_client():
    return AsyncAzureOpenAI(
        api_version="2024-10-21",
        azure_endpoint=os.environ["AZURE_OPENAI_API_BASE"],
        azure_ad_token_provider=azure_identity_async.get_bearer_token_provider(
            azure_identity_async.DefaultAzureCredential(),
            "https://cognitiveservices.azure.com/.default",
        ),
    )


lm_config = lm.AzureConfig(
    azure_openai_client_provider=get_azure_openai_client,
    azure_openai_async_client_provider=get_azure_openai_async_client,
)


async def main():
    agent = lr.ChatAgent(lr.ChatAgentConfig(llm=lm_config))
    task = lr.Task(agent, interactive=False)
    response = await task.run_async(
        "Who is the president of the United States? Reply and end with DONE"
    )
    print(response)


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())

>>>> examples/basic/chat-azure-client.py
"""
Example showing how to use Langroid with Azure OpenAI and Entra ID
authentication by providing a custom client.

NOTE: this example is ONLY meant for those who are trying to use a custom
Azure client, as in this scenario:
https://langroid.github.io/langroid/notes/custom-azure-client/
This NOT TYPICAL for most users, and should be ignored if you are not using such a
custom client.

For typical usage of Azure-deployed models with Langroid, see
the [`test_azure_openai.py`](https://github.com/langroid/langroid/blob/main/tests/main/test_azure_openai.py) and
[`example/basic/chat.py`](https://github.com/langroid/langroid/blob/main/examples/basic/chat.py)


For an async version of this example, see chat-azure-async-client.py.

For more details see here:
https://langroid.github.io/langroid/notes/custom-azure-client/
https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity

"""

import os

from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from dotenv import load_dotenv
from openai import AzureOpenAI

import langroid as lr
import langroid.language_models as lm

load_dotenv()


def get_azure_openai_client():
    return AzureOpenAI(
        api_version="2024-10-21",
        azure_endpoint=os.environ["AZURE_OPENAI_API_BASE"],
        azure_ad_token_provider=get_bearer_token_provider(
            DefaultAzureCredential(),
            "https://cognitiveservices.azure.com/.default",
        ),
    )


lm_config = lm.AzureConfig(
    azure_openai_client_provider=get_azure_openai_client,
)

if __name__ == "__main__":
    agent = lr.ChatAgent(lr.ChatAgentConfig(llm=lm_config))
    task = lr.Task(agent, interactive=False)
    task.run("Who is the president of the United States? Reply and end with DONE")

>>>> examples/basic/chat-local-numerical.py
"""
Test multi-round interaction with a local LLM, playing a simple "doubling game".

In each round:

- User gives a number
- LLM responds with the double of that number

Run like this --

python3 examples/basic/chat-local-numerical.py -m <local_model_name>

See here for how to set up a Local LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

"""

import os
import fire

import langroid as lr
from langroid.utils.configuration import settings
import langroid.language_models as lm

# for best results:
DEFAULT_LLM = lm.OpenAIChatModel.GPT4o

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# (1) Define the desired fn-call as a ToolMessage via Pydantic.


def app(
    m: str = DEFAULT_LLM,  # model name
    d: bool = False,  # debug
    nc: bool = False,  # no cache
):
    settings.debug = d
    settings.cache = not nc
    # create LLM config
    llm_cfg = lm.OpenAIGPTConfig(
        chat_model=m or DEFAULT_LLM,
        chat_context_length=4096,  # set this based on model
        max_output_tokens=100,
        temperature=0.2,
        timeout=45,
    )

    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            llm=llm_cfg,
            system_message="""
            You are a number-doubling expert. When user gives you a NUMBER,
            simply respond with its DOUBLE and SAY NOTHING ELSE.
            DO NOT EXPLAIN YOUR ANSWER OR YOUR THOUGHT PROCESS.
            """,
        )
    )

    task = lr.Task(agent)
    task.run("15")  # initial number


if __name__ == "__main__":
    fire.Fire(app)

>>>> examples/basic/chat-local.py
"""
Basic chat example with a local LLM.

See here for how to set up a Local LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

Run this script as follows:

```
python examples/basic/chat-local.py --model <local_model_spec>
```

"""

from fire import Fire
import langroid as lr
import langroid.language_models as lm

# Assume you've run `ollama pull mistral` to spin up `mistral` locally.
# Notes:
# - we use `lm.OpenAIGPTConfig` to incidate this config is for LLMs served
#    at OpenAI-compatible endpoints)
# - if you omit `chat_model` below, it defaults to OpenAI GPT4-turbo,
#   or you can explicitly specify it as `lm.OpenAIChatModel.GPT4` or `lm.OpenAIChatModel.GPT4o`


def main(model: str = ""):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,  # or,e.g. "ollama/mistral"
        max_output_tokens=200,
        chat_context_length=2048,  # adjust based on your local LLM params
    )

    # Alternatively, if you've used ooba or other lib to spin up a Local LLM
    # at an OpenAI-compatible endpoint, say http://localhost:8000, you can set the
    # `chat_model` as follows (note you have to prefix it with 'local'):
    # llm_config = lm.OpenAIGPTConfig(
    #     chat_model="local/localhost:8000"
    # )
    # If the endpoint is listening at https://localhost:8000/v1, you must include the `v1`
    # at the end, e.g. chat_model="local/localhost:8000/v1"

    agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        system_message="""Be helpful but very very concise""",
    )

    agent = lr.ChatAgent(agent_config)

    task = lr.Task(agent)

    task.run()


if __name__ == "__main__":
    Fire(main)

>>>> examples/basic/chat-persist.py
"""
Variant of chat.py, showing how you can save conversation state, end the script, and
resume the conversation later by re-running the script.

The most basic chatbot example, using the default settings.
A single Agent allows you to chat with a pre-trained Language Model.

Run like this:

python3 examples/basic/chat.py

Use optional arguments to change the settings, e.g.:

-m <local_model_spec>
-ns # no streaming
-d # debug mode
-nc # no cache
-sm <system_message>
-q <initial user msg>

For details on running with local or non-OpenAI models, see:
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

import typer
import pickle
from rich import print
from rich.prompt import Prompt
from dotenv import load_dotenv
from pathlib import Path
import logging


import langroid.language_models as lm
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.utils.configuration import set_global, Settings

STATE_CACHE_DIR = ".cache/agent-state"

app = typer.Typer()
logger = logging.getLogger(__name__)
# set the logging level to INFO
logger.setLevel(logging.INFO)
# Create classes for non-OpenAI model configs


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    query: str = typer.Option("", "--query", "-q", help="initial user query or msg"),
    sys_msg: str = typer.Option(
        "You are a helpful assistant. Be concise in your answers.",
        "--sysmsg",
        "-sm",
        help="system message",
    ),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
        )
    )
    print(
        """
        [blue]Welcome to the basic chatbot!
        Enter x or q to quit at any point.
        """
    )

    load_dotenv()

    # use the appropriate config instance depending on model name
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=4096,
        timeout=45,
    )

    # check if history.pkl exists under STATE_CACHE_DIR, and if it does, load it
    # into agent.message_history
    hist_path = Path(STATE_CACHE_DIR) / "history.pkl"
    hist_found = False
    try:
        if hist_path.exists():
            # read the history from the cache
            with open(str(hist_path), "rb") as f:
                msg_history = pickle.load(f)
            n_msgs = len(msg_history)
            logger.info(f"Loaded {n_msgs} messages from cache")
            hist_found = True
        else:
            sys_msg = Prompt.ask(
                "[blue]Tell me who I am. Hit Enter for default, or type your own\n",
                default=sys_msg,
            )

    except Exception:
        logger.warning("Failed to load message history from cache")
        pass

    config = ChatAgentConfig(
        system_message=sys_msg,
        llm=llm_config,
    )
    agent = ChatAgent(config)

    if hist_found:
        # overrides sys_msg set in config
        agent.message_history = msg_history

    # use restart=False so the state is not cleared out at start,
    # which allows continuing the conversation.
    task = Task(agent, restart=False)
    # OpenAI models are ok with just a system msg,
    # but in some scenarios, other (e.g. llama) models
    # seem to do better when kicked off with a sys msg and a user msg.
    # In those cases we may want to do task.run("hello") instead.
    if query:
        task.run(query)
    else:
        task.run()

    # Create STATE_CACHE_DIR if it doesn't exist
    Path(STATE_CACHE_DIR).mkdir(parents=True, exist_ok=True)
    # Save the conversation state to hist_path
    with open(str(hist_path), "wb") as f:
        pickle.dump(agent.message_history, f)
    logger.info(f"Saved {len(agent.message_history)} messages to cache")


if __name__ == "__main__":
    app()

>>>> examples/basic/chat-search-assistant-local.py
"""
Version of chat-search-assistant.py that uses local LLMs.
Tested and works ok nous-hermes2-mixtral, but still has issues.

3-Agent system where:
- Assistant takes user's (complex) question, breaks it down into smaller pieces
    if needed
- Searcher takes Assistant's question, uses the Search tool to search the web
    (using DuckDuckGo), and returns a coherent answer to the Assistant.
- Critic takes Assistant's final answer, and provides feedback on it.

Once the Assistant thinks it has enough info to answer the user's question, it
says DONE and presents the answer to the user.

See also: chat-search for a basic single-agent search

python3 examples/basic/chat-search-assistant.py

There are optional args, especially note these:

-m <model_name>: to run with a different LLM model (default: gpt4-turbo)

For example try this question:

during which years did Beethoven live, and does his life overlap with that of Liszt?

You can specify a local in a few different ways, e.g. `-m local/localhost:8000/v1`
or `-m ollama/mistral` etc. See here how to use Langroid with local LLMs:
https://langroid.github.io/langroid/tutorials/local-llm-setup/


"""

from typing import List, Optional, Type

import typer
from dotenv import load_dotenv
from rich import print
from rich.prompt import Prompt

import langroid as lr
import langroid.language_models as lm
from langroid import ChatDocument
from langroid.agent.tools.duckduckgo_search_tool import DuckduckgoSearchTool
from langroid.utils.configuration import Settings, set_global

app = typer.Typer()


class QuestionTool(lr.ToolMessage):
    request: str = "question_tool"
    purpose: str = "Ask a SINGLE <question> that can be answered from a web search."
    question: str

    @classmethod
    def examples(cls) -> List[lr.ToolMessage]:
        return [
            cls(question="Which superconductor material was discovered in 2023?"),
            cls(question="What AI innovation did Meta achieve in 2024?"),
        ]


class FinalAnswerTool(lr.ToolMessage):
    request: str = "final_answer_tool"
    purpose: str = """
        Present the intermediate <steps> and 
        final <answer> to the user's original query.
        """
    steps: str
    answer: str

    @classmethod
    def examples(cls) -> List["lr.ToolMessage"]:
        return [
            cls(
                steps="1. Man is mortal. 2. Plato was a man.",
                answer="Plato was mortal.",
            ),
            cls(
                steps="1. The moon landing was in 1969. 2. Kennedy was president "
                "during 1969.",
                answer="Kennedy was president during the moon landing.",
            ),
        ]


class FeedbackTool(lr.ToolMessage):
    request: str = "feedback_tool"
    purpose: str = "Provide <feedback> on the user's answer."
    feedback: str

    @classmethod
    def examples(cls) -> List["lr.ToolMessage"]:
        return [
            cls(feedback=""),
            cls(
                feedback="""
                The answer is invalid because the conclusion does not follow from the
                steps. Please check your reasoning and try again.
                """
            ),
        ]


class AssistantAgent(lr.ChatAgent):
    n_questions: int = 0  # how many questions in THIS round
    has_asked: bool = False  # has ANY question been asked
    original_query: str | None = None

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.USER:
            # either first query from user, or returned result from Searcher
            self.n_questions = 0  # reset search count

        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            if self.has_asked:
                return f"""
                You may have intended to use a tool, but your JSON format may be wrong.
                
                REMINDER: You must do one of the following:
                - If you are ready with the final answer to the user's ORIGINAL QUERY
                    [ Remember it was: {self.original_query} ],
                  then present your reasoning steps and final answer using the 
                  `final_answer_tool` in the specified JSON format.
                - If you still need to ask a question, then use the `question_tool`
                  to ask a SINGLE question that can be answered from a web search.
                """
            elif self.original_query is not None:
                return f"""
                You must ask a question using the `question_tool` in the specified format,
                to break down the user's original query: {self.original_query} into 
                smaller questions that can be answered from a web search.
                """

    def question_tool(self, msg: QuestionTool) -> str:
        self.n_questions += 1
        self.has_asked = True
        if self.n_questions > 1:
            # there was already a search, so ignore this one
            return ""
        # valid question tool: re-create it so Searcher gets it
        return msg.to_json()

    def final_answer_tool(self, msg: FinalAnswerTool) -> str:
        if not self.has_asked or self.n_questions > 1:
            # not yet asked any questions, or LLM is currently asking
            # a question (and this is the second one in this turn, and so should
            # be ignored), ==>
            # cannot present final answer yet (LLM may have hallucinated this json)
            return ""
        # valid final answer tool: PASS it on so Critic gets it
        return lr.utils.constants.PASS_TO + "Critic"

    def feedback_tool(self, msg: FeedbackTool) -> str:
        if msg.feedback == "":
            return lr.utils.constants.DONE
        else:
            return f"""
            Below is feedback about your answer. Take it into account to 
            improve your answer, and present it again using the `final_answer_tool`.
            
            FEEDBACK:
            
            {msg.feedback}
            """

    def llm_response(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        if self.original_query is None:
            self.original_query = (
                message if isinstance(message, str) else message.content
            )
        result = super().llm_response(message)
        if result is None:
            return result
        # result.content may contain a premature DONE
        # (because weak LLMs tend to repeat their instructions)
        # We deem a DONE to be accidental if no search query results were received
        if not isinstance(message, ChatDocument) or not (
            message.metadata.sender_name == "Searcher"
        ):
            # no search results received yet, so should NOT say DONE
            if isinstance(result, str):
                return result.content.replace(lr.utils.constants.DONE, "")
            result.content = result.content.replace(lr.utils.constants.DONE, "")
            return result

        return result


class CriticAgent(lr.ChatAgent):
    def final_answer_tool(self, msg: FinalAnswerTool) -> str:
        # received from Assistant. Extract the components as plain text,
        # so that the Critic LLM can provide feedback
        return f"""
        The user has presented the following intermediate steps and final answer
        shown below. Please provide feedback using the `feedback_tool`.
        Remember to set the `feedback` field to an empty string if the answer is valid,
        otherwise give specific feedback on what the issues are and how the answer 
        can be improved.
        
        STEPS: {msg.steps}
        
        ANSWER: {msg.answer}
        """

    def feedback_tool(self, msg: FeedbackTool) -> str:
        # say DONE and PASS to the feedback goes back to Assistant to handle
        return lr.utils.constants.DONE + " " + lr.utils.constants.PASS


class SearcherAgentConfig(lr.ChatAgentConfig):
    search_tool_class: Type[lr.ToolMessage]


class SearcherAgent(lr.ChatAgent):
    n_searches: int = 0
    curr_query: str | None = None

    def __init__(self, config: SearcherAgentConfig):
        super().__init__(config)
        self.config: SearcherAgentConfig = config
        self.enable_message(config.search_tool_class)
        self.enable_message(QuestionTool, use=False, handle=True)

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if (
            isinstance(msg, ChatDocument)
            and msg.metadata.sender == lr.Entity.LLM
            and self.n_searches == 0
        ):
            search_tool_name = self.config.search_tool_class.default_value("request")
            return f"""
            You forgot to use the web search tool to answer the 
            user's question : {self.curr_query}.
            REMEMBER - you must ONLY answer the user's questions based on 
             results from a web-search, and you MUST NOT ANSWER them yourself.
             
            Please use the `{search_tool_name}` tool 
            using the specified JSON format, then compose your answer.
            """

    def question_tool(self, msg: QuestionTool) -> str:
        self.curr_query = msg.question
        search_tool_name = self.config.search_tool_class.default_value("request")
        return f"""
        User asked this question: {msg.question}.
        Perform a web search using the `{search_tool_name}` tool
        using the specified JSON format, to find the answer.
        """

    def llm_response(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        if (
            isinstance(message, ChatDocument)
            and message.metadata.sender == lr.Entity.AGENT
            and self.n_searches > 0
        ):
            # must be search results from the web search tool,
            # so let the LLM compose a response based on the search results
            self.n_searches = 0  # reset search count

            result = super().llm_response_forget(message)
            # Augment the LLM's composed answer with a helpful nudge
            # back to the Assistant
            result.content = f"""
            Here are the web-search results for the question: {self.curr_query}.
            ===
            {result.content}
            ===
            Decide if you want to ask any further questions, for the 
            user's original question.             
            """
            self.curr_query = None
            return result

        # Handling query from user (or other agent)
        result = super().llm_response_forget(message)
        if result is None:
            return result
        tools = self.get_tool_messages(result)
        if all(not isinstance(t, self.config.search_tool_class) for t in tools):
            # LLM did not use search tool;
            # Replace its response with a placeholder message
            # and the agent fallback_handler will remind the LLM
            result.content = "Did not use web-search tool."
            return result

        self.n_searches += 1
        # result includes a search tool, but may contain DONE in content,
        # so remove that
        result.content = result.content.replace(lr.utils.constants.DONE, "")
        return result


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    print(
        """
        [blue]Welcome to the Web Search Assistant chatbot!
        I will try to answer your complex questions. 
        
        Enter x or q to quit at any point.
        """
    )
    load_dotenv()

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,
        temperature=0.2,
        max_output_tokens=500,
        timeout=45,
    )

    assistant_config = lr.ChatAgentConfig(
        system_message="""
        You are a resourceful assistant, able to think step by step to answer
        complex questions from the user. You must break down complex questions into
        simpler questions that can be answered by a web search. You must ask me 
        (the user) each question ONE BY ONE, using the `question_tool` in
         the specified format, and I will do a web search and send you
        a brief answer. Once you have enough information to answer my original
        (complex) question, you MUST present your INTERMEDIATE STEPS and FINAL ANSWER
        using the `final_answer_tool` in the specified JSON format.
        You will then receive FEEDBACK from the Critic, and if needed
        you should try to improve your answer based on this feedback.
        """,
        llm=llm_config,
        vecdb=None,
    )
    assistant_agent = AssistantAgent(assistant_config)
    assistant_agent.enable_message(QuestionTool)
    assistant_agent.enable_message(FinalAnswerTool)
    assistant_agent.enable_message(FeedbackTool, use=False, handle=True)

    search_tool_handler_method = DuckduckgoSearchTool.default_value("request")

    search_agent_config = SearcherAgentConfig(
        search_tool_class=DuckduckgoSearchTool,
        llm=llm_config,
        vecdb=None,
        system_message=f"""
        You are a web-searcher. For ANY question you get, you must use the
        `{search_tool_handler_method}` tool/function-call to get up to 5 results.
        Once you receive the results, you must compose a CONCISE answer 
        based on the search results and say DONE and show the answer to me,
        along with references, in this format:
        DONE [... your CONCISE answer here ...]
        SOURCES: [links from the web-search that you used]
        
        EXTREMELY IMPORTANT: DO NOT MAKE UP ANSWERS, ONLY use the web-search results.
        """,
    )
    search_agent = SearcherAgent(search_agent_config)

    assistant_task = lr.Task(
        assistant_agent,
        name="Assistant",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )
    search_task = lr.Task(
        search_agent,
        name="Searcher",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )

    critic_agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        vecdb=None,
        system_message="""
        You excel at logical reasoning and combining pieces of information.
        The user will send you a summary of the intermediate steps and final answer.
        You must examine these and provide feedback to the user, using the 
        `feedback_tool`, as follows:
        - If you think the answer is valid, 
            simply set the `feedback` field to an empty string "".
        - Otherwise set the `feedback` field to a reason why the answer is invalid,
            and suggest how the user can improve the answer.
        """,
    )
    critic_agent = CriticAgent(critic_agent_config)
    critic_agent.enable_message(FeedbackTool)
    critic_agent.enable_message(FinalAnswerTool, use=False, handle=True)
    critic_task = lr.Task(
        critic_agent,
        name="Critic",
        interactive=False,
    )
    assistant_task.add_sub_task([search_task, critic_task])
    question = Prompt.ask("What do you want to know?")
    assistant_task.run(question)


if __name__ == "__main__":
    app()

>>>> examples/basic/chat-search-assistant.py
"""
2-Agent system where:
- Assistant takes user's (complex) question, breaks it down into smaller pieces
    if needed
- WebSearcher takes Assistant's question, uses the Search tool to search the web
    (default DuckDuckGo, or Google or Metaphor as specified by user), and returns a
    coherent answer to the Assistant.

Once the Assistant thinks it has enough info to answer the user's question, it
says DONE and presents the answer to the user.

See also: chat-search for a basic single-agent search

python3 examples/basic/chat-search-assistant.py

There are optional args, especially note these:

-p or --provider: google or ddg or metaphor (default: google)
-m <model_name>: to run with a different LLM model (default: gpt4-turbo)

You can specify a local in a few different ways, e.g. `-m local/localhost:8000/v1`
or `-m ollama/mistral` etc. See here how to use Langroid with local LLMs:
https://langroid.github.io/langroid/tutorials/local-llm-setup/


NOTE:
(a) If using Google Search, you must have GOOGLE_API_KEY and GOOGLE_CSE_ID
environment variables in your `.env` file, as explained in the
[README](https://github.com/langroid/langroid#gear-installation-and-setup).

(b) If using MetaphorSearchTool, you need to:
* set the METAPHOR_API_KEY environment variables in
your `.env` file, e.g. `METAPHOR_API_KEY=your_api_key_here`
* install langroid with the `metaphor` extra, e.g.
`pip install langroid[metaphor]` or `uv pip install langroid[metaphor]`
`poetry add langroid[metaphor]` or `uv add langroid[metaphor]`
(it installs the `metaphor-python` package from pypi).
For more information, please refer to the official docs:
https://metaphor.systems/

"""

import typer
from dotenv import load_dotenv
from rich import print
from rich.prompt import Prompt

import langroid as lr
import langroid.language_models as lm
from langroid.agent.tools.google_search_tool import GoogleSearchTool
from langroid.agent.tools.duckduckgo_search_tool import DuckduckgoSearchTool
from langroid.utils.configuration import Settings, set_global
from langroid.utils.constants import DONE

app = typer.Typer()


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    provider: str = typer.Option(
        "ddg",
        "--provider",
        "-p",
        help="search provider name (google, metaphor, ddg)",
    ),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    print(
        """
        [blue]Welcome to the Web Search Assistant chatbot!
        I will try to answer your complex questions. 
        
        Enter x or q to quit at any point.
        """
    )
    load_dotenv()

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=8_000,
        temperature=0,
        max_output_tokens=200,
        timeout=45,
    )

    assistant_config = lr.ChatAgentConfig(
        system_message=f"""
        You are a resourceful assistant, able to think step by step to answer
        complex questions from the user. You must break down complex questions into
        simpler questions that can be answered by a web search. You must ask me 
        (the user) each question ONE BY ONE, and I will do a web search and send you
        a brief answer. Once you have enough information to answer my original
        (complex) question, you MUST say {DONE} and present the answer to me.
        """,
        llm=llm_config,
        vecdb=None,
    )
    assistant_agent = lr.ChatAgent(assistant_config)

    match provider:
        case "google":
            search_tool_class = GoogleSearchTool
        case "metaphor":
            from langroid.agent.tools.metaphor_search_tool import MetaphorSearchTool

            search_tool_class = MetaphorSearchTool
        case "ddg":
            search_tool_class = DuckduckgoSearchTool
        case _:
            raise ValueError(f"Unsupported provider {provider} specified.")

    search_tool_handler_method = search_tool_class.name()

    search_agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        vecdb=None,
        system_message=f"""
        You are a web-searcher. For any question you get, you must use the TOOL
        `{search_tool_handler_method}`  to get up to 5 results.
        I WILL SEND YOU THE RESULTS; DO NOT MAKE UP THE RESULTS!!
        Once you receive the results, you must compose a CONCISE answer 
        based on the search results and say {DONE} and show the answer to me,
        in this format:
        {DONE} [... your CONCISE answer here ...]
        IMPORTANT:
        * YOU MUST WAIT FOR ME TO SEND YOU THE SEARCH RESULTS BEFORE saying  {DONE}.
        * YOU Can only use the TOOL `{search_tool_handler_method}` 
            ONE AT A TIME, even if you get multiple questions!
        """,
    )
    search_agent = lr.ChatAgent(search_agent_config)
    search_agent.enable_message(search_tool_class)

    assistant_task = lr.Task(
        assistant_agent,
        name="Assistant",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )
    search_task = lr.Task(
        search_agent,
        name="Searcher",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )
    assistant_task.add_sub_task(search_task)
    question = Prompt.ask("What do you want to know?")
    assistant_task.run(question)


if __name__ == "__main__":
    app()

>>>> examples/basic/chat-search.py
"""
This is a basic example of a chatbot that uses one of these web-search Tools to
answer questions:
 - GoogleSearchTool
 - DuckduckgoSearchTool
 - ExaSearchTool
When the LLM doesn't know the answer to a question, it will use the tool to
search the web for relevant results, and then use the results to answer the
question.

Run like this:

    python3 examples/basic/chat-search.py

or

    uv run examples/basic/chat-search.py -m groq/deepseek-r1-distill-llama-70b

There are optional args, especially note these:

-p or --provider: google or ddg or Exa (default: google)
-m <model_name>: to run with a different LLM model (default: gpt4-turbo)

You can specify a local in a few different ways, e.g. `-m local/localhost:8000/v1`
or `-m ollama/mistral` etc. See here how to use Langroid with local LLMs:
https://langroid.github.io/langroid/tutorials/local-llm-setup/


NOTE:
(a) If using Google Search, you must have GOOGLE_API_KEY and GOOGLE_CSE_ID
environment variables in your `.env` file, as explained in the
[README](https://github.com/langroid/langroid#gear-installation-and-setup).


(b) If using ExaSearchTool, you need to:
* set the EXA_API_KEY environment variables in
your `.env` file, e.g. `EXA_API_KEY=your_api_key_here`
* install langroid with the `exa` extra, e.g.
`pip install langroid[exa]` or `uv pip install langroid[exa]`
or `poetry add langroid[exa]`  or `uv add langroid[exa]`
(it installs the `exa-py` package from pypi).
For more information, please refer to the official docs:
https://exa.ai/

"""

import typer
from dotenv import load_dotenv
from rich import print

import langroid as lr
import langroid.language_models as lm
from langroid.agent.tools.google_search_tool import GoogleSearchTool
from langroid.agent.tools.duckduckgo_search_tool import DuckduckgoSearchTool
from langroid.utils.configuration import Settings, set_global

app = typer.Typer()


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    provider: str = typer.Option(
        "ddg",
        "--provider",
        "-p",
        help="search provider name (google, ddg, exa)",
    ),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
        )
    )
    print(
        """
        [blue]Welcome to the Web Search chatbot!
        I will try to answer your questions, relying on (summaries of links from) 
        Web-Search when needed.
        
        Enter x or q to quit at any point.
        """
    )

    load_dotenv()

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=32_000,
        temperature=0.15,
        max_output_tokens=1000,
        timeout=45,
    )

    match provider:
        case "google":
            search_tool_class = GoogleSearchTool
        case "exa":
            from langroid.agent.tools.exa_search_tool import ExaSearchTool

            search_tool_class = ExaSearchTool
        case "ddg":
            search_tool_class = DuckduckgoSearchTool
        case _:
            raise ValueError(f"Unsupported provider {provider} specified.")

    search_tool_handler_method = search_tool_class.name()
    config = lr.ChatAgentConfig(
        name="Seeker",
        handle_llm_no_tool="user",  # fwd to user when LLM sends non-tool msg
        llm=llm_config,
        vecdb=None,
        system_message=f"""
        You are a helpful assistant. You will try your best to answer my questions.
        Here is how you should answer my questions:
        - IF my question is about a topic you ARE CERTAIN about, answer it directly
        - OTHERWISE, use the `{search_tool_handler_method}` tool/function-call to
          get up to 5 results from a web-search, to help you answer the question.
          I will show you the results from the web-search, and you can use those
          to answer the question.
        - If I EXPLICITLY ask you to search the web/internet, then use the 
            `{search_tool_handler_method}` tool/function-call to get up to 5 results
            from a web-search, to help you answer the question.


        In case you use the TOOL `{search_tool_handler_method}`, you MUST WAIT
        for results from this tool; do not make up results!
        
        Be very CONCISE in your answers, use no more than 1-2 sentences.
        When you answer based on a web search, First show me your answer, 
        and then show me the SOURCE(s) and EXTRACT(s) to justify your answer,
        in this format:
        
        <your answer here>
        SOURCE: https://www.wikihow.com/Be-a-Good-Assistant-Manager
        EXTRACT: Be a Good Assistant ... requires good leadership skills.
        
        SOURCE: ...
        EXTRACT: ...
        
        For the EXTRACT, ONLY show up to first 3 words, and last 3 words.
        DO NOT MAKE UP YOUR OWN SOURCES; ONLY USE SOURCES YOU FIND FROM A WEB SEARCH.
        """,
    )
    agent = lr.ChatAgent(config)

    agent.enable_message(search_tool_class)

    task = lr.Task(agent, interactive=False)

    # local models do not like the first message to be empty
    user_message = "Can you help me with some questions?"
    task.run(user_message)


if __name__ == "__main__":
    app()

>>>> examples/basic/chat-tool-function.py
"""
Bare bones example of using tool/function-call

Run like this, optionally specifying an LLM:

python3 examples/basic/chat-tool-function.py

or

python3 examples/basic/chat-tool-function.py -m ollama/mistral:7b-instruct-v0.2-q8_0

or 

uv run examples/basic/chat-tool-function.py -m deepseek/deepseek-reasoner

"""

import langroid as lr
import langroid.language_models as lm
from langroid.agent.tools.orchestration import FinalResultTool
from langroid.pydantic_v1 import BaseModel, Field
from fire import Fire

# define a nested structure for Company information


class CompanyFinancials(BaseModel):
    shares: int = Field(..., description="shares outstanding of company")
    price: float = Field(..., description="price per share of company")
    eps: float = Field(..., description="earnings per share of company")


class CompanyInfo(BaseModel):
    name: str = Field(..., description="name of company")
    industry: str = Field(..., description="industry of company")
    financials: CompanyFinancials = Field(..., description="financials of company")


# define a ToolMessage corresponding to the above structure


class CompanyInfoTool(lr.agent.ToolMessage):
    request: str = "company_info_tool"  # agent method that handles this tool
    purpose: str = (
        "To extract <company_info> from a passage and compute market-capitalization."
    )
    company_info: CompanyInfo

    @classmethod
    def examples(cls):
        """Examples that will be compiled to few-shot examples for the LLM.
        Illustrating two types of examples below:
        - example instance
        - (description, example) tuple
        """
        return [
            cls(
                company_info=CompanyInfo(
                    name="IBM",
                    industry="Technology",
                    financials=CompanyFinancials(shares=1.24e9, price=140.15, eps=4.68),
                )
            ),
            (
                "I want to extract and present company info from the passage",
                cls(
                    company_info=CompanyInfo(
                        name="Apple",
                        industry="Technology",
                        financials=CompanyFinancials(
                            shares=16.82e9, price=149.15, eps=5.68
                        ),
                    )
                ),
            ),
        ]

    def handle(self) -> FinalResultTool:
        """Handle LLM's structured output if it matches CompanyInfo structure.
        This suffices for a "stateless" tool.
        If the tool handling requires agent state, then
        instead of this `handle` method, define a `company_info_tool`
        method in the agent.
        """
        mkt_cap = (
            self.company_info.financials.shares * self.company_info.financials.price
        )
        print(
            f"""
            Got Valid Company Info.
            The market cap of {self.company_info.name} is ${mkt_cap/1e9}B.
            """
        )
        return FinalResultTool(
            market_cap=mkt_cap,
            info=self.company_info,
        )


def run(model: str = ""):  # or, e.g., "ollama/mistral:7b-instruct-v0.2-q8_0"
    lm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,  # or
    )
    tool_name = CompanyInfoTool.default_value("request")
    agent_config = lr.ChatAgentConfig(
        llm=lm_config,
        system_message=f"""
        You are a company-info extraction expert. When user gives you a TEXT PASSAGE,
        simply extract the company information and 
        present it using the `{tool_name}` tool/function-call.
        """,
    )
    agent = lr.ChatAgent(agent_config)
    agent.enable_message(CompanyInfoTool)

    # text to present to the LLM
    paragraph = """
        Apple Inc. is an American multinational technology company that specializes in 
        consumer electronics, computer software, and online services.
        It has shares outstanding of 16.82 billion, and a price per share of $149.15.
        The earnings per share is $5.68.
        """

    # test 1:
    # see that the LLM extracts the company information and presents it using the tool
    response = agent.llm_response(paragraph)

    print(response.content)

    # test 2:
    # wrap the agent in a Task, so that the ToolMessage is handled by the handle method
    task = lr.Task(agent, interactive=False)
    result = task[FinalResultTool].run(paragraph)
    assert result.market_cap > 0
    assert "Apple" in result.info.name


if __name__ == "__main__":
    Fire(run)

>>>> examples/basic/chat-tree-structured-simple.py
"""
Simple example showing tree-structured computation, 
a variation of `examples/basic/chat-tree.py` which uses strict output formatting
to reliably wrap calls to agents in standard Python functions, allowing
explicit control over control flow.

The task consists of performing this calculation for a given input number n:

def Main(n):
    if n is odd:
        return (3*n+1) + n
    else:
        If n is divisible by 10:
            return n/10 + n
        else:
            return n/2 + n

Each step is performed by an LLM call, and strict output formatting ensures that
a valid typed response is returned (rather than a string which requires another
LLM call to interpret).

We evaluate the conditions with a `condition_agent` which is given an integer and
a condition and return a Boolean and evaluate the transformations of `n` with
a `transformation_agent` which is given an integer and a transformation rule
and returns the transformed integer.

Finally, we add the result with the original `n` using an `adder_agent` which
illustrates strict output usage in `Task`s.

For more details on structured outputs, see the notes at
https://langroid.github.io/langroid/notes/structured-output/.
"""

import typer
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from rich.prompt import Prompt
from langroid.utils.constants import DONE
from langroid.utils.logging import setup_colored_logging
from langroid.utils.configuration import set_global, Settings

app = typer.Typer()

setup_colored_logging()


def chat() -> int:
    condition_agent = ChatAgent(
        ChatAgentConfig(
            system_message="""
            You will be provided with a condition and a
            number; your goal is to determine whether
            that number satisfies the condition.

            Respond in JSON format, with `value` set
            to the result.
            """,
            output_format=bool,
        )
    )
    transformation_agent = ChatAgent(
        ChatAgentConfig(
            system_message="""
            You will be provided with a number and an
            transformation of the number to perform.

            Respond in JSON format, with `value` set
            to the result.
            """,
            output_format=int,
        )
    )

    def check_condition(n: int, condition: str) -> bool:
        output = condition_agent.llm_response_forget(
            f"""
            Number: {n}
            Condition: {condition}
            """
        )
        return condition_agent.from_ChatDocument(output, bool)  # type: ignore

    def apply_transformation(n: int, transformation: str) -> int:
        output = transformation_agent.llm_response_forget(
            f"""
            Number: {n}
            Transformation: {transformation}
            """
        )
        return transformation_agent.from_ChatDocument(output, int)  # type: ignore

    num = int(Prompt.ask("Enter a number"))
    is_even = check_condition(num, "The number is even.")

    if is_even:
        is_divisible_by_10 = check_condition(num, "The number is divisible by 10.")

        if is_divisible_by_10:
            to_adder = apply_transformation(num, "n/10 where the number is n.")
        else:
            to_adder = apply_transformation(num, "n/2 where the number is n.")
    else:
        to_adder = apply_transformation(num, "3n+1 where the number is n.")

    class AddNumTool(ToolMessage):
        request = "add_num"
        purpose = "Add <number> to the original number, return the result"
        number: int

        def handle(self) -> str:
            total = num + self.number
            return f"{DONE} {total}"

    # We could also have the agent output a the call in a single step and handle
    # it ourselves (or apply it immediately)
    adder_agent = ChatAgent(
        ChatAgentConfig(
            system_message="""
            You will be given a number n.
            You have to add it to the original number and return the result.
            You do not know the original number, so you must use the 
            `add_num` tool/function for this. 
            """,
            output_format=AddNumTool,
        )
    )
    adder_agent.enable_message(AddNumTool)
    adder_task = Task(adder_agent, interactive=False, name="Adder")

    # compute the final output value
    return adder_task[int].run(str(to_adder))  # type: ignore


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
        )
    )
    chat()


if __name__ == "__main__":
    app()

>>>> examples/basic/chat-tree-structured.py
"""
Simple example showing tree-structured computation
where each node in the tree is handled by a separate agent.
A variation of `examples/basic/chat-tree.py` which uses strict output formatting
and agent logic to enforce the behavior specified in the prompts.

See the use of `set_output_format()` in ConditionalAgent.

The task consists of performing this calculation for a given input number n:

def Main(n):
    if n is odd:
        return (3*n+1) + n
    else:
        If n is divisible by 10:
            return n/10 + n
        else:
            return n/2 + n

To make this "interesting", we represent this computation hierarchically,
in the form of this tree:

Main
- Odd
    - Adder
- Even
    - EvenZ
        - Adder
    - EvenNZ
        - Adder

For a full write-up on the design considerations, see the documentation page on
Hiearchical Agent Computations at https://langroid.github.io/langroid/examples/agent-tree/

For more details on structured outputs, see the notes at
https://langroid.github.io/langroid/notes/structured-output/.
"""

import typer
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.chat_document import ChatDocument
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from rich.prompt import Prompt
from langroid.agent.tools.orchestration import AgentDoneTool
from langroid.utils.constants import DONE
from langroid.utils.logging import setup_colored_logging
from langroid.utils.configuration import set_global, Settings
from langroid.utils.globals import GlobalState

app = typer.Typer()

setup_colored_logging()


class MyGlobalState(GlobalState):
    number: int | None = None


class AskNumTool(ToolMessage):
    request = "ask_num"
    purpose = "Ask user for the initial number"

    def handle(self) -> str:
        """
        This is a stateless tool (i.e. does not use any Agent member vars), so we can
        define the handler right here, instead of defining an `ask_num`
        method in the agent.
        """
        num = int(Prompt.ask("Enter a number"))
        # record this in global state, so other agents can access it
        MyGlobalState.set_values(number=num)
        return str(num)


class AddNumTool(ToolMessage):
    request = "add_num"
    purpose = "Add <number> to the original number, return the result"
    number: int

    def handle(self) -> AgentDoneTool:
        """
        This is a stateless tool (i.e. does not use any Agent member vars), so we can
        define the handler right here, instead of defining an `add_num`
        method in the agent.
        """
        total = MyGlobalState.get_value("number") + self.number
        return AgentDoneTool(
            tools=[ResultTool(result=total)],
        )


class MatchTool(ToolMessage):
    request: str = "match"
    purpose: str = "To express whether the input number matches your condition."
    matches: bool


class ResultTool(ToolMessage):
    request: str = "result"
    purpose: str = (
        "To express the result of your transformation applied to the input number."
    )
    result: int


class ConditionalAgentConfig(ChatAgentConfig):
    top_level: bool = False


class ConditionalAgent(ChatAgent):
    def __init__(self, config: ConditionalAgentConfig = ConditionalAgentConfig()):
        super().__init__(config)
        self.config: ConditionalAgentConfig = config  # type: ignore
        # Should the next request be treated as self-generated?
        self.generated_request: bool = False

        if self.config.top_level:
            # We always begin by requesting a number from the user
            self.set_output_format(AskNumTool)
            self.enable_message(AskNumTool)
            self.enable_message(ResultTool, handle=True, use=False)
        else:
            self.enable_message([MatchTool, ResultTool])
            # We always begin by checking whether the number matches the agent's condiditon
            self.set_output_format(MatchTool)

    def ask_num(self, msg: AskNumTool) -> str:
        self.set_output_format(None)
        return msg.handle()

    def match(self, msg: MatchTool) -> str:
        if not msg.matches:
            return DONE

        # The agent must next return the transformed number
        self.set_output_format(ResultTool)
        self.generated_request = True
        return "Now, return the input number, after applying your transformation."

    def result(self, msg: ResultTool) -> str | ChatDocument | AgentDoneTool:
        if self.config.top_level:
            self.set_output_format(AskNumTool)
            # Return the answer if we are the top-level task
            return f"{DONE} {msg.result}"
        elif self.generated_request:
            self.generated_request = False
            return self.create_llm_response(
                content=str(msg.result),
            )
        else:
            self.set_output_format(MatchTool)

        # Propogate the result up if we are done
        return AgentDoneTool(
            tools=[msg],
        )


def chat() -> None:
    main_task = Task(
        ConditionalAgent(
            ConditionalAgentConfig(
                top_level=True,
            )
        ),
        interactive=False,
        name="Main",
        system_message="""
        You will ask the user for a number with the `ask_num` tool; you should respond with exactly that number,
        say nothing else.
        """,
    )

    prompt_format = """
        You will receive a number; you should first check whether that number
        matches your condition.

        Condition: {condition}

        If so, you should respond with a transformed version of the number:

        Transformation: {transformation}
        """

    even_task = Task(
        ConditionalAgent(),
        interactive=False,
        name="Even",
        system_message=prompt_format.format(
            condition="The number is even.",
            transformation="Nothing, return the number you were provided.",
        ),
    )
    evenz_task = Task(
        ConditionalAgent(),
        interactive=False,
        name="EvenZ",
        system_message=prompt_format.format(
            condition="The number is divisible by 10.",
            transformation="Return n/10 where n is the provided number.",
        ),
    )
    even_nz_task = Task(
        ConditionalAgent(),
        interactive=False,
        name="EvenNZ",
        system_message=prompt_format.format(
            condition="The number is not divisible by 10.",
            transformation="Return n/2 where n is the provided number.",
        ),
    )
    odd_task = Task(
        ConditionalAgent(),
        interactive=False,
        name="Odd",
        system_message=prompt_format.format(
            condition="The number is odd.",
            transformation="Return n*3 + 1",
        ),
    )

    adder_agent = ChatAgent()
    adder_agent.enable_message(AddNumTool)
    adder_task = Task(
        # ensure that the agent calls the tool:
        # agent[T] is a copy of agent which always outputs values of type T
        adder_agent[AddNumTool],
        name="Adder",
        interactive=False,
        system_message="""
        You will be given a number n.
        You have to add it to the original number and return the result.
        You do not know the original number, so you must use the 
        `add_num` tool/function for this. 
        """,
    )

    # set up tasks and subtasks
    main_task.add_sub_task([even_task, odd_task])
    even_task.add_sub_task([evenz_task, even_nz_task])
    evenz_task.add_sub_task(adder_task)
    even_nz_task.add_sub_task(adder_task)
    odd_task.add_sub_task(adder_task)

    # start the chat
    main_task.run()


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
        )
    )
    chat()


if __name__ == "__main__":
    app()

>>>> examples/basic/chat-tree.py
"""
Simple example showing tree-structured computation
where each node in the tree is handled by a separate agent.

This task consists of performing this calculation for a given input number n:

def Main(n):
    if n is odd:
        return (3*n+1) + n
    else:
        If n is divisible by 10:
            return n/10 + n
        else:
            return n/2 + n

To make this "interesting", we represent this computation hierarchically,
in the form of this tree:

Main
- Odd
    - Adder
- Even
    - EvenZ
        - Adder
    - EvenNZ
        - Adder

For a full write-up on the design considerations, see the documentation page on
Hiearchical Agent Computations at https://langroid.github.io/langroid/examples/agent-tree/
"""

import typer

from rich.prompt import Prompt
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from langroid.language_models.openai_gpt import OpenAIChatModel, OpenAIGPTConfig
from langroid.utils.globals import GlobalState
from langroid.utils.configuration import set_global, Settings
from langroid.utils.logging import setup_colored_logging
from langroid.utils.constants import DONE

app = typer.Typer()

setup_colored_logging()


class MyGlobalState(GlobalState):
    number: int | None = None


class AskNumTool(ToolMessage):
    request = "ask_num"
    purpose = "Ask user for the initial number"

    def handle(self) -> str:
        """
        This is a stateless tool (i.e. does not use any Agent member vars), so we can
        define the handler right here, instead of defining an `ask_num`
        method in the agent.
        """
        num = Prompt.ask("Enter a number")
        # record this in global state, so other agents can access it
        MyGlobalState.set_values(number=num)
        return str(num)


class AddNumTool(ToolMessage):
    request = "add_num"
    purpose = "Add <number> to the original number, return the result"
    number: int

    def handle(self) -> str:
        """
        This is a stateless tool (i.e. does not use any Agent member vars), so we can
        define the handler right here, instead of defining an `add_num`
        method in the agent.
        """
        return str(int(MyGlobalState.get_value("number")) + int(self.number))


def chat(model: str = "") -> None:
    config = ChatAgentConfig(
        llm=OpenAIGPTConfig(
            chat_model=model or OpenAIChatModel.GPT4o,
        ),
        vecdb=None,
    )

    main_agent = ChatAgent(config)
    main_task = Task(
        main_agent,
        name="Main",
        interactive=False,
        system_message="""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        In this case simply write the <number>, say nothing else.
        
        RESULT Message format: RESULT <number>
        In this case simply say "DONE <number>", e.g.:
        DONE 19

        To start off, ask the user for the initial number, 
        using the `ask_num` tool/function.
        """,
    )

    # Handles only even numbers
    even_agent = ChatAgent(config)
    even_task = Task(
        even_agent,
        name="Even",
        interactive=False,
        system_message=f"""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        - if the <number> is odd, say '{DONE}'
        - otherwise, simply write the <number>, say nothing else.
        
        RESULT Message format: RESULT <number>
        In this case simply write "DONE RESULT <number>", e.g.:
        DONE RESULT 19
        """,
    )

    # handles only even numbers ending in Zero
    evenz_agent = ChatAgent(config)
    evenz_task = Task(
        evenz_agent,
        name="EvenZ",
        interactive=False,
        system_message=f"""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        - if <number> n is even AND divisible by 10, compute n/10 and pass it on,
        - otherwise, say '{DONE}'
        
        RESULT Message format: RESULT <number>
        In this case simply write "DONE RESULT <number>", e.g.:
        DONE RESULT 19
        """,
    )

    # Handles only even numbers NOT ending in Zero
    even_nz_agent = ChatAgent(config)
    even_nz_task = Task(
        even_nz_agent,
        name="EvenNZ",
        interactive=False,
        system_message=f"""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        - if <number> n is even AND NOT divisible by 10, compute n/2 and pass it on,
        - otherwise, say '{DONE}'
        
        RESULT Message format: RESULT <number>
        In this case simply write "DONE RESULT <number>", e.g.:
        DONE RESULT 19
        """,
    )

    # Handles only odd numbers
    odd_agent = ChatAgent(config)
    odd_task = Task(
        odd_agent,
        name="Odd",
        interactive=False,
        system_message=f"""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        - if <number> n is odd, compute n*3+1 and write it.
        - otherwise, say '{DONE}'

        RESULT Message format: RESULT <number>        
        In this case simply write "DONE RESULT <number>", e.g.:
        DONE RESULT 19
        """,
    )

    adder_agent = ChatAgent(config)
    adder_task = Task(
        adder_agent,
        name="Adder",
        interactive=False,
        system_message="""
        You will be given a number n.
        You have to add it to the original number and return the result.
        You do not know the original number, so you must use the 
        `add_num` tool/function for this. 
        When you receive the result, say "DONE RESULT <result>", e.g.
        DONE RESULT 19
        """,
    )

    # set up tasks and subtasks
    main_task.add_sub_task([even_task, odd_task])
    even_task.add_sub_task([evenz_task, even_nz_task])
    evenz_task.add_sub_task(adder_task)
    even_nz_task.add_sub_task(adder_task)
    odd_task.add_sub_task(adder_task)

    # set up the tools
    main_agent.enable_message(AskNumTool)
    adder_agent.enable_message(AddNumTool)

    # start the chat
    main_task.run()


@app.command()
def main(
    model: str = typer.Option("", "--model", "-m", help="model to use"),
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
        )
    )
    chat(model)


if __name__ == "__main__":
    app()

>>>> examples/basic/chat.py
# script
# requires-python = ">=3.11"
# dependencies = [
#     "langroid",
# ]
# ///
"""
The most basic chatbot example, using the default settings.
A single Agent allows you to chat with a pre-trained Language Model.

Run like this:

python3 examples/basic/chat.py

Use optional arguments to change the settings, e.g.:

-m <local_model_spec>
-ns # no streaming
-d # debug mode
-nc # no cache
-sm <system_message>
-q <initial user msg>

For details on running with local or non-OpenAI models, see:
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

import typer
from rich import print
from rich.prompt import Prompt
from dotenv import load_dotenv

import langroid.language_models as lm
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.utils.configuration import set_global, Settings


app = typer.Typer()

# Create classes for non-OpenAI model configs


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    sys_msg: str = typer.Option(
        "You are a helpful assistant. Be concise in your answers.",
        "--sysmsg",
        "-sm",
        help="system message",
    ),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
        )
    )
    print(
        """
        [blue]Welcome to the basic chatbot!
        Enter x or q to quit at any point.
        """
    )

    load_dotenv()

    # use the appropriate config instance depending on model name
    # NOTE: when using Azure, change this to `lm.AzureConfig`
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=4096,
        timeout=45,
    )

    sys_msg = Prompt.ask(
        "[blue]Tell me who I am. Hit Enter for default, or type your own\n",
        default=sys_msg,
    )

    config = ChatAgentConfig(
        system_message=sys_msg,
        llm=llm_config,
    )
    agent = ChatAgent(config)
    task = Task(agent)
    task.run("hello")


if __name__ == "__main__":
    app()

>>>> examples/basic/completion.py
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "langroid",
# ]
# ///
"""
Interact with a base completion model, specifically the original GPT-3 base model
(i.e. davinci-002 or babbage-002),
one that has not been instruct-tuned for chat-like conversation.
This uses the legacy OpenAI Completion API.
This API simply takes pure text (NOT dialog) , and returns the LLM's completion.
Note there is no notion of system message here.

Run like this:

python3 examples/basic/completion.py

Use optional arguments to change the settings, e.g.:

-m <local_model_spec>
-ns # no streaming
-d # debug mode
-nc # no cache


For details on running with local or non-OpenAI models, see:
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

import typer
from rich import print
from rich.prompt import Prompt
from dotenv import load_dotenv

import langroid.language_models as lm
from langroid.utils.configuration import set_global, Settings


app = typer.Typer()


def multiline_input(prompt_text):
    lines = []
    while True:
        line = Prompt.ask(prompt_text)
        if not line:
            break
        lines.append(line)
    return "\n".join(lines)


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
        )
    )
    print(
        """
        [blue]Welcome to the basic completion engine.
        Text you enter will be completed by an LLM 
        (Default is a GPT3-class LLM, davinci-002). 
        You can enter multi-line inputs; Enter return TWICE to send your message.
        Enter x or q to quit at any point.
        """
    )

    load_dotenv()

    # use the appropriate config instance depending on model name
    llm_config = lm.OpenAIGPTConfig(
        completion_model=model or "davinci-002",  # or "babbage-002"
        chat_context_length=4096,
        timeout=45,
        use_chat_for_completion=False,
    )
    llm = lm.OpenAIGPT(llm_config)

    print()
    while True:
        print("\n")
        user_msg = multiline_input("[blue]You[/blue]")
        if user_msg.lower() in ["q", "x"]:
            break
        print("\nBot: ")
        response = llm.generate(prompt=user_msg, max_tokens=50)

        if response.cached:
            print(f"[red](Cached)[/red] [green] {response.message}[/green]")


if __name__ == "__main__":
    app()

>>>> examples/basic/concurrent-tasks.py
"""
Toy example showing how to combine results from multiple tasks running concurrently.

- main agent/task uses `multi_task_tool` tool to specify what to send to tasks t2, t3
- t2, t3 are run concurrently
- results from t2, t3 are combined and returned to main agent/task
- main agent/task then uses the combined results to generate a final response
"""

import langroid as lr
import langroid.language_models as lm
from langroid.agent.tools.orchestration import AgentDoneTool
from langroid.utils.globals import GlobalState
from langroid.agent.batch import run_batch_task_gen
from typing import Dict
from rich.prompt import Prompt
from fire import Fire

CITY_AGENT_NAME = "CityAgent"
NAME_AGENT_NAME = "NameAgent"


class MyGlobalState(GlobalState):
    name_task_map: Dict[str, str] = {}


class MultiTaskTool(lr.ToolMessage):
    request: str = "multi_task_tool"
    purpose: str = """
        Specify messages to send to multiple agents, via <agent_msgs>
        which is a dict mapping agent names to messages.
    """
    agent_msgs: Dict[str, str]

    def handle(self) -> AgentDoneTool:
        inputs = list(self.agent_msgs.values())
        agent_names = list(self.agent_msgs.keys())
        name_task_map = MyGlobalState.get_value("name_task_map")
        tasks = [name_task_map[name] for name in agent_names]

        def result2content_fn(chat_doc: lr.ChatDocument) -> str:
            return chat_doc.content

        def task_gen(i: int):  # task generator
            return tasks[i]

        results = run_batch_task_gen(task_gen, inputs, output_map=result2content_fn)
        output = "\n".join(
            f"{agent_names[i]}: {result}" for i, result in enumerate(results)
        )
        return AgentDoneTool(content=output)


def chat(model: str = "") -> None:

    cities_agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            name=CITY_AGENT_NAME,
            llm=lm.OpenAIGPTConfig(
                chat_model=model or lm.OpenAIChatModel.GPT4o,
            ),
            system_message="""
            You'll receive a sentence. 
            Simply show the the list of cities in the sentence if any,
            as a comma-separated list, say nothing else.
            If no cities are found, say "NO CITIES".
            """,
        )
    )

    names_agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            name=NAME_AGENT_NAME,
            llm=lm.OpenAIGPTConfig(
                chat_model=model or lm.OpenAIChatModel.GPT4o,
            ),
            system_message="""
            You'll receive a sentence. 
            Simply show the the list of names in the sentence if any,
            as a comma-separated list, say nothing else.
            If no names are found, say "NO NAMES".
            """,
        )
    )

    cities_task = lr.Task(cities_agent, interactive=False, single_round=True)
    names_task = lr.Task(names_agent, interactive=False, single_round=True)

    MyGlobalState.set_values(
        name_task_map={CITY_AGENT_NAME: cities_task, NAME_AGENT_NAME: names_task}
    )

    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            name="MainAgent",
            llm=lm.OpenAIGPTConfig(
                chat_model=model or lm.OpenAIChatModel.GPT4o,
            ),
            system_message=f"""
            You'll receive a sentence. Your end-goal is to get the 
            list of cities and names mentioned in the sentence,
            BUT YOU DO NOT KNOW HOW TO EXTRACT THEM;
            you'll receive the help of {CITY_AGENT_NAME} and {NAME_AGENT_NAME} for this.
            You must use the TOOL `{MultiTaskTool.name()}` to send the sentence 
            to them.
            Once you receive the consolidated results,
            say "DONE" and show the list of cities and names.
            """,
        )
    )

    agent.enable_message(MultiTaskTool)

    task = lr.Task(agent, interactive=False, single_round=False)

    sentence = Prompt.ask(
        "Enter a sentence, to extract cities and names from",
        default="Satoshi will meet Alice in New York and Bob in London",
    )

    result = task.run(sentence)

    print(
        f"""
        [bold]Final Result:[/bold]
        {result}
        """
    )


if __name__ == "__main__":
    Fire(chat)

>>>> examples/basic/drug-outcomes.py
"""
ADE (Adverse Drug Event) probability estimation task:

Given a pair of (Drug Category, Adverse Event), have the LLM generate an estimate
of the probability that the drug category is associated with an increased risk
of the adverse event.

Run this N times (without caching) to get statistics on the estimates.
Illustrates the use of `llm_response_batch`.

Default model is GPT4o, see how to specify alternative models below.

Example run:

python3 examples/basic/ drug-outcomes.py \
    --model litellm/claude-3-5-sonnet-20240620 --temp 0.1 \
    --pair "(Antibiotics, Acute Liver Injury)" --n 20 --reason true

Interesting models to try:
- gpt-4o (default)
- gpt-4
- litellm/claude-3-5-sonnet-20240620
- groq/llama3-70b-8192

See reference below for specific (DrugCategory, ADE) pairs to test.

References:
    - Guides to using Langroid with local and non-OpenAI models:
        https://langroid.github.io/langroid/tutorials/local-llm-setup/
        https://langroid.github.io/langroid/tutorials/non-openai-llms/
    - OMOP Ground Truth table of known Drug-ADE associations:
        (see page 16 for the table of Drug-ADE pairs)
        https://www.brookings.edu/wp-content/uploads/2012/04/OMOP-methods-review.pdf
"""

import langroid as lr
import langroid.language_models as lm
from langroid.utils.configuration import settings
import numpy as np
import re
from fire import Fire

# Turn off cache retrieval, to get independent estimates on each run
settings.cache = False

MODEL = lm.OpenAIChatModel.GPT4o
TEMP = 0.1
PAIR = "(Antibiotics, Acute Liver Injury)"
N = 20
# should LLM include reasoning along with probability?
# (meant to test whether including reasoning along with the probability
# improves accuracy and/or variance of estimates)
REASON: bool = False


def extract_num(x: str) -> int:
    """
    Extracts an integer from a string that contains a number.

    Args:
        x (str): The input string containing the number.

    Returns:
        int: The extracted integer.

    Raises:
        ValueError: If no number is found in the expected format.
    """
    match = re.search(r"\d+", x)
    if match:
        return int(match.group(0))
    else:
        return -1


def main(
    model: str = MODEL,
    temp: float = TEMP,
    pair: str = PAIR,
    n: int = N,
    reason: bool = REASON,
):
    REASONING_PROMPT = (
        """
            IMPORTANT: Before showing your estimated probability, 
            you MUST show 2-3 sentences with your REASONING, and THEN give your 
            percent probability estimate in the range [0,100].
    """
        if reason
        else ""
    )

    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            llm=lm.OpenAIGPTConfig(
                temperature=temp,
                chat_model=model,
            ),
            name="ADE-Estimator",
            system_message=f"""
            You are a clinician with deep knowledge of Adverse Drug Events (ADEs) 
            of various drugs and categories of drugs.
            You will be given a (DRUG CATEGORY, ADVERSE OUTCOME) pair,
            you have to estimate the probability that this DRUG CATEGORY
            is associated with INCREASED RISK of the ADVERSE OUTCOME. 
    
            {REASONING_PROMPT}
                
            You must give your probability estimate as a SINGLE NUMBER e.g. 56, 
            which means 56%.             
            DO NOT GIVE A RANGE OF PROBABILITIES, ONLY A SINGLE NUMBER. 
            """,
        )
    )

    results = lr.llm_response_batch(
        agent,
        [pair] * n,
        # ["(Beta Blockers, Mortality after Myocardial Infarction)"]*20,
    )
    probs = [extract_num(r.content) for r in results]
    cached = [r.metadata.cached for r in results]
    n_cached = sum(cached)
    # eliminate negatives (due to errs)
    probs = [p for p in probs if p >= 0]
    mean = np.mean(probs)
    std = np.std(probs)
    std_err = std / np.sqrt(len(probs))
    hi = max(probs)
    lo = min(probs)
    print(f"Stats for {pair} with {model} temp {temp} reason {reason}:")
    print(
        f"N: {len(probs)} ({n_cached} cached ) Mean: {mean:.2f}, Std: {std:.2f}, StdErr:"
        f" {std_err:.2f}, min: {lo:.2f}, max: {hi:.2f}"
    )
    toks, cost = agent.llm.tot_tokens_cost()
    print(f"Tokens: {toks}, Cost: {cost:.2f}")


if __name__ == "__main__":
    Fire(main)

>>>> examples/basic/example_free_text.txt
Time Restrictions origin data
" M 9-11am, F 8:30-10am, 10:30-12pm"
 weekdays 9a-3p at Kiddie Academy
" at Daycare M,W,TH, F 8:30am to 4:30pm"
 weekdays 1-4pm
 weekdays 9am-4pm at TT's Toy Box Daycare
 weekly 9:00am to 11:00am  at TT's Toy Box Daycare
" Home 4-6p on weekdays. Or Daycare T,W,Th 9-11:30 at the Seton Center 15234. Baldwin Whitehall SD."
" M, T, F anytime, W morning"
" M, W 9am to 11am is preferred, possibly TH afternoons if needed. Requests bilingual (Spanish) therapist"
 weekday mornings
 Mondays Between 1:00pm to 5:00pm
 weekdays 10a-11p
 weekly 9a-12p
" Home weekdays 10am-6pm, daycare T, W, Th 8:30am-3:30pm. Junita Collins Daycare 15136"
" any day, any time. Feeding / Sensory Concerns. She only eating purees and not using words to communicate pgh SD ."
" M, or F between 9-11a, or 3-4p. Growing Minds Daycare 15102."
" any day, any time. Feeding / Sensory Concerns. She only eating purees and not using words to communicate pgh SD ."
" M,T from 9a-11a at Daycare. Hart to Hart 15136"
" weekly 9a-11a, or after 3p"
" W,Th,F can be flexible. Mom would like first couple sessions at the childcare and the rest at home. The Childcare is also 15143. "
" M,T,W,Th 9a-11a. Woodland Hills SD. "
 weekly 8:30a-11a or 3-4p. Childcare Center 15239. Plum SD .
 M 8a-11:30a or 3p-4p. Or T 8a to 11;30a or Th 3-4p. Services at Daycare Love and Learn Brinton Road 15211 Woodland Hills SD .
 Wednesdays 10a-5p. Wilkinsburg SD. 
 weekly 12-2p. Or 4-6p. Left Head Side Preference. West Jefferson SD . 
" M 11a-1p, or after 5p of F 11a to 12p or after 5p. PT Session is on Friday at 12p. West Jefferson SD."
" weekly 9a-11a, or after 3p"
 weekly 10a-12p or 2p to 5p at Daycare.  Cassies Cradle 15210. Steel Valley SD. Family would like to try zoom 1x a month and f2f 1x a month. 
" Home weekdays 10am-6pm, daycare T, W, Th 8:30am-3:30pm. Junita Collins Daycare 15136"
" M,T,W, mornings 9a or 10a is best. Pgh SD. "
 weekly 1:00pm to 5:00pm
 weekly All Day
 weekly 12pm to 6pm. Female therapist
" M,W,F 8:30am to 10am or 12pm to 2pm or after 4pm"
 weekly 12pm to 6pm. Female therapist
 weekly 10am to 12pm or 3:30pm to 5:00pm at Heritage 4 Kids Learning Center
 weekly 9:00am to 12:00pm
 weekly 8am to 12pm at Beth Shalom
 weekly 9:00am to 12:00pm
 weekly after 12p
 weekly 9:00am to 12:00pm
 weekly from 10:00am to 2:00pm
 weekly from 10:00am to 2:00pm
 weekly from 10:00am to 2:00pm
 weekly 1:00pm to 5:00pm
 weekly 10am to 12pm or 3:30pm to 5:00pm at Heritage 4 Kids Learning Center
 M 8a-11:30a or 3p-4p. Or T 8a to 11;30a or Th 3-4p. Services at Daycare Love and Learn Brinton Road 15221 Woodland Hills SD .
" M,T,W,Th 9a-11a. Woodland Hills SD. "
 Wednesdays 10a-5p. Wilkinsburg SD. 
" prefers Daycare TH,F 8:30am to 11:00am or Home weekly 4:30pm to 6:30pm. Little Kids Playcare, 508 N Lewis Run Rd 15025"
Family is  Tuesday through Friday 10-12 or 2:30 & later.
 weekly from 9:30am to 3:00pm
" M,T,TH,F from 10:30am to 11:30am"
Family is  weekdays before 9am. Feeding concerns
Family is  Tuesday through Friday 10-12 or 2:30 & later.
 weekly from 9:30am to 3:00pm
" W,F after 3:30pm"
 weekly from 9:30am to 3:00pm
Family is  Wed 1-5 or Thurs after 2pm
" T,W 12:30pm to 1:30pm or M,T,W,TH,F 5pm to 6pm"
Family is  weekdays 10-3
"Splt svcs between home & childcare. Home is  Fri 2-5, Childcare  weekdays 9-11:30, 3pm-4:30pm. Learning Loft 15219"
 Friday Mornings 7am to 10am
" Wed 11-12 at home, Thurs 1pm at Family Friend's Home (15214). Alt locations"
" Wed 11-12 at home, Thurs 1pm at Family Friend's Home (15214). Alt locations"
"family is  T,Th , F after 1p"
" M,W,TH,F anytime around 2:30pm and later if on zoom."
 weekly 10am to 12pm or 3:30pm to 5:00pm at Heritage 4 Kids Learning Center
 weekly 9a-11a
 weekly 9a-11a
"Splt svcs between home & childcare. Home is  Fri 2-5, Childcare  weekdays 9-11:30, 3pm-4:30pm. Learning Loft 15219"
" M,T,W,Th 9a-11a. Woodland Hills SD. "
 M 8a-11:30a or 3p-4p. Or T 8a to 11;30a or Th 3-4p. Services at Daycare Love and Learn Brinton Road 15221 Woodland Hills SD .
 Wednesdays 10a-5p. Wilkinsburg SD. 
Family is  Wed 1-5 or Thurs after 2pm
"Splt svcs between home & childcare. Home is  Fri 2-5, Childcare  weekdays 9-11:30, 3pm-4:30pm. Learning Loft 15219"
" at Daycare M,W,F mornings, Little Explorers Learning Academy 2005 Sarah St PGH 15203"
" T,W,TH,F 11:00am to 1:00pm"
" W,F after 3:30pm"
" prefers Daycare TH,F 8:30am to 11:00am or Home weekly 4:30pm to 6:30pm. Little Kids Playcare, 508 N Lewis Run Rd 15025"
Family is  weekdays 10-3
 home F 10a-5p. Services for PT will be at home.
" M,T,W,TH 10a-3p. Therapist comfortable w/ medically complex child."
 weekly 3p or later. Pgh SD. 
" M,T,W<TH 10a-3p. Therapist comfortable w/ medically complex child."
 weekly 9:30a-2p. Penn Hills SD. 
" M,T,W,Th at Daycare 9a-4p, or at home F 10a-5p. TenderCare Learning Center 15205. Services will be held for OT at home and Daycare. "
 Tuesdays 9:30-11:30a. Bethel Park SD .
" M,W anytime during the day. Kiddo is not walking 19mo"
" M,F 8a-11a or W 8a-10a at Daycare. KidBiz in McMurray 15317. Sessions at daycare during school year and home in the summer"
 weekly 1a - 12p or 2p-5p. Pgh SD. 
" M,W after 11:30a or Friday anytime. North Agh SD. "
" M,T,W,TH 10a-3p. Therapist comfortable w/ medically complex child."
" M,W after 11:30a or Friday anytime. North Agh SD. "
" M,W after 11:30a or Friday anytime. North Agh SD. "
"Splt svcs between home & childcare. Home is  Fri 2-5, Childcare  weekdays 9-11:30, 3pm-4:30pm. Learning Loft 15219"
" Wed 11-12 at home, Thurs 1pm at Family Friend's Home (15214). Alt locations"
" M,W at noon or after. "
 weekly 9a-11a
 weekly 9a-11a
"Splt svcs between home & childcare. Home is  Fri 2-5, Childcare  weekdays 9-11:30, 3pm-4:30pm. Learning Loft 15219"
 weekly 10am to 12pm or 3:30pm to 5:00pm at Heritage 4 Kids Learning Center
"family is  T,Th , F after 1p"
" M,T,W,Th 9a-11a. Woodland Hills SD. "
 M 8a-11:30a or 3p-4p. Or T 8a to 11;30a or Th 3-4p. Services at Daycare Love and Learn Brinton Road 15221 Woodland Hills SD .
 Wednesdays 10a-5p. Wilkinsburg SD. 
"Splt svcs between home & childcare. Home is  Fri 2-5, Childcare  weekdays 9-11:30, 3pm-4:30pm. Learning Loft 15219"
" T,W,TH,F 11:00am to 1:00pm"
" prefers Daycare TH,F 8:30am to 11:00am or Home weekly 4:30pm to 6:30pm. Little Kids Playcare, 508 N Lewis Run Rd 15025"
" M,T,W,TH after 3pm and Fridays 10am or after 12:30pm"
 weekly anytime
 weekly between 8:30am and 11:00am ending by 11am
 weekly between 8am to 9am or after3pm is the best
" W 10am to 11:30 or after 12:30pm, TH 10am to 12pm or after 1:30"
 weekly 9:00am to 2:00pm
 weekly 1p or later
 weekly 1p or later
 weekly 1p or later
 weekly 1p or later
" Friday Afternoon, All Day Wed and Mon. morning the best"
" M,W at noon or after. "
" weekly from 8a-5p at Child's Way 5324 PennAve, 15224"
" M,T,TH,F 9am to 11am or W 10am to 11am. Alliance Christian Childcare 15132"
 weekly 11a or after
" W,TH mornings between 7am to 10am Ending by 11am"
 weekly 9a-11a
 weekly 9:00am to 2:00pm
 weekly 9:00am to 2:00pm
"family is  T,Th , F after 1p"
 weekly 10am to 12pm or 3:30pm to 5:00pm at Heritage 4 Kids Learning Center
 weekly 9a-11a
"Splt svcs between home & childcare. Home is  Fri 2-5, Childcare  weekdays 9-11:30, 3pm-4:30pm. Learning Loft 15219"
" T,W,Th,F 12:00pm or later"
" T,W,TH 9am to 12pm or 3pm to 5pm at Caring Castle 15236"
" M,T,W 9:30a-3p"
" T,W,TH,F 11:00am to 1:00pm"
" prefers Daycare TH,F 8:30am to 11:00am or Home weekly 4:30pm to 6:30pm. Little Kids Playcare, 508 N Lewis Run Rd 15025"
"Flexible with ability M,T,TH,F NO Wednesdays"
" weekly 8a-12p at childcare  610 Chartiers Ave, 15136"
" home weekly after 3p or at daycare weekly 9a-2p. Juanita Collins daycare 15136. Initial session at home, all others at daycare"
" weekly 8:30am to 12pm or 3pm to 4:30pm, Edu Care Children's Academy, 15136"
" weekly 8:30am to 12pm or 3pm to 4:30pm, Edu Care Children's Academy, 15136"
" weekly 8:30am to 12pm or 3pm to 4:30pm, Edu Care Children's Academy, 15136"
" T,F anytime"
 any day/time but prefers morning. Plum SD. 
 8:30a-10a or 11-12p. North Agh SD. 
" T,TH,F 11a. North Hills S."
 weekly 8a-4p. Hearth House 15116. Shaler SD. 
  Yeshiva School 15217. OT for Lunch at 12:30! 
 9a start to be done by 12p. Pgh SD. 
 M 5p or Th 10a-1p. Mom prefers female therapists. Shaler SD.
" 9a-12p weekly and T,TH after 4p. Home Address is Baldwin , services take place at Dads in Mt.Oliver 15210"
 weekly 10a-1p or 4p or later. Gateway SD
"Flexible with ability M,T,TH,F NO Wednesdays"
. First session at home and then sessions at daycare 316 George St. Turtle Creek 15145
" M,W,F after 2p. Mt.Lebo SD. "
" M,T after 12p or W all day or All Day Friday "
" T,TH,F 11a. North Hills S."
 11a-1p weekly
 Th at 3p. Duquesne F2F and Tele
" T,W,Th,F 12-5p. Cherrly Lane 15132 is grandma's house. Services will be at home or grandma's. the times are same for both houses."
" Friday Afternoon, All Day Wed and Mon. morning the best"
 3-6p weekdays
 M 5p or Th 10a-1p. Mom prefers female therapists. Shaler SD.
" M,W at noon or after. "
 W 11:30a-6p. Pgh SD. 
" M,T,TH,F 9-11am or W 10am- 11 Alliance Christian  15132"
 weekly 11a or after
 weekly 9a-11a
 weekly 10a-3p. Pgh SD. 
" T 8:30a-11a, or F 8:30a-4p. Gateway SD. "
 9a or 10a or 3p or 4p. Childcare is in Oakmont. Riverview SD.
 weekly 9:00am to 2:00pm
"family is  T,Th , F after 1p"
 weekly 10am to 12pm or 3:30pm to 5:00pm at Heritage 4 Kids Learning Center
 weekly 9a-11a
"Splt svcs between home & childcare. Home is  Fri 2-5, Childcare  weekdays 9-11:30, 3pm-4:30pm. Learning Loft 15219"
" T,W,TH 9am to 12pm or 3pm to 5pm at Caring Castle 15236"
" M,W 8:30a-12p. MckEesport SD."
 3-6p weekdays
" M,T,W,F 9:30a-3p"
 11a-1p weekly
" T,W,TH,F 11:00am to 1:00pm"
" prefers Daycare TH,F 8:30am to 11:00am or Home weekly 4:30pm to 6:30pm. Little Kids Playcare, 508 N Lewis Run Rd 15025"
" home weekly after 3p or at daycare weekly 9a-2p. Juanita Collins daycare 15136. Initial session at home, all others at daycare"
 9a-4p weekdays . Sto Rox SD. 
" Home T, F AT 8am, 4-6pm, Childcare M,T,Th,F 8-10am, 2-4pm. Kiddie Academy North, 111 Josephs Ln, 15237. first 2 sessions at home, rest at childcare"
" M, T, Th8-9am, 12-2pm"
" M 9a-1p, T anytime"
 T 8-10am
 F 1-4pm
" weekdays 10a-1, 3:30-6p"
 weekly 9am to 12pm or after 3pm
 weekly 9am to 12pm or after 3pm
 any day before 1 and after 3pm
 weekly 11am to 12pm or 1:30pm to 3pm
" weekdays 10a-1, 3:30-6p"
" M, T 1:30-6pm"
 weekdays 12pm and later
 weekdays 12pm and later
 weekly 9am to 12pm or after 3pm
" W, F 8:30am-2:30pm"
" T, Th 10am-2pm"
" T, Th 10am-2pm"
" M, T, W, F 11am-1pm"
" T, Th 8:30am-6, M, W 11:30am-6pm"
" weekdays 9am-12, 3-6pm"
" weekdays 9am-12, 3-6pm"
 W 3-5pm
" 8am-5pm Home Some F; Daycare M, W some F; Grandma T some F. Kindercare 15090 and Grandma 15202"
" M,T,TH,F 9-11am or W 10am- 11 Alliance Christian  15132"
" T, Th 8:30am-6, M, W 11:30am-6pm"
 weekly 9:00am to 2:00pm
" T,W,TH 9am to 12pm or 3pm to 5pm at Caring Castle 15236"
" M,W at noon or after. "
" T, W, Th 5-6pm"
 3-6p weekdays
" M, T 1:30-6pm"
 Fridays 3pm or later
 11a-1p weekly
" M,T,W,F 9:30a-3p"
" M,W 8:30a-12p. MckEesport SD."
" home weekly after 3p or at daycare weekly 9a-2p. Juanita Collins daycare 15136. Initial session at home, all others at daycare"
" M, W after 12pm"
 9a-4p weekdays . Sto Rox SD. 
" M, W after 12pm"
Family is  Weekdays 8-10 or 12-4.
Family is  Thurs or Fri 8-10 or 1-3
Daycare  weekdays before 12:30 or after 2:45.
Family is  weekdays 10-6
Family is  Thurs or Fri 8-10 or 1-3
At home & childcare.  Daycare: weekdays before 11:30a or after 2p. Home: M & F 3-6p.  A+ Childcare 15210. Has lunch at 11a if OT wants to go then
At home & childcare.  Daycare: weekdays before 11:30a or after 2p. Home: M & F 3-6p.  A+ Childcare 15210. Has lunch at 11a if OT wants to go then
 3-6p weekdays
Family is  Thursdays any time after 1pm.. F2F and TELE
"Family is  Mon & Wed at noon or later (Cedric M, has Nicole S for OT)"
Daycare  weekdays before 12:30 or after 2:45. Home  weekdays 4:45 or later.. Alt daycare/home
Family is  weekdays at 5pm
" M,T,TH,F 9-11am or W 10am- 11 Alliance Christian  15132"
"Family is  at home weekdays 10am-2pm, Daycare Mon or Tues 10am. Daycare 15120 Homestead"
Daycare  Tues &Wed 8am-11am. Katie Cares 
 weekly 9:00am to 2:00pm
"Daycare: M,T,Th,F 12-2p. Home: weekdays 4-6. Sonshine Quality Childcare, 15221. Prefers female therapist"
" T,W,TH 9am to 12pm or 3pm to 5pm at Caring Castle 15236"
"Daycare  weekdays 8-11 or 2-4, home weekdays at 5pm. Seton Ctr Whitehall 15234"
Family is  weekdays 8-11am or 2:30pm & after.
At home & childcare.  Daycare: weekdays before 11:30a or after 2p. Home: M & F 3-6p.  A+ Childcare 15210. Has lunch at 11a if OT wants to go then
" M, T 1:30-6pm"
 11a-1p weekly
" M,T,W,F 9:30a-3p"
 Fridays 3pm or later
" M,W 8:30a-12p. MckEesport SD."
" home weekly after 3p or at daycare weekly 9a-2p. Juanita Collins daycare 15136. Initial session at home, all others at daycare"
" M, W after 12pm"
 9a-4p weekdays . Sto Rox SD. 
Family is  Thurs 9-11am
" M 9-10am, 12-4pm, T, W, Th, F 8-10am, 12-4pm"
" weekdays Home 2-6pm, daycare 8am-4pm. Daycare starts 2/1/24. A Place to Grow 15238"
" M, F 9-11am, T, Th 1-3pm"
" M, T, Th, F 9am-12:30pm"
" M, W, F 8:30am-5pm, T 10am-5pm"
" M, W, Th, F after 11am"
" weekdays Home 2-6pm, daycare 8am-4pm. Daycare starts 2/1/24. A Place to Grow 15238"
" M, W, F 8:30am-5pm, T 10am-5pm"
" Home weekdays 5-6pm, grandparent's M, W, F 12-4, T, Th 9-4. Grandparent's in 15216"
" T, W, Th 2:30pm and later"
" M, W, Th, F 1pm and later"
" M, T, Th, F 9am-12:30pm"
" M 8am-12pm, T 3-4, F after 10am"
"Alt. home & grandpa's.  weekdays Home after 5:30pm, grandpa's anytime (15206)"
" M, W, F 2p-4p . F2F and TELE"
" M, W, F 8:30am-5pm, T 10am-5pm"
" M, W, F 8:30am-5pm, T 10am-5pm"
 Monday or Friday mornings at Grandma House 245 Kinvara Dr PGH PA 15237
" M, W, F mornings"
Family is  weekdays at 5pm
" M, T, Th, F 12-2pm, weekdays 4-7pm. Family can do back to back weeks, if possible. "
Daycare  Tues &Wed 8am-11am. Katie Cares 
"Family is  at home weekdays 10am-2pm, Daycare Mon or Tues 10am. Daycare 15120 Homestead"
"Daycare  weekdays before 12:30 or after 2:45, Home weekdays starting at 4:45 or later."
"Daycare  weekdays 8-11 or 2-4, home weekdays at 5pm. Seton Ctr Whitehall 15234"
" M, T 1:30-6pm"
" M,W 8:30a-12p. MckEesport SD."
 11a-1p weekly
Family is  weekdays 8-11am or 2:30pm & after.
" weekdays 9-11am, 1-4pm at Noah's Ark Christian Academy 15122. May want svcs at home in McKeesport in future"
 9a-4p weekdays . Sto Rox SD. 
Family is  Thurs 9-11am
" M 8am-12pm, T 3-4, F after 10am"
" M, W, F 6:30am-3:30pm"
 on Mondays 8:00am to 9:30am
" M,W,Th,F 10a-12p. 3-6p."
" M,W,Th 9a-12p. Weekdays 2p and later. North Hills SD "
 weekdays 11a-6p. West Mifflin SD. 
" M,T,W 9a-2p. Pine Richland SD. "
" M,W,Th,F 10a-12p. 3-6p."
" Th, F 11a-1p, 4-6p. Mckeesport SD. "
 M mornings and T afternoons. Upper St.Clair SD. 
" Home flexible, daycare T,W,F 8a-12p. Brightside Academy McKeesport 15132. Service 1x a month home in Woodland Hills SD and all others at daycare "
" M,T,W 9a-2p. Pine Richland SD. "

>>>> examples/basic/fn-call-local-numerical.py
"""
Function-calling example using a local LLM, with ollama.

"Function-calling" refers to the ability of the LLM to generate
a structured response, typically a JSON object, instead of a plain text response,
which is then interpreted by your code to perform some action.
This is also referred to in various scenarios as "Tools", "Actions" or "Plugins".
See more here: https://langroid.github.io/langroid/quick-start/chat-agent-tool/

This script is designed to have a basic ChatAgent (powered by an Open-LLM)
engage in a multi-round conversation where the user may occasionally
ask for the "Polinsky transform" of a number, which requires the LLM to
use a `Polinsky` tool/function-call. This is a fictitious transform,
that simply does n => 3n + 1.
We intentionally use a fictitious transform rather than something like "square"
or "double" to prevent the LLM from trying to answer the question directly.

The challenging part here is getting the LLM to decide on an appropriate response
to a few different types of user messages:
- user asks a general question -> LLM should answer the question directly
- user asks for the Polinsky transform of a number -> LLM should use the Polinsky tool
- result from applying Polinsky transform -> LLM should present this to the user
- user (tool-handler) says there was a format error in using the Polinsky tool -> LLM
    should try this tool again

Many models quickly get confused in a multi-round conversation like this.
However (as of Sep 2024), `llama-3.1-70b` seems to do well here (we run this via groq).

Run like this --

python3 examples/basic/fn-call-local-numerical.py -m groq/llama-3.1-70b-versatile

or

python3 examples/basic/fn-call-local-numerical.py -m ollama/qwen2.5-coder:latest


(if the optional -m <model_name> is not provided, it defaults to GPT-4o).

See here for ways to set up a Local/Open LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

"""

import os
from typing import List, Optional
import fire

import langroid as lr
from langroid.language_models.openai_gpt import OpenAICallParams
from langroid.utils.configuration import settings
from langroid.agent.tool_message import ToolMessage
import langroid.language_models as lm
from langroid.agent.chat_document import ChatDocument
from langroid.agent.tools.orchestration import ForwardTool

DEFAULT_LLM = lm.OpenAIChatModel.GPT4o


os.environ["TOKENIZERS_PARALLELISM"] = "false"

# (1) Define the desired fn-call as a ToolMessage via Pydantic.


class PolinskyTool(lr.agent.ToolMessage):
    """A fictitious number transformation tool. We intentionally use
    a fictitious tool rather than something like "square" or "double"
    to prevent the LLM from trying to answer the question directly.
    """

    request: str = "polinsky"
    purpose: str = (
        """
        To respond to user request for the Polinsky transform of a <number>.
        NOTE: ONLY USE THIS TOOL AFTER THE USER ASKS FOR A POLINSKY TRANSFORM. 
        """
    )
    number: int

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        # Used to provide few-shot examples in the system prompt
        return [
            cls(
                number=19,
            ),
            cls(
                number=5,
            ),
        ]


class MyChatAgent(lr.ChatAgent):
    def init_state(self) -> None:
        self.tool_expected = False

    def polinsky(self, msg: PolinskyTool) -> str:
        """Handle LLM's structured output if it matches Polinsky tool"""
        self.tool_expected = False
        result = msg.number * 3 + 1
        response = f"""
        SUCCESS! The Polinksy transform of {msg.number} is {result}.
        Present this result to the user, and ask what they need help with.
        """
        return response

    def llm_response(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        self.tool_expected = True
        return super().llm_response(message)

    def user_response(
        self,
        msg: Optional[str | ChatDocument] = None,
    ) -> Optional[ChatDocument]:
        self.tool_expected = False
        return super().user_response(msg)

    def handle_message_fallback(self, msg: str | ChatDocument) -> ForwardTool:
        """
        We end up here when there was no recognized tool msg from the LLM;
        In this case forward the message to the user using ForwardTool.
        """
        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            return ForwardTool(agent="User")


def app(
    m: str = DEFAULT_LLM,  # model name
    d: bool = False,  # debug
    nc: bool = False,  # no cache
):
    settings.debug = d
    settings.cache = not nc
    # create LLM config
    llm_cfg = lm.OpenAIGPTConfig(
        chat_model=m or DEFAULT_LLM,
        chat_context_length=16_000,  # for dolphin-mixtral
        max_output_tokens=100,
        params=OpenAICallParams(
            presence_penalty=0.8,
            frequency_penalty=0.8,
        ),
        temperature=0,
        stream=True,
        timeout=100,
    )

    # Recommended: First test if basic chat works with this llm setup as below:
    # Once this works, then you can try the rest of the example.
    #
    # agent = lr.ChatAgent(
    #     lr.ChatAgentConfig(
    #         llm=llm_cfg,
    #     )
    # )
    #
    # agent.llm_response("What is 3 + 4?")
    #
    # task = lr.Task(agent)
    # verify you can interact with this in a chat loop on cmd line:
    # task.run("Concisely answer some questions")

    # Define a ChatAgentConfig and ChatAgent
    config = lr.ChatAgentConfig(
        llm=llm_cfg,
        system_message="""
        You are an expert at deciding when to call 
        specified functions with the right syntax.
        You are very very CONCISE in your responses.
        
        Here is how you must respond to my messages:
        
        1. When I ask a general question, simply respond as you see fit.
            Example: 
                ME(User): "What is 3 + 4?"
                YOU(Assistant): "the answer is 7"
                
        2. When I ask to find the Polinksy transform of a number, 
            you  must use the `polinsky` function/tool
            to request the Polinsky transform of that number.
            Example:
                ME(User): "What is the Polinsky transform of 5?"
                YOU(Assistant): <polinsky tool request in JSON format>
                 
        3. When you receive a SUCCESS message with the result from the `polinsky` 
            tool, you must present the result to me in a nice way (CONCISELY), 
            and ask: 'What else can I help with?'
            Example:
                ME(User): "SUCCESS! The Polinksy transform of 5 is 16"
                YOU(Assistant): "The polinsky transform of 5 is 16. What else can I help with?"
                ME(User): "The answer is 16. What is the Polinsky transform of 19?"
                YOU(Assistant): <polinsky tool request in JSON format>
        4. If you receive an error msg when using the `polinsky` function/tool,
           you must try the function/tool again with the same number.
              Example:
               ME(User): "There was an error in your use of the polinsky tool:..."
               YOU(Assistant): <polinsky tool request in JSON format>
        """,
    )

    agent = MyChatAgent(config)

    # (4) Enable the Tool for this agent --> this auto-inserts JSON instructions
    # and few-shot examples into the system message
    agent.enable_message(PolinskyTool)

    # (5) Create task and run it to start an interactive loop
    task = lr.Task(agent, interactive=False)
    task.run("Can you help me with some questions?")


if __name__ == "__main__":
    fire.Fire(app)

>>>> examples/basic/fn-call-local-simple.py
"""
Function-calling example using a local/remote open LLM.

"Function-calling" refers to the ability of the LLM to generate
a structured response, typically a JSON object, instead of a plain text response,
which is then interpreted by your code to perform some action.
This is also referred to in various scenarios as "Tools", "Actions" or "Plugins".
See more here: https://langroid.github.io/langroid/quick-start/chat-agent-tool/

Run like this (to run with llama-3.1-8b-instant via groq):

python3 examples/basic/fn-call-local-simple.py -m groq/llama-3.1-8b-instant

See here for how to set up a Local LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/


"""

import os
from typing import List
import fire

from langroid.pydantic_v1 import BaseModel, Field
import langroid as lr
from langroid.utils.configuration import settings
from langroid.agent.tool_message import ToolMessage
from langroid.agent.tools.orchestration import FinalResultTool
import langroid.language_models as lm
from rich.prompt import Prompt
from langroid.agent.chat_document import ChatDocument

# for best results:
DEFAULT_LLM = lm.OpenAIChatModel.GPT4o

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# (1) Define the desired structure via Pydantic.
# Here we define a nested structure for City information.
# The "Field" annotations are optional, and are included in the system message
# if provided, and help with generation accuracy.


class CityData(BaseModel):
    population: int = Field(..., description="population of city")
    country: str = Field(..., description="country of city")


class City(BaseModel):
    name: str = Field(..., description="name of city")
    details: CityData = Field(..., description="details of city")


# (2) Define the Tool class for the LLM to use, to produce the above structure.
class CityTool(lr.agent.ToolMessage):
    """Present information about a city"""

    request: str = "city_tool"
    purpose: str = """
    To present <city_info> AFTER user gives a city name,
    with all fields of the appropriate type filled out;
    """
    city_info: City = Field(..., description="information about a city")

    def handle(self) -> FinalResultTool:
        """Handle LLM's structured output if it matches City structure"""
        print("SUCCESS! Got Valid City Info")
        return FinalResultTool(answer=self.city_info)

    @staticmethod
    def handle_message_fallback(
        agent: lr.ChatAgent, msg: str | ChatDocument
    ) -> str | None:
        """
        We end up here when there was no recognized tool msg from the LLM;
        In this case use the AgentDoneTool with content set to
        the original message content.
        """
        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            return f"""
            You forgot to use the TOOL/Function `{CityTool.name()}`.
            Please use this tool to present the city info.
            """

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        # Used to provide few-shot examples in the system prompt
        return [
            cls(
                city_info=City(
                    name="San Francisco",
                    details=CityData(
                        population=800_000,
                        country="USA",
                    ),
                )
            )
        ]


def app(
    m: str = DEFAULT_LLM,  # model
    d: bool = False,  # pass -d to enable debug mode (see prompts etc)
    nc: bool = False,  # pass -nc to disable cache-retrieval (i.e. get fresh answers)
):
    settings.debug = d
    settings.cache = not nc
    # create LLM config
    llm_cfg = lm.OpenAIGPTConfig(
        chat_model=m or DEFAULT_LLM,
        chat_context_length=32000,  # set this based on model
        max_output_tokens=1000,
        temperature=0.2,
        stream=True,
        timeout=45,
    )

    # Recommended: First test if basic chat works with this llm setup as below:
    # Once this works, then you can try the rest of the example.
    #
    # agent = lr.ChatAgent(
    #     lr.ChatAgentConfig(
    #         llm=llm_cfg,
    #     )
    # )
    #
    # agent.llm_response("What is 3 + 4?")
    #
    # task = lr.Task(agent)
    # verify you can interact with this in a chat loop on cmd line:
    # task.run("Concisely answer some questions")

    # Define a ChatAgentConfig and ChatAgent

    config = lr.ChatAgentConfig(
        llm=llm_cfg,
        system_message=f"""
        You will receive a city name, 
        and you must use the TOOL/FUNCTION `{CityTool.name()}` to generate/present
        information about the city.
        """,
    )

    agent = lr.ChatAgent(config)

    # (4) Enable the Tool for this agent --> this auto-inserts JSON instructions
    # and few-shot examples (specified in the tool defn above) into the system message
    agent.enable_message(CityTool)

    # (5) Create task specialized to return City object
    task: City | None = lr.Task(agent, interactive=False)[City]

    while True:
        city = Prompt.ask("Enter a city name")
        if city in ["q", "x"]:
            break
        result: City | None = task.run(city)
        if result:
            print(f"City Info: {result}")
        else:
            print("No valid city info found.")


if __name__ == "__main__":
    fire.Fire(app)

>>>> examples/basic/intent-classifier.py
"""
Agent-loop to classify the intent of a given text.

Run like this (--model is optional, defaults to GPT4o):

python3 examples/basic/intent-classifier.py --model groq/llama-3.1-8b-instant

Other ways to specify the model:
- gpt-4 (set OPENAI_API_KEY in your env or .env file)
- gpt-4o (ditto, set OPENAI_API_KEY)
- cerebras/llama3.1-70b (set CEREBRAS_API_KEY)

For more ways to use langroid with other LLMs, see:
- local/open LLMs: https://langroid.github.io/langroid/tutorials/local-llm-setup/
- non-OpenAPI LLMs: https://langroid.github.io/langroid/tutorials/non-openai-llms/
"""

from typing import List, Tuple

import langroid as lr
from langroid.agent.tools.orchestration import ResultTool
import langroid.language_models as lm
from enum import Enum
from rich.prompt import Prompt
from fire import Fire


class Intent(str, Enum):
    GREETING = "greeting"
    FAREWELL = "farewell"
    QUESTION = "question"
    STATEMENT = "statement"


class IntentTool(lr.ToolMessage):
    request: str = "intent_tool"
    purpose: str = """
        To classify the <intent> of a given text, into one of:
        - greeting
        - farewell
        - question
        - statement
        """

    intent: Intent

    @classmethod
    def examples(cls) -> List[lr.ToolMessage | Tuple[str, lr.ToolMessage]]:
        """Use these as few-shot tool examples"""
        return [
            cls(intent=Intent.GREETING),
            ("I want to classify this as a question", cls(intent=Intent.QUESTION)),
        ]

    def handle(self) -> ResultTool:
        """Handle the tool sent by LLM"""

        # ResultTool ends the task
        return ResultTool(intent=self.intent)

    def handle_message_fallback(self, message: lr.ChatDocument) -> str | None:
        """We end up here if the LLM did not send a Tool, so nudge it"""
        if (
            isinstance(message, lr.ChatDocument)
            and message.metadata.sender == lr.Entity.LLM
        ):
            return """
            You forgot to use the `intent_tool` to classify the intent.
            """


def main(model: str = ""):
    intent_tool_name = IntentTool.default_value("request")
    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            name="Intent",
            llm=lm.OpenAIGPTConfig(chat_model=model or lm.OpenAIChatModel.GPT4o),
            use_functions_api=False,  # suppress OpenAI functions/tools
            use_tools=True,  # use langroid-native tools: works with ANY LLM
            system_message=f"""
            You are an astute INTENT CLASSIFIER: given any piece of text
            from the user, you are able to smartly infer their intent.
            Given such a piece of text, classify its intent into one of the following:
             - greeting
             - farewell
             - question
             - statement
            To present your classification, use the 
            `{intent_tool_name}` tool.
            
            ALWAYS use this tool to respond, do NOT say anything else.
            """,
        )
    )

    agent.enable_message(IntentTool)

    # create a task loop specialized to return an Intent
    task = lr.Task(agent=agent, interactive=False)[Intent]

    while True:
        text = Prompt.ask("Enter a text to classify its intent")
        intent = task.run(
            f"""
         Please classify the intent of this text, present your answer
         using the `{intent_tool_name}` tool:
         ----
         {text}
         ----
         """
        )

        print(f"Intent: {intent}")


if __name__ == "__main__":

    Fire(main)

>>>> examples/basic/multi-agent-medical.py
"""
Credit to @burcusayin for contributing this example.

Run like this:

    python3 examples/basic/multi-agent-medical.py

or
    uv run examples/basic/multi-agent-medical.py

A two-agent system to answer medical questions that require a binary yes/no answer,
along with a `long_answer` explanation. The agents consist of:

- Chief Physician (CP) agent who is in charge of the final binary decision
    and explanation.
- Physician Assistant (PA) agent who is consulted by the CP; The CP may ask a
  series of questions to the PA, and once the CP decides they have sufficient
  information, they will return their final decision using a structured tool message.

The system is run over 445 medical questions from this dataset:
https://huggingface.co/datasets/burcusayin/pubmedqa_binary_with_plausible_gpt4_long_answers

In each row of this dataset, there is a QUESTION, and a final_decision
which we use as reference to compare the system-generated final decision.
"""

import langroid as lr
import langroid.language_models as lm
import logging
from langroid.pydantic_v1 import BaseModel, Field
from langroid.utils.configuration import settings
from langroid.agent.tools.orchestration import ForwardTool, ResultTool
from langroid.agent.task import TaskConfig
import datasets
from rich.prompt import Prompt
import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
lr.utils.logging.setup_colored_logging()

# MODEL = lm.OpenAIChatModel.GPT4o
MODEL = "ollama/llama3:8b"

CP_NAME = "CP"
PA_NAME = "PA"


class ExpectedText(BaseModel):
    final_decision: str = Field(..., description="binary yes/no answer")
    long_answer: str = Field(..., description="explanation for the final decision")


class ExpectedTextTool(lr.ToolMessage):
    request: str = "expected_text_tool"
    purpose: str = """
    To write the final <expectedText> AFTER having a multi-turn discussion
    with the Assistant Agent, with all fields of the appropriate type filled out.
    """
    expectedText: ExpectedText

    def handle(self) -> ResultTool:
        """Handle LLM's structured output if it matches ExpectedText structure"""
        print("SUCCESS! Got Valid ExpectedText Info")

        return ResultTool(status="**DONE!**", expectedText=self.expectedText)

    @staticmethod
    def handle_message_fallback(
        agent: lr.ChatAgent, msg: str | lr.ChatDocument
    ) -> ForwardTool:
        """
        We end up here when there was no recognized tool msg from the LLM;
        In this case forward the message to the Assistant agent (PA) using ForwardTool.
        """
        if isinstance(msg, lr.ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            return ForwardTool(agent=PA_NAME)


# Define fixed system messages outside of the question-loop
# Pass each question as senior_task.run(question)

SENIOR_SYS_MSG = f"""You are Dr. X, the Chief Physician, collaborating with Dr. Y, your assistant.
                    Your task is to come up with concise answers to medical questions.
                    To make better decisions, when you receive a question, you should follow a TWO-PHASE procedure:

                    PHASE 1: Ask your assistant NATURAL LANGUAGE questions (NO TOOLS), which may span
                        MULTIPLE ROUNDS. ASK EXACTLY ONE QUESTION in each round. DO NOT ASK MULTIPLE QUESTIONS AT ONCE.
                        Avoid fabricating interactions or simulating dialogue with Dr. Y.
                        Instead, clearly articulate your questions or follow-ups, analyze Dr. Y's responses,
                        and use this information to guide your decision-making.
                    PHASE 2: Once you have gathered sufficient information, return your final decision
                        using the TOOL `{ExpectedTextTool.name()}`:
                        - `final_decision` should be your BINARY yes/no answer
                        - `long_answer` should provide a detailed explanation for your final decision.
                    DO NOT mention the TOOL to Dr. Y. It is your responsibility to write and submit the expectedText.
                    """

ASSISTANT_SYS_MSG = """You are Dr. Y, an assistant physician working under the supervision of Dr. X, the chief physician.
                            Your role is to respond to a medical question
                            by providing your initial evaluation, which will guide Dr. X
                            toward finalizing the answer. Dr X may ask you a series of questions, and you should respond
                            based on your expertise and the preceding discussion.
                            ### Instructions:
                            1. Ensure your evaluation is clear, precise, and structured to facilitate an informed discussion.
                            2. In each round of the discussion, limit yourself to a CONCISE message.
                        ### Process:
                        You will first receive a message from Dr. X, asking for your initial assessment.
                        Afterward, you can follow up in each discussion round to collaboratively refine the answer.
                        """


class ChatManager:
    def __init__(
        self,
        d: bool = False,  # pass -d to enable debug mode (see prompts etc)
        nc: bool = False,  # pass -nc to disable cache-retrieval (i.e. get fresh answer)
    ):
        settings.debug = d
        settings.cache = not nc

        self.ass_lm_config = lm.OpenAIGPTConfig(
            chat_model=MODEL,
            chat_context_length=1040_000,
            seed=42,
        )
        self.ass_agent = lr.ChatAgent(
            lr.ChatAgentConfig(
                name=PA_NAME,
                llm=self.ass_lm_config,
                system_message=ASSISTANT_SYS_MSG,
            ),
        )
        # no need for the DiscussionTextTool
        # self.ass_agent.enable_message(DiscussionTextTool)
        self.senior_lm_config = lm.OpenAIGPTConfig(
            chat_model=MODEL,
            chat_context_length=1040_000,
            seed=42,
        )
        self.senior_agent = lr.ChatAgent(
            lr.ChatAgentConfig(
                llm=self.senior_lm_config,
                name=CP_NAME,
                system_message=SENIOR_SYS_MSG,
            ),
        )
        self.senior_agent.enable_message(ExpectedTextTool)

    def start_chat(
        self, question: str
    ) -> ExpectedText:  # this is our main function to start the chat
        task_config = TaskConfig(inf_loop_cycle_len=0)
        self.ass_task = lr.Task(
            self.ass_agent,
            llm_delegate=True,
            interactive=False,
            single_round=True,
            config=task_config,
        )

        self.senior_task = lr.Task(
            self.senior_agent,
            llm_delegate=True,
            interactive=False,
            single_round=False,
            config=task_config,
        )[
            ResultTool
        ]  # specialize task to strictly return ResultTool or None

        self.senior_task.add_sub_task(self.ass_task)
        response_tool: ResultTool | None = self.senior_task.run(
            question, turns=100
        )  # dialogues usually take less than 70 turns

        if response_tool is None:
            print(
                """
                RETURNED ANSWER DOES NOT HAVE A TOOL! LLM DID NOT FORMAT THE DISCHARGE TEXT!!!
                """
            )
            return ExpectedText(final_decision="unknown", long_answer="null")
        else:
            print("ResultTool has been received successfully!!!")
            print(response_tool.expectedText)
            return response_tool.expectedText


if __name__ == "__main__":
    chatAgent = ChatManager()

    pubmed_ds = pd.DataFrame(
        datasets.load_dataset(
            "burcusayin/pubmedqa_binary_with_plausible_gpt4_long_answers"
        )["test"]
    )
    model_responses = []
    nrows = len(pubmed_ds)
    print(f"Processing {nrows} questions")
    for i, row in enumerate(pubmed_ds.itertuples()):
        question = row.QUESTION
        reference_decision = row.final_decision
        print(f"QUESTION: {question}")
        response: ExpectedText = chatAgent.start_chat(question=question)
        model_responses.append(response)
        print(
            f"Got response {i}: {response.final_decision}, reference: {reference_decision}"
        )
        cont = Prompt.ask("Continue? (y/n)", default="y")
        if cont.lower() != "y":
            break

>>>> examples/basic/multi-agent-return-result.py
"""
3-agent system where Main task has subtasks that are able to directly return final
task result, "short-circuiting" the flow.

main_task has sub-tasks even_task and odd_task.

- main_task receives a number, simply passes it on.
- even_task can only handle even number N, returns N/2 as final result, 
    else passes it on.
- odd_task can only handle odd number N, returns 3N+1 as final result, 
    else passes it on.
"""

import langroid as lr

from langroid.agent.tools.orchestration import FinalResultTool


main_agent = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Main",
        system_message="Whatever number you receive, simply repeat it",
    )
)


class MyFinalResultTool(FinalResultTool):
    request: str = "my_final_result_tool"
    purpose: str = "To present the final result of the exercise"
    _allow_llm_use: bool = True

    answer: int  # could of course be str if answer is text


my_final_result_tool = MyFinalResultTool.default_value("request")

even_agent = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Even",
        system_message=f"""
        - If you receive an even number, return half of it using the 
          TOOL `{my_final_result_tool}` with `answer` set to your answer.
        - Otherwise simply repeat the number
        """,
    )
)

odd_agent = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Odd",
        system_message=f"""
        - If you receive an odd number N, return 3N+1 using the
          TOOL `{my_final_result_tool}` with `answer` set to your answer.
        - Otherwise simply repeat the number        
        """,
    )
)


even_agent.enable_message(MyFinalResultTool)
odd_agent.enable_message(MyFinalResultTool)

# set up main_task to return a result of type MyFinalResultTool
main_task = lr.Task(main_agent, interactive=False)[MyFinalResultTool]
even_task = lr.Task(even_agent, interactive=False)
odd_task = lr.Task(odd_agent, interactive=False)
main_task.add_sub_task([even_task, odd_task])

result = main_task.run("3")
assert isinstance(result, MyFinalResultTool)
assert result.answer == 10

result = main_task.run("4")
assert isinstance(result, MyFinalResultTool)
assert result.answer == 2

# we can also pass in an integer value

result = main_task.run(15)
assert isinstance(result, MyFinalResultTool)
assert result.answer == 46

result = main_task.run(16)
assert isinstance(result, MyFinalResultTool)
assert result.answer == 8

>>>> examples/basic/multi-agent-round-table.py
"""
Toy example where 3 agents concurrently respond to the current message,
and the current message is updated to the response of one such responder.

Run like this:

python3 examples/basic/multi-agent-round-table.py

"""

import langroid as lr
from langroid.agent.batch import run_batch_task_gen
from langroid.utils.constants import NO_ANSWER


agent1 = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="agent1",
        system_message=f"""
        You are a simple number transformer, follow this rule:
        - If you see a number ending in 0,1, or 2, respond with a random 3-digit number.
        - Otherwise, respond saying: {NO_ANSWER}
        """,
    )
)
task1 = lr.Task(agent1, interactive=False, single_round=True)

agent2 = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="agent2",
        system_message=f"""
        You are a simple number transformer, follow this rule:
        - If you see a number ending in 3,4, or 5, respond with a random 3-digit number.
        - Otherwise, respond saying: {NO_ANSWER}
        """,
    )
)
task2 = lr.Task(agent2, interactive=False, single_round=True)


agent3 = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="agent3",
        system_message=f"""
        You are a simple number transformer, follow this rule:
        - If you see a number ending in 6,7,8 or 9, respond with a random 3-digit number.
        - Otherwise, respond saying: {NO_ANSWER}
        """,
    )
)
task3 = lr.Task(agent3, interactive=False, single_round=True)

tasks = [task1, task2, task3]


def task_gen(i):
    return tasks[i]


# kickoff with n = 412
n = 412
# run for 10 rounds
for _ in range(10):
    print("n = ", n)
    inputs = [n] * 3
    results = run_batch_task_gen(task_gen, inputs)
    # find which result is not NO_ANSWER
    for i, r in enumerate(results):
        if r.content != NO_ANSWER:
            n = int(r.content)
            print(f"agent{i+1} responded with {n}")
            break

>>>> examples/basic/multi-agent-search-critic-no-orch/__init__.py

>>>> examples/basic/multi-agent-search-critic-no-orch/assistant_agent.py
"""
AssistantAgent takes a user's question, breaks it down into smaller questions
for SearcherAgent to answer, and then presents the final answer; It then considers
feedback from CriticAgent, and may ask more questions or present the final answer
using a corrected reasoning.

Flow: (L stands for LLM, i.e. llm_response; A stands for Agent i.e. agent_response)

User Q ->
[L] -> QuestionTool(q1) ->
[A] -> validate, return QuestionTool(q1) ->
... AnswerTool(a1) from SearcherAgent ->
[A] -> AnswerTool(a1) -> natural lang ans for LLM
[L] -> either QuestionTool(q2) or FinalAnswerTool(steps, ans) ->
... if FinalAnswerTool(steps, ans) ->
[A] -> validate, return FinalAnswerTool(steps, ans) with recipient=Critic ->
... FeedbackTool(feedback, suggested_fix) from CriticAgent ->
[A] -> FeedbackTool(feedback, suggested_fix) -> natural lang feedback for LLM
[L] -> either QuestionTool(q2) or FinalAnswerTool(steps, ans) ->
...
"""

from typing import Optional

import typer

from langroid.agent.tools.orchestration import AgentDoneTool, ForwardTool, PassTool
from .tools import QuestionTool, FinalAnswerTool, FeedbackTool, AnswerTool
from langroid import ChatDocument

import langroid as lr
import langroid.language_models as lm

app = typer.Typer()


class AssistantAgent(lr.ChatAgent):
    def init_state(self):
        super().init_state()
        self.expecting_question_tool: bool = False
        self.expecting_question_or_final_answer: bool = False  # expecting one of these
        # tools
        self.expecting_search_answer: bool = False
        self.original_query: str | None = None  # user's original query

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if self.expecting_question_or_final_answer:
            return f"""
            You may have intended to use a tool, but your JSON format may be wrong.
            
            REMINDER: You must do one of the following:
            - If you are ready with the final answer to the user's ORIGINAL QUERY
                [ Remember it was: {self.original_query} ],
              then present your reasoning steps and final answer using the 
              `final_answer_tool` in the specified JSON format.
            - If you still need to ask a question, then use the `question_tool`
              to ask a SINGLE question that can be answered from a web search.
            """
        elif self.expecting_question_tool:
            return f"""
            You must ask a question using the `question_tool` in the specified format,
            to break down the user's original query: {self.original_query} into 
            smaller questions that can be answered from a web search.
            """

    def question_tool(self, msg: QuestionTool) -> str | PassTool:
        self.expecting_search_answer = True
        self.expecting_question_tool = False
        # return the tool so it is handled by SearcherAgent
        # validated incoming, pass it on
        return AgentDoneTool(tools=[msg])

    def answer_tool(self, msg: AnswerTool) -> str:
        self.expecting_question_or_final_answer = True
        self.expecting_search_answer = False
        return f"""
        Here is the answer to your question from the web search:
        {msg.answer}
        Now decide whether you want to:
        - present your FINAL answer to the user's ORIGINAL QUERY, OR
        - ask another question using the `question_tool`
            (Maybe REPHRASE the question to get BETTER search results).
        """

    def final_answer_tool(self, msg: FinalAnswerTool) -> ForwardTool | str:
        if not self.expecting_question_or_final_answer:
            return ""
        self.expecting_question_or_final_answer = False
        # insert the original query into the tool, in case LLM forgot to do so.
        msg.query = self.original_query
        # fwd to critic
        return AgentDoneTool(tools=[msg])

    def feedback_tool(self, msg: FeedbackTool) -> str:
        if msg.suggested_fix == "":
            return AgentDoneTool()
        else:
            self.expecting_question_or_final_answer = True
            # reset question count since feedback may initiate new questions
            return f"""
            Below is feedback about your answer. Take it into account to 
            improve your answer, EITHER by:
            - using the `final_answer_tool` again but with improved REASONING, OR
            - asking another question using the `question_tool`, and when you're 
                ready, present your final answer again using the `final_answer_tool`.
            
            FEEDBACK: {msg.feedback}
            SUGGESTED FIX: {msg.suggested_fix}
            """

    def llm_response(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        if self.original_query is None:
            self.original_query = (
                message if isinstance(message, str) else message.content
            )
            # just received user query, so we expect a question tool next
            self.expecting_question_tool = True

        if self.expecting_question_or_final_answer or self.expecting_question_tool:
            return super().llm_response(message)


def make_assistant_task(
    model: str = "",
    restart: bool = True,
) -> lr.Task:
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,
        temperature=0.2,
        max_output_tokens=500,
        timeout=45,
    )

    assistant_config = lr.ChatAgentConfig(
        system_message="""
        You are a resourceful assistant, able to think step by step to answer
        complex questions from the user. You must break down complex questions into
        simpler questions that can be answered by a web search. You must ask me 
        (the user) each question ONE BY ONE, using the `question_tool` in
         the specified format, and I will do a web search and send you
        a brief answer. Once you have enough information to answer my original
        (complex) question, you MUST present your INTERMEDIATE STEPS and FINAL ANSWER
        using the `final_answer_tool` in the specified JSON format.
        You will then receive FEEDBACK from the Critic, and if needed
        you should try to improve your answer based on this feedback,
        possibly by asking more questions.
        """,
        llm=llm_config,
        vecdb=None,
    )
    assistant_agent = AssistantAgent(assistant_config)
    assistant_agent.enable_message(QuestionTool)
    assistant_agent.enable_message(AnswerTool, use=False, handle=True)
    assistant_agent.enable_message(FinalAnswerTool)
    assistant_agent.enable_message(ForwardTool)
    assistant_agent.enable_message(PassTool)
    assistant_agent.enable_message(FeedbackTool, use=False, handle=True)

    assistant_task = lr.Task(
        assistant_agent,
        name="Assistant",
        llm_delegate=True,
        single_round=False,
        interactive=False,
        restart=restart,
    )

    return assistant_task


if __name__ == "__main__":
    # restart = False, to preserve state across task.run() calls
    task = make_assistant_task(restart=False)
    question = task.run("which planet has more moons, Jupiter or Saturn?")
    assert isinstance(question.tool_messages[0], QuestionTool)

>>>> examples/basic/multi-agent-search-critic-no-orch/critic_agent.py
"""
CriticAgent task enforces FinalAnswerTool -> FeedbackTool, i.e.
- incoming msg must be a FinalAnswerTool
- outgoing msg must be a FeedbackTool

Flow:

FinalAnswerTool ->
[A] -> natural lang presentation to LLM
[L] -> FeedbackTool ->
[A] -> AgentDoneTool(FeedbackTool)

"""

import typer
from dotenv import load_dotenv

import langroid as lr
import langroid.language_models as lm
from .tools import FinalAnswerTool, FeedbackTool
from langroid.agent.tools.orchestration import AgentDoneTool
from langroid import ChatDocument
from langroid.utils.configuration import Settings, set_global

app = typer.Typer()


class CriticAgent(lr.ChatAgent):
    def init_state(self):
        super().init_state()
        self.expecting_feedback_tool: bool = False

    def final_answer_tool(self, msg: FinalAnswerTool) -> str:
        # received from Assistant. Extract the components as plain text,
        # so that the Critic LLM can provide feedback
        self.expecting_feedback_tool = True

        return f"""
        The user has presented the following query, intermediate steps and final answer
        shown below. Please provide feedback using the `feedback_tool`, 
        with the `feedback` field containing your feedback, and 
        the `suggested_fix` field containing a suggested fix, such as fixing how
        the answer or the steps, or how it was obtained from the steps, or 
        asking new questions.
        
        REMEMBER to set the `suggested_fix` field to an EMPTY string if the answer is 
        VALID.
        
        QUERY: {msg.query}
        
        STEPS: {msg.steps}
        
        ANSWER: {msg.answer}
        """

    def feedback_tool(self, msg: FeedbackTool) -> FeedbackTool:
        # validate, signal DONE, include the tool
        self.expecting_feedback_tool = False
        return AgentDoneTool(tools=[msg])

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if self.expecting_feedback_tool:
            return """
            You forgot to provide feedback using the `feedback_tool` 
            on the user's reasoning steps and final answer.
            """


def make_critic_task(model: str):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,
        temperature=0.2,
        max_output_tokens=500,
        timeout=45,
    )
    critic_agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        vecdb=None,
        system_message="""
        You excel at logical reasoning and combining pieces of information.
        You will receive a summary of the original query, intermediate steps and final 
        answer.
        You must examine these and provide feedback to the user, using the 
        `feedback_tool`, as follows:
        - If you think the answer and reasoning are valid, 
            simply set the `suggested_fix` field to an empty string "".
        - Otherwise set the `feedback` field to a reason why the answer is invalid,
            and in the `suggested_fix` field indicate how the user can improve the 
            answer, for example by reasoning differently, or asking different questions.
        """,
    )
    critic_agent = CriticAgent(critic_agent_config)
    critic_agent.enable_message(FeedbackTool)
    critic_agent.enable_message(FinalAnswerTool, use=False, handle=True)
    critic_task = lr.Task(
        critic_agent,
        name="Critic",
        interactive=False,
    )
    return critic_task


if __name__ == "__main__":

    @app.command()
    def main(
        debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
        model: str = typer.Option("", "--model", "-m", help="model name"),
        nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    ) -> None:
        set_global(
            Settings(
                debug=debug,
                cache=not nocache,
            )
        )
        load_dotenv()

        llm_config = lm.OpenAIGPTConfig(
            chat_model=model or lm.OpenAIChatModel.GPT4o,
            chat_context_length=16_000,
            temperature=0.2,
            max_output_tokens=500,
            timeout=45,
        )

        critic_agent_config = lr.ChatAgentConfig(
            llm=llm_config,
            vecdb=None,
            system_message="""
            You excel at logical reasoning and combining pieces of information.
            The user will send you a summary of the intermediate steps and final answer.
            You must examine these and provide feedback to the user, using the 
            `feedback_tool`, as follows:
            - If you think the answer and reasoning are valid, 
                simply set the `suggested_fix` field to an empty string "".
            - Otherwise set the `feedback` field to a reason why the answer is invalid,
                and in the `suggested_fix` field indicate how the user can improve the 
                answer, for example by reasoning differently, or asking different questions.
            """,
        )
        critic_agent = CriticAgent(critic_agent_config)
        critic_agent.enable_message(FeedbackTool)
        critic_agent.enable_message(FinalAnswerTool, use=False, handle=True)
        critic_task = lr.Task(
            critic_agent,
            name="Critic",
            interactive=False,
        )
        final_ans_tool = FinalAnswerTool(
            steps="""
            1. The moon landing was in 1969.
            2. Kennedy was president during 1969.            
            """,
            answer="Kennedy was president during the moon landing.",
        )
        # simulate receiving the tool from Assistant
        final_ans_doc = critic_agent.create_agent_response(
            tool_messages=[final_ans_tool]
        )
        result = critic_task.run(final_ans_doc)
        tools = critic_agent.get_tool_messages(result)
        assert len(tools) == 1
        assert isinstance(tools[0], FeedbackTool)

    app()

>>>> examples/basic/multi-agent-search-critic-no-orch/main.py
"""
Version of main.py, but does NOT use any inter-agent orchestration,
 i.e. we create a separate Task object from each agent, but we do not
 connect them as sub-tasks.
 Instead we write extra code to handle each task's output, and
 determine what to do with it.

3-Agent system where:
- Assistant takes user's (complex) question, breaks it down into smaller pieces
    if needed
- Searcher takes Assistant's question, uses the Search tool to search the web
    (using DuckDuckGo), and returns a coherent answer to the Assistant.
- Critic takes Assistant's final answer, and provides feedback on it.

Once the Assistant thinks it has enough info to answer the user's question, it
says DONE and presents the answer to the user.

See also: chat-search for a basic single-agent search

Run like this from root of repo:

python3 -m examples.basic.multi-agent-search-critic-no-orch.main

There are optional args, especially note these:

-m <model_name>: to run with a different LLM model (default: gpt4o)

For example try this question:

did Bach make more music than Beethoven?

You can specify a local LLM in a few different ways, e.g. `-m local/localhost:8000/v1`
or `-m ollama/mistral` etc. See here how to use Langroid with local LLMs:
https://langroid.github.io/langroid/tutorials/local-llm-setup/


"""

import typer
from dotenv import load_dotenv
from rich import print
from rich.prompt import Prompt
import langroid as lr
from .tools import QuestionTool, AnswerTool, FinalAnswerTool, FeedbackTool
from .search_agent import make_search_task
from .critic_agent import make_critic_task
from .assistant_agent import make_assistant_task
from langroid.utils.configuration import Settings, set_global

app = typer.Typer()


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    print(
        """
        [blue]Welcome to the Web Search Assistant chatbot!
        I will try to answer your complex questions. 
        
        Enter x or q to quit at any point.
        """
    )
    load_dotenv()

    assistant_task = make_assistant_task(model, restart=False)
    search_task = make_search_task(model)
    critic_task = make_critic_task(model)

    def search_answer(qtool: QuestionTool) -> AnswerTool:
        """
        Take a QuestionTool, return an AnswerTool
        """
        return search_task[AnswerTool].run(qtool)

    def critic_feedback(fa: FinalAnswerTool) -> FeedbackTool:
        """
        Take a FinalAnswerTool, return a FeedbackTool
        """
        return critic_task[FeedbackTool].run(fa)

    def query_to_final_answer(question: str) -> FinalAnswerTool:
        """
        Take user's question, return FinalAnswerTool after
        iterating based on feedback from Critic.
        """

        question_tool_name = QuestionTool.default_value("request")
        final_answer_tool_name = FinalAnswerTool.default_value("request")

        tool = assistant_task[lr.ToolMessage].run(question)

        while True:
            if not isinstance(tool, (QuestionTool, FinalAnswerTool)):
                # no tool => nudge
                tool = assistant_task[lr.ToolMessage].run(
                    f"""
                     You forgot to use one of the tools:
                     `{question_tool_name}` or `{final_answer_tool_name}`.
                     """,
                )
            elif isinstance(tool, QuestionTool):
                # QuestionTool => get search result
                answer_tool = search_answer(tool)
                tool = assistant_task[lr.ToolMessage].run(answer_tool)
            else:
                # FinalAnswerTool => get feedback
                fb_tool = critic_feedback(tool)
                if fb_tool.suggested_fix == "":
                    # no suggested fix => return tool (which is a FinalAnswerTool)
                    return tool
                else:
                    # suggested fix => ask again
                    tool = assistant_task[lr.ToolMessage].run(fb_tool)

    # Interactive loop with user
    while True:
        question = Prompt.ask("What do you want to know?")
        if question.lower() in ["x", "q"]:
            break
        assistant_task.agent.init_state()
        final_answer = query_to_final_answer(question)
        assert isinstance(final_answer, FinalAnswerTool)


if __name__ == "__main__":
    app()

>>>> examples/basic/multi-agent-search-critic-no-orch/search_agent.py
"""
SearcherAgent flow:

[A] stands for Agent response (i.e. agent_response)
[L] stands for LLM response (i.e. llm_response)

QuestionTool ->
[A] -> natural lang question for LLM ->
[L] -> DuckduckgoSearchTool ->
[A] -> results ->
[L] -> AnswerTool(results) ->
[A] -> AgentDoneTool(AnswerTool)

Note that this Agent's task enforces QuestionTool -> AnswerTool, i.e.
- incoming msg must be a QuestionTool
- outgoing msg must be an AnswerTool
"""

from typing import Optional

import typer
from dotenv import load_dotenv

import langroid as lr
from .tools import QuestionTool, AnswerTool
import langroid.language_models as lm
from langroid.agent.tools.orchestration import AgentDoneTool
from langroid import ChatDocument
from langroid.utils.configuration import Settings, set_global

from langroid.agent.tools.duckduckgo_search_tool import DuckduckgoSearchTool
from langroid.agent.tools.metaphor_search_tool import MetaphorSearchTool

app = typer.Typer()

# class MyDDGSearchTool(DuckduckgoSearchTool):
#     request = "my_ddg_search"


class SearcherAgent(lr.ChatAgent):
    def init_state(self):
        super().init_state()
        self.curr_query: str | None = None
        self.expecting_search_results: bool = False
        self.expecting_search_tool: bool = False

    def __init__(self, config: lr.ChatAgentConfig):
        super().__init__(config)
        self.config = config
        self.enable_message(MetaphorSearchTool)  # DuckduckgoSearchTool
        self.enable_message(QuestionTool, use=False, handle=True)
        # agent is producing AnswerTool, so LLM should not be allowed to "use" it
        self.enable_message(AnswerTool, use=False, handle=True)

    def duckduckgo_search(self, msg: DuckduckgoSearchTool) -> str:
        """Override the DDG handler to update state"""
        self.expecting_search_results = True
        self.expecting_search_tool = False
        return msg.handle()

    def metaphor_search(self, msg: MetaphorSearchTool) -> str:
        """Override the Metaphor handler to update state"""
        self.expecting_search_results = True
        self.expecting_search_tool = False
        return msg.handle()

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        # we're here because msg has no tools
        if self.curr_query is None:
            # did not receive a question tool, so short-circuit and return None
            return None
        if self.expecting_search_tool:
            search_tool_name = MetaphorSearchTool.default_value("request")
            return f"""
            You forgot to use the web search tool`{search_tool_name}`  
            to answer the user's question : {self.curr_query}!!
            REMEMBER - you must ONLY answer the user's questions based on 
             results from a web-search, and you MUST NOT ANSWER them yourself.
             
            Please use the `{search_tool_name}` tool 
            using the specified JSON format, then compose your answer based on 
            the results from this web-search tool.
            """

    def question_tool(self, msg: QuestionTool) -> str:
        self.curr_query = msg.question
        self.expecting_search_tool = True
        search_tool_name = MetaphorSearchTool.default_value("request")
        return f"""
        User asked this question: {msg.question}.
        Perform a web search using the `{search_tool_name}` tool
        using the specified JSON format, to find the answer.
        """

    def answer_tool(self, msg: AnswerTool) -> AgentDoneTool:
        # signal DONE, and return the AnswerTool
        return AgentDoneTool(tools=[msg])

    def llm_response(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        if self.expecting_search_results:
            # message must be search results from the web search tool,
            # so let the LLM compose a response based on the search results

            curr_query = self.curr_query
            # reset state
            self.curr_query = None
            self.expecting_search_results = False
            self.expecting_search_tool = False

            result = super().llm_response_forget(message)

            # return an AnswerTool containing the answer,
            # with a nudge meant for the Assistant
            answer = f"""
                Here are the web-search results for the question: {curr_query}.
                ===
                {result.content}
                """

            ans_tool = AnswerTool(answer=answer)
            # cannot return a tool, so use this to create a ChatDocument
            return self.create_llm_response(tool_messages=[ans_tool])

        # Handling query from user (or other agent) => expecting a search tool
        result = super().llm_response_forget(message)
        return result


def make_search_task(model: str):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,
        temperature=0.2,
        max_output_tokens=500,
        timeout=45,
    )

    search_tool_handler_method = MetaphorSearchTool.default_value("request")

    search_agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        vecdb=None,
        system_message=f"""
        You are a web-searcher. For ANY question you get, you must use the
        `{search_tool_handler_method}` tool/function-call to get up to 5 results.
        Once you receive the results, you must compose a CONCISE answer 
        based on the search results and present the answer in this format:
        ANSWER: [... your CONCISE answer here ...]
        SOURCES: [links from the web-search that you used]
        
        EXTREMELY IMPORTANT: DO NOT MAKE UP ANSWERS, ONLY use the web-search results.
        """,
    )
    search_agent = SearcherAgent(search_agent_config)
    search_task = lr.Task(
        search_agent,
        name="Searcher",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )
    return search_task


if __name__ == "__main__":

    @app.command()
    def main(
        debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
        model: str = typer.Option("", "--model", "-m", help="model name"),
        nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    ) -> None:
        set_global(
            Settings(
                debug=debug,
                cache=not nocache,
            )
        )

        load_dotenv()

        search_task = make_search_task(model)
        # simulate an incoming message to this Task, from the Assistant agent
        q_doc = search_task.agent.create_agent_response(
            tool_messages=[QuestionTool(question="Who was Beethoven's teacher?")]
        )
        result = search_task.run(q_doc)
        tools = search_task.agent.get_tool_messages(result)
        assert len(tools) == 1
        assert isinstance(tools[0], AnswerTool)

    app()

>>>> examples/basic/multi-agent-search-critic-no-orch/tools.py
from typing import List

import typer

import langroid as lr

app = typer.Typer()


class QuestionTool(lr.ToolMessage):
    request: str = "question_tool"
    purpose: str = "Ask a SINGLE <question> that can be answered from a web search."
    question: str

    @classmethod
    def examples(cls) -> List[lr.ToolMessage]:
        return [
            cls(question="Which superconductor material was discovered in 2023?"),
            cls(question="What AI innovation did Meta achieve in 2024?"),
        ]


class AnswerTool(lr.ToolMessage):
    request = "answer_tool"
    purpose = "Present the <answer> to a web-search question"
    answer: str


class FinalAnswerTool(lr.ToolMessage):
    request: str = "final_answer_tool"
    purpose: str = """
        Present the intermediate <steps> and 
        final <answer> to the user's original <query>.
        """
    query: str
    steps: str
    answer: str

    @classmethod
    def examples(cls) -> List["lr.ToolMessage"]:
        return [
            (
                "I want to show my reasoning steps, along with my final answer",
                cls(
                    query="was Plato mortal?",
                    steps="1. Man is mortal. 2. Plato was a man.",
                    answer="Plato was mortal.",
                ),
            ),
            cls(
                query="Who was president during the moon landing?",
                steps="1. The moon landing was in 1969. 2. Kennedy was president "
                "during 1969.",
                answer="Kennedy was president during the moon landing.",
            ),
        ]


class FeedbackTool(lr.ToolMessage):
    request: str = "feedback_tool"
    purpose: str = """
    Provide <feedback> on the user's answer. If the answer is valid based on the
    reasoning steps, then the feedback MUST be EMPTY
    """
    feedback: str
    suggested_fix: str

    @classmethod
    def examples(cls) -> List["lr.ToolMessage"]:
        return [
            # just example
            cls(feedback="This looks fine!", suggested_fix=""),
            # thought + example
            (
                "I want to provide feedback on the reasoning steps and final answer",
                cls(
                    feedback="""
                    The answer is invalid because the conclusion does not follow from the
                    steps. Please check your reasoning and try again.
                    """,
                    suggested_fix="Check reasoning and try again",
                ),
            ),
        ]

>>>> examples/basic/multi-agent-search-critic/__init__.py

>>>> examples/basic/multi-agent-search-critic/assistant_agent.py
"""
AssistantAgent takes a user's question, breaks it down into smaller questions
for SearcherAgent to answer, and then presents the final answer; It then considers
feedback from CriticAgent, and may ask more questions or present the final answer
using a corrected reasoning.

Flow:

User Q ->
[L] -> QuestionTool(q1) ->
[A] -> validate, return QuestionTool(q1) ->
... AnswerTool(a1) from SearcherAgent ->
[A] -> AnswerTool(a1) -> natural lang ans for LLM
[L] -> either QuestionTool(q2) or FinalAnswerTool(steps, ans) ->
... if FinalAnswerTool(steps, ans) ->
[A] -> validate, return FinalAnswerTool(steps, ans) with recipient=Critic ->
... FeedbackTool(feedback, suggested_fix) from CriticAgent ->
[A] -> FeedbackTool(feedback, suggested_fix) -> natural lang feedback for LLM
[L] -> either QuestionTool(q2) or FinalAnswerTool(steps, ans) ->
...
"""

from typing import Optional

import typer

from langroid.agent.tools.orchestration import AgentDoneTool, ForwardTool, PassTool
from .tools import QuestionTool, FinalAnswerTool, FeedbackTool, AnswerTool
from langroid import ChatDocument

import langroid as lr
import langroid.language_models as lm

app = typer.Typer()


class AssistantAgent(lr.ChatAgent):

    def init_state(self):
        super().init_state()
        self.expecting_question_tool: bool = False
        self.expecting_question_or_final_answer: bool = False  # expecting one of these
        # tools
        self.expecting_search_answer: bool = False
        self.original_query: str | None = None  # user's original query

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if self.expecting_question_or_final_answer:
            return f"""
            You may have intended to use a tool, but your JSON format may be wrong.
            
            REMINDER: You must do one of the following:
            - If you are ready with the final answer to the user's ORIGINAL QUERY
                [ Remember it was: {self.original_query} ],
              then present your reasoning steps and final answer using the 
              `final_answer_tool` in the specified JSON format.
            - If you still need to ask a question, then use the `question_tool`
              to ask a SINGLE question that can be answered from a web search.
            """
        elif self.expecting_question_tool:
            return f"""
            You must ask a question using the `question_tool` in the specified format,
            to break down the user's original query: {self.original_query} into 
            smaller questions that can be answered from a web search.
            """

    def question_tool(self, msg: QuestionTool) -> str | PassTool:
        self.expecting_search_answer = True
        self.expecting_question_tool = False
        # return the tool so it is handled by SearcherAgent
        # validated incoming, pass it on
        return PassTool()

    def answer_tool(self, msg: AnswerTool) -> str:
        self.expecting_question_or_final_answer = True
        self.expecting_search_answer = False
        return f"""
        Here is the answer to your question from the web search:
        {msg.answer}
        Now decide whether you want to:
        - present your FINAL answer to the user's ORIGINAL QUERY, OR
        - ask another question using the `question_tool`
            (Maybe REPHRASE the question to get BETTER search results).
        """

    def final_answer_tool(self, msg: FinalAnswerTool) -> ForwardTool | str:
        if not self.expecting_question_or_final_answer:
            return ""
        self.expecting_question_or_final_answer = False
        # insert the original query into the tool, in case LLM forgot to do so.
        msg.query = self.original_query
        # fwd to critic
        return ForwardTool(agent="Critic")

    def feedback_tool(self, msg: FeedbackTool) -> str:
        if msg.suggested_fix == "":
            return AgentDoneTool()
        else:
            self.expecting_question_or_final_answer = True
            # reset question count since feedback may initiate new questions
            return f"""
            Below is feedback about your answer. Take it into account to 
            improve your answer, EITHER by:
            - using the `final_answer_tool` again but with improved REASONING, OR
            - asking another question using the `question_tool`, and when you're 
                ready, present your final answer again using the `final_answer_tool`.
            
            FEEDBACK: {msg.feedback}
            SUGGESTED FIX: {msg.suggested_fix}
            """

    def llm_response(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        if self.original_query is None:
            self.original_query = (
                message if isinstance(message, str) else message.content
            )
            # just received user query, so we expect a question tool next
            self.expecting_question_tool = True

        if self.expecting_question_or_final_answer or self.expecting_question_tool:
            return super().llm_response(message)


def make_assistant_task(
    model: str,
    restart: bool = True,
) -> lr.Task:
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,
        temperature=0.2,
        max_output_tokens=500,
        timeout=45,
    )

    assistant_config = lr.ChatAgentConfig(
        system_message="""
        You are a resourceful assistant, able to think step by step to answer
        complex questions from the user. You must break down complex questions into
        simpler questions that can be answered by a web search. You must ask me 
        (the user) each question ONE BY ONE, using the `question_tool` in
         the specified format, and I will do a web search and send you
        a brief answer. Once you have enough information to answer my original
        (complex) question, you MUST present your INTERMEDIATE STEPS and FINAL ANSWER
        using the `final_answer_tool` in the specified JSON format.
        You will then receive FEEDBACK from the Critic, and if needed
        you should try to improve your answer based on this feedback,
        possibly by asking more questions.
        """,
        llm=llm_config,
        vecdb=None,
    )
    assistant_agent = AssistantAgent(assistant_config)
    assistant_agent.enable_message(QuestionTool)
    assistant_agent.enable_message(AnswerTool, use=False, handle=True)
    assistant_agent.enable_message(FinalAnswerTool)
    assistant_agent.enable_message(ForwardTool)
    assistant_agent.enable_message(PassTool)
    assistant_agent.enable_message(FeedbackTool, use=False, handle=True)

    assistant_task = lr.Task(
        assistant_agent,
        name="Assistant",
        llm_delegate=True,
        single_round=False,
        interactive=False,
        restart=restart,
    )

    return assistant_task

>>>> examples/basic/multi-agent-search-critic/critic_agent.py
"""
CriticAgent task enforces FinalAnswerTool -> FeedbackTool, i.e.
- incoming msg must be a FinalAnswerTool
- outgoing msg must be a FeedbackTool

Flow:

FinalAnswerTool ->
[A] -> natural lang presentation to LLM
[L] -> FeedbackTool ->
[A] -> AgentDoneTool(FeedbackTool)

"""

import typer
from dotenv import load_dotenv

import langroid as lr
import langroid.language_models as lm
from .tools import FinalAnswerTool, FeedbackTool
from langroid.agent.tools.orchestration import AgentDoneTool
from langroid import ChatDocument
from langroid.utils.configuration import Settings, set_global

app = typer.Typer()


class CriticAgent(lr.ChatAgent):
    def init_state(self):
        super().init_state()
        self.expecting_feedback_tool: bool = False

    def final_answer_tool(self, msg: FinalAnswerTool) -> str:
        # received from Assistant. Extract the components as plain text,
        # so that the Critic LLM can provide feedback
        self.expecting_feedback_tool = True

        return f"""
        The user has presented the following query, intermediate steps and final answer
        shown below. Please provide feedback using the `feedback_tool`, 
        with the `feedback` field containing your feedback, and 
        the `suggested_fix` field containing a suggested fix, such as fixing how
        the answer or the steps, or how it was obtained from the steps, or 
        asking new questions.
        
        REMEMBER to set the `suggested_fix` field to an EMPTY string if the answer is 
        VALID.
        
        QUERY: {msg.query}
        
        STEPS: {msg.steps}
        
        ANSWER: {msg.answer}
        """

    def feedback_tool(self, msg: FeedbackTool) -> FeedbackTool:
        # validate, signal DONE, include the tool
        self.expecting_feedback_tool = False
        return AgentDoneTool(tools=[msg])

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if self.expecting_feedback_tool:
            return """
            You forgot to provide feedback using the `feedback_tool` 
            on the user's reasoning steps and final answer.
            """


def make_critic_task(model: str):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,
        temperature=0.2,
        max_output_tokens=500,
        timeout=45,
    )
    critic_agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        vecdb=None,
        system_message="""
        You excel at logical reasoning and combining pieces of information.
        You will receive a summary of the original query, intermediate steps and final 
        answer.
        You must examine these and provide feedback to the user, using the 
        `feedback_tool`, as follows:
        - If you think the answer and reasoning are valid, 
            simply set the `suggested_fix` field to an empty string "".
        - Otherwise set the `feedback` field to a reason why the answer is invalid,
            and in the `suggested_fix` field indicate how the user can improve the 
            answer, for example by reasoning differently, or asking different questions.
        """,
    )
    critic_agent = CriticAgent(critic_agent_config)
    critic_agent.enable_message(FeedbackTool)
    critic_agent.enable_message(FinalAnswerTool, use=False, handle=True)
    critic_task = lr.Task(
        critic_agent,
        name="Critic",
        interactive=False,
    )
    return critic_task


if __name__ == "__main__":

    @app.command()
    def main(
        debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
        model: str = typer.Option("", "--model", "-m", help="model name"),
        nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    ) -> None:
        set_global(
            Settings(
                debug=debug,
                cache=not nocache,
            )
        )
        load_dotenv()

        llm_config = lm.OpenAIGPTConfig(
            chat_model=model or lm.OpenAIChatModel.GPT4o,
            chat_context_length=16_000,
            temperature=0.2,
            max_output_tokens=500,
            timeout=45,
        )

        critic_agent_config = lr.ChatAgentConfig(
            llm=llm_config,
            vecdb=None,
            system_message="""
            You excel at logical reasoning and combining pieces of information.
            The user will send you a summary of the intermediate steps and final answer.
            You must examine these and provide feedback to the user, using the 
            `feedback_tool`, as follows:
            - If you think the answer and reasoning are valid, 
                simply set the `suggested_fix` field to an empty string "".
            - Otherwise set the `feedback` field to a reason why the answer is invalid,
                and in the `suggested_fix` field indicate how the user can improve the 
                answer, for example by reasoning differently, or asking different questions.
            """,
        )
        critic_agent = CriticAgent(critic_agent_config)
        critic_agent.enable_message(FeedbackTool)
        critic_agent.enable_message(FinalAnswerTool, use=False, handle=True)
        critic_task = lr.Task(
            critic_agent,
            name="Critic",
            interactive=False,
        )
        final_ans_tool = FinalAnswerTool(
            steps="""
            1. The moon landing was in 1969.
            2. Kennedy was president during 1969.            
            """,
            answer="Kennedy was president during the moon landing.",
        )
        # simulate receiving the tool from Assistant
        final_ans_doc = critic_agent.create_agent_response(
            tool_messages=[final_ans_tool]
        )
        result = critic_task.run(final_ans_doc)
        tools = critic_agent.get_tool_messages(result)
        assert len(tools) == 1
        assert isinstance(tools[0], FeedbackTool)

    app()

>>>> examples/basic/multi-agent-search-critic/main.py
"""
Version of chat-search-assistant.py that is more likely to work local LLMs.

3-Agent system where:
- Assistant takes user's (complex) question, breaks it down into smaller pieces
    if needed
- Searcher takes Assistant's question, uses the Search tool to search the web
    (using DuckDuckGo), and returns a coherent answer to the Assistant.
- Critic takes Assistant's final answer, and provides feedback on it.

Once the Assistant thinks it has enough info to answer the user's question, it
says DONE and presents the answer to the user.

See also: chat-search for a basic single-agent search

Run like this from root of repo:

python3 -m examples.basic.multi-agent-search-critic.main

There are optional args, especially note these:

-m <model_name>: to run with a different LLM model (default: gpt4o)

For example try this question:

did Bach make more music than Beethoven?

You can specify a local LLM in a few different ways, e.g. `-m local/localhost:8000/v1`
or `-m ollama/mistral` etc. See here how to use Langroid with local LLMs:
https://langroid.github.io/langroid/tutorials/local-llm-setup/


"""

import typer
from dotenv import load_dotenv
from rich import print
from rich.prompt import Prompt
from .search_agent import make_search_task
from .critic_agent import make_critic_task
from .assistant_agent import make_assistant_task
from langroid.utils.configuration import Settings, set_global

app = typer.Typer()


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    print(
        """
        [blue]Welcome to the Web Search Assistant chatbot!
        I will try to answer your complex questions. 
        
        Enter x or q to quit at any point.
        """
    )
    load_dotenv()

    assistant_task = make_assistant_task(model)
    search_task = make_search_task(model)
    critic_task = make_critic_task(model)

    assistant_task.add_sub_task([search_task, critic_task])
    question = Prompt.ask("What do you want to know?")
    assistant_task.run(question)


if __name__ == "__main__":
    app()

>>>> examples/basic/multi-agent-search-critic/search_agent.py
"""
SearcherAgent flow:

[A] stands for Agent response (i.e. agent_response)
[L] stands for LLM response (i.e. llm_response)

QuestionTool ->
[A] -> natural lang question for LLM ->
[L] -> DuckduckgoSearchTool ->
[A] -> results ->
[L] -> AnswerTool(results) ->
[A] -> AgentDoneTool(AnswerTool)

Note that this Agent's task enforces QuestionTool -> AnswerTool, i.e.
- incoming msg must be a QuestionTool
- outgoing msg must be an AnswerTool
"""

from typing import Optional

import typer
from dotenv import load_dotenv

import langroid as lr
from .tools import QuestionTool, AnswerTool
import langroid.language_models as lm
from langroid.agent.tools.orchestration import AgentDoneTool
from langroid import ChatDocument
from langroid.utils.configuration import Settings, set_global

from langroid.agent.tools.duckduckgo_search_tool import DuckduckgoSearchTool
from langroid.agent.tools.metaphor_search_tool import MetaphorSearchTool

app = typer.Typer()

# class MyDDGSearchTool(DuckduckgoSearchTool):
#     request = "my_ddg_search"


class SearcherAgent(lr.ChatAgent):
    def init_state(self):
        super().init_state()
        self.curr_query: str | None = None
        self.expecting_search_results: bool = False
        self.expecting_search_tool: bool = False

    def __init__(self, config: lr.ChatAgentConfig):
        super().__init__(config)
        self.config = config
        self.enable_message(MetaphorSearchTool)  # DuckduckgoSearchTool
        self.enable_message(QuestionTool, use=False, handle=True)
        # agent is producing AnswerTool, so LLM should not be allowed to "use" it
        self.enable_message(AnswerTool, use=False, handle=True)

    def duckduckgo_search(self, msg: DuckduckgoSearchTool) -> str:
        """Override the DDG handler to update state"""
        self.expecting_search_results = True
        self.expecting_search_tool = False
        return msg.handle()

    def metaphor_search(self, msg: MetaphorSearchTool) -> str:
        """Override the Metaphor handler to update state"""
        self.expecting_search_results = True
        self.expecting_search_tool = False
        return msg.handle()

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        # we're here because msg has no tools
        if self.curr_query is None:
            # did not receive a question tool, so short-circuit and return None
            return None
        if self.expecting_search_tool:
            search_tool_name = MetaphorSearchTool.default_value("request")
            return f"""
            You forgot to use the web search tool`{search_tool_name}`  
            to answer the user's question : {self.curr_query}!!
            REMEMBER - you must ONLY answer the user's questions based on 
             results from a web-search, and you MUST NOT ANSWER them yourself.
             
            Please use the `{search_tool_name}` tool 
            using the specified JSON format, then compose your answer based on 
            the results from this web-search tool.
            """

    def question_tool(self, msg: QuestionTool) -> str:
        self.curr_query = msg.question
        self.expecting_search_tool = True
        search_tool_name = MetaphorSearchTool.default_value("request")
        return f"""
        User asked this question: {msg.question}.
        Perform a web search using the `{search_tool_name}` tool
        using the specified JSON format, to find the answer.
        """

    def answer_tool(self, msg: AnswerTool) -> AgentDoneTool:
        # signal DONE, and return the AnswerTool
        return AgentDoneTool(tools=[msg])

    def llm_response(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        if self.expecting_search_results:
            # message must be search results from the web search tool,
            # so let the LLM compose a response based on the search results

            curr_query = self.curr_query
            # reset state
            self.curr_query = None
            self.expecting_search_results = False
            self.expecting_search_tool = False

            result = super().llm_response_forget(message)

            # return an AnswerTool containing the answer,
            # with a nudge meant for the Assistant
            answer = f"""
                Here are the web-search results for the question: {curr_query}.
                ===
                {result.content}
                """

            ans_tool = AnswerTool(answer=answer)
            # cannot return a tool, so use this to create a ChatDocument
            return self.create_llm_response(tool_messages=[ans_tool])

        # Handling query from user (or other agent) => expecting a search tool
        result = super().llm_response_forget(message)
        return result


def make_search_task(model: str):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,
        temperature=0.2,
        max_output_tokens=500,
        timeout=45,
    )

    search_tool_handler_method = MetaphorSearchTool.default_value("request")

    search_agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        vecdb=None,
        system_message=f"""
        You are a web-searcher. For ANY question you get, you must use the
        `{search_tool_handler_method}` tool/function-call to get up to 5 results.
        Once you receive the results, you must compose a CONCISE answer 
        based on the search results and present the answer in this format:
        ANSWER: [... your CONCISE answer here ...]
        SOURCES: [links from the web-search that you used]
        
        EXTREMELY IMPORTANT: DO NOT MAKE UP ANSWERS, ONLY use the web-search results.
        """,
    )
    search_agent = SearcherAgent(search_agent_config)
    search_task = lr.Task(
        search_agent,
        name="Searcher",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )
    return search_task


if __name__ == "__main__":

    @app.command()
    def main(
        debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
        model: str = typer.Option("", "--model", "-m", help="model name"),
        nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    ) -> None:
        set_global(
            Settings(
                debug=debug,
                cache=not nocache,
            )
        )

        load_dotenv()

        search_task = make_search_task(model)
        # simulate an incoming message to this Task, from the Assistant agent
        q_doc = search_task.agent.create_agent_response(
            tool_messages=[QuestionTool(question="Who was Beethoven's teacher?")]
        )
        result = search_task.run(q_doc)
        tools = search_task.agent.get_tool_messages(result)
        assert len(tools) == 1
        assert isinstance(tools[0], AnswerTool)

    app()

>>>> examples/basic/multi-agent-search-critic/tools.py
from typing import List

import typer

import langroid as lr

app = typer.Typer()


class QuestionTool(lr.ToolMessage):
    request: str = "question_tool"
    purpose: str = "Ask a SINGLE <question> that can be answered from a web search."
    question: str

    @classmethod
    def examples(cls) -> List[lr.ToolMessage]:
        return [
            cls(question="Which superconductor material was discovered in 2023?"),
            cls(question="What AI innovation did Meta achieve in 2024?"),
        ]


class AnswerTool(lr.ToolMessage):
    request = "answer_tool"
    purpose = "Present the <answer> to a web-search question"
    answer: str


class FinalAnswerTool(lr.ToolMessage):
    request: str = "final_answer_tool"
    purpose: str = """
        Present the intermediate <steps> and 
        final <answer> to the user's original <query>.
        """
    query: str
    steps: str
    answer: str

    @classmethod
    def examples(cls) -> List["lr.ToolMessage"]:
        return [
            (
                "I want to show my reasoning steps, along with my final answer",
                cls(
                    query="was Plato mortal?",
                    steps="1. Man is mortal. 2. Plato was a man.",
                    answer="Plato was mortal.",
                ),
            ),
            cls(
                query="Who was president during the moon landing?",
                steps="1. The moon landing was in 1969. 2. Kennedy was president "
                "during 1969.",
                answer="Kennedy was president during the moon landing.",
            ),
        ]


class FeedbackTool(lr.ToolMessage):
    request: str = "feedback_tool"
    purpose: str = """
    Provide <feedback> on the user's answer. If the answer is valid based on the
    reasoning steps, then the feedback MUST be EMPTY
    """
    feedback: str
    suggested_fix: str

    @classmethod
    def examples(cls) -> List["lr.ToolMessage"]:
        return [
            # just example
            cls(feedback="This looks fine!", suggested_fix=""),
            # thought + example
            (
                "I want to provide feedback on the reasoning steps and final answer",
                cls(
                    feedback="""
                    The answer is invalid because the conclusion does not follow from the
                    steps. Please check your reasoning and try again.
                    """,
                    suggested_fix="Check reasoning and try again",
                ),
            ),
        ]

>>>> examples/basic/multi-agent-triage.py
"""
3-agent student assistant system:

- Triage agent: routes questions to the appropriate agent
- Course Agent: answers questions about courses
- Finance Agent: answers questions about finances

Illustrates use of AgentDoneTool, ForwardTool

Run like this (if --model is omitted, it defaults to the GPT-4o model):

python3 examples/basic/multi-agent-triage.py --model groq/llama-3.1-70b-versatile


"""

from typing import Optional

import langroid as lr
import langroid.language_models as lm
from langroid.parsing.urls import find_urls
from langroid import ChatDocument
from langroid.agent.tools.orchestration import (
    ForwardTool,
    AgentDoneTool,
    SendTool,
)
from langroid.parsing.parser import ParsingConfig, PdfParsingConfig
from langroid.vector_store.qdrantdb import QdrantDBConfig
import os
from fire import Fire

os.environ["TOKENIZERS_PARALLELISM"] = "false"

forward_tool_name = ForwardTool.default_value("request")


class FinanceAnswerTool(lr.ToolMessage):
    request: str = "finance_answer_tool"
    purpose: str = "Present the <answer> to a question about finances"

    answer: str

    def handle(self) -> SendTool:
        return SendTool(to="User", content=self.answer)


class CoursesAnswerTool(lr.ToolMessage):
    request: str = "courses_answer_tool"
    purpose: str = "Present the <answer> to a question about courses"

    answer: str

    def handle(self) -> SendTool:
        return SendTool(to="User", content=self.answer)


def main(model: str = ""):
    class TriageAgent(lr.ChatAgent):
        def init_state(self) -> None:
            # self.expecting_course_answer = False
            # self.expecting_finance_answer = False
            super().init_state()
            self.llm_responded = False

        def user_response(
            self,
            msg: Optional[str | ChatDocument] = None,
        ) -> Optional[ChatDocument]:
            self.llm_responded = False
            return super().user_response(msg)

        def llm_response(
            self, message: Optional[str | ChatDocument] = None
        ) -> Optional[ChatDocument]:
            self.llm_responded = True
            return super().llm_response(message)

        def handle_message_fallback(
            self, msg: str | ChatDocument
        ) -> str | ChatDocument | lr.ToolMessage | None:
            """Handle any non-tool msg"""
            if self.llm_responded:
                self.llm_responded = False
                # LLM generated non-tool msg => send to user
                content = msg.content if isinstance(msg, ChatDocument) else msg
                return SendTool(to="User", content=content)

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        max_output_tokens=200,
        chat_context_length=16_000,
    )

    triage_agent = TriageAgent(
        lr.ChatAgentConfig(
            name="Triage",
            llm=llm_config,
            system_message=f"""
            You are a helpful assistant to students at a university. 
            
            Students may ask about the following TYPES of questions and you must handle 
            each TYPE as specified below:
            
            - (a) COURSES:
                - use the TOOL: `{forward_tool_name}` to forward the 
                    question to the "Courses" agent
            - (b) FINANCES (student loans, scholarships, tuition, dining plans, etc)
                - use the TOOL: `{forward_tool_name}` to forward the
                    question to the "Finance" agent
            - (c) OTHER questions not specific to the university:
                - attempt to answer these based on your own knowledge, 
                  otherwise admit you don't know.
            
            Start by greeting the user and asking them what they need help with.
            """,
        )
    )
    triage_agent.enable_message(ForwardTool)
    triage_agent.enable_message(
        [FinanceAnswerTool, CoursesAnswerTool],
        use=False,
        handle=True,
    )

    triage_task = lr.Task(triage_agent, interactive=False)

    parsing_config = ParsingConfig(  # modify as needed
        chunk_size=200,  # aim for this many tokens per chunk
        overlap=50,  # overlap between chunks
        max_chunks=10_000,
        # aim to have at least this many chars per chunk when
        # truncating due to punctuation
        min_chunk_chars=50,
        discard_chunk_chars=5,  # discard chunks with fewer than this many chars
        n_similar_docs=5,
        n_neighbor_ids=5,  # num chunk IDs to store on either side of each chunk
        pdf=PdfParsingConfig(
            # NOTE: PDF parsing is extremely challenging, and each library
            # has its own strengths and weaknesses.
            # Try one that works for your use case.
            # See here for available alternatives:
            # https://github.com/langroid/langroid/blob/main/langroid/parsing/parser.py
            library="pymupdf4llm",
        ),
    )

    class CoursesAgent(lr.agent.special.DocChatAgent):
        def llm_response(
            self,
            message: None | str | ChatDocument = None,
        ) -> Optional[ChatDocument]:
            answer = super().llm_response(message)
            if answer is None:
                return None
            return self.create_llm_response(
                tool_messages=[
                    AgentDoneTool(tools=[CoursesAnswerTool(answer=answer.content)])
                ]
            )

    course_url = "https://csd.cmu.edu/cs-and-related-undergraduate-courses"

    courses_agent = CoursesAgent(
        config=lr.agent.special.DocChatAgentConfig(
            name="Courses",
            llm=llm_config,
            doc_paths=[course_url],  # contents will be ingested into vecdb
            vecdb=QdrantDBConfig(
                collection_name="courses",
                replace_collection=True,
                storage_path=".qdrantdb/data/",
            ),
            parsing=parsing_config,
            n_neighbor_chunks=3,
        )
    )

    courses_task = lr.Task(courses_agent, interactive=False, single_round=True)

    finance_url = "https://www.cmu.edu/sfs/tuition/index.html"
    all_finance_urls = find_urls(finance_url, max_links=20, max_depth=3)

    class FinanceAgent(lr.agent.special.DocChatAgent):
        def llm_response(
            self,
            message: None | str | ChatDocument = None,
        ) -> Optional[ChatDocument]:
            answer = super().llm_response(message)
            if answer is None:
                return None
            return self.create_llm_response(
                tool_messages=[
                    AgentDoneTool(tools=[FinanceAnswerTool(answer=answer.content)])
                ]
            )

    finance_agent = FinanceAgent(
        config=lr.agent.special.DocChatAgentConfig(
            name="Finance",
            llm=llm_config,
            doc_paths=all_finance_urls,  # contents will be ingested into vecdb
            vecdb=QdrantDBConfig(
                collection_name="finances",
                replace_collection=True,
                storage_path=".qdrantdb/data/",
            ),
            parsing=parsing_config,
            n_neighbor_chunks=3,
        )
    )

    finance_task = lr.Task(finance_agent, interactive=False, single_round=True)

    triage_task.add_sub_task([courses_task, finance_task])

    triage_task.run()


if __name__ == "__main__":
    Fire(main)

>>>> examples/basic/oai-asst-chat.py
"""
The most basic chatbot example, using an OpenAssistant agent,
powered by the OpenAI Assistant API.

Run like this:

python3 examples/basic/oai-asst-chat.py
"""

import typer
from rich import print
from rich.prompt import Prompt
from dotenv import load_dotenv

from langroid.agent.openai_assistant import OpenAIAssistant, OpenAIAssistantConfig
from langroid.agent.task import Task
from langroid.language_models.openai_gpt import OpenAIGPTConfig, OpenAIChatModel
from langroid.utils.logging import setup_colored_logging


app = typer.Typer()

setup_colored_logging()


@app.command()
def chat() -> None:
    print(
        """
        [blue]Welcome to the basic chatbot!
        Enter x or q to quit at any point.
        """
    )

    load_dotenv()

    default_sys_msg = "You are a helpful assistant. Be concise in your answers."

    sys_msg = Prompt.ask(
        "[blue]Tell me who I am. Hit Enter for default, or type your own\n",
        default=default_sys_msg,
    )

    config = OpenAIAssistantConfig(
        system_message=sys_msg,
        llm=OpenAIGPTConfig(chat_model=OpenAIChatModel.GPT4o),
    )
    agent = OpenAIAssistant(config)
    task = Task(agent)

    task.run()


if __name__ == "__main__":
    app()

>>>> examples/basic/oai-code-chat.py
"""
The most basic use of code-interpreter, using an OpenAssistant agent,
powered by the OpenAI Assistant API's code-interpreter tool.

Run like this:

python3 examples/basic/oai-code-chat.py
"""

import typer
from rich import print
from rich.prompt import Prompt
from dotenv import load_dotenv
import tempfile

from langroid.agent.openai_assistant import (
    OpenAIAssistant,
    OpenAIAssistantConfig,
    AssistantTool,
    ToolType,
)
from langroid.parsing.url_loader import URLLoader
from langroid.agent.task import Task
from langroid.language_models.openai_gpt import OpenAIGPTConfig, OpenAIChatModel
from langroid.utils.logging import setup_colored_logging


app = typer.Typer()

setup_colored_logging()


@app.command()
def chat() -> None:
    print(
        """
        [blue]Welcome to the basic chatbot!
        Enter x or q to quit at any point.
        """
    )

    load_dotenv()

    default_sys_msg = "You are a helpful assistant. Be concise in your answers."

    sys_msg = Prompt.ask(
        "[blue]Tell me who I am. Hit Enter for default, or type your own\n",
        default=default_sys_msg,
    )

    path = Prompt.ask("Enter a URL or file path, or hit enter if no files")
    if path:
        # if path is a url, use UrlLoader to get text as a document
        if path.startswith("http"):
            text = URLLoader([path]).load()[0].content
            # save text to a temp file
            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".txt", delete=False
            ) as f:
                f.write(text)
                f.close()
                # get the filename
                path = f.name

    config = OpenAIAssistantConfig(
        system_message=sys_msg,
        llm=OpenAIGPTConfig(chat_model=OpenAIChatModel.GPT4o),
    )
    agent = OpenAIAssistant(config)
    agent.add_assistant_tools([AssistantTool(type=ToolType.CODE_INTERPRETER)])
    if path:
        agent.add_assistant_files([path])

    task = Task(agent)

    task.run(
        """
        Help me with some questions, 
        using the CODE INTERPRETER tool, and any uploaded files as needed.
        """
    )


if __name__ == "__main__":
    app()

>>>> examples/basic/plan-subtasks.py
"""
Planner agent receives a math calculation expression from user,
involving + - * / ops, with possible parentheses. Planner has no math abilities,
so it needs to create a plan of elementary operations to compute the result,
and send each step to the appropriate helper agent, who will return the result.

Run like this:

python3 examples/basic/plan-subtasks.py

When it waits for user input, try asking things like:

- (10 + 2)/6 - 1
- 3*(4+1) - 3

"""

import langroid as lr
from langroid.utils.constants import NO_ANSWER, DONE, AT

planner = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Planner",
        system_message=f"""
        User will give you a math calculation, but you have no math abilities.
        However you are a great planner, so your task is to do two things:
        
        1. CREATE a PLAN of what 
          sequence of ELEMENTARY operations (ONLY add/subtract, multiply/divide) need
          to performed, in order to compute what the user asked for.
        2. EMIT the needed operations, ONE BY ONE, and wait for the answer from
            each, before emitting the next operation. Since you cannot directly
            calculate these, you will have to SEND the needed operations to 
            specific helpers, as follows:
            
            * Send Multiplication operation to `Multiplier`
            * Send Add operation to `Adder`
            * Send Subtract operation to `Subtractor`
            * Send Divide operation to `Divider`
            
            To clarify who you are sending the message to, preface your message with
            {AT}<helper_name>, e.g. "{AT}Multiplier multiply with 5" 
            
            When you have the final answer, say {DONE} and show it.
            
            At the START, ask the user what they need help with, 
            address them as "{AT}user"
            
        EXAMPLE: 
        ============
        User: please calculate (4*5 + 1)/3
        Assistant (You): 
            PLAN: 
                1. multiply 4 with 5
                2. add 1 to the result
                3. divide result by 3
            {AT}Multiplier multiply 4 with 5
            [... wait for result, then show your NEW PLAN and send a new request]
            and so on.                         
                        
        """,
    )
)

adder = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Adder",
        system_message=f"""
        If you receive an Add request, return the result,
        otherwise say {NO_ANSWER}.
        """,
    )
)

multiplier = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Multiplier",
        system_message=f"""
        If you receive a Multiply request, return the result,
        otherwise say {NO_ANSWER}.
        """,
    )
)

subtractor = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Subtractor",
        system_message=f"""
        If you receive a Subtraction request, return the result,
        otherwise say {NO_ANSWER}.
        """,
    )
)

divider = lr.ChatAgent(
    lr.ChatAgentConfig(
        name="Divider",
        system_message=f"""
        If you receive a Division request, return the result,
        otherwise say {NO_ANSWER}.
        """,
    )
)


task_config = lr.TaskConfig(addressing_prefix=AT)
planner_task = lr.Task(planner, interactive=False, config=task_config)
adder_task = lr.Task(adder, interactive=False, single_round=True)
multiplier_task = lr.Task(multiplier, interactive=False, single_round=True)
divider_task = lr.Task(divider, interactive=False, single_round=True)
subtractor_task = lr.Task(subtractor, interactive=False, single_round=True)

planner_task.add_sub_task([adder_task, multiplier_task, divider_task, subtractor_task])


planner_task.run()

>>>> examples/basic/planner-workflow.py
"""
Task: Process a number through a sequence of two steps:
- Burify: increment the number by 3
- Tonify: multiply the number by 4

Planner Agent oversees the process, using two worker agents:
- BurifyAgent: handles the Burify step
- TonifyAgent: handles the Tonify step

Planner checks intermediate results and provides feedback to worker agents,
until their step is complete, before proceeding to the next step.

Run like this from repo root (omit `-m` to use default model gpt-4.1-mini):

    uv run examples/basic/planner-workflow.py -m gpt-4.1-mini
"""

from typing import List
import langroid as lr
import langroid.language_models as lm
from langroid.pydantic_v1 import Field
from langroid.agent.tools.orchestration import AgentDoneTool, ForwardTool
from fire import Fire
import logging

logger = logging.getLogger(__name__)
MODEL = lm.OpenAIChatModel.GPT4_1_MINI

class BurifyTool(lr.ToolMessage):
    request: str = "burify_tool"
    purpose: str = "To apply the 'Burify' process to a <number>"
    number: int = Field(..., description="The number (int) to Burify")

    def handle(self) -> str:
        # stateless tool: handler used in BurifyAgent
        return f"Burify this number: {self.number}"


class TonifyTool(lr.ToolMessage):
    request: str = "tonify_tool"
    purpose: str = "To apply the 'Tonify' process to a <number>"
    number: int = Field(..., description="The number (int) to Tonify")

    def handle(self) -> str:
        # stateless tool: handler used in TonifyAgent
        return f"Tonify this number: {self.number}"


class BurifyCheckTool(lr.ToolMessage):
    request: str = "burify_check_tool"
    purpose: str = "To check if the Burify process is complete"
    number: int = Field(..., description="The number (int) to check")
    original_number: int = Field(
        ...,
        description="The original number (int) given to the BurifyAgent",
    )

    def handle(self) -> str:
        # stateless tool
        if self.number == self.original_number + 3:
            return AcceptTool(result=self.number)
        else:
            return BurifyRevisionTool(
                feedback="Burify is NOT complete! Please try again.",
                recipient="Burify",
            )


class TonifyCheckTool(lr.ToolMessage):
    request: str = "tonify_check_tool"
    purpose: str = "To check if the Tonify process is complete"
    number: int = Field(..., description="The number (int) to check")
    original_number: int = Field(
        ...,
        description="The original number (int) given to the TonifyAgent",
    )

    def handle(self):
        # stateless tool
        if self.number == self.original_number * 4:
            return AcceptTool(result=self.number)
        else:
            return TonifyRevisionTool(
                feedback="Tonify is NOT complete! Please try again.",
                recipient="Tonify",
            )


class BurifyRevisionTool(lr.ToolMessage):
    request: str = "burify_revision_tool"
    purpose: str = "To give <feedback> to the  'BurifyAgent' on their Burify Attempt"
    feedback: str = Field(..., description="Feedback for the BurifyAgent")

    def handle(self):
        return f"""
        Below is feedback on your attempt to Burify: 
        <Feedback>
        {self.feedback}
        </Feedback>
        Please try again!
        """


class TonifyRevisionTool(lr.ToolMessage):
    request: str = "tonify_revision_tool"
    purpose: str = "To give <feedback> to the  'TonifyAgent' on their Tonify Attempt"
    feedback: str = Field(..., description="Feedback for the TonifyAgent")

    def handle(self):
        return f"""
        Below is feedback on your attempt to Tonify: 
        <Feedback>
        {self.feedback}
        </Feedback>
        Please try again!
        """


class BurifySubmitTool(lr.ToolMessage):
    request: str = "burify_submit_tool"
    purpose: str = "To submit the result of an attempt of the Burify process"
    result: int = Field(..., description="The result (int) to submit")

    def handle(self):
        return AgentDoneTool(content=str(self.result))


class TonifySubmitTool(lr.ToolMessage):
    request: str = "tonify_submit_tool"
    purpose: str = "To submit the result of an attempt of the Tonify process"
    result: int = Field(..., description="The result (int) to submit")

    def handle(self):
        return AgentDoneTool(content=str(self.result))


class AcceptTool(lr.ToolMessage):
    request: str = "accept_tool"
    purpose: str = "To accept the result of the 'Burify' or 'Tonify' process"
    result: int


class PlannerConfig(lr.ChatAgentConfig):
    name: str = "Planner"
    steps: List[str] = ["Burify", "Tonify"]
    handle_llm_no_tool: str = "You FORGOT to use one of your TOOLs!"
    system_message: str = f"""
    You are a Planner in charge of PROCESSING a given integer through
    a SEQUENCE of 2 processing STEPS, which you CANNOT do by yourself, but you must
    rely on WORKER AGENTS who will do these for you:
    - Burify - will be done by the BurifyAgent
    - Tonify - will be done by the TonifyAgent
    
    In order to INITIATE each process, you MUST use the appropriate TOOLs:
    - `{BurifyTool.name()}` to Burify the number (the tool will be handled by the BurifyAgent)
    - `{TonifyTool.name()}` to Tonify the number (the tool will be handled by the TonifyAgent)
    
    Each of the WORKER AGENTS works like this:
    - The Agent will ATTEMPT a processing step, using the number you give it.
    - You will VERIFY whether the processing step is COMPLETE or NOT
         using the CORRESPONDING CHECK TOOL:
         - check if the Burify step is complete using the `{BurifyCheckTool.name()}`
         - check if the Tonify step is complete using the `{TonifyCheckTool.name()}`
    - If the step is NOT complete, you will ask the Agent to try again,
        by using the CORRESPONDING Revision TOOL where you can include your FEEDBACK: 
        - `{BurifyRevisionTool.name()}` to revise the Burify step
        - `{TonifyRevisionTool.name()}` to revise the Tonify step
    - If you determine (see below) that the step is COMPLETE, you MUST
        use the `{AcceptTool.name()}` to ACCEPT the result of the step.    
    """


class PlannerAgent(lr.ChatAgent):
    current_step: int
    current_num: int
    original_num: int

    def __init__(self, config: PlannerConfig):
        super().__init__(config)
        self.config: PlannerConfig = config
        self.current_step = 0
        self.current_num = 0

    def burify_tool(self, msg: BurifyTool) -> str:
        """Handler of BurifyTool: uses/updates Agent state"""
        self.original_num = msg.number
        logger.warning(f"Planner handled BurifyTool: {self.current_num}")

        return ForwardTool(agent="Burify")

    def tonify_tool(self, msg: TonifyTool) -> str:
        """Handler of TonifyTool: uses/updates Agent state"""
        self.original_num = msg.number
        logger.warning(f"Planner handled TonifyTool: {self.current_num}")

        return ForwardTool(agent="Tonify")

    def accept_tool(self, msg: AcceptTool) -> str:
        """Handler of AcceptTool: uses/updates Agent state"""
        curr_step_name = self.config.steps[self.current_step]
        n_steps = len(self.config.steps)
        self.current_num = msg.result
        if self.current_step == n_steps - 1:
            # last step -> done
            return AgentDoneTool(content=str(self.current_num))

        self.current_step += 1
        next_step_name = self.config.steps[self.current_step]
        return f"""
            You have ACCEPTED the result of the {curr_step_name} step.
            Your next step is to apply the {next_step_name} process
            to the result of the {curr_step_name} step, which is {self.current_num}.
            So use a TOOL to initiate the {next_step_name} process!
            """


class BurifyAgentConfig(lr.ChatAgentConfig):
    name: str = "Burify"
    handle_llm_no_tool: str = f"You FORGOT to use the TOOL `{BurifySubmitTool.name()}`!"
    system_message: str = f"""
    You will receive an integer from your supervisor, to apply
    a process Burify to it, which you are not quite sure how to do,
    but you only know that it involves INCREMENTING the number by 1 a few times
    (but you don't know how many times).
    When you first receive a number to Burify, simply return the number + 1.
    If this is NOT sufficient, you will be asked to try again, and 
    you must CONTINUE to return your last number, INCREMENTED by 1.
    To send your result, you MUST use the TOOL `{BurifySubmitTool.name()}`. 
    """


class TonifyAgentConfig(lr.ChatAgentConfig):
    name: str = "Tonify"
    handle_llm_no_tool: str = f"You FORGOT to use the TOOL `{TonifySubmitTool.name()}`!"
    system_message: str = """
    You will receive an integer from your supervisor, to apply
    a process Tonify to it, which you are not quite sure how to do,
    but you only know that it involves MULTIPLYING the number by 2 a few times
    (and you don't know how many times).
    When you first receive a number to Tonify, simply return the number * 2.
    If this is NOT sufficient, you will be asked to try again, and 
    you must CONTINUE to return your last number, MULTIPLIED by 2.
    To send your result, you MUST use the TOOL `{TonifySubmitTool.name()}`.
    """


def main(model: str = ""):
    planner = PlannerAgent(
        PlannerConfig(
            llm=lm.OpenAIGPTConfig(
                chat_model=model or MODEL,
            )
        ),
    )

    planner.enable_message(
        [
            BurifyRevisionTool,
            TonifyRevisionTool,
        ],
        use=True,  # LLM allowed to generate
        handle=False,  # agent cannot handle
    )

    planner.enable_message(  # can use and handle
        [
            AcceptTool,
            BurifyCheckTool,
            TonifyCheckTool,
            BurifyTool,
            TonifyTool,
        ]
    )

    burifier = lr.ChatAgent(
        BurifyAgentConfig(
            llm=lm.OpenAIGPTConfig(
                chat_model=model or MODEL,
            )
        )
    )
    burifier.enable_message(
        [
            BurifyTool,
            BurifyRevisionTool,
        ],
        use=False,  # LLM cannot generate
        handle=True,  # agent can handle
    )
    burifier.enable_message(BurifySubmitTool)

    tonifier = lr.ChatAgent(
        TonifyAgentConfig(
            llm=lm.OpenAIGPTConfig(
                chat_model=model or MODEL,
            )
        )
    )

    tonifier.enable_message(
        [
            TonifyTool,
            TonifyRevisionTool,
        ],
        use=False,  # LLM cannot generate
        handle=True,  # agent can handle
    )
    tonifier.enable_message(TonifySubmitTool)

    planner_task = lr.Task(planner, interactive=False)
    burifier_task = lr.Task(burifier, interactive=False)
    tonifier_task = lr.Task(tonifier, interactive=False)

    planner_task.add_sub_task(
        [
            burifier_task,
            tonifier_task,
        ]
    )

    # Buify(5) = 5+3 = 8; Tonify(8) = 8*4 = 32
    result = planner_task.run("Sequentially all processes to this number: 5")
    assert "32" in result.content, f"Expected 32, got {result.content}"


if __name__ == "__main__":
    Fire(main)

>>>> examples/basic/python-code-exec-tool.py
"""
Agent that uses a Tool to execute python code.

CAUTION - this is a security risk, as it allows arbitrary code execution.
This is a bare-bones example. For a real application, you would want to restrict
the code in various ways, e.g. by using a sandboxed environment, or by restricting
the modules that can be imported.

Run like this (leave model empty to use default GPT4o)

uv run examples/basic/python-code-exec-tool.py -m gpt4o-mini
"""

import io
import contextlib
from fire import Fire
from rich.prompt import Prompt
from langroid.pydantic_v1 import Field
from langroid.agent.tools.orchestration import ResultTool
import langroid as lr
import langroid.language_models as lm


def execute_code(code_string):
    """
    A minimal function to execute Python code and capture its output.

    Args:
        code_string: The Python code to execute

    Returns:
        Tuple of (output, local_variables)
    """
    # Create dictionary for local variables
    local_vars = {}

    # Capture stdout
    buffer = io.StringIO()

    # Execute code with stdout redirection
    with contextlib.redirect_stdout(buffer):
        try:
            exec(code_string, globals(), local_vars)
            success = True
        except Exception as e:
            print(f"Error: {str(e)}")
            success = False

    output = buffer.getvalue()
    return output, local_vars, success


class PyCodeTool(lr.ToolMessage):
    request: str = "py_code_tool"
    purpose: str = "To execute python <code> and return results"

    code: str = Field(
        ...,
        description="""
            Syntactically valid Python code that can be placed in file to 
            be run by the Python interpreter. MUST NOT CONTAIN any CODE-BLOCK
            delimiters like triple-backticks.
            """,
    )

    def handle(self):
        output, local_vars, success = execute_code(self.code)
        if success:
            print("Successfully ran code. Results:")
            print(output)
            print("Local variables:")
            print(local_vars)
        else:
            print("Failed to run code.")
        return ResultTool(output=output, local_vars=local_vars, success=success)


def main(model: str = ""):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
    )
    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            name="Coder",
            llm=llm_config,
            # handle LLM non-tool msg
            handle_llm_no_tool=lambda msg: ResultTool(
                output=msg.content,
                success=True,
            ),
            system_message=f"""
            You are an expert python coder. When you get a user's message, 
            respond as follows:
            - if you think you need to run Python code,
                use the TOOL `{PyCodeTool.name()}` to perform the task.
            - otherwise simply respond to the user's message.
            """,
        )
    )
    agent.enable_message(PyCodeTool)
    # task specialized to return ResultTool
    # set restart to False to maintain conv history across `run` calls
    task = lr.Task(agent, interactive=False, restart=False)[ResultTool]

    while True:
        user_input = Prompt.ask("User")
        if user_input.lower() in ["x", "q"]:
            break
        result: ResultTool | None = task.run(user_input)
        if result is not None:
            # code was run; do something with the output if any
            if result.success:
                print("Output:", result.output)
            else:
                print("Code execution failed.")


if __name__ == "__main__":
    Fire(main)

>>>> examples/basic/schedule-extract.py
"""
Extract schedule/availability information from unstructured text.

Enter vague, unstructured info like:

M-F 8-3pm at home or Tue/Wed 9-1030am at daycare

Run like this -- (omit the -m arg for default gpt-4o-mini LLM)

```bash
uv run examples/basic/schedule-extract.py -m gpt-4o
"""

import langroid as lr
import langroid.language_models as lm
from langroid.agent.tools.orchestration import FinalResultTool
from typing import List, Dict, Literal, Tuple
from langroid.pydantic_v1 import BaseModel, Field
from rich.prompt import Prompt
from fire import Fire


class Slot(BaseModel):
    start_time: str = Field(..., description="start time of the slot, e.g. 11:30AM")
    end_time: str = Field(..., description="end time of the slot, e.g. 12:30PM")
    location: str = Field(..., description="location of the slot or UNKNOWN")


class DaySchedule(BaseModel):
    """
    A class to represent a day's schedule.
    """

    slots: List[Slot] = Field(..., description="List of time slots for the day")


Weekday = Literal["Mon", "Tue", "Wed", "Thu", "Fri"]


class Availability(BaseModel):
    """
    A class to represent schedule information.
    """

    week_availability: Dict[Weekday, DaySchedule] = Field(
        ...,
        description="""
        Dictionary mapping weekday to DaySchedule,
        where weekday is one of "Mon", "Tue", "Wed", "Thu", "Fri"
        """,
    )


class AvailabilityTool(lr.ToolMessage):
    request: str = "availability_tool"
    purpose: str = """
        To present the available slots from a piece of text.
    """
    availabilities: Availability

    @classmethod
    def examples(cls) -> List["lr.ToolMessage" | Tuple[str, "lr.ToolMessage"]]:
        """
        Example of how to use the tool.
        """
        return [
            (
                """
                I figured out that the availability is 10am-4pm on Mon and Wed at 
                home, and 3-4pm on Monday at daycare
                """,
                cls(
                    availabilities=Availability(
                        week_availability={
                            "Mon": DaySchedule(
                                slots=[
                                    Slot(
                                        start_time="10:00",
                                        end_time="16:00",
                                        location="home",
                                    ),
                                    Slot(
                                        start_time="15:00",
                                        end_time="16:00",
                                        location="daycare",
                                    ),
                                ]
                            ),
                            "Wed": DaySchedule(
                                slots=[
                                    Slot(
                                        start_time="10:00",
                                        end_time="16:00",
                                        location="home",
                                    )
                                ]
                            ),
                        }
                    )
                ),
            )
        ]

    def handle(self) -> str:
        """
        This method is called when the tool is invoked.
        It processes the input and returns the availability information.
        """
        # Here, we would implement the logic to extract availability information
        # from the input text. For this example, we'll just return a placeholder.
        print("Successfully extracted availability information.")
        print(self.availabilities.json(indent=2))
        return FinalResultTool(avails=self.availabilities)


def make_schedule_task(model: str = ""):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o_MINI,
    )
    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            llm=llm_config,
            system_message=f"""
            You are an expert at figuring out schedules from unstructured text.
            You will be given a string that represents availability information.
            Your task is to figure out the available slots and present this info
            using the TOOL `{AvailabilityTool.name()}`, with the `week_availability` 
            field set to a dictionary showing the available slots for certain days
            of the week if any. The string you will get may contain MULTIPLE 
            availabilities for the same day, but at different locations. 
            You have to present the availability information in the `availabilities`
            field, as an Availability object, which is a dictionary mapping
            the day of the week to a DaySchedule object, which is a list of
            Slot objects. The Slot object contains the start time of the slot,
            the duration of the slot in minutes, and the location of the slot.
            """,
        )
    )
    agent.enable_message(AvailabilityTool)
    task = lr.Task(agent, interactive=False, restart=True)[Availability]
    return task


def main(model: str = ""):
    task = make_schedule_task(model)
    while True:
        sched = Prompt.ask("Enter your schedule text")
        avails = task.run(sched, allow_restart=True)
        print(avails)


if __name__ == "__main__":
    Fire(main)

>>>> examples/basic/text-to-structured.py
"""
Function-calling example using a local LLM, with ollama.

"Function-calling" refers to the ability of the LLM to generate
a structured response, typically a JSON object, instead of a plain text response,
which is then interpreted by your code to perform some action.
This is also referred to in various scenarios as "Tools", "Actions" or "Plugins".
See more here: https://langroid.github.io/langroid/quick-start/chat-agent-tool/

Run like this (to run with llama-3.1-8b-instant via groq):

python3 examples/basic/text-to-structured.py -m groq/llama-3.1-8b-instant

Other models to try it with:
- ollama/qwen2.5-coder
- ollama/qwen2.5


See here for how to set up a Local LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/


"""

import os
from typing import List, Literal
import fire
import json
from rich.prompt import Prompt

from langroid.pydantic_v1 import BaseModel, Field
import langroid as lr
from langroid.utils.configuration import settings
from langroid.agent.tool_message import ToolMessage
from langroid.agent.tools.orchestration import ResultTool
import langroid.language_models as lm

# for best results:
DEFAULT_LLM = lm.OpenAIChatModel.GPT4o

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# (1) Define the desired structure via Pydantic.
# The "Field" annotations are optional, and are included in the system message
# if provided, and help with generation accuracy.


class Wifi(BaseModel):
    name: str


class HomeSettings(BaseModel):
    App: List[str] = Field(..., description="List of apps found in text")
    wifi: List[Wifi] = Field(..., description="List of wifi networks found in text")
    brightness: Literal["low", "medium", "high"] = Field(
        ..., description="Brightness level found in text"
    )


# (2) Define the Tool class for the LLM to use, to produce the above structure.
class HomeAutomationTool(lr.agent.ToolMessage):
    """Tool to extract Home Automation structure from text"""

    request: str = "home_automation_tool"
    purpose: str = """
    To extract <home_settings> structure from a given text.
    """
    home_settings: HomeSettings = Field(
        ..., description="Home Automation settings from given text"
    )

    def handle(self) -> str:
        """Handle LLM's structured output if it matches HomeAutomationTool structure"""
        print(
            f"""
            SUCCESS! Got Valid Home Automation Settings:
            {json.dumps(self.home_settings.dict(), indent=2)}
            """
        )
        return ResultTool(settings=self.home_settings)

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        # Used to provide few-shot examples in the system prompt
        return [
            (
                """
                    I have extracted apps Spotify and Netflix, 
                    wifi HomeWifi, and brightness medium
                    """,
                cls(
                    home_settings=HomeSettings(
                        App=["Spotify", "Netflix"],
                        wifi=[Wifi(name="HomeWifi")],
                        brightness="medium",
                    )
                ),
            )
        ]


def app(
    m: str = DEFAULT_LLM,  # model
    d: bool = False,  # pass -d to enable debug mode (see prompts etc)
    nc: bool = False,  # pass -nc to disable cache-retrieval (i.e. get fresh answers)
):
    settings.debug = d
    settings.cache = not nc
    # create LLM config
    llm_cfg = lm.OpenAIGPTConfig(
        chat_model=m or DEFAULT_LLM,
        chat_context_length=4096,  # set this based on model
        max_output_tokens=100,
        temperature=0.2,
        stream=True,
        timeout=45,
    )

    tool_name = HomeAutomationTool.default_value("request")
    config = lr.ChatAgentConfig(
        llm=llm_cfg,
        system_message=f"""
        You are an expert in extracting home automation settings from text.
        When user gives a piece of text, use the TOOL `{tool_name}`
        to present the extracted structured information.
        """,
    )

    agent = lr.ChatAgent(config)

    # (4) Enable the Tool for this agent --> this auto-inserts JSON instructions
    # and few-shot examples (specified in the tool defn above) into the system message
    agent.enable_message(HomeAutomationTool)

    # (5) Create task and run it to start an interactive loop
    # Specialize the task to return a ResultTool object
    task = lr.Task(agent, interactive=False)[ResultTool]

    # set up a loop to extract Home Automation settings from text
    while True:
        text = Prompt.ask("[blue]Enter text (or q/x to exit)")
        if not text or text.lower() in ["x", "q"]:
            break
        result = task.run(text)
        assert isinstance(result, ResultTool)
        assert isinstance(result.settings, HomeSettings)


if __name__ == "__main__":
    fire.Fire(app)

>>>> examples/basic/tool-custom-handler.py
"""
Short example of using `_handler` attribute in ToolMessage to define
custom name for `Agent` tool handler.

Run like this:

python3 examples/basic/tool-custom-handler.py

"""

import requests

import langroid as lr
from langroid.pydantic_v1 import Field


class CountryLanguageTool(lr.agent.ToolMessage):
    request: str = "country_language_tool"
    purpose: str = "To determine <language> spoken in specific country."
    country_name: str = Field(..., description="country name")
    _handler: str = "country_tools_handler"


class CountryPopulationTool(lr.agent.ToolMessage):
    request: str = "country_population_tool"
    purpose: str = "To determine <population> of specific country."
    country_name: str = Field(..., description="country name")
    _handler: str = "country_tools_handler"


class CountryAreaTool(lr.agent.ToolMessage):
    request: str = "country_area_tool"
    purpose: str = "To determine <area> of specific country."
    country_name: str = Field(..., description="country name")
    _handler: str = "country_tools_handler"


class AssistantAgent(lr.ChatAgent):
    def country_tools_handler(self, tool: lr.agent.ToolMessage):
        response = requests.get(
            f"https://restcountries.com/v3.1/name/{tool.country_name}", timeout=5
        )
        if not response.ok:
            return "invalid country name"

        try:
            data = response.json()[0]
        except (ValueError, IndexError):
            return "invalid response"

        match tool.request:
            case "country_language_tool":
                language = ", ".join(data["languages"].values())
                return language
            case "country_population_tool":
                population_millions = data["population"] / 1e6
                return f"{population_millions:.1f} million people"
            case "country_area_tool":
                area_sq_km = data["area"] / 1e6
                return f"{area_sq_km:.1f} million sq. km"

        return "invalid tool name"


def make_assistant_task() -> lr.Task:
    llm_config = lr.language_models.OpenAIGPTConfig(
        temperature=0.2, max_output_tokens=250
    )

    assistant_config = lr.ChatAgentConfig(
        system_message="""
        You are a helpful assistant helping users with country-related questions.

        You know answers to the following questions:
          - what is the <language> spoken in specific country?
          - what is <population> of specific country?
          - what is <areay> of specific country?

        Ask user for the country name and information that he is interested in.
        Then use the appropriate tool to find the answer.
        """,
        llm=llm_config,
    )

    assistant_agent = AssistantAgent(assistant_config)
    assistant_agent.enable_message(CountryLanguageTool)
    assistant_agent.enable_message(CountryPopulationTool)
    assistant_agent.enable_message(CountryAreaTool)

    assistant_task = lr.Task(agent=assistant_agent, interactive=True)
    return assistant_task


if __name__ == "__main__":
    task = make_assistant_task()
    task.run()

>>>> examples/basic/tool-extract-short-example.py
"""
Short example of using Langroid ToolMessage to extract structured info from a passage,
and perform computation on it.

Run like this (omit --model to default to GPT4o):

python3 examples/basic/tool-extract-short-example.py --model deepseek/deepseek-reasoner

or

uv run examples/basic/tool-extract-short-example.py --model deepseek/deepseek-reasoner

"""

import langroid as lr
import langroid.language_models as lm
from langroid.pydantic_v1 import BaseModel, Field
from langroid.agent.tools.orchestration import ResultTool
from rich.prompt import Prompt
from rich import print
from fire import Fire


# desired output structure
class CompanyInfo(BaseModel):
    name: str = Field(..., description="name of company")
    shares: int = Field(..., description="shares outstanding of company")
    price: float = Field(..., description="price per share of company")


# tool definition based on this
class CompanyInfoTool(lr.agent.ToolMessage):
    request: str = "company_info_tool"  # agent method that handles this tool
    purpose: str = (
        "To extract <company_info> from a passage and compute market-capitalization."
    )
    company_info: CompanyInfo

    @classmethod
    def examples(cls):
        """Examples that will be compiled to few-shot examples for the LLM.
        Illustrating two types of examples below:
        - example instance
        - (thought, example) tuple
        """
        return [
            # Example 1: just the instance
            cls(company_info=CompanyInfo(name="IBM", shares=1.24e9, price=140.15)),
            # Example 2: (thought, instance) tuple
            (
                "I want to extract and present company info from the passage",
                cls(
                    company_info=CompanyInfo(name="Apple", shares=16.82e9, price=149.15)
                ),
            ),
        ]

    def handle(self) -> ResultTool:
        """Handle LLM's structured output if it matches CompanyInfo structure.
        This suffices for a "stateless" tool.
        If the tool handling requires agent state, then
        instead of this `handle` method, define a `company_info_tool`
        method in the agent.
        Since this method is returning a  ResultTool,
        the task of this agent will be terminated,
        with this tool T appearing in the result ChatDocument's `tool_messages` list.
        """
        mkt_cap = self.company_info.shares * self.company_info.price
        return ResultTool(
            market_cap=mkt_cap,
            info=self.company_info,
            comment="success",  # arbitrary undeclared fields allowed
        )


# define agent, attach the tool


def main(model: str = ""):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
    )
    agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            llm=llm_config,
            system_message=f"""
            Use the TOOL `{CompanyInfoTool.name()}` 
            tool to extract company information from a passage
            and compute market-capitalization.
            """,
        )
    )

    agent.enable_message(CompanyInfoTool)

    # define and run task on a passage about some company

    task = lr.Task(agent, interactive=False)

    print(
        """
        [blue]Welcome to the company info extractor!
        Write a sentence containing company name, shares outstanding and share price,
        and the Agent will use a tool/function extract the info in structured form,
        and the tool-handler will compute the market-cap.[/blue]
        """
    )

    while True:
        statement = Prompt.ask(
            """
            Enter a sentence containing company name, 
            shares outstanding and share price, or 
            hit enter to use default sentence.
            """,
            default="""
            Qualcomm has shares outstanding of 1.12 billion and a 
            price per share of $217.09.
            """,
        )
        result = task.run(statement)
        if result is None:
            print("Tool-call failed, try again.")
            continue
        # note the result.tool_messages will be a list containing
        # an obj of type FinalResultTool, so we can extract fields from it.
        company_result = result.tool_messages[0]
        assert isinstance(company_result, ResultTool)
        assert isinstance(company_result.info, CompanyInfo)

        info = company_result.info
        mktcap = company_result.market_cap
        assert company_result.comment == "success"
        print(
            f"""
            Found company info: {info} and market cap: {mktcap}
            """
        )


if __name__ == "__main__":
    Fire(main)

>>>> examples/basic/xml_tool.py
"""
Example of defining a variant of an existing tool, but inheriting from XMLToolMessage,
to have the LLM use XML rather than JSON to generate the tool.

This will not work with built-in functions/tools of OpenAI,
so in the `ChatAgentConfig` , you have to set the following to ensure
that Langroid's built-in XML Tool calls are activated:
- `use_functions_api = False`
- `use_tools = True`

Run like this (--model is optional, defaults to GPT4o):

python3 examples/basic/xml_tool.py --model groq/llama-3.1-8b-instant
"""

import langroid as lr
import langroid.language_models as lm
from langroid.pydantic_v1 import Field
from langroid.agent.tools.orchestration import SendTool
from langroid.agent.xml_tool_message import XMLToolMessage
import fire


class XMLSendTool(SendTool, XMLToolMessage):
    """
    Variant of SendTool, using XML rather than JSON.
    """

    request: str = "xml_send_tool"
    purpose: str = """
        To send <content> to an entity/agent identified in the <to> field.
        """

    content: str = Field(
        ...,
        description="The content to send",
        verbatim=True,  # enforces content enclosed within CDATA block in xml.
    )
    to: str


xml_send_tool_name = XMLSendTool.default_value("request")


def main(model: str = ""):
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
    )
    alice = lr.ChatAgent(
        lr.ChatAgentConfig(
            name="Alice",
            llm=llm_config,
            use_functions_api=False,
            use_tools=True,
            system_message=f"""
            Whatever number you receive, send it to Bob using the  
            `{xml_send_tool_name}` tool.
            """,
        )
    )

    bob = lr.ChatAgent(
        lr.ChatAgentConfig(
            name="Bob",
            llm=llm_config,
            use_functions_api=False,
            use_tools=True,
            system_message=f"""
            Whatever number you receive, add 1 to it and send 
            the result back to Alice
            using the `{xml_send_tool_name}` tool.
            """,
        )
    )

    alice.enable_message(XMLSendTool)
    bob.enable_message(XMLSendTool)

    # specialize alice_task to return an int
    alice_task = lr.Task(alice, interactive=False)[int]
    bob_task = lr.Task(bob, interactive=False)

    alice_task.add_sub_task(bob_task)

    result = alice_task.run("5", turns=6)
    assert result == 7


if __name__ == "__main__":
    fire.Fire(main)

>>>> examples/chainlit/README.md
# Running the chainlit apps

In your Python virtual env, ensure you have 
installed `langroid` with the `chainlit` extra using, e.g.

```bash
pip install langroid[chainlit]
```

Or if you already have `langroid` installed, you can install the `chainlit` extra using:

```bash
pip install chainlit
```

To check that `chainlit` is installed, run:

```bash
chainlit hello
```

and you should see the `hello app` open in your browser.


## General usage
See [chainlit docs](https://docs.chainlit.io/get-started/overview) to learn the basics.

Generally speaking to use Langroid `ChatAgents` or `Tasks` with 
`chainlit`, you simply need to wrap your `ChatAgent` or `Task` in the appropriate 
"callback injection" class, e.g. either
```
import langroid as lr
agent = lr.ChatAgent(...)
lr.ChainlitAgentCallbacks(agent) 
```
or 
```
task = lr.Task(...)
lr.ChainlitTaskCallbacks(task) 
```
The `ChainlitTaskCallbacks` class recursively injects callbacks into 
`ChatAgents` belonging to the task, and any sub-tasks.
The callback classes are defined 
[here](https://github.com/langroid/langroid/blob/main/langroid/agent/callbacks/chainlit.py).

You also need to write an `on_chat_start` function and possibly an `on_message`
function to start off the app. See the examples to learn more.

## Configuration

⚠️ It is very important that you download the `.chainlit` directory from the `langroid` repo
(or the `langroid-examples` repo) and place it *in the directory from
which you run the `chainlit` command*. E.g. if you run the `chainlit` command from the
root of the repo, then the `.chainlit` directory should be placed there.
This directory contains various customizations, but most importantly, it contains the
file `translations/en-US.json`, where the default placeholder text in the chat box is defined
(as described below as well). If you've correctly placed this directory, this default text should say
something like 
```
Ask, respond, give feedback, or just 'c' for continue...
```

You can configure some aspects of the chainlit app via these files,
which are included in this repo at the root level (see
the Chainlit [customization docs](https://docs.chainlit.io/customisation/overview) for more details):
- `.chainlit/config.toml` to customize project, features, UI (see [here](https://docs.chainlit.io/backend/config/overview))
- `.chainlit/translations/en-US.json` for various ["translations"](https://docs.chainlit.io/customisation/translation) and language-specific
   customizations. In particular, the default text in the input box is customized here.
- `chainlit.md`, which contains the initial "Readme" content
- [Logo, favicons](https://docs.chainlit.io/customisation/custom-logo-and-favicon) should be placed in a directory
  named `public` adjacent to the apps. 

Depending on how you organize your apps, you may need to run the `chainlit` command 
from the directory where the above customization files/dirs are placed.

>>>> examples/chainlit/books.txt

Book Title: Crime and Redemption by Filidor Dostoyevski, released in 1877, offers a
riveting exploration of guilt, morality, and the possibility of spiritual rebirth.
Set against the bleak backdrop of 19th century Russia, it follows the tormented journey
of Rodion Romanovich Raskolnikov, a young man driven to murder and subsequently
haunted by his actions. Through Raskolnikov's story, Dostoyevski delves deep into the
human psyche, presenting a timeless narrative of human imperfection and the
redemptive power.

Book Title: The Siblings Karamazoff by Fyodar Dostoyevskiy, published in 1881,
weaves a complex narrative around the ethical battles and spiritual dilemmas
faced by the Karamazoff family. Set in the heart of Russia, it explores themes of faith,
doubt, and the nature of free will through the intersecting lives of three brothers,
each embodying different facets of humanity. Dostoyevskiy masterfully crafts a tale of
familial bonds, existential questioning, and the search for truth in a morally ambiguous
world.
>>>> examples/chainlit/chainlit.md
# Welcome to Langroid 👋

![Langroid](public/langroid-card.png)

---
When it is your turn to enter a message, you can do one of two things:
- write `c` to tell the agent to continue,
    - This is provided as a safeguard against infinite loops, or to prevent a large 
    amount of text to be sent to the LLM (which can be costly + slow). 
    If you simply want to continue with normal operation, just enter c.
- write a response, question or feedback to the agent, depending on context.

>>>> examples/chainlit/chat-doc-qa.py
"""
Document question-answering using RAG on a single file, using ChainlitAgentCallbacks.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-doc-qa.py

Note, to run this with a local LLM, you can click the settings symbol
on the left of the chat window and enter the model name, e.g.:

ollama/mistral:7b-instruct-v0.2-q8_0

or

local/localhost:8000/v1"

depending on how you have set up your local LLM.

For more on how to set up a local LLM to work with Langroid, see:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

"""

import chainlit as cl
import langroid as lr
import langroid.parsing.parser as lp
from langroid.agent.special.doc_chat_agent import DocChatAgent, DocChatAgentConfig
from langroid.utils.constants import NO_ANSWER
from langroid.agent.callbacks.chainlit import (
    add_instructions,
    make_llm_settings_widgets,
    setup_llm,
    update_llm,
    get_text_files,
    SYSTEM,
)
from textwrap import dedent


async def initialize_agent() -> None:
    await setup_llm()
    llm_config = cl.user_session.get("llm_config")
    config = DocChatAgentConfig(
        name="DocAgent",
        n_query_rephrases=0,
        hypothetical_answer=False,
        # set it to > 0 to retrieve a window of k chunks on either side of a match
        n_neighbor_chunks=0,
        llm=llm_config,
        parsing=lp.ParsingConfig(  # modify as needed
            splitter=lp.Splitter.TOKENS,
            chunk_size=300,  # aim for this many tokens per chunk
            overlap=30,  # overlap between chunks
            max_chunks=10_000,
            n_neighbor_ids=5,  # store ids of window of k chunks around each chunk.
            # aim to have at least this many chars per chunk when
            # truncating due to punctuation
            min_chunk_chars=200,
            discard_chunk_chars=5,  # discard chunks with fewer than this many chars
            n_similar_docs=3,
            # NOTE: PDF parsing is extremely challenging, each library has its own
            # strengths and weaknesses. Try one that works for your use case.
            pdf=lp.PdfParsingConfig(
                # alternatives: "unstructured", "docling", "fitz"
                library="pymupdf4llm",
            ),
        ),
    )
    agent = DocChatAgent(config)
    cl.user_session.set("agent", agent)


@cl.on_settings_update
async def on_update(settings):
    await update_llm(settings)
    await initialize_agent()


@cl.on_chat_start
async def on_chat_start():
    await add_instructions(
        title="Basic Doc-Question-Answering using RAG (Retrieval Augmented Generation).",
        content=dedent(
            """
        **Upload** a document (click the attachment button in the chat dialog) and ask questions.
        **Change LLM settings** by clicking the settings symbol on the left of the chat window.
        
        You can keep uploading more documents, and questions will be answered based on all documents.
        """
        ),
    )

    await make_llm_settings_widgets()

    cl.user_session.set("callbacks_inserted", False)
    await initialize_agent()


@cl.on_message
async def on_message(message: cl.Message):
    agent: DocChatAgent = cl.user_session.get("agent")
    file2path = await get_text_files(message)
    agent.callbacks.show_start_response(entity="llm")
    if len(file2path) > 0:
        n_files = len(file2path)
        waiting = cl.Message(
            author=SYSTEM, content=f"Received {n_files} files. Ingesting..."
        )
        await waiting.send()
        agent.ingest_doc_paths(list(file2path.values()))
        file_or_files = "file" if n_files == 1 else "files"
        file_list = "\n".join([f"- `{file}`" for file in file2path.keys()])
        waiting.content = dedent(
            f"""
            Ingested `{n_files}` {file_or_files}:
            {file_list}
            """
        )
        await waiting.update()

    if not cl.user_session.get("callbacks_inserted", False):
        # first time user entered a msg, so inject callbacks and display first msg
        lr.ChainlitAgentCallbacks(agent)

    # Note DocChatAgent has no llm_response_async,
    # so we use llm_response with make_async
    response: lr.ChatDocument | None = await cl.make_async(agent.llm_response)(
        message.content
    )
    if response.content.strip() == NO_ANSWER:
        # in this case there were no relevant extracts
        # and we never called the LLM, so response was not shown in UI,
        # hence we need to send it here
        # TODO: It is possible the LLM might have already responded with NO_ANSWER,
        # so we may be duplicating the response here.
        agent.callbacks.show_llm_response(content=NO_ANSWER)

>>>> examples/chainlit/chat-search-assistant-local.py
"""
Chainlit version of examples/basic/chat-search-assistant-local.py,
with a minor change to enable Chainlit callbacks.
Tested and works ok nous-hermes2-mixtral, but may still have issues.
See that script for details.

You can specify a local model in a few different ways, e.g. `groq/llama3-70b-8192`
or `ollama/mistral` etc. See here how to use Langroid with local LLMs:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

Since chainlit does not take cmd line args in the normal way, you have to specify
the model via an environment variable, e.g. `MODEL=ollama/mistral` before the
script is run, e.g.

MODEL=ollama/mistral chainlit run  examples/chainlit/chat-search-assistant-local.py

Note - this is just an example of using an open/local LLM;
 it does not mean that this will work with ANY local LLM.

You may get good results using `groq/llama3-70b-8192` (see the above-linked guide
to using open/local LLMs with Langroid for more details).

"""

from typing import List, Optional, Type
import os
from dotenv import load_dotenv
from textwrap import dedent

import chainlit as cl
import langroid as lr
from langroid.agent.callbacks.chainlit import add_instructions
import langroid.language_models as lm
from langroid import ChatDocument
from langroid.agent.tools.metaphor_search_tool import MetaphorSearchTool
from langroid.utils.configuration import Settings, set_global


class QuestionTool(lr.ToolMessage):
    request: str = "question_tool"
    purpose: str = "Ask a SINGLE <question> that can be answered from a web search."
    question: str

    @classmethod
    def examples(cls) -> List[lr.ToolMessage]:
        return [
            cls(question="Which superconductor material was discovered in 2023?"),
            cls(question="What AI innovation did Meta achieve in 2024?"),
        ]


class FinalAnswerTool(lr.ToolMessage):
    request: str = "final_answer_tool"
    purpose: str = """
        Present the intermediate <steps> and 
        final <answer> to the user's original query.
        """
    steps: str
    answer: str

    @classmethod
    def examples(cls) -> List["lr.ToolMessage"]:
        return [
            cls(
                steps="1. Man is mortal. 2. Plato was a man.",
                answer="Plato was mortal.",
            ),
            cls(
                steps="1. The moon landing was in 1969. 2. Kennedy was president "
                "during 1969.",
                answer="Kennedy was president during the moon landing.",
            ),
        ]


class FeedbackTool(lr.ToolMessage):
    request: str = "feedback_tool"
    purpose: str = "Provide <feedback> on the user's answer."
    feedback: str

    @classmethod
    def examples(cls) -> List["lr.ToolMessage"]:
        return [
            cls(feedback=""),
            cls(
                feedback="""
                The answer is invalid because the conclusion does not follow from the
                steps. Please check your reasoning and try again.
                """
            ),
        ]


class AssistantAgent(lr.ChatAgent):
    n_questions: int = 0  # how many questions in THIS round
    has_asked: bool = False  # has ANY question been asked
    original_query: str | None = None

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.USER:
            # either first query from user, or returned result from Searcher
            self.n_questions = 0  # reset search count

        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            if self.has_asked:
                return f"""
                You may have intended to use a tool, but your JSON format may be wrong.
                
                REMINDER: You must do one of the following:
                - If you are ready with the final answer to the user's ORIGINAL QUERY
                    [ Remember it was: {self.original_query} ],
                  then present your reasoning steps and final answer using the 
                  `final_answer_tool` in the specified JSON format.
                - If you still need to ask a question, then use the `question_tool`
                  to ask a SINGLE question that can be answered from a web search.
                """
            elif self.original_query is not None:
                return f"""
                You must ask a question using the `question_tool` in the specified format,
                to break down the user's original query: {self.original_query} into 
                smaller questions that can be answered from a web search.
                """

    def question_tool(self, msg: QuestionTool) -> str:
        self.n_questions += 1
        self.has_asked = True
        if self.n_questions > 1:
            # there was already a search, so ignore this one
            return ""
        # valid question tool: re-create it so Searcher gets it
        return msg.to_json()

    def final_answer_tool(self, msg: FinalAnswerTool) -> str:
        if not self.has_asked or self.n_questions > 1:
            # not yet asked any questions, or LLM is currently asking
            # a question (and this is the second one in this turn, and so should
            # be ignored), ==>
            # cannot present final answer yet (LLM may have hallucinated this json)
            return ""
        # valid final answer tool: PASS it on so Critic gets it
        return lr.utils.constants.PASS_TO + "Critic"

    def feedback_tool(self, msg: FeedbackTool) -> str:
        if msg.feedback == "":
            return lr.utils.constants.DONE
        else:
            return f"""
            Below is feedback about your answer. Take it into account to 
            improve your answer, and present it again using the `final_answer_tool`.
            
            FEEDBACK:
            
            {msg.feedback}
            """

    async def llm_response_async(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        if self.original_query is None:
            self.original_query = (
                message if isinstance(message, str) else message.content
            )
        result = await super().llm_response_async(message)
        if result is None:
            return result
        # result.content may contain a premature DONE
        # (because weak LLMs tend to repeat their instructions)
        # We deem a DONE to be accidental if no search query results were received
        if not isinstance(message, ChatDocument) or not (
            message.metadata.sender_name == "Searcher"
        ):
            # no search results received yet, so should NOT say DONE
            if isinstance(result, str):
                return result.content.replace(lr.utils.constants.DONE, "")
            result.content = result.content.replace(lr.utils.constants.DONE, "")
            return result

        return result


class CriticAgent(lr.ChatAgent):
    def final_answer_tool(self, msg: FinalAnswerTool) -> str:
        # received from Assistant. Extract the components as plain text,
        # so that the Critic LLM can provide feedback
        return f"""
        The user has presented the following intermediate steps and final answer
        shown below. Please provide feedback using the `feedback_tool`.
        Remember to set the `feedback` field to an empty string if the answer is valid,
        otherwise give specific feedback on what the issues are and how the answer 
        can be improved.
        
        STEPS: {msg.steps}
        
        ANSWER: {msg.answer}
        """

    def feedback_tool(self, msg: FeedbackTool) -> str:
        # say DONE and PASS to the feedback goes back to Assistant to handle
        return lr.utils.constants.DONE + " " + lr.utils.constants.PASS


class SearcherAgentConfig(lr.ChatAgentConfig):
    search_tool_class: Type[lr.ToolMessage]


class SearcherAgent(lr.ChatAgent):
    n_searches: int = 0
    curr_query: str | None = None

    def __init__(self, config: SearcherAgentConfig):
        super().__init__(config)
        self.config: SearcherAgentConfig = config
        self.enable_message(config.search_tool_class)
        self.enable_message(QuestionTool, use=False, handle=True)

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if (
            isinstance(msg, ChatDocument)
            and msg.metadata.sender == lr.Entity.LLM
            and self.n_searches == 0
        ):
            search_tool_name = self.config.search_tool_class.default_value("request")
            return f"""
            You forgot to use the web search tool to answer the 
            user's question : {self.curr_query}.
            REMEMBER - you must ONLY answer the user's questions based on 
             results from a web-search, and you MUST NOT ANSWER them yourself.
             
            Please use the `{search_tool_name}` tool 
            using the specified JSON format, then compose your answer.
            """

    def question_tool(self, msg: QuestionTool) -> str:
        self.curr_query = msg.question
        search_tool_name = self.config.search_tool_class.default_value("request")
        return f"""
        User asked this question: {msg.question}.
        Perform a web search using the `{search_tool_name}` tool
        using the specified JSON format, to find the answer.
        """

    async def llm_response_async(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        if (
            isinstance(message, ChatDocument)
            and message.metadata.sender == lr.Entity.AGENT
            and self.n_searches > 0
        ):
            # must be search results from the web search tool,
            # so let the LLM compose a response based on the search results
            self.n_searches = 0  # reset search count

            result = await super().llm_response_forget_async(message)
            # Augment the LLM's composed answer with a helpful nudge
            # back to the Assistant
            result.content = f"""
            Here are the web-search results for the question: {self.curr_query}.
            ===
            {result.content}
            ===
            Decide if you want to ask any further questions, for the 
            user's original question.             
            """
            self.curr_query = None
            return result

        # Handling query from user (or other agent)
        result = await super().llm_response_forget_async(message)
        if result is None:
            return result
        tools = self.get_tool_messages(result)
        if all(not isinstance(t, self.config.search_tool_class) for t in tools):
            # LLM did not use search tool;
            # Replace its response with a placeholder message
            # and the agent fallback_handler will remind the LLM
            result.content = "Did not use web-search tool."
            return result

        self.n_searches += 1
        # result includes a search tool, but may contain DONE in content,
        # so remove that
        result.content = result.content.replace(lr.utils.constants.DONE, "")
        return result


@cl.on_chat_start
async def main(
    debug: bool = True,
    model: str = os.getenv("MODEL", "gpt-4o"),
    nocache: bool = True,
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    await add_instructions(
        title="2-Agent Search Assistant",
        content=dedent(
            """
        Enter a complex question; 
        - The Assistant will break it down into smaller questions for the Searcher
        - The Searcher will search the web and compose a concise answer
        Once the Assistant has enough information, it will say DONE and present the answer.
        
        To answer a new question, click "New Chat".        
        """
        ),
    )

    load_dotenv()

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,
        temperature=0.2,
        max_output_tokens=500,
        timeout=45,
    )

    assistant_config = lr.ChatAgentConfig(
        system_message="""
        You are a resourceful assistant, able to think step by step to answer
        complex questions from the user. You must break down complex questions into
        simpler questions that can be answered by a web search. You must ask me 
        (the user) each question ONE BY ONE, using the `question_tool` in
         the specified format, and I will do a web search and send you
        a brief answer. Once you have enough information to answer my original
        (complex) question, you MUST present your INTERMEDIATE STEPS and FINAL ANSWER
        using the `final_answer_tool` in the specified JSON format.
        You will then receive FEEDBACK from the Critic, and if needed
        you should try to improve your answer based on this feedback.
        """,
        llm=llm_config,
        vecdb=None,
    )
    assistant_agent = AssistantAgent(assistant_config)
    assistant_agent.enable_message(QuestionTool)
    assistant_agent.enable_message(FinalAnswerTool)
    assistant_agent.enable_message(FeedbackTool, use=False, handle=True)

    search_tool_handler_method = MetaphorSearchTool.name()

    search_agent_config = SearcherAgentConfig(
        search_tool_class=MetaphorSearchTool,
        llm=llm_config,
        vecdb=None,
        system_message=f"""
        You are a web-searcher. For ANY question you get, you must use the
        `{search_tool_handler_method}` tool/function-call to get up to 5 results.
        Once you receive the results, you must compose a CONCISE answer 
        based on the search results and say DONE and show the answer to me,
        along with references, in this format:
        DONE [... your CONCISE answer here ...]
        SOURCES: [links from the web-search that you used]
        
        EXTREMELY IMPORTANT: DO NOT MAKE UP ANSWERS, ONLY use the web-search results.
        """,
    )
    search_agent = SearcherAgent(search_agent_config)

    assistant_task = lr.Task(
        assistant_agent,
        name="Assistant",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )
    search_task = lr.Task(
        search_agent,
        name="Searcher",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )

    critic_agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        vecdb=None,
        system_message="""
        You excel at logical reasoning and combining pieces of information.
        The user will send you a summary of the intermediate steps and final answer.
        You must examine these and provide feedback to the user, using the 
        `feedback_tool`, as follows:
        - If you think the answer is valid, 
            simply set the `feedback` field to an empty string "".
        - Otherwise set the `feedback` field to a reason why the answer is invalid,
            and suggest how the user can improve the answer.
        """,
    )
    critic_agent = CriticAgent(critic_agent_config)
    critic_agent.enable_message(FeedbackTool)
    critic_agent.enable_message(FinalAnswerTool, use=False, handle=True)
    critic_task = lr.Task(
        critic_agent,
        name="Critic",
        interactive=False,
    )
    assistant_task.add_sub_task([search_task, critic_task])
    cl.user_session.set("assistant_task", assistant_task)


@cl.on_message
async def on_message(message: cl.Message):
    assistant_task = cl.user_session.get("assistant_task")
    lr.ChainlitTaskCallbacks(assistant_task)
    await assistant_task.run_async(message.content)

>>>> examples/chainlit/chat-search-assistant.py
"""
Chainlit version of examples/basic/chat-search-assistant.py,
with only a small change to add the Chainlit callbacks.

See that script for details.

Run like this:

chainlit run examples/chainlit/chat-search-assistant.py

To run with a different LLM, set the MODEL environment variable:

MODEL=ollama/mistral chainlit run examples/chainlit/chat-search-assistant.py

or

MODEL=groq/llama3-70b-8192 chainlit run examples/chainlit/chat-search-assistant.py
"""

from dotenv import load_dotenv
from textwrap import dedent

import os
import chainlit as cl
import langroid as lr
from langroid.agent.callbacks.chainlit import add_instructions
import langroid.language_models as lm
from langroid.agent.tools.orchestration import SendTool
from langroid.agent.tools.google_search_tool import GoogleSearchTool
from langroid.agent.tools.duckduckgo_search_tool import DuckduckgoSearchTool
from langroid.utils.configuration import Settings, set_global


@cl.on_chat_start
async def main(
    debug: bool = False,
    # e.g. ollama/mistral or local/localhost:5000/v1 default is GPT4o
    model: str = os.getenv("MODEL", ""),
    provider: str = "metaphor",  # or "google", "ddg"
    nocache: bool = False,
):
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    load_dotenv()

    await add_instructions(
        title="2-Agent Search Assistant",
        content=dedent(
            """
        Enter a complex question; 
        - The Assistant will break it down into smaller questions for the Searcher
        - The Searcher will search the web and compose a concise answer
        
        Once the Assistant has enough information, it will say DONE and present the answer.        
        """
        ),
    )

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=8_000,
        temperature=0,
        max_output_tokens=200,
        timeout=45,
    )

    assistant_config = lr.ChatAgentConfig(
        system_message=f"""
        You are a resourceful assistant, able to think step by step to answer
        complex questions from the user. You must break down complex questions into
        simpler questions that can be answered by a web search agent. You must ask 
        each question ONE BY ONE, and the agent will do a web search and send you
        a brief answer. 
        Once you have enough information to answer my original
        (complex) question, you MUST use the TOOL `{SendTool.name()}`
        with `to` set to "User" to send me the answer. 
        """,
        llm=llm_config,
        vecdb=None,
    )
    assistant_agent = lr.ChatAgent(assistant_config)
    assistant_agent.enable_message(SendTool)

    match provider:
        case "google":
            search_tool_class = GoogleSearchTool
        case "metaphor":
            from langroid.agent.tools.metaphor_search_tool import MetaphorSearchTool

            search_tool_class = MetaphorSearchTool
        case "ddg":
            search_tool_class = DuckduckgoSearchTool
        case _:
            raise ValueError(f"Unsupported provider {provider} specified.")

    search_tool_handler_method = search_tool_class.default_value("request")

    search_agent_config = lr.ChatAgentConfig(
        llm=llm_config,
        vecdb=None,
        system_message=f"""
        You are a web-searcher. For any question you get, you must use the
        `{search_tool_handler_method}` tool/function-call to get up to 5 results.
        I WILL SEND YOU THE RESULTS; DO NOT MAKE UP THE RESULTS!!
        Once you receive the results, you must compose a CONCISE answer 
        based on the search results and say DONE and show the answer to me,
        in this format:
        DONE [... your CONCISE answer here ...]
        IMPORTANT: YOU MUST WAIT FOR ME TO SEND YOU THE 
        SEARCH RESULTS BEFORE saying you're DONE.
        """,
    )
    search_agent = lr.ChatAgent(search_agent_config)
    search_agent.enable_message(search_tool_class)

    assistant_task = lr.Task(
        assistant_agent,
        name="Assistant",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )
    search_task = lr.Task(
        search_agent,
        name="Searcher",
        llm_delegate=True,
        single_round=False,
        interactive=False,
    )
    assistant_task.add_sub_task(search_task)
    cl.user_session.set("assistant_task", assistant_task)


@cl.on_message
async def on_message(message: cl.Message):
    assistant_task = cl.user_session.get("assistant_task")
    lr.ChainlitTaskCallbacks(assistant_task)
    await assistant_task.run_async(message.content)

>>>> examples/chainlit/chat-search-rag.py
"""
Single-agent question-answering system that has access to
Metaphor web search when needed,
and in case a web search is used, ingests contents into a vector-db,
and uses Retrieval Augmentation to answer the question.

This is a chainlit UI version of examples/docqa/chat-search.py

Run like this:

    chainlit run examples/chainlit/chat-search-rag.py


(See here for guide to using local LLMs with Langroid:)
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

from typing import List, Optional, Any

import typer
import langroid as lr
import langroid.language_models as lm
from langroid.agent.tool_message import ToolMessage
from langroid.agent.tools.orchestration import ForwardTool
from langroid.agent.chat_agent import ChatAgent, ChatDocument
from langroid.agent.special.doc_chat_agent import (
    DocChatAgent,
    DocChatAgentConfig,
)
from langroid.parsing.web_search import metaphor_search
from langroid.agent.task import Task
from langroid.parsing.parser import ParsingConfig, PdfParsingConfig, Splitter
from langroid.utils.constants import NO_ANSWER
from langroid.utils.configuration import set_global, Settings

import chainlit as cl
from langroid.agent.callbacks.chainlit import (
    add_instructions,
    make_llm_settings_widgets,
    setup_llm,
    update_llm,
)
from textwrap import dedent
import logging

logger = logging.getLogger(__name__)

app = typer.Typer()


class RelevantExtractsTool(ToolMessage):
    request = "relevant_extracts"
    purpose = "Get docs/extracts relevant to the <query>, from prior search results"
    query: str

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        return [
            cls(query="when was the Mistral LLM released?"),
        ]

    @classmethod
    def instructions(cls) -> str:
        return """
        IMPORTANT: You must include an ACTUAL query in the `query` field,
        """


class RelevantSearchExtractsTool(ToolMessage):
    request = "relevant_search_extracts"
    purpose = (
        "Perform an internet search for up to <num_results> results "
        "relevant to the <query>"
    )

    query: str
    num_results: int = 3

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        return [
            cls(
                query="when was the Mistral LLM released?",
                num_results=3,
            ),
        ]

    @classmethod
    def instructions(cls) -> str:
        return """
        IMPORTANT: You must include an ACTUAL query in the `query` field,
        """


class SearchDocChatAgent(DocChatAgent):
    tried_vecdb: bool = False

    def llm_response_async(
        self,
        message: None | str | ChatDocument = None,
    ) -> Optional[ChatDocument]:
        return ChatAgent.llm_response_async(self, message)

    def handle_message_fallback(self, msg: str | ChatDocument) -> Any:
        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            # non-tool LLM msg => forward to User
            return ForwardTool(agent="User")

    def relevant_extracts(self, msg: RelevantExtractsTool) -> str:
        """Get docs/extracts relevant to the query, from vecdb"""
        self.tried_vecdb = True
        self.callbacks.show_start_response(entity="agent")
        query = msg.query
        logger.info(f"Trying to get relevant extracts for query: {query}")
        _, extracts = self.get_relevant_extracts(query)
        if len(extracts) == 0:
            return """
            No extracts found! You can try doing a web search with the
            `relevant_search_extracts` tool/function-call.
            """
        return "\n".join(str(e) for e in extracts)

    def relevant_search_extracts(self, msg: RelevantSearchExtractsTool) -> str:
        """Get docs/extracts relevant to the query, from a web search"""
        if not self.tried_vecdb and len(self.original_docs) > 0:
            return "Please try the `relevant_extracts` tool, before using this tool"
        query = msg.query
        num_results = msg.num_results
        self.callbacks.show_start_response(entity="agent")
        results = metaphor_search(query, num_results)
        links = [r.link for r in results]
        self.config.doc_paths = links
        self.ingest()
        _, extracts = self.get_relevant_extracts(query)
        if len(extracts) == 0:
            return """
            No release search results found! You can try 
            rephrasing your query to see if results improve, using the
            `relevant_search_extracts` tool/function-call.
            """
        return "\n".join(str(e) for e in extracts)


async def setup_agent_task():
    """Set up Agent and Task from session settings state."""

    # set up LLM and LLMConfig from settings state
    await setup_llm()
    llm_config = cl.user_session.get("llm_config")

    set_global(
        Settings(
            debug=False,
            cache=True,
        )
    )

    config = DocChatAgentConfig(
        name="Searcher",
        llm=llm_config,
        system_message=f"""
        You are a savvy, tenacious, persistent researcher, who knows when to search the 
        internet for an answer.
        
        You will try your best to answer my questions,
        in this order of preference:
        1. If you can answer from your own knowledge, simply return the answer
        2. Otherwise, use the `relevant_extracts` tool/function to
            ask me for some relevant text, and I will send you.  
            Then answer based on the relevant text.
            If I say {NO_ANSWER}, it means I found no relevant docs, and you can try 
            the next step, using a web search.
        3. If you are still unable to answer, you can use the `relevant_search_extracts`
           tool/function-call to get some text from a web search. Answer the question
           based on these text pieces.
        4. If you still can't answer, simply say {NO_ANSWER} 
        5. Be tenacious and persistent, DO NOT GIVE UP. Try asking your questions
        differently to arrive at an answer.
        
        Remember to always FIRST try `relevant_extracts` to see if there are already 
        any relevant docs, before trying web-search with `relevant_search_extracts`.
        
        Be very concise in your responses, use no more than 1-2 sentences.
        When you answer based on provided documents, be sure to show me 
        the SOURCE(s) and EXTRACT(s), for example:
        
        SOURCE: https://www.wikihow.com/Be-a-Good-Assistant-Manager
        EXTRACT: Be a Good Assistant ... requires good leadership skills.
        
        For the EXTRACT, ONLY show up to first 3 words, and last 3 words.
        """,
        parsing=ParsingConfig(  # modify as needed
            splitter=Splitter.TOKENS,
            chunk_size=200,  # aim for this many tokens per chunk
            overlap=30,  # overlap between chunks
            max_chunks=10_000,
            n_neighbor_ids=5,  # store ids of window of k chunks around each chunk.
            # aim to have at least this many chars per chunk when
            # truncating due to punctuation
            min_chunk_chars=200,
            discard_chunk_chars=5,  # discard chunks with fewer than this many chars
            n_similar_docs=3,
            # NOTE: PDF parsing is extremely challenging, each library has its own
            # strengths and weaknesses. Try one that works for your use case.
            pdf=PdfParsingConfig(
                # alternatives: "unstructured", "docling", "fitz"
                library="pymupdf4llm",
            ),
        ),
    )

    agent = SearchDocChatAgent(config)
    agent.enable_message(RelevantExtractsTool)
    agent.enable_message(RelevantSearchExtractsTool)
    collection_name = "chainlit-chat-search-rag"

    agent.vecdb.set_collection(collection_name, replace=True)

    # set up task with interactive=False, so awaits user ONLY
    # when LLM sends  non-tool msg (see handle_message_fallback method).
    task = Task(agent, interactive=False)
    cl.user_session.set("agent", agent)
    cl.user_session.set("task", task)


@cl.on_settings_update
async def on_update(settings):
    await update_llm(settings)
    await setup_agent_task()


@cl.on_chat_start
async def chat() -> None:
    await add_instructions(
        title="Welcome to the Internet Search + RAG chatbot!",
        content=dedent(
            """
        Ask me anything, especially about recent events that I may not have been trained on.
        
        I have access to two Tools, which I will try to use in order of priority:
        - `relevant_extracts` to try to answer your question using Retrieval Augmented Generation
           from prior search results ingested into a vector-DB (from prior searches in this session),
           and failing this, I will use my second tool:
        - `relevant_search_extracts` to do a web search (Using Metaphor Search)
        and ingest the results into the vector-DB, and then use 
        Retrieval Augmentation Generation (RAG) to answer the question.
        """
        ),
    )

    await make_llm_settings_widgets(
        lm.OpenAIGPTConfig(
            timeout=180,
            chat_context_length=16_000,
            chat_model="",
            temperature=0.1,
        )
    )
    await setup_agent_task()


@cl.on_message
async def on_message(message: cl.Message):
    task = cl.user_session.get("task")
    lr.ChainlitTaskCallbacks(task)
    await task.run_async(message.content)

>>>> examples/chainlit/chat-search.py
"""
Basic single-agent chat example, using a web Search Tool, using ChainlitTaskCallbacks.

- User asks a question
- LLM either responds directly or generates a Metaphor web search Tool/function-call
    - if Tool used:
         - Agent handler recognizes this tool and returns search results
         - LLM sees search results and composes a response.
- user asks another question


After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-search.py
"""

from typing import Optional

import chainlit as cl
import langroid as lr
from langroid import ChatDocument
from langroid.agent.tools.metaphor_search_tool import MetaphorSearchTool
from langroid.agent.tools.duckduckgo_search_tool import DuckduckgoSearchTool
from langroid.agent.callbacks.chainlit import (
    add_instructions,
    make_llm_settings_widgets,
    setup_llm,
    update_llm,
)
from textwrap import dedent
import logging

logger = logging.getLogger(__name__)


def search_system_message(search_tool: lr.ToolMessage) -> str:
    tool_name = search_tool.default_value("request")
    sys_msg = f"""
        You are an astute, self-aware AI assistant, and you are adept at 
        responding to a user's question in one of two ways:
        - If you KNOW the answer from your own knowledge, respond directly.
        - OTHERWISE, request up to 5 results from a web search using 
          the `{tool_name}` tool/function-call.
          In this case you will receive the web search results, and you can 
          then compose a response to the user's question. 
    """
    return sys_msg


class SearchAgent(lr.ChatAgent):
    async def user_response_async(
        self, message: Optional[str | ChatDocument] = None
    ) -> Optional[ChatDocument]:
        response = await super().user_response_async(message)
        if response is None:
            return None
        content = response.content
        search_tool = MetaphorSearchTool
        if content.startswith("/"):
            match content[1]:
                case "d":
                    search_tool = DuckduckgoSearchTool
                    self.enable_message(DuckduckgoSearchTool)
                    self.enable_message(MetaphorSearchTool, use=False, handle=False)
                case "m":
                    search_tool = MetaphorSearchTool
                    self.enable_message(MetaphorSearchTool)
                    self.enable_message(DuckduckgoSearchTool, use=False, handle=False)

            self.clear_history(0)
            sys_msg = search_system_message(search_tool)
            self.set_system_message(sys_msg)

            response.content = content[2:]
        return response

    async def agent_response_async(self, message: ChatDocument) -> ChatDocument:
        response = await super().agent_response_async(message)
        if response is None:
            return None
        # ensure tool result goes to LLM
        response.metadata.recipient = lr.Entity.LLM
        return response


async def setup_agent_task(search_tool: lr.ToolMessage):
    """Set up Agent and Task from session settings state."""

    # set up LLM and LLMConfig from settings state
    await setup_llm()
    llm_config = cl.user_session.get("llm_config")
    sys_msg = search_system_message(search_tool)
    config = lr.ChatAgentConfig(
        llm=llm_config,
        name="Searcher",
        system_message=sys_msg,
    )
    agent = SearchAgent(config)
    agent.enable_message(search_tool)
    task = lr.Task(agent, interactive=True)
    cl.user_session.set("agent", agent)
    cl.user_session.set("task", task)


@cl.on_settings_update
async def on_update(settings):
    await update_llm(settings)
    await setup_agent_task(MetaphorSearchTool)


@cl.on_chat_start
async def on_chat_start():
    await add_instructions(
        title="Agent with access to a web search Tool",
        content=dedent(
            """
        Agent uses a tool/fn-call to search the web 
        
        Default search is using DuckDuckGo. You can switch the search to 
        - Duckduckgo by typing `/d` at the start of your question
        - Metaphor by typing `/m` at the start of your question
        
        This is the flow:
        - User asks question
        - Agent LLM uses an internet search tool to generate search results
        - Agent handler recognizes this tool and returns search results
        - User hits `c` to continue
        - Agent LLM composes answer
        
        To change LLM settings, including model name, click the settings symbol on the 
        left of the chat window.        
        """
        ),
    )

    await make_llm_settings_widgets()
    await setup_agent_task(MetaphorSearchTool)


@cl.on_message
async def on_message(message: cl.Message):
    task = cl.user_session.get("task")
    lr.ChainlitTaskCallbacks(task)
    await task.run_async(message.content)

>>>> examples/chainlit/chat-tool.py
"""
Basic single-agent chat example, using task.run(), with a tool, with streaming,
using ChainlitTaskCallbacks.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-tool.py
"""

import langroid as lr
import chainlit as cl
from langroid.agent.callbacks.chainlit import add_instructions
from textwrap import dedent


class CapitalTool(lr.ToolMessage):
    request = "capital"
    purpose = "To present the capital of given <country>."
    country: str
    capital: str

    def handle(self) -> str:
        return f"""
        Success! LLM responded with a tool/function-call, with result:
        
        Capital of {self.country} is {self.capital}.
        """


@cl.on_chat_start
async def on_chat_start():
    config = lr.ChatAgentConfig(
        name="CapitalExpert",
        system_message="""
        When asked for the <capital> of a <country>, present
        your response using the `capital` tool/function-call.
        """,
    )
    agent = lr.ChatAgent(config)
    agent.enable_message(CapitalTool)

    await add_instructions(
        title="Instructions",
        content=dedent(
            """
        Interact with a **Langroid Task**, whose ChatAgent has access 
        to a `capital` tool. You can ask about anything, but whenever you ask 
        about a country's capital, the agent will use the `capital` tool to present 
        the capital of that country. This "tool-message" is handled by the Agent's 
        handler method, and the result is presented as plain text.
        """
        ),
    )
    # inject callbacks into the agent
    task = lr.Task(
        agent,
        interactive=True,
    )
    cl.user_session.set("task", task)


@cl.on_message
async def on_message(message: cl.Message):
    task = cl.user_session.get("task")
    lr.ChainlitTaskCallbacks(task)
    await task.run_async(message.content)

>>>> examples/chainlit/chat-transcript.py
"""
Variant of chat-agent.py, that waits for user to type "/s" (meaning submit)
to store chat transcript in a file.

Directly uses an Agent (i.e. without Task) 
using callbacks, which also enables streaming.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-transcript.py

or:
    
uv run chainlit run examples/chainlit/chat-transcript.py

"""

import chainlit as cl
import langroid as lr
from langroid.agent.callbacks.chainlit import add_instructions
import logging

# set info logger
logging.basicConfig(level=logging.INFO)

FILE = "examples/chainlit/chat-transcript.txt"


@cl.on_chat_start
async def on_chat_start():
    config = lr.ChatAgentConfig(
        name="Demo",
        system_message="You are a helpful assistant. Be concise in your answers.",
    )
    agent = lr.ChatAgent(config)

    cl.user_session.set("agent", agent)

    await add_instructions(
        title="Instructions",
        content="Interact with a **Langroid ChatAgent**",
    )


@cl.on_message
async def on_message(message: cl.Message):
    agent: lr.ChatAgent = cl.user_session.get("agent")
    # important: only apply callbacks after getting first msg.
    lr.ChainlitAgentCallbacks(agent)
    if message.content.startswith("/s"):
        content = message.content
        # get transcript of entire conv history as a string
        history = (
            "\n\n".join(
                [
                    f"{msg.role.value.upper()}: {msg.content}"
                    for msg in agent.message_history
                ]
            )
            + "\n\n"
            + "FINAL User Answer: "
            + content[2:]
        )

        # save chat transcript to file
        with open(FILE, "w") as f:
            f.write(f"Chat transcript:\n\n{history}\n")
            await cl.Message(
                content=f"Chat transcript saved to {FILE}.",
                author="System",
            ).send()
        return

    await agent.llm_response_async(message.content)

>>>> examples/chainlit/chat-transcript.txt
Chat transcript:

SYSTEM: You are a helpful assistant. Be concise in your answers.

USER: what causes smallpox?

ASSISTANT: Smallpox is caused by the variola virus.

USER: is there a vaccine

ASSISTANT: Yes, there is a vaccine for smallpox. The original smallpox vaccine was developed using a related virus called vaccinia. Although routine vaccination for smallpox was stopped after the disease was declared eradicated in 1980, the vaccine is still available for certain groups, such as laboratory workers who handle orthopoxviruses.

FINAL User Answer:  polio is caused by a virus, and there is a vaccine

>>>> examples/chainlit/chat-tree-chainlit.py
"""
Variant of chat-tree.py but with Chainlit UI.
The ONLY change is we apply ChainlitTaskCallbacks() to the top-level task!

Run like this:

chainlit run examples/chainlit/chat-tree-chainlit.py
"""

from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from langroid.language_models.openai_gpt import OpenAIChatModel, OpenAIGPTConfig
from langroid.utils.globals import GlobalState
from langroid.utils.configuration import set_global, Settings
from langroid.utils.constants import DONE
from langroid.agent.callbacks.chainlit import add_instructions
import langroid as lr
import chainlit as cl
from textwrap import dedent

INTERACTIVE = False


class MyGlobalState(GlobalState):
    number: int | None = None


class AskNumTool(ToolMessage):
    request = "ask_num"
    purpose = "Ask user for the initial number"


class AddNumTool(ToolMessage):
    request = "add_num"
    purpose = "Add <number> to the original number, return the result"
    number: int

    def handle(self) -> str:
        """
        This is a stateless tool (i.e. does not use any Agent member vars), so we can
        define the handler right here, instead of defining an `add_num`
        method in the agent.
        """
        return str(int(MyGlobalState.get_value("number")) + int(self.number))


class MainChatAgent(ChatAgent):
    def ask_num(self, msg: AskNumTool) -> str:
        res = self.callbacks.get_user_response(prompt="Please enter a number")
        # record this in global state, so other agents can access it
        num = res
        MyGlobalState.set_values(number=num)
        return str(num)


@cl.on_chat_start
async def on_start():
    await add_instructions(
        title="Multi-agent chat for tree-structured computation with tools",
        content=dedent(
            """
        This task consists of performing this calculation for a given input number n:
        
        ```python
        def Main(n):
            if n is odd:
                return (3*n+1) + n
            else:
                If n is divisible by 10:
                    return n/10 + n
                else:
                    return n/2 + n
        ```
        
        See details in the [chat-tree.py](https://github.com/langroid/langroid/blob/main/examples/basic/chat-tree.py), 
        and the writeup on 
        [Hierarchical Agent Computation](https://langroid.github.io/langroid/examples/agent-tree/).
        
        To start the computation, enter a number.  
        """
        ),
    )


@cl.on_message
async def chat(msg: cl.Message) -> None:
    set_global(
        Settings(
            debug=False,
            cache=True,
            stream=True,
        )
    )

    MyGlobalState.set_values(number=int(msg.content))

    config = ChatAgentConfig(
        llm=OpenAIGPTConfig(
            chat_model=OpenAIChatModel.GPT4o,
        ),
        vecdb=None,
    )

    main_agent = MainChatAgent(config)
    main_task = Task(
        main_agent,
        name="Main",
        interactive=INTERACTIVE,
        system_message="""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        In this case simply write the <number>, say nothing else.
        
        RESULT Message format: RESULT <number>
        In this case simply say "DONE <number>", e.g.:
        DONE 19
        """,
    )

    # Handles only even numbers
    even_agent = ChatAgent(config)
    even_task = Task(
        even_agent,
        name="Even",
        interactive=INTERACTIVE,
        system_message=f"""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        - if the <number> is odd, say '{DONE}'
        - otherwise, simply write the <number>, say nothing else.
        
        RESULT Message format: RESULT <number>
        In this case simply write "DONE RESULT <number>", e.g.:
        DONE RESULT 19
        """,
    )

    # handles only even numbers ending in Zero
    evenz_agent = ChatAgent(config)
    evenz_task = Task(
        evenz_agent,
        name="EvenZ",
        interactive=INTERACTIVE,
        system_message=f"""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        - if <number> n is even AND divisible by 10, compute n/10 and pass it on,
        - otherwise, say '{DONE}'
        
        RESULT Message format: RESULT <number>
        In this case simply write "DONE RESULT <number>", e.g.:
        DONE RESULT 19
        """,
    )

    # Handles only even numbers NOT ending in Zero
    even_nz_agent = ChatAgent(config)
    even_nz_task = Task(
        even_nz_agent,
        name="EvenNZ",
        interactive=INTERACTIVE,
        system_message=f"""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        - if <number> n is even AND NOT divisible by 10, compute n/2 and pass it on,
        - otherwise, say '{DONE}'
        
        RESULT Message format: RESULT <number>
        In this case simply write "DONE RESULT <number>", e.g.:
        DONE RESULT 19
        """,
    )

    # Handles only odd numbers
    odd_agent = ChatAgent(config)
    odd_task = Task(
        odd_agent,
        name="Odd",
        interactive=INTERACTIVE,
        system_message=f"""
        You will receive two types of messages, to which you will respond as follows:
        
        INPUT Message format: <number>
        - if <number> n is odd, compute n*3+1 and write it.
        - otherwise, say '{DONE}'

        RESULT Message format: RESULT <number>        
        In this case simply write "DONE RESULT <number>", e.g.:
        DONE RESULT 19
        """,
    )

    adder_agent = ChatAgent(config)
    # set up the tools
    adder_agent.enable_message(AddNumTool)
    # main_agent.enable_message(AskNumTool)

    adder_task = Task(
        adder_agent,
        name="Adder",
        interactive=INTERACTIVE,
        system_message="""
        You will be given a number n.
        You have to add it to the original number and return the result.
        You do not know the original number, so you must use the 
        `add_num` tool/function for this. 
        When you receive the result, say "DONE RESULT <result>", e.g.
        DONE RESULT 19
        """,
    )

    # set up tasks and subtasks
    main_task.add_sub_task([even_task, odd_task])
    even_task.add_sub_task([evenz_task, even_nz_task])
    evenz_task.add_sub_task(adder_task)
    even_nz_task.add_sub_task(adder_task)
    odd_task.add_sub_task(adder_task)

    # inject chainlit callbacks: this is the ONLY change to chat-tree.py
    lr.ChainlitTaskCallbacks(main_task)

    # start the chat
    await main_task.run_async(msg.content)

>>>> examples/chainlit/chat-with-agent.py
"""
Basic single-agent chat example, to directly use an Agent (i.e. without Task)
using callbacks, which also enables streaming.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-with-agent.py

"""

import chainlit as cl
import langroid as lr
from langroid.agent.callbacks.chainlit import add_instructions
import logging

# set info logger
logging.basicConfig(level=logging.INFO)


@cl.on_chat_start
async def on_chat_start():
    config = lr.ChatAgentConfig(
        name="Demo",
        system_message="You are a helpful assistant. Be concise in your answers.",
    )
    agent = lr.ChatAgent(config)

    cl.user_session.set("agent", agent)

    await add_instructions(
        title="Instructions",
        content="Interact with a **Langroid ChatAgent**",
    )


@cl.on_message
async def on_message(message: cl.Message):
    agent: lr.ChatAgent = cl.user_session.get("agent")
    # important: only apply callbacks after getting first msg.
    lr.ChainlitAgentCallbacks(agent)
    await agent.llm_response_async(message.content)

>>>> examples/chainlit/chat-with-task.py
"""
Basic single-agent chat example using Task along with ChainlitTaskCallbacks.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-with-task.py
"""

import langroid as lr
import chainlit as cl
from langroid.agent.callbacks.chainlit import (
    add_instructions,
    make_llm_settings_widgets,
    update_llm,
    setup_llm,
)
from textwrap import dedent


@cl.on_settings_update
async def on_settings_update(settings: cl.ChatSettings):
    await update_llm(settings)
    await setup_agent_task()


async def setup_agent_task():
    await setup_llm()
    llm_config = cl.user_session.get("llm_config")

    config = lr.ChatAgentConfig(
        llm=llm_config,
        name="Demo",
        system_message="You are a helpful assistant. Be concise in your answers.",
    )
    agent = lr.ChatAgent(config)

    task = lr.Task(
        agent,
        interactive=True,
    )
    cl.user_session.set("task", task)


@cl.on_chat_start
async def on_chat_start():
    await add_instructions(
        title="Basic Langroid Chatbot",
        content=dedent(
            """
        Uses Langroid's `Task.run()`. 
        Before starting the chat, 
        you can change LLM settings by clicking the settings icon next to the chat window.
        """
        ),
    )
    await make_llm_settings_widgets()
    await setup_agent_task()


@cl.on_message
async def on_message(message: cl.Message):
    task = cl.user_session.get("task")
    # sometimes we may want the User to NOT have agent name in front,
    # and just show them as YOU.
    callback_config = lr.ChainlitCallbackConfig(user_has_agent_name=False)
    lr.ChainlitTaskCallbacks(task, config=callback_config)
    await task.run_async(message.content)

>>>> examples/chainlit/cypher_message.py
CONSTRUCT_DEPENDENCY_GRAPH = """
        with "{package_type}" as system, "{package_name}" as name, "{package_version}" as version

        call apoc.load.json("https://api.deps.dev/v3alpha/systems/"+system+"/packages/"
                            +name+"/versions/"+version+":dependencies")
        yield value as r
        
        call {{ with r
                unwind r.nodes as package
                merge (p:Package:PyPi {{name: package.versionKey.name, version: package.versionKey.version}})
                return collect(p) as packages
        }}
        call {{ with r, packages
            unwind r.edges as edge
            with packages[edge.fromNode] as from, packages[edge.toNode] as to, edge
            merge (from)-[rel:DEPENDS_ON]->(to) ON CREATE SET rel.requirement 
            = edge.requirement
            return count(*) as numRels
        }}
        
        match (root:Package:PyPi) where root.imported is null
        set root.imported = true
        with "{package_type}" as system, root.name as name, root.version as version
        call apoc.load.json("https://api.deps.dev/v3alpha/systems/"+system+"/packages/"
                            +name+"/versions/"+version+":dependencies")
        yield value as r
        
        call {{ with r
                unwind r.nodes as package
                merge (p:Package:PyPi {{name: package.versionKey.name, version: package.versionKey.version}})
                return collect(p) as packages
        }}
        call {{ with r, packages
                unwind r.edges as edge
                with packages[edge.fromNode] as from, packages[edge.toNode] as to, edge
                merge (from)-[rel:DEPENDS_ON]->(to) ON CREATE SET 
                rel.requirement = edge.requirement
                return count(*) as numRels
        }}
        return size(packages) as numPackages, numRels
        """

>>>> examples/chainlit/dependency_chatbot.py
"""
Single-agent to use to chat with a Neo4j knowledge-graph (KG)
that models a dependency graph of Python packages.

This is a chainlit UI version of examples/kg-chat/dependency_chatbot.py

Run like this:
```
chainlit run examples/kg-chat/dependency_chatbot.py
```

The requirements are described in
 `https://github.com/langroid/langroid/blob/main/examples/kg-chat/README.md`
"""

import typer
from rich import print

from pyvis.network import Network
import webbrowser
from pathlib import Path

import langroid as lr
import langroid.language_models as lm
import chainlit as cl
from langroid.agent.callbacks.chainlit import (
    add_instructions,
    make_llm_settings_widgets,
    setup_llm,
    update_llm,
)
from textwrap import dedent

from langroid.agent.special.neo4j.neo4j_chat_agent import (
    Neo4jChatAgent,
    Neo4jChatAgentConfig,
    Neo4jSettings,
)
from langroid.utils.constants import NO_ANSWER
from langroid.utils.configuration import set_global, Settings
from langroid.agent.tool_message import ToolMessage
from langroid.agent.tools.google_search_tool import GoogleSearchTool

from langroid.agent.task import Task
from cypher_message import CONSTRUCT_DEPENDENCY_GRAPH

app = typer.Typer()


class DepGraphTool(ToolMessage):
    request = "construct_dependency_graph"
    purpose = f"""Get package <package_version>, <package_type>, and <package_name>.
    For the <package_version>, obtain the recent version, it should be a number. 
    For the <package_type>, return if the package is PyPI or not.
      Otherwise, return {NO_ANSWER}.
    For the <package_name>, return the package name provided by the user.
    ALL strings are in lower case.
    """
    package_version: str
    package_type: str
    package_name: str


class VisualizeGraph(ToolMessage):
    request = "visualize_dependency_graph"
    purpose = """
      Use this tool/function to display the dependency graph.
      """
    package_version: str
    package_type: str
    package_name: str
    query: str


class DependencyGraphAgent(Neo4jChatAgent):
    def construct_dependency_graph(self, msg: DepGraphTool) -> None:
        check_db_exist = (
            "MATCH (n) WHERE n.name = $name AND n.version = $version RETURN n LIMIT 1"
        )
        response = self.read_query(
            check_db_exist, {"name": msg.package_name, "version": msg.package_version}
        )
        if response.success and response.data:
            # self.config.database_created = True
            return "Database Exists"
        else:
            construct_dependency_graph = CONSTRUCT_DEPENDENCY_GRAPH.format(
                package_type=msg.package_type.lower(),
                package_name=msg.package_name,
                package_version=msg.package_version,
            )
            response = self.write_query(construct_dependency_graph)
            if response.success:
                self.config.database_created = True
                return "Database is created!"
            else:
                return f"""
                    Database is not created!
                    Seems the package {msg.package_name} is not found,
                    """

    def visualize_dependency_graph(self, msg: VisualizeGraph) -> str:
        """
        Visualizes the dependency graph based on the provided message.

        Args:
            msg (VisualizeGraph): The message containing the package info.

        Returns:
            str: response indicates whether the graph is displayed.
        """
        # Query to fetch nodes and relationships
        # TODO: make this function more general to return customized graphs
        # i.e, displays paths or subgraphs
        query = """
            MATCH (n)
            OPTIONAL MATCH (n)-[r]->(m)
            RETURN n, r, m
        """

        query_result = self.read_query(query)
        nt = Network(notebook=False, height="750px", width="100%", directed=True)

        node_set = set()  # To keep track of added nodes

        for record in query_result.data:
            # Process node 'n'
            if "n" in record and record["n"] is not None:
                node = record["n"]
                # node_id = node.get("id", None)  # Assuming each node has a unique 'id'
                node_label = node.get("name", "Unknown Node")
                node_title = f"Version: {node.get('version', 'N/A')}"
                node_color = "blue" if node.get("imported", False) else "green"

                # Check if node has been added before
                if node_label not in node_set:
                    nt.add_node(
                        node_label, label=node_label, title=node_title, color=node_color
                    )
                    node_set.add(node_label)

            # Process relationships and node 'm'
            if (
                "r" in record
                and record["r"] is not None
                and "m" in record
                and record["m"] is not None
            ):
                source = record["n"]
                target = record["m"]
                relationship = record["r"]

                source_label = source.get("name", "Unknown Node")
                target_label = target.get("name", "Unknown Node")
                relationship_label = (
                    relationship[1]
                    if isinstance(relationship, tuple) and len(relationship) > 1
                    else "Unknown Relationship"
                )

                # Ensure both source and target nodes are added before adding the edge
                if source_label not in node_set:
                    source_title = f"Version: {source.get('version', 'N/A')}"
                    source_color = "blue" if source.get("imported", False) else "green"
                    nt.add_node(
                        source_label,
                        label=source_label,
                        title=source_title,
                        color=source_color,
                    )
                    node_set.add(source_label)
                if target_label not in node_set:
                    target_title = f"Version: {target.get('version', 'N/A')}"
                    target_color = "blue" if target.get("imported", False) else "green"
                    nt.add_node(
                        target_label,
                        label=target_label,
                        title=target_title,
                        color=target_color,
                    )
                    node_set.add(target_label)

                nt.add_edge(source_label, target_label, title=relationship_label)

        nt.options.edges.font = {"size": 12, "align": "top"}
        nt.options.physics.enabled = True
        nt.show_buttons(filter_=["physics"])

        output_file_path = "neo4j_graph.html"
        nt.write_html(output_file_path)

        # Try to open the HTML file in a browser
        try:
            abs_file_path = str(Path(output_file_path).resolve())
            webbrowser.open("file://" + abs_file_path, new=2)
        except Exception as e:
            print(f"Failed to automatically open the graph in a browser: {e}")


async def setup_agent_task():
    """Set up Agent and Task from session settings state."""

    # set up LLM and LLMConfig from settings state
    await setup_llm()
    llm_config = cl.user_session.get("llm_config")

    set_global(
        Settings(
            debug=False,
            cache=True,
        )
    )

    neo4j_settings = Neo4jSettings()

    dependency_agent = DependencyGraphAgent(
        config=Neo4jChatAgentConfig(
            neo4j_settings=neo4j_settings,
            show_stats=False,
            llm=llm_config,
        ),
    )

    system_message = f"""You are an expert in Dependency graphs and analyzing them using
    Neo4j. 
    
    FIRST, I'll give you the name of the package that I want to analyze.
    
    THEN, you can also use the `web_search` tool/function to find out information about a package,
      such as version number and package type (PyPi or not). 
    
    If unable to get this info, you can ask me and I can tell you.
    
    DON'T forget to include the package name in your questions. 
      
    After receiving this information, make sure the package version is a number and the
    package type is PyPi.
    THEN ask the user if they want to construct the dependency graph,
    and if so, use the tool/function `construct_dependency_graph` to construct
      the dependency graph. Otherwise, say `Couldn't retrieve package type or version`
      and {NO_ANSWER}.
    After constructing the dependency graph successfully, you will have access to Neo4j 
    graph database, which contains dependency graph.
    You will try your best to answer my questions. Note that:
    1. You can use the tool `get_schema` to get node label and relationships in the
    dependency graph. 
    2. You can use the tool `retrieval_query` to get relevant information from the
      graph database. I will execute this query and send you back the result.
      Make sure your queries comply with the database schema.
    3. Use the `web_search` tool/function to get information if needed.
    To display the dependency graph use this tool `visualize_dependency_graph`.
    """
    task = Task(
        dependency_agent,
        name="DependencyAgent",
        system_message=system_message,
    )

    dependency_agent.enable_message(DepGraphTool)
    dependency_agent.enable_message(GoogleSearchTool)
    dependency_agent.enable_message(VisualizeGraph)

    cl.user_session.set("dependency_agent", dependency_agent)
    cl.user_session.set("task", task)


@cl.on_settings_update
async def on_update(settings):
    await update_llm(settings)
    await setup_agent_task()


@cl.on_chat_start
async def chat() -> None:
    await add_instructions(
        title="Welcome to Python Dependency chatbot!",
        content=dedent(
            """
        Ask any questions about Python packages, and I will try my best to answer them.
        But first, the user specifies package name
        -> agent gets version number and type of package using google search
        -> agent builds dependency graph using Neo4j
        -> user asks natural language query about dependencies
        -> LLM translates to Cypher query to get info from KG
        -> Query results returned to LLM
        -> LLM translates to natural language response
        """
        ),
    )

    await make_llm_settings_widgets(
        lm.OpenAIGPTConfig(
            timeout=180,
            chat_context_length=16_000,
            chat_model="",
            temperature=0.1,
        )
    )
    await setup_agent_task()


@cl.on_message
async def on_message(message: cl.Message):
    task = cl.user_session.get("task")
    lr.ChainlitTaskCallbacks(task)
    await task.run_async(message.content)

>>>> examples/chainlit/extract-then-chat.py
"""
3-Agent system to first extract a few pieces of info, then chat with user.

- Assistant: helps user answer questions about a Book. But first it needs to
    extract some information from a document about the Book, using Extractor.
- Extractor: generates questions about the Book document, one by one,
    then returns all info to Assistant using a tool message.
- DocAgent: answers the questions generated by Extractor, based on the Book doc.

Run like this:

chainlit run examples/chainlit/extract-then-chat.py

"""

from langroid import ChatDocument
from langroid.pydantic_v1 import BaseModel
from typing import List
import os

import chainlit as cl
import langroid as lr
import langroid.language_models as lm
from langroid.mytypes import Entity
from langroid.agent.special.doc_chat_agent import DocChatAgent, DocChatAgentConfig
from langroid.parsing.parser import ParsingConfig
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from langroid.utils.configuration import set_global, Settings
from langroid.utils.constants import NO_ANSWER, DONE, SEND_TO, PASS

from langroid.agent.callbacks.chainlit import add_instructions
from textwrap import dedent
from dotenv import load_dotenv

os.environ["TOKENIZERS_PARALLELISM"] = "false"


class BookInfo(BaseModel):
    title: str
    author: str
    year: int


class BookInfoTool(ToolMessage):
    request: str = "book_info"
    purpose: str = "Collect <info> about Books"

    info: List[BookInfo]

    def handle(self) -> str:
        """Exit task and pass tool to parent"""
        return DONE + " " + PASS

    @classmethod
    def examples(cls) -> List["BookInfoTool"]:
        return [
            cls(
                info=[
                    BookInfo(title="The Hobbit", author="J.R.R. Tolkien", year=1937),
                    BookInfo(
                        title="The Great Gatsby",
                        author="F. Scott Fitzgerald",
                        year=1925,
                    ),
                ]
            )
        ]


class Assistant(ChatAgent):
    def book_info(self, msg: BookInfoTool) -> str:
        # convert info  to NON-JSON so it doesn't look like a tool,
        # and insert routing so that the Assistan't LLM responds to it, not user.
        info_str = str(msg.info).replace("{", "[").replace("}", "]")
        return f"""{SEND_TO}LLM
        Below is INFO about various books, you received from the Extractor.
        Now ask the user what help they need, and respond ONLY based on this INFO.
        
        INFO: 
        {info_str} 
        """


class Extractor(ChatAgent):
    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        """Nudge LLM when it fails to use book_info correctly"""
        if self.has_tool_message_attempt(msg):
            return """
            You must use the "book_info" tool to present the info.
            You either forgot to use it, or you used it with the wrong format.
            Make sure all fields are filled out and pay attention to the 
            required types of the fields.
            """


@cl.on_chat_start
async def on_chat_start():
    await add_instructions(
        title="Hello! I am your book info helper. "
        "First I will get info about some books",
        content=dedent(
            """
        Enter `x` or `q` to quit at any point.
        """
        ),
    )

    load_dotenv()

    set_global(
        Settings(
            debug=False,
            cache=True,  # disables cache lookup; set to True to use cache
        )
    )

    llm_cfg = lm.OpenAIGPTConfig(
        # or, e.g. "ollama/mistral:7b-instruct-v0.2-q8_0" but result may be brittle
        chat_model=lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,  # adjust based on model
    )
    doc_agent = DocChatAgent(
        DocChatAgentConfig(
            llm=llm_cfg,
            n_neighbor_chunks=2,
            parsing=ParsingConfig(
                chunk_size=50,
                overlap=10,
                n_similar_docs=3,
                n_neighbor_ids=4,
            ),
            vecdb=lr.vector_store.QdrantDBConfig(
                collection_name="book_info",
                replace_collection=True,
                storage_path=".qdrant/data/",
                cloud=False,
                embedding=lr.embedding_models.SentenceTransformerEmbeddingsConfig(
                    model_type="sentence-transformer",
                    model_name="BAAI/bge-large-en-v1.5",
                ),
            ),
            cross_encoder_reranking_model="",
        )
    )
    doc_agent.ingest_doc_paths(["examples/chainlit/books.txt"])
    doc_task = Task(
        doc_agent,
        name="DocAgent",
        done_if_no_response=[Entity.LLM],  # done if null response from LLM
        done_if_response=[Entity.LLM],  # done if non-null response from LLM
        # Don't use system_message here since it will override doc chat agent's
        # default system message
    )

    extractor_agent = Extractor(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
        )
    )
    extractor_agent.enable_message(BookInfoTool)

    extractor_task = Task(
        extractor_agent,
        name="Extractor",
        interactive=False,  # set to True to slow it down (hit enter to progress)
        system_message=f"""
        You are an expert at understanding JSON function/tool specifications.
        You must extract information about various books from a document,
        to finally present the info using the `book_info` tool/function,
        but you do not have access to the document. 
        I can help with your questions about the document.
        You have to ask questions in these steps:
        1. ask which books are in the document
        2. for each book, ask the various pieces of info you need.
        
        If I am unable to answer your question initially, try asking differently,
        and if I am still unable to answer after 3 tries, 
        fill in {NO_ANSWER} for that field. 
        Think step by step. 
        
        Do not explain yourself, or say any extraneous things. 
        When you receive the answer, then ask for the next field, and so on.
        """,
    )

    assistant_agent = Assistant(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
        )
    )
    assistant_agent.enable_message(lr.agent.tools.RecipientTool)
    # enable assistant to HANDLE the book_info tool but not USE it
    assistant_agent.enable_message(BookInfoTool, use=False, handle=True)
    assistant_task = Task(
        assistant_agent,
        name="Assistant",
        interactive=True,
        system_message="""
        You are a helpful librarian, answering my (the user) questions about 
        books described in a certain document, and you do NOT know which 
        books are in the document.
        
        FIRST you need to ask the "Extractor" to collect information
        about various books that are in a certain document. Address your request to the 
        Extractor using the 'recipient_message' tool/function. 
        
        Once you receive the information, you should then ask me (the user) 
        what I need help with.                
        """,
    )

    assistant_task.add_sub_task([extractor_task])
    extractor_task.add_sub_task([doc_task])

    lr.ChainlitTaskCallbacks(assistant_task)
    # must use run() instead of run_async() because DocChatAgent
    # does not have an async llm_response method
    await assistant_task.run_async()

>>>> examples/chainlit/multi-agent-nested-tool.py
"""
TODO - this example does not work yet due to breaking changes in Chainlit

2-agent chat, using task.run(), where the sub-task uses a tool to get user input.
This illustrates how a sub-task's steps, including tool-calls, are nested
one level under the parent task's steps.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/multi-agent-nested-tool.py
"""

import langroid as lr
import chainlit as cl
from langroid.agent.callbacks.chainlit import ChainlitTaskCallbacks
from langroid.utils.constants import DONE
from langroid.utils.configuration import settings
from langroid.agent.callbacks.chainlit import add_instructions
from textwrap import dedent

settings.cache = False


class ExportTool(lr.ToolMessage):
    request = "main_export"
    purpose = "To request the main export of a given <country>."
    country: str


class StudentChatAgent(lr.ChatAgent):
    def main_export(self, msg: ExportTool) -> str:
        assert (
            self.callbacks.get_user_response is not None
        ), "No get_user_response method"
        assert (
            self.callbacks.show_agent_response is not None
        ), "No show_agent_response method"

        prompt = "Please tell me the main export of " + msg.country
        # create the question for user as an agent response since it
        # will ensure it is shown at right nesting level
        # self.callbacks.show_agent_response(content=prompt)
        user_response = self.callbacks.get_user_response(prompt=prompt)
        res = "the main export is " + user_response
        return res


@cl.on_chat_start
async def on_chat_start():
    await add_instructions(
        title="Two-Agent Demo, where sub-agent uses a Tool/function-call",
        content=dedent(
            """
        **Teacher Agent** delegates to **Student Agent.** 
        - **Teacher** Agent asks a "country export" question to **Student** Agent
        - user (you) hits `c` to continue on to the **Student**
        - **Student** LLM uses `export` tool/fn-call to get answer from user
        - **Student** Agent handler code presents this question to you (user)
        - you answer the question
        - **Student** Agent handler returns your answer
        - **Student** LLM shows the answer
        - user hits `c` to continue on to the **Teacher**
        - **Teacher** Agent gives feedback
        - and so on.
        
        Note how all steps of the (student) sub-task are nested one level below 
        the main (teacher) task.
        """
        ),
    )

    config = lr.ChatAgentConfig()
    teacher_agent = lr.ChatAgent(config)
    teacher_task = lr.Task(
        teacher_agent,
        name="Teacher",
        interactive=True,
        system_message="""
        Ask your student what the main export of a country is, and give feedback. 
        Start with a question!
        """,
    )
    student_agent = StudentChatAgent(config)
    student_agent.enable_message(ExportTool)
    student_task = lr.Task(
        student_agent,
        name="Student",
        interactive=True,
        system_message=f"""
        When you receive a country-export question, 
        use the `main_export` tool to get the answer from the user.
        When you get the answer, say {DONE} and show the answer.
        """,
    )

    teacher_task.add_sub_task(student_task)
    ChainlitTaskCallbacks(teacher_task)
    await teacher_task.run_async()

>>>> examples/chainlit/multi-agent.py
"""
2-agent chat, using task.run(), where:
- Teacher Agent asks a question
- Student Agent answers the question
- Teacher Agent gives feedback
- ...


After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/multi-agent.py
"""

import langroid as lr
import chainlit as cl
import os
from langroid.agent.callbacks.chainlit import ChainlitTaskCallbacks
from langroid.agent.callbacks.chainlit import add_instructions
from langroid.utils.configuration import settings
from textwrap import dedent


@cl.on_chat_start
async def on_chat_start(
    debug: bool = os.getenv("DEBUG", False),
    no_cache: bool = os.getenv("NOCACHE", False),
):
    settings.debug = debug
    settings.cache = not no_cache

    await add_instructions(
        title="Two-Agent Demo",
        content=dedent(
            """
        **Teacher Agent** delegates to **Student Agent.**
        - **Teacher** Agent asks a numerical question to **Student** Agent
        - **Student** Agent answers the question
        - **Teacher** Agent gives feedback        
        - and so on until 10 turns are done.
        
        Note how all steps of the (student) sub-task are nested one level below 
        the main (teacher) task.
        """
        ),
    )
    config = lr.ChatAgentConfig()
    teacher_agent = lr.ChatAgent(config)
    teacher_task = lr.Task(
        teacher_agent,
        name="Teacher",
        interactive=False,
        system_message="""
        Ask your student concise numerical questions, and give feedback. 
        Start with a question!
        """,
    )
    student_agent = lr.ChatAgent(config)
    student_task = lr.Task(
        student_agent,
        name="Student",
        interactive=False,
        system_message="""Concisely answer your teacher's numerical questions""",
        single_round=True,
    )

    teacher_task.add_sub_task(student_task)
    ChainlitTaskCallbacks(teacher_task)
    await teacher_task.run_async(turns=10)

>>>> examples/chainlit/multi-extract-3.py
"""
TODO: Fix this example, it fails due to breaking changes in Chainlit

3-Agent system to extract structured information from a document.
(This is a chainlit version of examples/docqa/chat-multi-extract-3.py)

- LeaseExtractor: is tasked with extracting structured information from a
    commercial lease document, and must present the terms in a specific nested JSON
    format. This agent generates questions corresponding to each field in the JSON
    format.
- Validator: This agent detects if LeaseExtractorAgent's message is asking for ONE
    piece of information, or MULTIPLE pieces. If the message is only asking about ONE
    thing, OR if it is NOT EVEN a question, it responds with "DONE" and says nothing.
    If the message is asking MORE THAN ONE thing, it responds with a message asking to
    only ask ONE question at a time.
    [Why restrict to one question at a time? Because the DocAgent is more likely to
    understand and answer a single question at a time]

- DocAgent: This agent answers the questions generated by LeaseExtractorAgent,
    based on the lease document it has access to via vecdb, using RAG.

Run like this:

```
chainlit run examples/chainlit/multi-extract-3.py
```

Edit the `model` argument in main() fn below to change the model.
If you set it to "", it will default to the GPT4-turbo model.


For more on setting up local LLMs with Langroid, see here:
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

from rich import print
from langroid.pydantic_v1 import BaseModel
from typing import List
import json
import os

import chainlit as cl
import langroid as lr
import langroid.language_models as lm
from langroid.mytypes import Entity
from langroid.agent.special.doc_chat_agent import DocChatAgent, DocChatAgentConfig
from langroid.parsing.parser import ParsingConfig
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from langroid.language_models.openai_gpt import OpenAIGPTConfig
from langroid.utils.configuration import set_global, Settings
from langroid.utils.constants import NO_ANSWER, DONE


os.environ["TOKENIZERS_PARALLELISM"] = "false"


class LeasePeriod(BaseModel):
    start_date: str
    end_date: str


class LeaseFinancials(BaseModel):
    monthly_rent: str
    deposit: str


class Lease(BaseModel):
    """
    Various lease terms.
    Nested fields to make this more interesting/realistic
    """

    period: LeasePeriod
    financials: LeaseFinancials
    address: str


class LeaseMessage(ToolMessage):
    """Tool/function to use to present details about a commercial lease"""

    request: str = "lease_info"
    purpose: str = """
        Collect information about a Commercial Lease.
        """
    terms: Lease
    result: str = ""

    def handle(self) -> str:
        print(
            f"""
        DONE! Successfully extracted Lease Info:
        {self.terms}
        """
        )
        return "DONE " + json.dumps(self.terms.dict())

    @classmethod
    def format_instructions(cls, tool: bool = False) -> str:
        instr = super().format_instructions(tool)
        instr += """
        ------------------------------
        ASK ME QUESTIONS ONE BY ONE, to FILL IN THE FIELDS 
        of the `lease_info` function/tool.
        First ask me for the start date of the lease.
        DO NOT ASK ANYTHING ELSE UNTIL YOU RECEIVE MY ANSWER.
        """
        return instr

    @classmethod
    def examples(cls) -> List["LeaseMessage"]:
        return [
            cls(
                terms=Lease(
                    period=LeasePeriod(start_date="2021-01-01", end_date="2021-12-31"),
                    financials=LeaseFinancials(monthly_rent="$1000", deposit="$1000"),
                    address="123 Main St, San Francisco, CA 94105",
                ),
                result="",
            ),
        ]


@cl.on_chat_start
async def main(
    debug: bool = False,
    model: str = "",  # or e.g. "ollama/nous-hermes2-mixtral",
    cache: bool = False,  # disables cache lookup; set to True to use cache
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=cache,
        )
    )
    llm_cfg = OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,  # adjust based on model
        temperature=0,
        timeout=45,
    )
    doc_agent = DocChatAgent(
        DocChatAgentConfig(
            llm=llm_cfg,
            n_neighbor_chunks=2,
            parsing=ParsingConfig(
                chunk_size=50,
                overlap=10,
                n_similar_docs=3,
                n_neighbor_ids=4,
            ),
            cross_encoder_reranking_model="",
        )
    )
    doc_agent.vecdb.set_collection("docqa-chat-multi-extract", replace=True)
    print("[blue]Welcome to the real-estate info-extractor!")
    doc_agent.config.doc_paths = [
        "examples/docqa/lease.txt",
    ]
    doc_agent.ingest()
    doc_task = Task(
        doc_agent,
        name="DocAgent",
        done_if_no_response=[Entity.LLM],  # done if null response from LLM
        done_if_response=[Entity.LLM],  # done if non-null response from LLM
        system_message="""You are an expert on Commercial Leases. 
        You will receive various questions about a Commercial 
        Lease contract, along with some excerpts from the Lease.
        Your job is to answer them concisely in at most 2 sentences.
        """,
    )

    lease_extractor_agent = ChatAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
        )
    )
    lease_extractor_agent.enable_message(LeaseMessage)

    lease_task = Task(
        lease_extractor_agent,
        name="LeaseExtractor",
        interactive=False,  # set to True to slow it down (hit enter to progress)
        system_message=f"""
        You are an expert at understanding JSON function/tool specifications, and
        you are also very familiar with commercial lease terminology and concepts.
         
        See the `lease_info` function/tool below,  Your FINAL GOAL is to fill
        in the required fields in this `lease_info` function/tool,
        as shown in the example. This is ONLY an EXAMPLE,
        and YOU CANNOT MAKE UP VALUES FOR THESE FIELDS.
        
        To fill in these fields, you must ASK ME QUESTIONS about the lease,
        ONE BY ONE, and I will answer each question. 
        If I am unable to answer your question initially, try asking me 
        differently. If I am still unable to answer after 3 tries, fill in 
        {NO_ANSWER} for that field.
        When you have collected this info, present it to me using the 
        'lease_info' function/tool.
        DO NOT USE THIS Function/tool UNTIL YOU HAVE ASKED QUESTIONS 
        TO FILL IN ALL THE FIELDS.
        
        Think step by step. 
        Phrase each question simply as "What is ... ?",
        and do not explain yourself, or say any extraneous things. 
        Start by asking me for the start date of the lease.
        When you receive the answer, then ask for the next field, and so on.
        """,
    )

    validator_agent = ChatAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
            system_message=f"""
            You are obedient, understand instructions, and follow them faithfully,
            paying attention to the FORMAT specified,
            and you are also extremely CONCISE and SUCCINCT in your responses.
            
            Your task is to detect if the user's message is asking for ONE
            piece of information, or MULTIPLE pieces. Here is how you respond:
            
            IF the msg is only asking about ONE thing, OR if it is NOT EVEN a question:
                respond '{DONE}' and say nothing else.

            IF the msg is asking MORE THAN ONE thing,  respond like this:
            "Please only ask ONE question at a time. Try your question again.
            ONLY when you have ALL the answers, then present the info
            using the `lease_info` function/tool."
            """,
        )
    )
    validator_task = Task(
        validator_agent,
        name="Validator",
        single_round=True,
        interactive=False,
    )

    lease_task.add_sub_task([validator_task, doc_task])
    lr.ChainlitTaskCallbacks(lease_task)

    # DocChatAgent does not have an async llm_response method,
    # so we must use task.run() instead of task.run_async(),
    # but fortunately we can wrap it in a cl.make_async() call
    await cl.make_async(lease_task.run)()

>>>> examples/chainlit/multi-extract.py
"""
TODO: examples does not work due to breaking changes in Chainlit

Two-agent chat with Retrieval-augmented LLM + function-call/tool.
ExtractorAgent (has no access to docs) is tasked with extracting structured
information from a commercial lease document, and must present the terms in
a specific nested JSON format.
This agent generates questions corresponding to each field in the JSON format,
and the RAG-enabled DocAgent (has access to the lease) answers the  questions.

This is a Chainlit version of examples/docqa/chat_multi_extract.py.

Example:
chainlit run examples/chainlit/multi-extract.py

This uses GPT4-turbo by default, but works very well with the `dolphin-mixtral`
local LLM, which you can specify in the llm_config below
using `chat_model = "ollama/dolphin-mixtral:latest"`,
provided you've already spun it up with ollama:
```
ollama run dolphin-mixtral
```

See here for more on setting up LLMs to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

The challenging parts in this script are agent-to-agent delegation, and the extractor
agent planning out a sequence of questions to ask the doc agent, and finally presenting
the collected information in a structured format to the user using a Tool/Function-call.
The `dolphin-mixtral` model seems to handle this pretty well, however weaker models
may not be able to handle this.

"""

from rich import print
from langroid.pydantic_v1 import BaseModel
from typing import List
import json
import os

import langroid as lr
import chainlit as cl
import langroid.language_models as lm
from langroid.mytypes import Entity
from langroid.agent.special.doc_chat_agent import DocChatAgent, DocChatAgentConfig
from langroid.parsing.parser import ParsingConfig
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from langroid.language_models.openai_gpt import OpenAIGPTConfig
from langroid.utils.configuration import set_global, Settings
from langroid.utils.constants import NO_ANSWER

os.environ["TOKENIZERS_PARALLELISM"] = "false"


class LeasePeriod(BaseModel):
    start_date: str
    end_date: str


class LeaseFinancials(BaseModel):
    monthly_rent: str
    deposit: str


class Lease(BaseModel):
    """
    Various lease terms.
    Nested fields to make this more interesting/realistic
    """

    period: LeasePeriod
    financials: LeaseFinancials
    address: str


class LeaseMessage(ToolMessage):
    """Tool/function to use to present details about a commercial lease"""

    request: str = "lease_info"
    purpose: str = """
        Collect information about a Commercial Lease.
        """
    terms: Lease
    result: str = ""

    @classmethod
    def examples(cls) -> List["LeaseMessage"]:
        return [
            cls(
                terms=Lease(
                    period=LeasePeriod(start_date="2021-01-01", end_date="2021-12-31"),
                    financials=LeaseFinancials(monthly_rent="$1000", deposit="$1000"),
                    address="123 Main St, San Francisco, CA 94105",
                ),
                result="",
            ),
            cls(
                terms=Lease(
                    period=LeasePeriod(start_date="2021-04-01", end_date="2022-04-28"),
                    financials=LeaseFinancials(monthly_rent="$2000", deposit="$2000"),
                    address="456 Main St, San Francisco, CA 94111",
                ),
                result="",
            ),
        ]


class LeaseExtractorAgent(ChatAgent):
    def __init__(self, config: ChatAgentConfig):
        super().__init__(config)

    def lease_info(self, message: LeaseMessage) -> str:
        print(
            f"""
        DONE! Successfully extracted Lease Info:
        {message.terms}
        """
        )
        return "DONE \n" + json.dumps(message.terms.dict(), indent=4)


@cl.on_chat_start
async def main(
    debug: bool = False,
    model: str = "",  # or "ollama/dolphin-mixtral:latest"
    nocache: bool = False,
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    llm_cfg = OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,  # adjust based on model
        temperature=0,
        timeout=45,
    )
    doc_agent = DocChatAgent(
        DocChatAgentConfig(
            llm=llm_cfg,
            parsing=ParsingConfig(
                chunk_size=300,
                overlap=50,
                n_similar_docs=3,
            ),
            cross_encoder_reranking_model="",
        )
    )
    doc_agent.vecdb.set_collection("docqa-chat-multi-extract", replace=True)
    print("[blue]Welcome to the real-estate info-extractor!")
    doc_agent.config.doc_paths = [
        "examples/docqa/lease.txt",
    ]
    doc_agent.ingest()
    doc_task = Task(
        doc_agent,
        name="DocAgent",
        done_if_no_response=[Entity.LLM],  # done if null response from LLM
        done_if_response=[Entity.LLM],  # done if non-null response from LLM
        system_message="""You are an expert on Commercial Leases. 
        You will receive various questions about a Commercial 
        Lease contract, along with some excerpts from the Lease.
        Your job is to answer them concisely in at most 2 sentences.
        """,
    )

    lease_extractor_agent = LeaseExtractorAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
        )
    )
    lease_extractor_agent.enable_message(LeaseMessage)

    lease_task = Task(
        lease_extractor_agent,
        name="LeaseExtractor",
        interactive=False,  # set to True to slow it down (hit enter to progress)
        system_message=f"""
        You have to collect some SPECIFIC STRUCTURED information 
        about a Commercial Lease, as specified in the `lease_info` function/tool. 
        But you do not have access to the lease itself. 
        You can ask me questions about the lease, ONE AT A TIME, I will answer each 
        question. You only need to collect info to fill the fields in the 
        `field_info` function/tool. 
        If I am unable to answer your question initially, try asking me 
        differently. If I am still unable to answer after 3 tries, fill in 
        {NO_ANSWER} for that field.
        When you have collected this info, present it to me using the 
        'lease_info' function/tool.
        DO NOT USE THIS Function/tool UNTIL YOU HAVE ASKED QUESTIONS 
        TO FILL IN ALL THE FIELDS.
        
        Start by asking me for the start date of the lease.
        """,
    )
    lease_task.add_sub_task(doc_task)
    # The below line is essentially the ONLY change to make
    # to the original script on which this is based.
    lr.ChainlitTaskCallbacks(lease_task)
    # DocChatAgent does not have an async llm_response method,
    # so we must use task.run() instead of task.run_async(),
    # but fortunately we can wrap it in a cl.make_async() call
    await cl.make_async(lease_task.run)()

>>>> examples/chainlit/non-callback/README.md
## Chainlit examples without using Callbacks

These are all deprecated, but retaining here for reference.
The much better way to use Langroid Agents/Tasks with Chainlit is to use 
the `ChainlitAgentCallbacks` and `ChainlitTaskCallbacks` classes.

>>>> examples/chainlit/non-callback/chat-doc-qa-no-callback.py
"""
Basic single-agent chat example, without streaming.

DEPCRECATED: Script kept only for reference. Best way is to use ChainlitAgentCallbacks,
as in chat-doc-qa.py

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-doc-qa-no-callback.py

Note, to run this with a local LLM, you can click the settings symbol
on the left of the chat window and enter the model name, e.g.:

ollama/mistral:7b-instruct-v0.2-q8_0

or

local/localhost:8000/v1"

depending on how you have set up your local LLM.

For more on how to set up a local LLM to work with Langroid, see:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

"""

import chainlit as cl
import langroid.parsing.parser as lp
import langroid.language_models as lm
from langroid.agent.special.doc_chat_agent import DocChatAgent, DocChatAgentConfig


async def setup_agent() -> None:
    model = cl.user_session.get("settings", {}).get("ModelName")
    print(f"Using model: {model}")
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        # or, other possibilities for example:
        # "litellm/bedrock/anthropic.claude-instant-v1"
        # "ollama/llama2"
        # "local/localhost:8000/v1"
        # "local/localhost:8000"
        chat_context_length=16_000,  # adjust based on model
        timeout=90,
    )

    config = DocChatAgentConfig(
        n_query_rephrases=0,
        hypothetical_answer=False,
        # set it to > 0 to retrieve a window of k chunks on either side of a match
        n_neighbor_chunks=0,
        llm=llm_config,
        parsing=lp.ParsingConfig(  # modify as needed
            splitter=lp.Splitter.TOKENS,
            chunk_size=300,  # aim for this many tokens per chunk
            overlap=30,  # overlap between chunks
            max_chunks=10_000,
            n_neighbor_ids=5,  # store ids of window of k chunks around each chunk.
            # aim to have at least this many chars per chunk when
            # truncating due to punctuation
            min_chunk_chars=200,
            discard_chunk_chars=5,  # discard chunks with fewer than this many chars
            n_similar_docs=3,
            # NOTE: PDF parsing is extremely challenging, each library has its own
            # strengths and weaknesses. Try one that works for your use case.
            pdf=lp.PdfParsingConfig(
                # alternatives: "unstructured", "docling", "fitz"
                library="pymupdf4llm",
            ),
        ),
    )
    agent = DocChatAgent(config)
    cl.user_session.set("agent", agent)
    file = cl.user_session.get("file")
    msg = cl.Message(content=f"Processing `{file.name}`...", disable_feedback=True)
    await msg.send()
    agent.ingest_doc_paths([file.path])
    msg.content = f"Processing `{file.name}` done. Ask questions!"
    await msg.update()


@cl.on_settings_update
async def update_agent(settings):
    cl.user_session.set("settings", settings)
    await setup_agent()


@cl.on_chat_start
async def on_chat_start():
    await cl.ChatSettings(
        [
            cl.input_widget.TextInput(
                id="ModelName",
                label="Model Name (Default GPT4-Turbo)",
                default="",
            )
        ]
    ).send()

    # get file
    files = None
    # Wait for the user to upload a file
    while files is None:
        files = await cl.AskFileMessage(
            content="Please upload a text file to begin!",
            accept=["text/plain"],
            max_size_mb=20,
            timeout=180,
        ).send()

    file = files[0]
    print(f"got file: {file.name}")
    cl.user_session.set("file", file)
    await setup_agent()


@cl.on_message
async def on_message(message: cl.Message):
    agent: DocChatAgent = cl.user_session.get("agent")
    msg = cl.Message(content="")

    # need to do this since DocChatAgent does not have an async version of llm_response
    response = await cl.make_async(agent.llm_response)(message.content)
    msg.content = response.content
    await msg.send()

>>>> examples/chainlit/non-callback/chat-no-callback.py
"""
Basic single-agent chat example, without streaming.

DEPCRECATED: Script kept only for reference.
The better way is shown in chat-agent.py or chat-task.py, which uses callbacks.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-no-callback.py
"""

import chainlit as cl
import langroid as lr


@cl.on_chat_start
async def on_chat_start():
    sys_msg = "You are a helpful assistant. Be concise in your answers."
    config = lr.ChatAgentConfig(
        system_message=sys_msg,
    )
    agent = lr.ChatAgent(config)
    cl.user_session.set("agent", agent)


@cl.on_message
async def on_message(message: cl.Message):
    agent: lr.ChatAgent = cl.user_session.get("agent")
    response = await agent.llm_response_async(message.content)
    msg = cl.Message(content=response.content)
    await msg.send()

>>>> examples/chainlit/non-callback/chat-search-no-callback.py
"""
Basic single-agent chat example, using a web Search Tool, without streaming.

DEPCRECATED: Script kept only for reference. The better way is shown in
chat-search.py, which uses ChainlitTaskCallbacks.

- User asks a question
- LLM either responds directly or generates a Metaphor web search Tool/function-call
    - if Tool used:
         - Agent handler recognizes this tool and returns search results
         - LLM sees search results and composes a response.
- user asks another question


After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-search-no-callback.py
"""

import chainlit as cl
import langroid as lr
from langroid.agent.tools.metaphor_search_tool import MetaphorSearchTool


@cl.step(name="LLM Response")
async def llm_response(msg: str) -> lr.ChatDocument:
    agent: lr.ChatAgent = cl.user_session.get("agent")
    response = await agent.llm_response_async(msg)
    return response


@cl.step(name="Agent Tool Handler")
async def agent_response(msg: lr.ChatDocument) -> lr.ChatDocument:
    agent: lr.ChatAgent = cl.user_session.get("agent")
    response = await agent.agent_response_async(msg)
    return response


@cl.on_chat_start
async def on_chat_start():
    tool_name = MetaphorSearchTool.default_value("request")
    sys_msg = f"""
        You are an astute, self-aware AI assistant, and you are adept at 
        responding to a user's question in one of two ways:
        - If you KNOW the answer from your own knowledge, respond directly.
        - OTHERWISE, request up to 5 results from a web search using 
          the `{tool_name}` tool/function-call.
          In this case you will receive the web search results, and you can 
          then compose a response to the user's question. 
    """
    config = lr.ChatAgentConfig(
        system_message=sys_msg,
    )
    agent = lr.ChatAgent(config)
    agent.enable_message(MetaphorSearchTool)
    cl.user_session.set("agent", agent)


@cl.on_message
async def on_message(message: cl.Message):
    agent: lr.ChatAgent = cl.user_session.get("agent")
    msg = cl.Message(content="")
    # expecting a tool here
    response = await llm_response(message.content)
    if agent.has_tool_message_attempt(response):
        search_results = await agent_response(response)
        response = await llm_response(search_results)
    msg.content = response.content
    await msg.send()

>>>> examples/chainlit/non-callback/chat-stream.py
"""
DEPRECATED, not guaranteed to work: We are keeping this example for reference,
but do not use this as way to chat with streaming.
See chat-callback.py for the best way to do this
(i.e. use ChainlitAgentCallbacks when interacting directly an Agent,
or use ChainlitTaskCallbacks when interacting with a Task).

Basic single-agent chat example, with streaming,
using an older method, rather than the best way,
which is via callbacks, as in chat-callback.py.


After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-stream.py
"""

import chainlit as cl
from langroid import ChatAgent, ChatAgentConfig
from langroid.utils.configuration import settings

import re
import sys
import asyncio

settings.stream = True  # works if False as well


class ContinuousCaptureStream:
    """
    Capture stdout in a stream.
    This allows capturing of streaming output that would normally be printed to stdout,
    e.g. streaming tokens coming from OpenAI's API.
    """

    def __init__(self):
        self.content = ""
        self.new_content_event = asyncio.Event()
        self.is_finished = False  # Flag to indicate completion

    def write(self, data):
        self.content += data
        self.new_content_event.set()

    def flush(self):
        pass

    async def get_new_content(self):
        await self.new_content_event.wait()
        self.new_content_event.clear()
        new_content, self.content = self.content, ""
        return new_content

    def set_finished(self):
        self.is_finished = True
        self.new_content_event.set()  # T


def strip_ansi_codes(text):
    ansi_escape = re.compile(
        r"(?:\x1B[@-_]|[\x80-\x9A\x9C-\x9F]|[\x1A-\x1C\x1E-\x1F])+\[[0-?]*[ -/]*[@-~]"
    )
    return ansi_escape.sub("", text)


@cl.on_chat_start
async def on_chat_start():
    sys_msg = "You are a helpful assistant. Be concise in your answers."
    config = ChatAgentConfig(
        system_message=sys_msg,
        show_stats=False,
    )
    agent = ChatAgent(config)
    cl.user_session.set("agent", agent)


@cl.on_message
async def on_message(message: cl.Message):
    agent: ChatAgent = cl.user_session.get("agent")
    msg = cl.Message(content="")
    await msg.send()

    capture_stream = ContinuousCaptureStream()
    original_stdout = sys.stdout
    sys.stdout = capture_stream

    # Run response() in a separate thread or as a non-blocking call
    asyncio.create_task(run_response(agent, message, capture_stream))

    while not capture_stream.is_finished:
        new_output = await capture_stream.get_new_content()
        new_output = strip_ansi_codes(new_output)
        if new_output:
            await msg.stream_token(new_output)

    # Restore original stdout when done
    sys.stdout = original_stdout

    await msg.update()


async def run_response(agent: ChatAgent, message: cl.Message, stream):
    await agent.llm_response_async(message.content)
    stream.set_finished()

>>>> examples/chainlit/non-callback/chat-tool-no-callback.py
"""
Basic single-agent chat example, using a Tool, without streaming.
DEPCRECATED: Script kept only for reference.
The better way is shown in chat-task-tool, which uses ChainlitTaskCallbacks.

- User enters a country
- LLM responds with a tool/function-call showing {country=country, capital=...}
- Agent handler recognizes this tool and returns plain text version of the tool result.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/chat-tool-no-callback.py
"""

import chainlit as cl
import langroid as lr


class CapitalTool(lr.ToolMessage):
    request = "capital"
    purpose = "To present the capital of given <country>."
    country: str
    capital: str

    def handle(self) -> str:
        return f"""
        Success! LLM responded with a tool/function-call, with result:
        Capital of {self.country} is {self.capital}.
        """


@cl.step
async def llm_tool_call(msg: str) -> lr.ChatDocument:
    agent: lr.ChatAgent = cl.user_session.get("agent")
    response = await agent.llm_response_async(msg)
    return response


@cl.on_chat_start
async def on_chat_start():
    sys_msg = """
        You are an expert in country capitals.
        When user gives a country name, you should respond 
        with the capital of that country, using the `capital` tool/function-call.
    """
    config = lr.ChatAgentConfig(
        system_message=sys_msg,
    )
    agent = lr.ChatAgent(config)
    agent.enable_message(CapitalTool)
    cl.user_session.set("agent", agent)


@cl.on_message
async def on_message(message: cl.Message):
    agent: lr.ChatAgent = cl.user_session.get("agent")
    msg = cl.Message(content="")
    # expecting a tool here
    tool = await llm_tool_call(message.content)
    tool_result = await agent.agent_response_async(tool)
    msg.content = tool_result.content
    await msg.send()

>>>> examples/chainlit/simplest.py
"""
Absolute bare-bones way to set up a simple chatbot using all default settings,
using a Langroid Task + callbacks.

After setting up the virtual env as in README,
and you have your OpenAI API Key in the .env file, run like this:

chainlit run examples/chainlit/simplest.py
"""

import langroid as lr
import langroid.language_models as lm
import chainlit as cl


@cl.on_message
async def on_message(message: cl.Message):
    lm_config = lm.OpenAIGPTConfig()
    agent = lr.ChatAgent(lr.ChatAgentConfig(llm=lm_config))
    task = lr.Task(agent, interactive=True)

    lr.ChainlitTaskCallbacks(task)
    await task.run_async(message.content)

>>>> examples/chainlit/test-step-nesting.py
"""
Test whether the current chainlit version shows nested steps as expected.
Note that this does NOT show what you'd expect, due to breaking changes in Chainlit.

Two things to look for:
(1) are all types of steps shown, or only type = "tool"?
(2) when step B has parent_id pointing to Step A, we want to see Step B shown:
    - nested under Step A
    - shown in a chronologically correct order, i.e. if Step A says "hello",
        then calls Step B, then step B should be shown AFTER the "hello" message from A.

(1) is fine in chainlit 1.1.202, i.e. all steps are shown whether tools or not
    but in 1.1.300, only type = "tool" steps are shown.
    For example if the `type` params are other than "tool" in the example below,
    the steps will not show up in the chat.
(2) is broken in 1.1.202 -- the sub-step is correctly nested BUT always shows up
    at the TOP, and can look very unintuitive, as this example shows.
"""

import chainlit as cl


@cl.on_chat_start
async def on_chat_start():
    a_step = cl.Step(name="A", type="tool")
    a_step.output = "asking B"
    await a_step.send()

    b_step = cl.Step(
        name="B",
        parent_id=a_step.id,
        type="tool",
    )
    b_step.output = "asking C"
    await b_step.send()

    c_step = cl.Step(
        name="C",
        parent_id=b_step.id,
        type="tool",
    )
    c_step.output = "C answered!"
    await c_step.send()

>>>> examples/data-qa/__init__.py

>>>> examples/data-qa/sql-chat/__init__.py

>>>> examples/data-qa/sql-chat/demo.json
{
    "departments": {
        "description": "The 'departments' table holds details about the various departments. It relates to the 'employees' table via a foreign key in the 'employees' table.",
        "columns": {
            "id": "A unique identifier for a department. This ID is used as a foreign key in the 'employees' table.",
            "name": "The name of the department."
        }
    },
    "employees": {
        "description": "The 'employees' table contains information about the employees. It relates to the 'departments' and 'sales' tables via foreign keys.",
        "columns": {
            "id": "A unique identifier for an employee. This ID is used as a foreign key in the 'sales' table.",
            "name": "The name of the employee.",
            "department_id": "The ID of the department the employee belongs to. This is a foreign key referencing the 'id' in the 'departments' table."
        }
    },
    "sales": {
        "description": "The 'sales' table keeps a record of all sales made by employees. It relates to the 'employees' table via a foreign key.",
        "columns": {
            "id": "A unique identifier for a sale.",
            "amount": "The amount of the sale in eastern Caribbean dollars (XCD).",
            "employee_id": "The ID of the employee who made the sale. This is a foreign key referencing the 'id' in the 'employees' table."
        }
    }
}
>>>> examples/data-qa/sql-chat/sql_chat.py
"""
Example showing how to chat with a SQL database.

Note if you are using this with a postgres db, you will need to:

(a) Install PostgreSQL dev libraries for your platform, e.g.
    - `sudo apt-get install libpq-dev` on Ubuntu,
    - `brew install postgresql` on Mac, etc.
(b) langroid with the postgres extra, e.g. `pip install langroid[postgres]`
    or `poetry add langroid[postgres]` or `poetry install -E postgres`
    or `uv pip install langroid[postgres]` or `uv add langroid[postgres]`.
    If this gives you an error, try `pip install psycopg2-binary` in your virtualenv.
"""

import typer
from rich import print
from rich.prompt import Prompt
from typing import Dict, Any
import json
import os
from langroid.exceptions import LangroidImportError

try:
    from sqlalchemy import create_engine, inspect
    from sqlalchemy.engine import Engine
except ImportError as e:
    raise LangroidImportError(extra="sql", error=str(e))

from prettytable import PrettyTable

try:
    from .utils import get_database_uri, fix_uri
except ImportError:
    from utils import get_database_uri, fix_uri
from langroid.agent.task import Task
from langroid.agent.special.sql.sql_chat_agent import (
    SQLChatAgentConfig,
    SQLChatAgent,
)
from langroid.language_models.openai_gpt import OpenAIChatModel, OpenAIGPTConfig
from langroid.utils.configuration import set_global, Settings
from langroid.utils.constants import SEND_TO
import logging

logger = logging.getLogger(__name__)


app = typer.Typer()


def create_descriptions_file(filepath: str, engine: Engine) -> None:
    """
    Create an empty descriptions JSON file for SQLAlchemy tables.

    This function inspects the database, generates a template for table and
    column descriptions, and writes that template to a new JSON file.

    Args:
        filepath: The path to the file where the descriptions should be written.
        engine: The SQLAlchemy Engine connected to the database to describe.

    Raises:
        FileExistsError: If the file at `filepath` already exists.

    Returns:
        None
    """
    if os.path.exists(filepath):
        raise FileExistsError(f"File {filepath} already exists.")

    inspector = inspect(engine)
    descriptions: Dict[str, Dict[str, Any]] = {}

    for table_name in inspector.get_table_names():
        descriptions[table_name] = {
            "description": "",
            "columns": {col["name"]: "" for col in inspector.get_columns(table_name)},
        }

    with open(filepath, "w") as f:
        json.dump(descriptions, f, indent=4)


def load_context_descriptions(engine: Engine) -> dict:
    """
    Ask the user for a path to a JSON file and load context descriptions from it.

    Returns:
        dict: The context descriptions, or an empty dictionary if the user decides to skip this step.
    """

    while True:
        filepath = Prompt.ask(
            "[blue]Enter the path to your context descriptions file. \n"
            "('n' to create a NEW file, 's' to SKIP, or Hit enter to use DEFAULT) ",
            default="examples/data-qa/sql-chat/demo.json",
        )

        if filepath.strip() == "s":
            return {}

        if filepath.strip() == "n":
            filepath = Prompt.ask(
                "[blue]To create a new context description file, enter the path",
                default="examples/data-qa/sql-chat/description.json",
            )
            print(f"[blue]Creating new context description file at {filepath}...")
            create_descriptions_file(filepath, engine)
            print(
                f"[blue] Please fill in the descriptions in {filepath}, "
                f"then try again."
            )

        # Try to load the file
        if not os.path.exists(filepath):
            print(f"[red]The file '{filepath}' does not exist. Please try again.")
            continue

        try:
            with open(filepath, "r") as file:
                return json.load(file)
        except json.JSONDecodeError:
            print(
                f"[red]The file '{filepath}' is not a valid JSON file. Please try again."
            )


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    tools: bool = typer.Option(
        False, "--tools", "-t", help="use langroid tools instead of function-calling"
    ),
    schema_tools: bool = typer.Option(
        False, "--schema_tools", "-st", help="use schema tools"
    ),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
            cache_type="redis",
        )
    )
    print("[blue]Welcome to the SQL database chatbot!\n")
    database_uri = Prompt.ask(
        """
        [blue]Enter the URI for your SQL database 
        (type 'i' for interactive, or hit enter for default)
        """,
        default="sqlite:///examples/data-qa/sql-chat/demo.db",
    )

    if database_uri == "i":
        database_uri = get_database_uri()

    database_uri = fix_uri(database_uri)
    logger.warning(f"Using database URI: {database_uri}")

    # Create engine and inspector
    engine = create_engine(database_uri)
    inspector = inspect(engine)

    context_descriptions = load_context_descriptions(engine)

    # Get table names
    table_names = inspector.get_table_names()

    for table_name in table_names:
        print(f"[blue]Table: {table_name}")

        # Create a new table for the columns
        table = PrettyTable()
        table.field_names = ["Column Name", "Type"]

        # Get the columns for the table
        columns = inspector.get_columns(table_name)
        for column in columns:
            table.add_row([column["name"], column["type"]])

        print(table)

    agent_config = SQLChatAgentConfig(
        name="sql",
        database_uri=database_uri,
        use_tools=tools,
        use_functions_api=not tools,
        show_stats=False,
        chat_mode=True,
        use_helper=True,
        context_descriptions=context_descriptions,  # Add context descriptions to the config
        use_schema_tools=schema_tools,
        addressing_prefix=SEND_TO,
        llm=OpenAIGPTConfig(
            chat_model=OpenAIChatModel.GPT4o,
        ),
    )
    agent = SQLChatAgent(agent_config)
    # Set interactive = False, but we user gets chance to respond
    # when explicitly addressed by LLM
    task = Task(agent, interactive=False)
    task.run()


if __name__ == "__main__":
    app()

>>>> examples/data-qa/sql-chat/utils.py
from rich import print
from rich.prompt import Prompt
import urllib.parse

from langroid.parsing.utils import closest_string
import logging

logger = logging.getLogger(__name__)


DEFAULT_PORTS = dict(
    postgresql=5432,
    mysql=3306,
    mariadb=3306,
    mssql=1433,
    oracle=1521,
    mongodb=27017,
    redis=6379,
)


def fix_uri(uri: str) -> str:
    """Fixes a URI by percent-encoding the username and password."""

    if "%" in uri:
        return uri  # already %-encoded, so don't do anything
    # Split by '://'
    scheme_part, rest_of_uri = uri.split("://", 1)

    # Get the final '@' (assuming only the last '@' is the separator for user info)
    last_at_index = rest_of_uri.rfind("@")
    userinfo_part = rest_of_uri[:last_at_index]
    rest_of_uri_after_at = rest_of_uri[last_at_index + 1 :]

    if ":" not in userinfo_part:
        return uri
    # Split userinfo by ':' to get username and password
    username, password = userinfo_part.split(":", 1)

    # Percent-encode the username and password
    username = urllib.parse.quote(username)
    password = urllib.parse.quote(password)

    # Construct the fixed URI
    fixed_uri = f"{scheme_part}://{username}:{password}@{rest_of_uri_after_at}"

    return fixed_uri


def _create_database_uri(
    scheme: str,
    username: str,
    password: str,
    hostname: str,
    port: int,
    databasename: str,
) -> str:
    """Generates a database URI based on provided parameters."""
    username = urllib.parse.quote_plus(username)
    password = urllib.parse.quote_plus(password)
    port_str = f":{port}" if port else ""
    return f"{scheme}://{username}:{password}@{hostname}{port_str}/{databasename}"


def get_database_uri() -> str:
    """Main function to gather input and print the database URI."""
    scheme_input = Prompt.ask("Enter the database type (e.g., postgresql, mysql)")
    scheme = closest_string(scheme_input, list(DEFAULT_PORTS.keys()))

    # Handle if no close match is found.
    if scheme == "No match found":
        print(f"No close match found for '{scheme_input}'. Please verify your input.")
        return

    username = Prompt.ask("Enter the database username")
    password = Prompt.ask("Enter the database password", password=True)
    hostname = Prompt.ask("Enter the database hostname")

    # Inform user of default port, and let them choose to override or leave blank
    default_port = DEFAULT_PORTS.get(scheme, "")
    port_msg = (
        f"Enter the database port "
        f"(hit enter to use default: {default_port} or specify another value)"
    )

    port = Prompt.ask(port_msg, default=default_port)
    if not port:  # If user pressed enter without entering anything
        port = default_port
    port = int(port)

    databasename = Prompt.ask("Enter the database name")

    uri = _create_database_uri(scheme, username, password, hostname, port, databasename)
    print(f"Your {scheme.upper()} URI is:\n{uri}")
    return uri

>>>> examples/data-qa/table_chat.py
"""
Example showing how to chat with a tabular dataset:
csv, tsv, or any other pandas-readable.

Run like this

python3 examples/data-qa/table_chat.py

Optional args:
* -d or --debug to enable debug mode
* -ns or --nostream to disable streaming
* -nc or --nocache to disable caching
* -m or --model to specify a model name

To run with a local model via ollama, do this:
```
ollama run dolphin-mixtral # best model for this script

python3 examples/data-qa/table_chat.py -m ollama/dolphin-mixtral:latest
```

For more info on running Langroid with local LLM, see here:
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

import typer
from rich.prompt import Prompt
from rich import print

from langroid.agent.special.table_chat_agent import TableChatAgent, TableChatAgentConfig
from langroid.agent.task import Task
from langroid.language_models.openai_gpt import OpenAIChatModel, OpenAIGPTConfig
from langroid.utils.configuration import set_global, Settings

app = typer.Typer()


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    no_stream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not no_stream,
        )
    )

    print("[blue]Welcome to the tabular-data chatbot!\n")
    path = Prompt.ask(
        "[blue]Enter a local path or URL to a tabular dataset (hit enter to use default)\n",
        default="https://raw.githubusercontent.com/fivethirtyeight/data/master/airline-safety/airline-safety.csv",
    )

    agent = TableChatAgent(
        config=TableChatAgentConfig(
            data=path,
            llm=OpenAIGPTConfig(
                chat_model=model or OpenAIChatModel.GPT4o,
                chat_context_length=16_000,  # adjust based on model
                timeout=45,
                temperature=0.2,
            ),
        )
    )
    task = Task(agent, interactive=True)
    task.run("Can you help me with some questions about a tabular dataset?")


if __name__ == "__main__":
    app()

>>>> examples/docqa/FAT_Cleaned.csv
﻿Unique_ID,Project Number,Submit Date,Emerson Office,FAT Type,Milestones,Equipment,Readiness,Demonstration,Attitude,Skill,Compare,Customer Comment
1,V8240/3341718,1/27/25,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Great FAT.  
2,V8242,1/20/25,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,"You guys did great, very well organized. Thank you."
3,V6122,1/16/25,"iCenter, St. Louis, MO",Hardware only,5,5,5,5,5,5,5,No Comment Provided
4,C1195,12/11/24,"iCenter, St. Louis, MO",Hardware only,4,4,4,4,4,4,4,Great job on the FAT!  
5,V6122,12/4/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,5,5,5,5,No Comment Provided
6,C1172 / 3331616,10/31/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),4,5,5,5,5,5,5,"New Office was outstanding. VFAT room and surrounding area is very nice and conducive for conducting software FATs. The TV monitors on the wall inside the VFAT Room #7 would ideally be bigger though, if planning to utilize with a group of 6-7+ people in the room."
7,K0384,10/18/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Everyone involved on this project did an excellent job. 
8,V6120,10/11/24,"Headquarter - Projects, Pittsburgh, PA",Hardware only,5,5,5,5,5,4,5,"Ovation Green was to be new to the team, would have been nice to have someone quickly avialable to answer questions that the team onsite could not answer"
9,C1129/3317702,10/10/24,"iCenter, St. Louis, MO",Hardware only,5,4,5,5,5,5,5,No Comment Provided
10,V8226,10/7/24,"Headquarter - Projects, Pittsburgh, PA",Hardware only,5,5,5,5,5,5,5,"This AVR FAT was excellent!  My colleague and I that attended the FAT had limited knowledge on how Excitation systems work.  Dan Toohey took the time to explain how each individual parts and sequences with in the system.  This developed our knowledge to the point where we were able to ask relevant questions about the system.  Additionally, there were times we asked more basic questions and Dan Toohey had patience with us and explained everything in detail so we could gain better knowledge.  Ron and Dan work real well together and have been a pleasure to deal with before and during the AVR FAT.  I look forward to working with them on this controls upgrade and have no doubt they will provide an excellent system that will be worthy of the Emerson logo.  Thank you very much gentlemen!"
11,Z3757,10/1/24,"Southeast Region, Charlotte, NC", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Very good experience and completely satisfied. 
12,Z6900,9/27/24,"Southwest Region, Houston, TX", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,We had a great team from Emerson working with us to complete the FAT. It was a great atmosphere with great communication and teamwork to get any issue resolved. 
13,Y6682,9/23/24,"Western Region, Riverside, CA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Staff is compromised of experienced and professional individuals. Thank you 
14,Z6915,9/18/24,"Southwest Region, Houston, TX", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,I and the plant operations teams were very impressed at how thorough and well thought out the controls were.  All of the testing went well and I am confident that if the mechanical side works out we will have a very successful integrated project. 
15,Z6915,9/18/24,"Southwest Region, Houston, TX", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,No Comment Provided
16,Z6920,9/16/24,"Southwest Region, Houston, TX", Fully integrated (Hardware & Software)3,5,5,2,3,5,4,3,"The ELC datalinks were not ready for testing the first day of the FAT.  The week was used as a work session between Calpine and Emerson to develop the datalinks. It was explained to me that Emerson typically waits to do the datalinks during the outage, but Calpine prefers the datalinks be complete by the FAT so we can validate them during the FAT.  We completed some ELC-to-RTU testing during the FAT, but as of the last day of the FAT, the SLC algorithms still had not all been removed from the logic."
17,Z3758,9/12/24,"Southeast Region, Charlotte, NC", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,"Was a very good good experience, everything was smooth, no issues "
18,Z3758,9/12/24,"Southeast Region, Charlotte, NC", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Charlotte office always exceeds our expectations during factory acceptance tests. We are thankful for the expertise we receive while here.   
19,LC122,9/10/24,"Central Region, Chicago, IL", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Late changes were accommodated without issue. Process was very smooth. Everything went very well.
20,V8209,9/4/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,4,5,5,5,5,5,5,The team was very knowledgeable about the AVR and equipment.  They were very open to questions and suggestions to make this project very successful.  
21,U0597,9/4/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Everyone at the FAT was knowledgeable and professional. It was a very well put together experience. 
22,V1621,8/30/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),4,0,4,5,5,5,5,"Very helpful, cooperative, and knowledgeable Emerson engineering support. Updates and changes required were primarily due to limited or changing customer feedback for control desires."
23,V6121,8/30/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,5,5,5,5,Not in love with Ovation Green yet but I’m excited to see how it progresses 
24,V6121,8/30/24,Unkown Office,Software only (VFAT),4,0,5,5,5,5,5,No Comment Provided
25,V6121,8/30/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),0,0,5,5,5,5,5,No Comment Provided
26,V6121,8/30/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,5,5,5,5,No Comment Provided
27,V6121,8/30/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,4,5,5,5,No Comment Provided
28,C1156,8/28/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,3,5,5,5,5,"Lola, Chris, and Udit have been essential to the success of the software FATs and the project as a whole.  "
29,K0383,8/27/24,"Central Region, Chicago, IL", Fully integrated (Hardware & Software)3,5,5,4,4,5,4,5,No Comment Provided
30,U0566,8/26/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,They did a great job
31,C1185,8/23/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,0,5,5,5,5,5,FAT test was very well executed.  Lots of improvements were made through the testing.  The team was very responsive and worked hard to implement any changes we asked for.  Very satisfied with the overall process and how we were treated.  
32,BMCD Contract 6110 - Cooperative Energy CPA 91868,8/22/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),4,5,5,5,5,5,5,"This team combination is unstoppable.  They were always exceptionally well prepared and extremely knowledgeable in all facets of our project.  Truly the most capable and talented team of engineers that I've had the privilege to work with thus far in my 40-year career.  Customer satisfaction was well beyond approach, more than what I have ever experienced."
33,DB-126,8/21/24,"Western Region, San Francisco, CA",Software only (VFAT),5,4,5,4,4,4,4,"The personnel that provided this service was cooperative and had a very strong handle of the strategy. There were some items that Overall, a thorough and well-prepared Operational Readiness test for the Grit and Sludge handling software was provided to SFPUC.  cooperative. "
34,3283836,8/16/24,"Central Region, Chicago, IL", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Suk-Ho always provides outstanding service for his customer.  This encompasses everything from solving technical issues or finding additional resources if needed to ensuring that visitors are welcomed and comfortable while visiting.
35,K0376,8/15/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,No Comment Provided
36,K0376,8/15/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,4,5,5,5,5,5,5,"The entire Emerson Team was very professional, cooperative, and easy to work with.
A good experience all around"
37,C1186,8/13/24,"Central Region, Chicago, IL",Hardware only,5,5,5,5,5,5,5,Guys did great.
38,V6121,7/31/24,"iCenter, St. Louis, MO",Hardware only,4,5,4,5,5,5,5,No Comment Provided
39,V6121,7/31/24,"iCenter, St. Louis, MO",Hardware only,4,5,5,4,5,5,0,No Comment Provided
40,V6121,7/31/24,"iCenter, St. Louis, MO",Hardware only,5,5,5,5,5,5,5,Great Job Team! All are very cooperative and efficient to reach goal.
41,C1186,7/18/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,4,4,5,5,5,0,"Team did a great job addressing any variances found. Testing went good, Operation and simulation worked as expected."
42,K0387,7/17/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,4,5,5,5,0,No Comment Provided
43,KO387,7/17/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Great  professionalism shown with both Engineers 
44,C1163,7/17/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,5,5,5,5,Digital Variance using Microsoft Teams worked very well. 
45,DB-126,7/15/24,"Western Region, San Francisco, CA",Hardware only,5,4,5,5,5,5,4,Matt and Emerson's team displayed a deep understanding of the product and were responsive to the inspection team's questions and requests. We appreciate the Emerson team's dedication and commitment to both the project and the client.  
46,C5053,6/20/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,4,5,5,5,5,4,No Comment Provided
47,U0594,6/20/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,4,5,5,5,5,5,5,No Comment Provided
48,U0587,4/29/24,"Northeast Region, Warren, NJ", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Emerson staff is very professional and knowledgeable. 
49,U0587,4/24/24,Unkown Office, Fully integrated (Hardware & Software)3,4,5,5,5,5,5,5,No Comment Provided
50,C1111,4/12/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,5,5,5,5,"The extreme focus on detail by all members of the team was highly appreciated considering the challenges associated with a first of its kind project such as this. The sacrifices made by Vaibhav, Andrezj, and Sachin to spend a prolonged time working with me in person was greatly appreciated. Darryl did a fantastic job working through all of our hardware changes and provided fast response to any issue. And Li’s ability to organize all our changes and fix everything behind the scenes kept the project on track despite scope changes."
51,Y6530,4/6/24,"Western Region, Riverside, CA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Robert was awesome!
52,L9904,3/27/24,"Central Region, Chicago, IL", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,"If there were an option to select something above Very Satisfied, I would've done it. Suk-Ho did such a good job setting everything up for us, that we spent most of our time at the FAT just getting our custom scripts and group policies in order, as opposed to correcting anything with the Ovation system. He also went above and beyond to help us test a theory with our domain controller(s) as well as incorporate RADIUS onto all of our network components, which are both going to be huge benefits for Sunflower moving forward. Usually, the first site in an Evergreen cycle is difficult and time consuming to setup, but thanks to Suk-Ho and BK, everything was incredibly smooth and easy; 10 out of 10."
53,C1111,3/27/24,"Headquarter - Projects, Pittsburgh, PA",Hardware only,5,5,5,5,5,5,5,The project team has executed the hardware FAT perfectly. I am highly impressed with Darryl’s knowledge of the system hardware and networking. Vaibhav’s ability to explain and execute everything SIS along with his organization kept the FAT moving ahead of schedule. Li and Dr. Koba were integral in getting the software integrated seamlessly into the hardware design. This project team could not have executed this project any better than they have. A+
54,C111/3312244,3/22/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,5,5,5,5,"Excellent Project Team, no issues at all."
55,TEST 123,3/20/24,"iCenter, St. Louis, MO", Fully integrated (Hardware & Software)3,5,4,5,5,4,4,4,I hope this isn't a live survey. Please delete if it is. Dan.mcgonigal@emerson.com
56,Z2904,3/12/24,"Southeast Region, Charlotte, NC", Fully integrated (Hardware & Software)3,4,4,5,4,5,5,4,No Comment Provided
57,C1175,3/11/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,5,5,5,5,"Emerson Team was knowledgeable, professional and supportive during the entire process. I was able to review the entire system with very few variances illustrating the thorough preparation and attention to detail of the team.  Hats off to the group for a job well done.  "
58,3324794,3/11/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,4,4,5,5,5,5,5,Dan and Milad did a great job explaining the system and understanding our needs
59,Z6803,3/11/24,"Southwest Region, Houston, TX", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,William Sewell did a great job showing and explaining us the new upgrade. William made sure all the i's were dotted and all the t's crossed on the upgrade. He made sure all of our questions were answered. Jesse Foreman also came by to make sure everything was running smoothly. Great job and team work.
60,V8208,3/4/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,4,No Comment Provided
61,Y6560,2/29/24,"Western Region, Riverside, CA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,Excellent team. Engineers went above and beyond to fulfill requests.
62,U0481/U0498,2/26/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,4,5,5,5,5,5,"Bill Minick and Mike Lieberum have been very professional, knowledgeable and easy to work with on this project.  Bill and Mike exceeded expectations during the VFAT with their meticulous attention to detail.  I feel confident that we will maintain our high standards and critical elements will not overlooked on this project making it a success.  "
63,U0550,2/21/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),4,5,5,2,5,4,4,"The FAT was a ""do-it yourself"" mentality. Isaiah did not guide us through the FAT plan."
64,U0550,2/21/24,"Headquarter - Projects, Pittsburgh, PA",Hardware only,4,3,5,5,5,5,5,No Comment Provided
65,C1161,2/15/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),4,0,5,5,5,5,0,Zach was very thorough and organized. Kept the FAT on track and a ton of progress was made. 
66,V8212,2/14/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,3,3,5,5,5,5,4,Emerson engineers and project manager were hospitable during our visit. The team was friendly and very knowledgeable. They were helpful in working through demo and questions from numerous OGE personnel. 
67,V8220,2/13/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,No Comment Provided
68,V8220,2/12/24,"Headquarter - Projects, Pittsburgh, PA", Fully integrated (Hardware & Software)3,4,4,3,3,3,3,3,The project has been great from the bi-weekly meeting to the FAT. Everyone I have been involved with has been great.
69,U0581,2/12/24,"Southwest Region, Houston, TX", Fully integrated (Hardware & Software)3,5,5,4,4,4,4,4,No Comment Provided
70,3324794,2/12/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),4,4,4,5,5,5,5,Robert did a great job working with us to understand our needs.
71,V6079,2/9/24,"iCenter, St. Louis, MO",Hardware only,5,5,5,5,5,5,5,No Comment Provided
72,V6079,2/9/24,"iCenter, St. Louis, MO",Hardware only,5,4,4,5,5,5,5,The FAT was exceptionally well structured and the engineers were absolutely at the pinnacle of performance and support. All objectives were clearly stated and were well instructed by the engineering team. Very impressed with the speed and attention to discovered variances and the entire experience was very educational. Very excited to for implementation!
73,C1128/3317699,2/9/24,"Headquarter - Projects, Pittsburgh, PA",Software only (VFAT),5,5,5,5,5,5,5,"Darryl Jones should be the next Manager, Project Manager."
74,C1158,2/7/24,"iCenter, St. Louis, MO",Hardware only,5,5,5,5,5,5,5,No Comment Provided
75,Z3722 / 3326178,2/5/24,"Southeast Region, Charlotte, NC", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,I was very impressed with Emerson’s knowledge and support.
76,Z3723,2/5/24,"Southeast Region, Charlotte, NC", Fully integrated (Hardware & Software)3,5,5,5,5,5,5,5,I was very impressed with the knowledge and support provided.
77,V8215,12/18/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,Ron and Andrew were great hosts to my Instrument Tech and I. We both had an amazing experience with the FAT and we thoroughly enjoyed meeting the Emerson team. This team is top notch and we’re very thankful they’re building our equipment. We can’t wait to see them again onsite and compete the installation. 
78,Z6885,12/15/23,"Southwest Region, Houston, TX",Unknown Type,5,5,5,5,5,5,5,Good Work
79,K0362,12/13/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,"The project team proved to be exceptional. Bill's proactive approach ensured that he remained in control of every aspect, consistently keeping us well-informed throughout the entire project.  His leadership was instrumental in driving the development team forward.  Working with Pravesh was truly a pleasure, as his wealth of experience significantly enriched the project.  The valuable inclusion of Bhim later in the process seamlessly accelerated our progress.  The synergy between Bhim and Pravesh not only facilitated the project but also fostered a sense of camaraderie.  Looking ahead, it would be highly advantageous to retain this team for our upcoming retune in 2024."
80,C1128/G8578,12/8/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,Darryl and Nick have been great resources in collaboration to make the project successful. I would love to work with them on future projects.
81,U0545,12/6/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
82,NJ029,12/6/23,"Northeast Region, Warren, NJ",Unknown Type,4,4,5,5,5,5,5,No Comment Provided
83,C5046,12/5/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,4,5,5,5,5,It has been a pleasure working with this Emerson project team. Jay continues to stay on task by submitting monthly reports after equipment has shipped (and the project basically done) and has been very helpful ordering replacement parts for equipment damaged at site.
84,C1136,11/16/23,"iCenter, St. Louis, MO",Unknown Type,5,5,5,5,5,4,5,No Comment Provided
85,V6101,11/14/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,4,5,2,4,5,4,4,Biggest reason for lower scores was a fault with the configuration that kept team from being ready to begin when I arrived and ultimately led to us not finishing the entire checkout process while I was there. We did go back and complete the final items with a virtual meeting. 
86,C1120,11/8/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,4,4,5,5,5,5,4,No Comment Provided
87,C1129,11/7/23,"iCenter, St. Louis, MO",Unknown Type,5,5,5,5,5,5,5,Testing went smoothly and enjoyed playing the disc golf course on campus. Only issues were we couldn't find a solid copper jumper for testing digital unless and couldn't get log in to guest network because log in page wouldn't pop up after connecting.
88,C1136,11/6/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
89,V61000,11/6/23,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,This was a great improvement over my experience last year. 
90,U0515,10/16/23,"Southeast Region, Charlotte, NC",Unknown Type,4,4,4,4,4,4,4,No Comment Provided
91,V8203 / 3319258,10/13/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,4,5,5,5,5,No Comment Provided
92,V8203 / 3319258,10/13/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,4,5,5,5,5,No Comment Provided
93,C1135,10/13/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,"Very happy with all aspects of this project Design review, FAT .
hard work for both parties in a hard times, for a long time , finally get landed."
94,DB-126,10/4/23,"Western Region, San Francisco, CA",Unknown Type,3,4,3,4,3,4,4,No Comment Provided
95,Z6740,9/22/23,"Southwest Region, Houston, TX",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
96,C5046,9/21/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,4,5,5,5,5,"Some lingering development issues were still open prior to starting SW FAT, which complicated things a bit. But we were still able to complete on time. "
97,Z3712,9/19/23,"Southeast Region, Charlotte, NC",Unknown Type,4,4,4,4,4,4,4,Four new 4 port switches and fuses were not available at the FAT.  
98,Y6506,9/19/23,"Western Region, Riverside, CA",Unknown Type,5,5,5,5,5,5,5,"Emerson staff and facilities are always top-notch and professional.
Riverside was no exception. Ken and his team are a true asset for Emerson Power & Water Solutions. "
99,3325752,9/18/23,"Central Region, Chicago, IL",Unknown Type,5,4,5,3,4,5,4,"Other FATs from other vendors have been way more organized. Our FAT plan was rife with inaccuracies.  The engineer did not always seem to be focusing  on the FAT which now seems like it could have been due to the amount of time we had allotted... but it was a concern while we were there.  I chalk all of these items up to the Engineer on the project being new and hopefully he will improve in those areas.

The hospitality was over and above what other vendors provide. The flexibility of the project team exceeded expectations and is above what other vendors provide (but in line with what we expect as a customer).   The support team supporting the project engineer (Bhargav Kansara and Andrew Cockie) are second to none.  The 'evergreen' staff is very green but as long as they focus on the project and learn as much as they can from their leadership they will turn out to be good engineers. "
100,U0538,9/6/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,Thanks everyone for all your hard work. It is appreciated .
101,U0538,9/1/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,Great performance building on the two previous projects and keeping all three coordinated.  Great team all concientious and enthusiastic.
102,Z6698,9/1/23,"Southwest Region, Houston, TX",Unknown Type,5,5,5,5,5,5,5,“Protect this man at all costs”
103,units 5 & 6,8/31/23,"Central Region, Chicago, IL",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
104,LC107,8/31/23,"Central Region, Chicago, IL",Unknown Type,5,5,5,5,5,5,5,Process was clear and well thought out ahead of time. Presentation was relevant. Engineers were very open to changes and questions. Overall a very positive and professional experience. Relationship with Emerson continues to be a strong and positive experience. 
105,LC107 / LC108,8/31/23,"Central Region, Chicago, IL",Unknown Type,3,4,5,4,4,4,4,Facilitation and documentation communication / planning ahead of time could be improved. Actual FAT went well and I have confidence in the team’s ability to execute while on site. 
106,C1103,8/24/23,"iCenter, St. Louis, MO",Unknown Type,2,2,1,3,5,5,2,"I have been involved with several Emerson Ovation projects, the Hardware test in St. Louis was a major disappointment.  

The cabinets were incomplete, the quality of workmanship varied greatly between cabinets and in one instance where we have 3 wall mount cabinets that should be identical, the configurations were very different, there was no consistency.  

It was very apparent that the assembly had been rushed in order to meet our test date, these cabinets were originally to be ready for testing months earlier. 

There had been no quality control or testing.  We found one module that was connected to the wrong wiring assembly.

I definitely didn't leave the hardware FAT feeling confident that the cabinets were ready to be shipped to site.

On the computer and software side there had been very little that was tested and upon talking to the St Louis techs I got the impression that there is some confusion as to what is the responsibility of the St Louis staff and the Pittsburgh project engineers.  The tech I talked to was a fairly new hire and had very limited Ovation experience.

I realize that great effort was put in by the Project engineers and St Louis staff the week before our arrival, I can only imagine where things would have been at without this effort.

The SaskPower team along with the Pittsburgh project engineers worked late everyday to try to test/fix the issues that we could however other than Matt Borgens none of the other St Louis staff stayed to work on issues and to be honest we never really seen a concerted effort to address our concerns from the St Louis techs until our last day Thursday.

This situation is reminiscent of the quality of work we experienced from another control system vendor and not what we expect from Emerson PWS. 

Our project engineers worked diligently to try to get the system ready for testing and my thanks to them.  I could sense their frustration on the state of systems and embarrassed as to how it reflected poorly on them.

I understand that there have been several meetings to discuss the state of our system and to come up with a plan to ensure a satisfactory completion.  I have faith that Emerson will get our cabinets up to their normal standard, however it is unfortunate that the systems were not ready for us upon arrival.  If this would have been my first experience with Emerson I am not sure that I would have the same confidence.
"
107,C1117,8/22/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,4,5,5,5,5,5,Milad and Jerry were very well organized and prepared for the FAT. They did a very good job testing and demonstrating that the equipment works as it should.
108,LC083 3319794,8/18/23,"Central Region, Chicago, IL",Unknown Type,5,5,5,5,5,5,5,FAT was completed with less than 4 open variances which mainly are onsite completable.  Mel was solid running the testing. Andrew Cockie and BK were able to assist if needed.
109,141367,8/10/23,"Central Region, Chicago, IL",Unknown Type,5,4,5,5,5,5,5,Hardware FAT went as expected.  Biggest issues were with not identifying the ELC RTU limit which caused some reconfiguration.  Only outstanding issue is with TVA's requirement for the external NAS used for the Historian which looked to be missed in the original proposal.
110,DB-126,7/27/23,"Western Region, San Francisco, CA",Unknown Type,4,4,4,5,5,5,4,No Comment Provided
111,Y6220,7/20/23,"Western Region, Riverside, CA",Unknown Type,4,3,4,5,4,5,0,No Comment Provided
112,Z3527,7/20/23,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
113,V8193 / 3305436,6/22/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,Very pleased with the FAT. It went well. We checked everything out in a timely and efficient manner. 
114,C1091,6/2/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,4,5,5,0,"Project support was great, and the Emerson engineers involved with the FAT were a pleasure to work with. The St. Louis facility was too busy, too crowded and lacked certain testing equipment as compared to the Pittsburgh Test Floor. "
115,S0238/3306559,5/11/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
116,V8196,4/20/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,0,5,5,5,5,5,5,The product was great and functioned as planned.  The people were very accommodating and helpful.
117,23654,4/5/23,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
118,L9903,4/4/23,"Central Region, Chicago, IL",Unknown Type,5,5,5,5,5,5,5,Suk Ho was very professional and has worked very well with our team at Evergy.  He is very knowledgable and eager to help.
119,S0238/3306559,3/29/23,"Central Region, Chicago, IL",Unknown Type,0,0,4,5,5,5,5,No Comment Provided
120,L9855,3/24/23,"Central Region, Chicago, IL",Unknown Type,5,3,5,4,5,5,5,No Comment Provided
121,C1110,3/20/23,"Northeast Region, Warren, NJ",Unknown Type,5,5,5,5,5,5,5,"The entire team was quick to respond to any issues with the program. Udit Chaturvedi was my main point of contact during corrections. He was very responsive to all of my requests/changes to logic and graphics, and did a great job describing how the logic would work as changes were made."
122,Z3451,3/16/23,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,FAT had no findings of significant scope. FAT team from Emerson were very accommodating to customer needs.
123,Z3616,3/16/23,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,I have worked with John a few times over the years and he is always great to work with.  This is my first time working with James and Robbie but they are great to work with as well.  John and Robbie took time to answer all questions about new software we noticed in this new version.  We are thankful for their patience and time.
124,V6089,3/2/23,"Southeast Region, Charlotte, NC",Unknown Type,5,4,5,4,5,4,5,No Comment Provided
125,C1120,2/25/23,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,4,4,4,4,5,5,4,"Emerson engineering has done a great job dealing with everything from device shortages, shipping delays, lost shipments at the factory and resource shortages to meet expected schedule with a couple of acceptable delays.
What has been frustrating has been the disconnect between STL and Pittsburgh which seemed to be mostly due to lack of resources and/or procedures in STL. I also noticed lack of proper knowledge with the STL staff for required activities like ovation software installation, hardware FAT checkout and general troubleshooting. "
126,C0982,2/24/23,"Western Region, Riverside, CA",Unknown Type,5,4,5,5,5,5,5,The engineer team did a great job.
127,L9379,2/23/23,"Central Region, Chicago, IL",Unknown Type,5,3,4,5,5,3,4,No Comment Provided
128,L7891,2/22/23,"Headquarter – Lifecycle, Pittsburgh, PA",Unknown Type,5,4,5,5,5,5,5,"Jon is super helpful, very well mannered and went out of his way to answer/show/teach whenever I
had a question or concern."
129,Z3598,2/16/23,"Southeast Region, Charlotte, NC",Unknown Type,5,0,5,5,5,5,5,No Comment Provided
130,Z3599,2/16/23,"Southeast Region, Charlotte, NC",Unknown Type,5,0,5,5,5,5,5,No Comment Provided
131,Z3562,2/16/23,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,4,5,5,Great as always.
132,Z3559,2/16/23,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,Always a pleasure to work with this team!
133,U0523 C1101,2/8/23,"Southwest Region, Houston, TX",Unknown Type,5,4,5,5,5,5,5,No Comment Provided
134,U0523 C1101,2/7/23,"Southwest Region, Houston, TX",Unknown Type,5,0,5,5,5,5,5,No Comment Provided
135,V6086,1/11/23,"Southeast Region, Charlotte, NC",Unknown Type,4,4,4,5,5,4,5,No Comment Provided
136,143346,12/15/22,"Central Region, Chicago, IL",Unknown Type,4,5,5,5,5,5,5,Great responsive team. Missing hardware limits progress. 
137,V6089,12/12/22,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
138,V6088,12/12/22,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
139,U0508,11/10/22,Unkown Office,Unknown Type,5,5,5,5,5,5,5,Thank you all for your hard work!
140,L9657,11/9/22,"Central Region, Chicago, IL",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
141,L9657,11/9/22,"Central Region, Chicago, IL",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
142,Y6230,10/7/22,"Western Region, Riverside, CA",Unknown Type,5,5,5,5,5,5,5,Ray and  Christian helped solving most of our issues and took time to educate us on the new products with professionalism and courtesy. Stayed long hours to make sure our servers were properly build and design. They answered all questions we had in a timely manner. Lunch and breakfast were generous and appreciated the team effort at Riverside office.
143,D7159,10/7/22,"Northeast Region, Warren, NJ",Unknown Type,5,5,5,5,5,5,5,Mithona was very professional and attentive to my queries and request during the FAT. The system testing went well and tie back simulation helped in verifying most of the logic. There other remaining items that needs to field verified during the installation and commissioning stage of the project. 
144,Y6345,10/4/22,"Western Region, Riverside, CA",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
145,Z2902,10/3/22,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
146,Z3569,10/3/22,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
147,Z2902,9/28/22,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
148,3287614,9/28/22,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,0,5,5,5,5,5,"The virtual Factory Acceptance testing for the HMI software went extremely well, Eric did a great job of explaining everything he was doing and what would be displayed on the HMI screen. The staff staying on line from India were a great help on the occassion we needed them, which I believe was once! "
149,3296928,9/28/22,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,0,5,5,5,5,5,"As with project 3287614 (Memphis Maxson Process Upgrades Package 2A) Eric did a terrific job of walking through the FAT testing of the HMI software remotely. For the second evening in a row, personnel in India were on hand to answer questions (which again was only one or two) but it was great to get resolution in real time."
150,U0521,9/27/22,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,4,5,5,5,No Comment Provided
151,C1078,9/26/22,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,4,5,5,5,5,5,No Comment Provided
152,L7893,9/23/22,"Central Region, Chicago, IL",Unknown Type,5,4,5,5,5,5,5,No Comment Provided
153,L7892,9/23/22,"Central Region, Chicago, IL",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
154,L7890,9/23/22,"Central Region, Chicago, IL",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
155,Z3508,9/21/22,"Southeast Region, Charlotte, NC",Unknown Type,5,5,5,5,5,5,5,No Comment Provided
156,3304157,9/20/22,"Western Region, Riverside, CA",Unknown Type,5,5,5,5,5,5,5,Emerson provided their A-team for this project. 
157,L7881,9/16/22,"Headquarter - Projects, Pittsburgh, PA",Unknown Type,5,5,5,5,5,5,5,Jacob was very thorough in the explanations of what was done and how it will be transitioned to site.  he will also be the installation and commissioning engineer.
158,S0235,9/13/22,Unkown Office,Unknown Type,5,5,5,5,5,5,5,No Comment Provided
159,S0236,9/13/22,Unkown Office,Unknown Type,5,4,4,4,5,5,5,The HW and SW FAT identified some areas needing additional details and the Emerson team helped get the best product out the door for TVA.
160,D7158,9/13/22,Unkown Office,Unknown Type,5,5,5,5,5,5,5,"Very satisfied with experience, specially with Mithona’s help and knowledge. "
161,Z3381,9/13/22,Unkown Office,Unknown Type,5,5,5,5,5,5,0,No Comment Provided
162,D7140,9/1/22,Unkown Office,Unknown Type,5,4,5,0,5,0,5,No Comment Provided
163,D7150,9/1/22,Unkown Office,Unknown Type,5,0,5,0,5,0,5,"Great team, Garrett Krautwald and Jesse Ardizzone did great work."
164,D7131,8/31/22,Unkown Office,Unknown Type,4,4,4,4,4,4,4,No Comment Provided
165,C1062,8/30/22,Unkown Office,Unknown Type,0,3,4,5,5,5,5,"Paul Glance provides a well organized FAT.  He has the drawings printed out ahead of time and ready for each of us, along with notepad and pen.  He speaks knowledgeably about every aspect of the system: hardware, electrical wiring, and logic equally.  He has a thorough FAT checklist that outlines and documents every test that we do--a model for other FAT checklists.  He is a hospitable host too.

The equipment for Calpine was not complete at the time of the FAT.  A couple of hardware items were missing; however, Paul borrowed the hardware needed so that we could complete the FAT."
166,C1062,8/30/22,Unkown Office,Unknown Type,0,0,5,4,5,4,4,"Neil led us through Emerson's FAT plan, but he also demonstrated additional features and answered additional questions as prompted by Calpine throughout the FAT.  I appreciated his cooperation in that.  Kevin Bergeron also provided behind the scenes support in finding answers to questions and generally coordinating the FAT and recording variances. "
167,U0507,8/26/22,Unkown Office,Unknown Type,5,5,5,0,5,0,5,The team was great to work with. They delivered a quality product on schedule.
168,3283795,8/26/22,Unkown Office,Unknown Type,5,4,5,5,5,5,5,Supply chain prevented all equipment being at FAT
169,C1105,8/25/22,Unkown Office,Unknown Type,5,0,5,0,5,0,5,No Comment Provided
170,Z3476,8/23/22,Unkown Office,Unknown Type,5,4,5,0,5,5,5,No Comment Provided
171,C0192,8/19/22,Unkown Office,Unknown Type,4,3,5,5,5,5,5,Paul did an excellent job going thru the AVR FAT and answered all the questions that I had. Thank you Paul!
172,L9674,8/18/22,Unkown Office,Unknown Type,5,5,5,5,5,5,5,"Great to work with, efficient , and well educated on the system. Hospitality was outstanding. "
173,Z3505,8/18/22,Unkown Office,Unknown Type,5,5,5,5,5,5,5,Emerson personnel were well prepared and the FAT went smoothly.  
174,V8179 ,8/12/22,Unkown Office,Unknown Type,5,5,5,5,5,5,5,Colin did a great job.
175,Y6326,8/11/22,Unkown Office,Unknown Type,5,4,5,5,5,0,5,No Comment Provided
176,C1082,8/5/22,Unkown Office,Unknown Type,4,4,5,5,5,5,5,No Comment Provided
177,C1077,8/5/22,Unkown Office,Unknown Type,4,4,5,5,5,5,5,No Comment Provided
178,C1092,8/2/22,Unkown Office,Unknown Type,4,4,4,5,5,5,4,No Comment Provided
179,C1092,8/2/22,Unkown Office,Unknown Type,1,4,5,5,5,5,5,Generator Power monitor missing
180,C1019,7/28/22,Unkown Office,Unknown Type,4,5,5,5,5,5,4,No Comment Provided
181,C1019,7/28/22,Unkown Office,Unknown Type,4,4,4,4,4,4,4,"Vast improvement over the Phase 2/Unit 1 & Common FAT, thanks to all at Emerson who made that possible. "
182,U0393,6/6/22,Unkown Office,Unknown Type,0,0,5,5,5,5,5,Mr. Murray and Mr. Davido have always made us feel welcome and they displayed a great commitment to customer satisfaction.   
183,S0229,5/9/22,Unkown Office,Unknown Type,5,5,5,5,4,5,5,No Comment Provided
184,C1089,5/5/22,Unkown Office,Unknown Type,5,4,5,0,5,0,5,Emerson worked well and towards SRP’s best interest when integrating third party logic. 
185,C1089,5/5/22,Unkown Office,Unknown Type,5,4,5,5,5,5,5,No Comment Provided
186,C1072,4/21/22,Unkown Office,Unknown Type,4,5,5,5,5,5,5,We appreciate Emerson and their willingness to overcome supply chain issues and work alternative strategies for various equipment in our cabinets. A lot of value was realized during the FAT week from the customers' perspective.
187,S0230,3/28/22,Unkown Office,Unknown Type,5,5,5,5,5,5,0,No Comment Provided
188,U0494,3/7/22,Unkown Office,Unknown Type,5,5,5,4,5,5,5,FAT testing could have been a bit more structured.
189,V8186,2/27/22,Unkown Office,Unknown Type,5,4,5,5,5,5,5,"The equipment order was not complete due to COVID shortages, but the missing equipment is not critical. Also, Paul was an excellent host and made the most of our time in the factory. The Xcel team left Pittsburgh being very satisfied and we're looking forward to a successful installation."
190,K0317,1/25/22,Unkown Office,Unknown Type,5,5,5,5,5,5,5,No Comment Provided
191,406556,1/24/22,Unkown Office,Unknown Type,4,4,5,4,4,5,0,I'm satisfied with the FAT results and the level of responsiveness from AGC(Emerson).
192,C5006/3294580,1/10/22,Unkown Office,Unknown Type,5,5,5,5,5,5,5,Brian and Pat did an excellent job of running through the hardware FAT for DCU-2.  Two minor issues were resolved in minutes and they took their time to answer all my questions and talk through an concerns.  
193,C1080,1/7/22,Unkown Office,Unknown Type,5,4,5,5,5,5,5,"""Concerning the Equipment order question - the CISCO Fanout switches required for our system  are still on order and were missing from the cabinet as well as some ST Vibration hardware for new points. That is the only reason “Very Satisfied” was not selected. Emerson did communicate a plan for obtaining the needed equipment.

Overall we were very satisfied with the HW FAT visit at Latham. Several questions were asked relating to the Emerson system (as it will be a new technology for us at the plant) and if the answer was not immediately known, an appropriate resource was consulted to get the question answered. Emerson personnel took time to answer our questions relating the Ovation software which was greatly appreciated. Everyone we interfaced with made us feel welcome and confident that our final product will meet our expectations."""
194,C1063,12/17/21,Unkown Office,Unknown Type,5,5,5,5,5,5,5,"Had I not been through the training already, I would have thought the FAT was rushed.  However, I had the benefit of taking a week of training on the system right before the FAT, so I was able to understand what we were doing and follow along, even though we moved quickly.  The training helped us move at a good pace.  Paul would stop frequently and ask if we had questions, which I appreciated.  Paul was knowledgeable and able to answer just about any question we had.  We were disappointed to learn that the LCI equipment would not be part of any FAT prior to installation onsite."
195,C0881-U3,12/3/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,No Comment Provided
196,V6073,11/29/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,No Comment Provided
197,K0317,11/18/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,Instructor well prepared. Explained system well. Very good to work with 
198,K0317,11/18/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,No Comment Provided
199,K0317,11/18/21,Unkown Office,Unknown Type,4,0,4,0,4,0,4,"Great training, we had issues with the drops and had to keep resetting the drop. Corey and Kendall tried their best to get it fixed, hardware must have issues."
200,K0317,11/18/21,Unkown Office,Unknown Type,4,4,4,0,4,0,4,No Comment Provided
201,V6076,11/11/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,I thought the whole team did an Excellent job.
202,S0229,11/9/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,Derrick and his team adjusted to our IP address change request very quickly.  All issues were resolved at the HW FAT.
203,S0228,10/29/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,Very productive Hardware FAT and appreciate the hospitality Emerson provided for us. Thank you!
204,U0488,10/6/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,"The entire experience was great. The system was ready for testing, and there were very few deviations. Mike and Bill were very knowledgeable and made sure we understood everything while we were on-site. "
205,C1063,9/28/21,Unkown Office,Unknown Type,4,0,4,4,4,4,3,Several issues with screen sharing system made some of the review cumbersome and hard to follow. Emerson needs to have the GT Lead and ST Lead work together more to standardize how the logic and graphics are laid out.
206,C1072,9/28/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,FAT was conducted excellently. Emerson was accommodating in facilities and personnel. They worked with us all week while we tested and optimized the system.
207,C1075,9/24/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,The entire project team including Project Manager Tom Hebda were very responsive and worked around the end user's schedule (TECO) for the design review meeting.  Any questions during the development stage were forwarded to me in a timely manner that did not impact the quality of the system set up for the FAT.  The Emerson project team even identified several issues with the existing control logic (logic that was not part of this project) that needed minor fixes.  There were no show stoppers during the entire FAT and any wait time between testing sequences was minimal.  Any issues discovered during testing were solved in a timely manner. TECO is very particular with their graphic displays and the Emerson project team was able to accommodate all of their requests.  Both TECO and myself were very happy with what will be shipped to the field.  The expertise of the project team was very evident to myself and TECO.  
208,Q0272/3281295,9/21/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,"The ECMS SIFT was challenging schedule and so tough for everybody, but we were able to complete all Ovation testing items that can be tested in Pittsburgh. Appreciate for all stuff's effort and kind support."
209,U0482,9/17/21,Unkown Office,Unknown Type,4,0,4,0,4,0,4,No Comment Provided
210,20015690,9/14/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,No Comment Provided
211,C0881-U3,9/3/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,HW FAT went very well and finished ahead of schedule.  We had good help and Emerson's engineering support was good!
212,U0480,9/2/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,"FAT preparation, hardware testing and software simulations were well prepared. Emerson Team was very knowledgeable and fixed any minor variances identified promptly. No major concerns."
213,U0480,9/2/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,Ken and the team did a great job showing and explaining our new system. If we had questions they took the time to answer them in detail. 
214,U0479,9/1/21,Unkown Office,Unknown Type,3,4,1,2,4,3,3,"System was ready for FAT as it was going to just be a picture show which could be done remotely. VFAT system is terrible, we eventually got to have some control but we worked on a different VFAT system than the engineers in the room, so we never got to test corrected issues. This FAT should have been done on the actual hardware which was staged on the Pittsburgh test floor. 
Typical GE methods and mentality applied by Latham to the Emerson project. On the actual system security was all incorrect, some statement of a security standard which doesn’t match any standard, so customer had to make appropriate changes, many configuration issues. System never did get loaded on the test floor, so the hardware FAT could not be completed or verified. This was not a good FAT."
215,U048204,8/20/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,No Comment Provided
216,U048200,8/20/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,RVP cards were delivered this week of hardware FAT.  The plan is to configure and test RVP during software FAT.
217,C1060,8/12/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,"Please maintain the level of customer service while doing these projects.  Do not become like the turbine OEM's, Where the departments don't communicate between each other / have any interaction.  Emerson's bread & butter is the communication and seemless interaction while doing these projects.  (Gas Turbine / Steam Turbine / AVR. That is what makes it so easy to complete these large turbine / HRSG / BOP DCS change outs.  The teams that have supported us through the FAT's are top notch!"
218,C1059,8/12/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,The system provided and configured for RMEC was excellently done and the system presented exceeded our expectations. Great work by all the different Emerson groups working together on this project to provide one integrated system. We look forward to seeing all their efforts come to fruition soon with a successful commissioning.
219,S0221,8/9/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,"In addition to the HRSG cabinet HW testing, we also had our vendor (MHPS) come to Emerson to test the OPC datalink communications b/n the MHPS OPC Server and Ovation OPC Client.  During testing came across an anomaly for not being able to acknowledge alarms across the OPC Classic AE protocol, however, Emerson immediately got their subject matter specialists involved including an Emerson datalink specialist as well as an Emerson development engineer asap to help troubleshoot the issue and is continuing to do so to resolve the problem.  The intent of noting this in comments section, is that Emerson did a great job of immediately getting the right experts involved who came down to the test floor, and the project team made sure these individuals were available prior to the test, thus proving that they prepared.  Job well done and much appreciated."
220,S0227,8/5/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,This has been a challenging project with numerous parties involved.  Emerson has handled this coordination very well and we are completely satisfied with the product that we have received.
221,C1054,8/5/21,Unkown Office,Unknown Type,4,5,4,4,4,4,0,"The staff, facility and equipment performed to all expectations. A great spirit of cooperation from the staff was greatly appreciated. Issue tracking and resolution was executed in a timely manner. Simulator activities were a big help for the Operators."
222,091395,8/1/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,"The entire American Governor/Emerson team was very professional, knowledgeable and friendly. We were treated very well and I enjoyed my time at the facility. The shop is clean and all the staff have a visible sense of pride in their craft.   "
223,091393,7/27/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,I was very satisfied with all aspects of the project.  All personnel involved displayed excellence in their field.
224,091395,7/26/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,"I was very impressed with Michael's expertise during the acceptance test.  He was very flexible as we went through the integration design and came up with modifications that needed to be made to the Governor program.  He was able to quickly make changes and update the simulations to verify the logic changes.  I'm very confident this will be a smooth and successful installation after having the chance to sit down with Michael and the rest of the Emerson team to go over this project.  Alongside the technical aspect of the testing the rest of the visit went very well.  The rest of the staff were professional and easy to work with, and the accommodations were excellent. "
225,C1058,6/15/21,Unkown Office,Unknown Type,4,4,4,4,4,4,4,No Comment Provided
226,C1070,6/1/21,Unkown Office,Unknown Type,4,5,4,4,4,4,4,It took a bit to get going between using Webex and Teams.  I had multiple invitations and wasn't sure what to use.  Once we got going it worked well.
227,122874,4/8/21,Unkown Office,Unknown Type,4,3,4,4,4,4,4,No Comment Provided
>>>> examples/docqa/__init__.py

>>>> examples/docqa/books.txt

Book Title: Crime and Redemption by Filidor Dostoyevski, released in 1877, offers a
riveting exploration of guilt, morality, and the possibility of spiritual rebirth.
Set against the bleak backdrop of 19th century Russia, it follows the tormented journey
of Rodion Romanovich Raskolnikov, a young man driven to murder and subsequently
haunted by his actions. Through Raskolnikov's story, Dostoyevski delves deep into the
human psyche, presenting a timeless narrative of human imperfection and the
redemptive power.

Book Title: The Siblings Karamazoff by Fyodar Dostoyevskiy, published in 1881,
weaves a complex narrative around the ethical battles and spiritual dilemmas
faced by the Karamazoff family. Set in the heart of Russia, it explores themes of faith,
doubt, and the nature of free will through the intersecting lives of three brothers,
each embodying different facets of humanity. Dostoyevskiy masterfully crafts a tale of
familial bonds, existential questioning, and the search for truth in a morally ambiguous
world.
>>>> examples/docqa/chat-local.py
"""
Single agent to use to chat with an LLM using  Retrieval-Augmented Generation (RAG).
Similar to chat.py but allows specifying a local LLM.

See here for how to set up a Local LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

NOTES:
(1) The app works best with GPT4/Turbo, but results may be mixed with local LLMs.
You may have to tweak the system_message, use_message, and summarize_prompt
as indicated in comments below, to get good results.
(2) The default vector-db in DocChatAgent is QdrantDB, but you can switch to the
other supported vector-dbs, e.g. lancedb or chroma.

"""

import re
import typer
from rich import print
from rich.prompt import Prompt
import os

import langroid.language_models as lm
from langroid.agent.special.doc_chat_agent import (
    DocChatAgent,
    DocChatAgentConfig,
)
from langroid.parsing.parser import ParsingConfig, PdfParsingConfig, Splitter
from langroid.agent.task import Task
from langroid.utils.configuration import set_global, Settings

app = typer.Typer()

os.environ["TOKENIZERS_PARALLELISM"] = "false"


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
) -> None:
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        # or, other possibilities for example:
        # "litellm/bedrock/anthropic.claude-instant-v1"
        # "ollama/llama2"
        # "local/localhost:8000/v1"
        # "local/localhost:8000"
        chat_context_length=4096,  # adjust based on model
        timeout=90,
    )

    config = DocChatAgentConfig(
        n_query_rephrases=0,
        hypothetical_answer=False,
        # set it to > 0 to retrieve a window of k chunks on either side of a match
        n_neighbor_chunks=0,
        llm=llm_config,
        # system_message="...override default DocChatAgent system msg here",
        # user_message="...override default DocChatAgent user msg here",
        # summarize_prompt="...override default DocChatAgent summarize prompt here",
        parsing=ParsingConfig(  # modify as needed
            splitter=Splitter.TOKENS,
            chunk_size=300,  # aim for this many tokens per chunk
            overlap=30,  # overlap between chunks
            max_chunks=10_000,
            n_neighbor_ids=5,  # store ids of window of k chunks around each chunk.
            # aim to have at least this many chars per chunk when
            # truncating due to punctuation
            min_chunk_chars=200,
            discard_chunk_chars=5,  # discard chunks with fewer than this many chars
            n_similar_docs=3,
            # NOTE: PDF parsing is extremely challenging, each library has its own
            # strengths and weaknesses. Try one that works for your use case.
            pdf=PdfParsingConfig(
                # alternatives: "unstructured", "docling", "fitz"
                library="pymupdf4llm",
            ),
        ),
    )

    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )

    agent = DocChatAgent(config)
    print("[blue]Welcome to the document chatbot!")
    agent.user_docs_ingest_dialog()
    print("[cyan]Enter x or q to quit, or ? for evidence")

    system_msg = Prompt.ask(
        """
    [blue] Tell me who I am; complete this sentence: You are...
    [or hit enter for default] 
    [blue] Human
    """,
        default="a helpful assistant.",
    )
    system_msg = re.sub("you are", "", system_msg, flags=re.IGNORECASE)
    task = Task(
        agent,
        system_message="You are " + system_msg,
    )
    task.run()


if __name__ == "__main__":
    app()

>>>> examples/docqa/chat-multi-extract-3.py
"""
Variant of chat_multi_extract.py more suited to local LLM, using 3 Agents
(instead of 2 agents):

- LeaseExtractorAgent: is tasked with extracting structured information from a
    commercial lease document, and must present the terms in a specific nested JSON
    format. This agent generates questions corresponding to each field in the JSON
    format.
- Validator: This agent detects if LeaseExtractorAgent's message is asking for ONE
    piece of information, or MULTIPLE pieces. If the message is only asking about ONE
    thing, OR if it is NOT EVEN a question, it responds with "DONE" and says nothing.
    If the message is asking MORE THAN ONE thing, it responds with a message asking to
    only ask ONE question at a time.
    [Why restrict to one question at a time? Because the DocAgent is more likely to
      understand and answer a single question at a time]

- DocAgent: This agent answers the questions generated by LeaseExtractorAgent,
    based on the lease document it has access to via vecdb, using RAG.

Run like this:

```
python3 examples/docqa/chat-multi-extract-3.py -m ollama/nous-hermes2-mixtral
```

If you omit the -m arg, it will use the default GPT4-turbo model.

For more on setting up local LLMs with Langroid, see here:
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

import typer
from rich import print
from langroid.pydantic_v1 import BaseModel
from typing import List
import json
import os

import langroid.language_models as lm
from langroid.mytypes import Entity
from langroid.agent.special.doc_chat_agent import DocChatAgent, DocChatAgentConfig
from langroid.parsing.parser import ParsingConfig
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from langroid.language_models.openai_gpt import OpenAIGPTConfig
from langroid.utils.configuration import set_global, Settings
from langroid.utils.constants import NO_ANSWER, DONE

app = typer.Typer()

os.environ["TOKENIZERS_PARALLELISM"] = "false"


class LeasePeriod(BaseModel):
    start_date: str
    end_date: str


class LeaseFinancials(BaseModel):
    monthly_rent: str
    deposit: str


class Lease(BaseModel):
    """
    Various lease terms.
    Nested fields to make this more interesting/realistic
    """

    period: LeasePeriod
    financials: LeaseFinancials
    address: str


class LeaseMessage(ToolMessage):
    """Tool/function to use to present details about a commercial lease"""

    request: str = "lease_info"
    purpose: str = """
        Collect information about a Commercial Lease.
        """
    terms: Lease
    result: str = ""

    def handle(self) -> str:
        print(
            f"""
        DONE! Successfully extracted Lease Info:
        {self.terms}
        """
        )
        return "DONE " + json.dumps(self.terms.dict())

    @classmethod
    def format_instructions(cls, tool: bool = True) -> str:
        instr = super().format_instructions(tool)
        instr += """
        ------------------------------
        ASK ME QUESTIONS ONE BY ONE, to FILL IN THE FIELDS 
        of the `lease_info` function/tool.
        First ask me for the start date of the lease.
        DO NOT ASK ANYTHING ELSE UNTIL YOU RECEIVE MY ANSWER.
        """
        return instr

    @classmethod
    def examples(cls) -> List["LeaseMessage"]:
        return [
            cls(
                terms=Lease(
                    period=LeasePeriod(start_date="2021-01-01", end_date="2021-12-31"),
                    financials=LeaseFinancials(monthly_rent="$1000", deposit="$1000"),
                    address="123 Main St, San Francisco, CA 94105",
                ),
                result="",
            ),
        ]


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    llm_cfg = OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,  # adjust based on model
        temperature=0,
        timeout=45,
    )
    doc_agent = DocChatAgent(
        DocChatAgentConfig(
            llm=llm_cfg,
            n_neighbor_chunks=2,
            parsing=ParsingConfig(
                chunk_size=50,
                overlap=10,
                n_similar_docs=3,
                n_neighbor_ids=4,
            ),
            cross_encoder_reranking_model="",
        )
    )
    doc_agent.vecdb.set_collection("docqa-chat-multi-extract", replace=True)
    print("[blue]Welcome to the real-estate info-extractor!")
    doc_agent.config.doc_paths = [
        "examples/docqa/lease.txt",
    ]
    doc_agent.ingest()
    doc_task = Task(
        doc_agent,
        name="DocAgent",
        done_if_no_response=[Entity.LLM],  # done if null response from LLM
        done_if_response=[Entity.LLM],  # done if non-null response from LLM
        system_message="""You are an expert on Commercial Leases. 
        You will receive various questions about a Commercial 
        Lease contract, along with some excerpts from the Lease.
        Your job is to answer them concisely in at most 2 sentences.
        """,
    )

    lease_extractor_agent = ChatAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
        )
    )
    lease_extractor_agent.enable_message(LeaseMessage)

    lease_task = Task(
        lease_extractor_agent,
        name="LeaseExtractorAgent",
        interactive=False,  # set to True to slow it down (hit enter to progress)
        system_message=f"""
        You are an expert at understanding JSON function/tool specifications, and
        you are also very familiar with commercial lease terminology and concepts.
         
        See the `lease_info` function/tool below,  Your FINAL GOAL is to fill
        in the required fields in this `lease_info` function/tool,
        as shown in the example. This is ONLY an EXAMPLE,
        and YOU CANNOT MAKE UP VALUES FOR THESE FIELDS.
        
        To fill in these fields, you must ASK ME QUESTIONS about the lease,
        ONE BY ONE, and I will answer each question. 
        If I am unable to answer your question initially, try asking me 
        differently. If I am still unable to answer after 3 tries, fill in 
        {NO_ANSWER} for that field.
        When you have collected this info, present it to me using the 
        'lease_info' function/tool.
        DO NOT USE THIS Function/tool UNTIL YOU HAVE ASKED QUESTIONS 
        TO FILL IN ALL THE FIELDS.
        
        Think step by step. 
        Phrase each question simply as "What is ... ?",
        and do not explain yourself, or say any extraneous things. 
        Start by asking me for the start date of the lease.
        When you receive the answer, then ask for the next field, and so on.
        """,
    )

    validator_agent = ChatAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
            system_message=f"""
            You are obedient, understand instructions, and follow them faithfully,
            paying attention to the FORMAT specified,
            and you are also extremely CONCISE and SUCCINCT in your responses.
            
            Your task is to detect if the user's message is asking for ONE
            piece of information, or MULTIPLE pieces. Here is how you respond:
            
            IF the msg is only asking about ONE thing, OR if it is NOT EVEN a question:
                respond '{DONE}' and say nothing else.

            IF the msg is asking MORE THAN ONE thing,  respond like this:
            "Please only ask ONE question at a time. Try your question again.
            ONLY when you have ALL the answers, then present the info
            using the `lease_info` function/tool."
            """,
        )
    )
    validator_task = Task(
        validator_agent,
        name="Validator",
        single_round=True,
        interactive=False,
    )

    lease_task.add_sub_task([validator_task, doc_task])
    lease_task.run()


if __name__ == "__main__":
    app()

>>>> examples/docqa/chat-multi-extract-local.py
"""
Extract structured info from a commercial lease document,
using multiple agents, powered by a weaker/local LLM, combining tools/functions and RAG.

TASK:
Given a lease document, generate the lease terms, organized into
 a nested JSON structure defined by the Pydantic class `Lease`

Solution with Langroid Agents and tools:
1. QuestionGeneratorAgent: Lease JSON Spec -> list of questions to ask
2. InterrogatorAgent: For each question, generate 2 variants of the question,
   so we use total 3 variants per question, joined together, to increase
   the likelihood of getting an answer from the DocAgent (RAG).
3. DocAgent (has access to the lease) -> answer one question using RAG
3. LeasePresenterAgent: List of (question, answer) pairs ->
        organized into specified Lease JSON structure

Run like this:
```
python3 examples/docqa/chat-multi-extract-local.py -m ollama/mistral:7b-instruct-v0.2-q8_0
```
This works with a local mistral-instruct-v0.2 model.
(To use with ollama, first do `ollama run <model>` then
specify the model name as -m ollama/<model>)

See here for how to set up a Local LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

Optional script args:
-m <local-model-name>, e.g. -m ollama/mistral:7b-instruct-v0.2-q8_0
(if omitted, defaults to GPT4o)
-nc to disable cache retrieval
-d to enable debug mode: see prompts, agent msgs etc.
"""

import typer
from rich import print
from langroid.pydantic_v1 import BaseModel
from typing import List, Optional
import json
import os

import langroid.language_models as lm
from langroid.agent import ChatDocument
from langroid.mytypes import Entity
from langroid.agent.special.doc_chat_agent import DocChatAgent, DocChatAgentConfig
from langroid.parsing.parser import ParsingConfig
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from langroid.language_models.openai_gpt import OpenAIGPTConfig
from langroid.utils.configuration import set_global, Settings
from langroid.utils.constants import NO_ANSWER, DONE
from langroid.utils.pydantic_utils import get_field_names

app = typer.Typer()

os.environ["TOKENIZERS_PARALLELISM"] = "false"


class LeasePeriod(BaseModel):
    start_date: str
    end_date: str


class LeaseFinancials(BaseModel):
    monthly_rent: str
    deposit: str


class Lease(BaseModel):
    """
    Various lease terms.
    Nested fields to make this more interesting/realistic
    """

    period: LeasePeriod
    financials: LeaseFinancials
    address: str


class QuestionsTool(ToolMessage):
    request: str = "questions_tool"
    purpose: str = """
    To present a list of <questions> to ask, to fill a desired JSON structure.
    """
    questions: List[str]


class QuestionGeneratorAgent(ChatAgent):
    questions_list: List[str] = []

    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        if isinstance(msg, ChatDocument) and msg.metadata.sender == Entity.LLM:
            return """
            You forgot to present the information in JSON format 
            according to the `questions_tool` specification,
            or you may have used a wrong tool name or field name.
            Remember that you must include `request` and `questions` fields,
            where `request` is "questions_tool" and `questions` is a list of questions.
            Try again.
            """
        return None

    def questions_tool(self, msg: QuestionsTool) -> str:
        # get all the field names, including nested ones
        fields = get_field_names(Lease)
        if len(msg.questions) < len(fields):
            return f"""
            ERROR: Expected {len(fields)} questions, but only got {len(msg.questions)}.
            See what you may have missed and try again.
            Hint: the required fields are {fields}
            """
        elif len(msg.questions) > len(fields):
            return f"""
            ERROR: Expected {len(fields)} questions, but got {len(msg.questions)}.
            You generated an extra question. Try again.
            Hint: the required fields are {fields}
            """
        else:
            self.questions_list = msg.questions
            return DONE + json.dumps(msg.questions)


class MyDocChatAgent(DocChatAgent):
    def llm_response(
        self,
        message: None | str | ChatDocument = None,
    ) -> Optional[ChatDocument]:
        """
        Override the default LLM response to return the full document,
        to forget the last round in conversation, so we don't clutter
        the chat history with all previous questions
        (Assume questions don't depend on past ones, as is the case here,
        since we are extracting separate pieces of info from docs)
        """
        n_msgs = len(self.message_history)
        response = super().llm_response(message)
        # If there is a response, then we will have two additional
        # messages in the message history, i.e. the user message and the
        # assistant response. We want to (carefully) remove these two messages.
        self.message_history.pop() if len(self.message_history) > n_msgs else None
        self.message_history.pop() if len(self.message_history) > n_msgs else None
        return response


class LeasePresenterAgent(ChatAgent):
    def handle_message_fallback(
        self, msg: str | ChatDocument
    ) -> str | ChatDocument | None:
        """Handle scenario where Agent failed to present the Lease JSON"""
        if isinstance(msg, ChatDocument) and msg.metadata.sender == Entity.LLM:
            return """
            You either forgot to present the information in the JSON format
            required in `lease_info` JSON specification,
            or you may have used the wrong name of the tool or fields.
            Try again.
            """
        return None


class LeaseMessage(ToolMessage):
    """Tool/function to use to present details about a commercial lease"""

    request: str = "lease_info"
    purpose: str = "To present the <terms> of a Commercial lease."
    terms: Lease

    def handle(self) -> str:
        print(
            f"""
        DONE! Successfully extracted Lease Info:
        {self.terms}
        """
        )
        return DONE + " " + json.dumps(self.terms.dict())

    @classmethod
    def examples(cls) -> List["LeaseMessage"]:
        return [
            cls(
                terms=Lease(
                    period=LeasePeriod(start_date="2021-01-01", end_date="2021-12-31"),
                    financials=LeaseFinancials(monthly_rent="$1000", deposit="$1000"),
                    address="123 Main St, San Francisco, CA 94105",
                ),
                result="",
            ),
            cls(
                terms=Lease(
                    period=LeasePeriod(start_date="2021-04-01", end_date="2022-04-28"),
                    financials=LeaseFinancials(monthly_rent="$2000", deposit="$2000"),
                    address="456 Main St, San Francisco, CA 94111",
                ),
                result="",
            ),
        ]


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            cache_type="fakeredis",
        )
    )
    llm_cfg = OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=32_000,  # adjust based on model
        timeout=120,
        temperature=0.2,
    )

    # (1) QUESTION GENERATOR
    question_generator_agent = QuestionGeneratorAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
            system_message="""
            See the `lease_info` JSON structure below. 
            Your ONLY task is to generate 
            QUESTIONS corresponding to each field in the `lease_info` JSON,
            and present these to me using the `questions_tool` in JSON format.
            Pay attention to the format and fields in the `questions_tool` JSON.
            """,
        )
    )
    question_generator_agent.enable_message(LeaseMessage)
    question_generator_agent.enable_message(QuestionsTool)
    question_generator_task = Task(
        question_generator_agent,
        name="QuestionGeneratorAgent",
        interactive=False,
    )

    # (2) RAG AGENT: try to answer a given question based on documents
    doc_agent = MyDocChatAgent(
        DocChatAgentConfig(
            llm=llm_cfg,
            assistant_mode=True,
            n_neighbor_chunks=2,
            parsing=ParsingConfig(
                chunk_size=150,
                overlap=30,
                n_similar_docs=3,
                n_neighbor_ids=4,
            ),
            cross_encoder_reranking_model="",
        )
    )
    doc_agent.vecdb.set_collection("docqa-chat-multi-extract", replace=True)
    doc_agent.ingest_doc_paths(["examples/docqa/lease.txt"])
    print("[blue]Welcome to the real-estate info-extractor!")
    doc_task = Task(
        doc_agent,
        name="DocAgent",
        interactive=False,
        done_if_no_response=[Entity.LLM],  # done if null response from LLM
        done_if_response=[Entity.LLM],  # done if non-null response from LLM
        system_message="""You are an expert on Commercial Leases. 
        You will receive a question about a Commercial 
        Lease contract, and your job is to answer concisely in at most 2 sentences.
        """,
    )

    # (3) Interrogator: persists in getting an answer for a SINGLE question
    #       from the RAG agent
    interrogator = ChatAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
            system_message="""
            You are an expert on Commercial leases and their terms. 
            User will send you a QUESTION about such a lease.
            Your ONLY job is to reply with TWO VARIATIONS of the QUESTION,
            and say NOTHING ELSE.
            """,
        )
    )
    interrogator_task = Task(
        interrogator,
        name="Interrogator",
        restart=True,  # clear agent msg history
        interactive=False,
        single_round=True,
    )

    # (4) LEASE PRESENTER: Given full list of question-answer pairs,
    #       organize them into the Lease JSON structure
    lease_presenter = LeasePresenterAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
        )
    )
    lease_presenter.enable_message(LeaseMessage)

    lease_presenter_task = Task(
        lease_presenter,
        name="LeasePresenter",
        interactive=False,  # set to True to slow it down (hit enter to progress)
        system_message="""
        The user will give you a list of Questions and Answers 
        about a commercial lease.
        
        Organize this information into the `lease_info` JSON structure specified below,
        and present it to me. 
        For fields where the answer is NOT KNOWN, fill in "UNKNOWN" as the value.
        """,
    )

    # (5) Use the agents/tasks

    # Lease info JSON -> Questions
    question_generator_task.run()
    questions = question_generator_agent.questions_list
    print(f"found {len(questions)} questions! Now generating answers...")

    # Questions -> Answers using RAG
    answers = []
    for q in questions:
        # use 3 variants of the question at the same time,
        # to increase likelihood of getting an answer
        q_variants = interrogator_task.run(q).content
        result = doc_task.run(q + "\n" + q_variants)
        answer = result.content or NO_ANSWER
        answers.append(answer)
    print(f"got {len(answers)} answers!")

    q2a = dict(zip(questions, answers))
    print(f"q2a: {q2a}")
    questions_answers = "\n\n".join(
        f"Question: {q}:\nAnswer: {a}" for q, a in q2a.items()
    )
    # Questions + Answers -> organized into nested Lease Info JSON
    lease_presenter_task.run(questions_answers)


if __name__ == "__main__":
    app()

>>>> examples/docqa/chat-qa-summarize.py
"""
Two-agent system to do Question-Answer based summarization of documents.
E.g. one could use this to summarize a very large document, assuming there is a
reasonable abstract/intro at the start that "covers" the import aspects.

WriterAgent (has no access to docs) is tasked with writing 5 bullet points based on
some docs. Initially it generates a summary of the docs from the beginning of the doc,
then it formulates questions to ask until it gets 5 key pieces of information.

DocAgent (has access to docs) answers these questions using RAG.

Run like this:

python examples/docqa/chat-qa-summarize.py

You can let it run and it will finish with 5 key bullet points about the document(s).

There are optional args, especially note you can pass in a different LLM model, e.g.

python3 examples/docqa/chat-qa-summarize.py -m ollama/nous-hermes2-mixtral

See here for how to set up a Local LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

"""

import typer
from rich import print
import os

import langroid as lr
import langroid.language_models as lm
from langroid.parsing.urls import get_list_from_user
from langroid.utils.configuration import set_global, Settings

app = typer.Typer()

os.environ["TOKENIZERS_PARALLELISM"] = "false"


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    model: str = typer.Option(
        "",
        "--model",
        "-m",
        help="specify alternative LLM, e.g. ollama/mistral",
    ),
) -> None:
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
    )
    config = lr.agent.special.DocChatAgentConfig(
        llm=llm_config,
        n_neighbor_chunks=2,
        parsing=lr.parsing.parser.ParsingConfig(
            chunk_size=50,
            overlap=10,
            n_similar_docs=3,
            n_neighbor_ids=4,
        ),
    )
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    doc_agent = lr.agent.special.DocChatAgent(config)
    doc_agent.vecdb.set_collection("docqa-chat-multi", replace=True)
    print("[blue]Welcome to the document chatbot!")
    print("[cyan]Enter x or q to quit, or ? for evidence")
    print(
        """
        [blue]Enter some URLs or file/dir paths below (or leave empty for default URLs)
        """.strip()
    )
    inputs = get_list_from_user()
    if len(inputs) == 0:
        inputs = config.default_paths
    doc_agent.config.doc_paths = inputs
    doc_agent.ingest()
    topics_doc = doc_agent.summarize_docs(
        instruction="""
        Ignore the system message, and follow these instructions.
        Below is some text. Do not react to it. 
        Simply read it and give me a list of up to 3 main topics from the text,
        in the form of short NUMBERED SENTENCES.
        --------------------------------
        """,
    )
    topics = topics_doc.content
    doc_task = lr.Task(
        doc_agent,
        name="DocAgent",
        done_if_no_response=[lr.Entity.LLM],  # done if null response from LLM
        done_if_response=[lr.Entity.LLM],  # done if non-null response from LLM
        system_message="""You will receive various questions about some documents, and
        your job is to answer them concisely in at most 2 sentences, citing sources.
        """,
    )

    writer_agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            llm=llm_config,
            vecdb=None,
        )
    )
    writer_task = lr.Task(
        writer_agent,
        # SET interactive to True to slow it down, but keep hitting enter to progress
        interactive=False,
        name="WriterAgent",
        system_message=f"""
        You have to collect some information from some documents, on these topics:
        {topics}
        However you do not have access to those documents, so you must ask me
        questions, ONE AT A TIME, and I will answer each question.
        Once you have collected 5 key pieces of information, say "DONE" and summarize 
        them in bullet points.  
        """,
    )

    validator_agent = lr.ChatAgent(
        lr.ChatAgentConfig(
            name="Validator",
            llm=llm_config,
            system_message="""
            Your only task is to check whether the user's message consists of
            NO QUESTION, ONE question or MULTIPLE questions. This is how you must respond:
        
            - If the msg is NOT SEEKING any INFO, respond with this:
                "Please ask a SINGLE QUESTION about a topic you want to know about.
                Wait for the answer before asking your next question".
            - If user's msg contains just ONE question, or no question at all, say DONE
            - Otherwise (i.e there are MULTIPLE questions/requests for info),
              then respond with this:
            "Please ask only ONE question at a time. Ask your question again.
            Only when you have answers to all of your questions present your final
            bullet points saying  'DONE here are the bullet pts...'."
            
            IMPORTANT: DO NOT TRY TO ANSWER THE QUESTIONS YOURSELF.            
            """,
        ),
    )
    validator_task = lr.Task(validator_agent, interactive=False, single_round=True)

    writer_task.add_sub_task([validator_task, doc_task])

    writer_task.run()


if __name__ == "__main__":
    app()

>>>> examples/docqa/chat-search-filter.py
"""
Variant of chat-search.py that uses a filter to identify different
set of ingested docs (obtained from web-search), so that cross-doc
questions can be answered.

This is a single-agent question-answering system that has access to a Web-Search
Tool when needed,
and in case a web search is used, ingests scraped link contents into a vector-db,
and uses Retrieval Augmentation to answer the question.

Run like this:

    python3 examples/docqa/chat-search-filter.py

Optional args:
    -nc : turn off caching (i.e. don't retrieve cached LLM responses)
    -d: debug mode, to show all intermediate results
    -f: use OpenAI functions api instead of tools
    -m <model_name>:  (e.g. -m ollama/mistral:7b-instruct-v0.2-q4_K_M)
    (defaults to GPT4-Turbo if blank)

(See here for guide to using local LLMs with Langroid:)
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

import re
from typing import List, Any
import json

from rich import print
from rich.prompt import Prompt

import langroid as lr
import langroid.language_models as lm
from langroid.pydantic_v1 import Field
from langroid.agent.tools.orchestration import ForwardTool
from langroid.agent.tool_message import ToolMessage
from langroid.agent.chat_agent import ChatAgent, ChatDocument
from langroid.agent.special.doc_chat_agent import (
    DocChatAgent,
    DocChatAgentConfig,
)
from langroid.parsing.web_search import metaphor_search
from langroid.parsing.parser import ParsingConfig, Splitter, PdfParsingConfig
from langroid.agent.task import Task
from langroid.utils.constants import NO_ANSWER
from langroid.utils.configuration import set_global, Settings
from fire import Fire


class RelevantExtractsTool(ToolMessage):
    request: str = Field(
        "relevant_extracts", description="MUST be included in EVERY use of this tool!"
    )
    purpose: str = "Get docs/extracts relevant to the <query> from prior searches"
    query: str = Field(..., description="The query to get relevant extracts for")
    filter_tag: str = Field(
        "",
        description="""
        Optional LOWER-CASE tag to filter to use for the search, 
        to restrict relevance extraction to a SPECIFIC PRIOR search result.
        IMPORTANT - DO NOT INTRODUCE A NEW TAG HERE!! You MUST use ONLY a
        tag you previously used in the `relevant_search_extracts` tool,
        to correctly identify a prior search result.
        """,
    )

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        return [
            cls(
                query="when was the Mistral LLM released?",
                filter_tags=["mistral", "llm"],
            ),
        ]

    @classmethod
    def instructions(cls) -> str:
        return """
        IMPORTANT: You must include an ACTUAL query in the `query` field,
        """


class RelevantSearchExtractsTool(ToolMessage):
    request: str = Field(
        "relevant_search_extracts",
        description="MUST be included in EVERY use of this tool!",
    )
    purpose: str = "Get docs/extracts relevant to the <query> from a web search"
    query: str = Field(..., description="The search query to get relevant extracts for")
    num_results: int = Field(3, description="The number of search results to use")
    tag: str = Field(
        "",
        description="""
        Optional LOWER-CASE tag to attach to the documents ingested from the search, 
        to UNIQUELY IDENTIFY the docs ingested from this search, for future reference
        when using the `relevant_extracts` tool.
        """,
    )

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        return [
            cls(
                query="when was the Mistral LLM released?",
                num_results=3,
                tag="mistral",
            ),
        ]

    @classmethod
    def instructions(cls) -> str:
        return """
        IMPORTANT: You must include an ACTUAL query in the `query` field,
        """


def tags_to_filter(tags: List[str]) -> str | None:
    """
    Given a list of tags, create a qdrant-db filter condition expressing:
    EVERY tag MUST appear in the metadata.tags field of the document.
    Args:
        tags: List of tags to filter by
    Returns:
        json string of the qdrant filter condition, or None
    """
    if len(tags) == 0:
        return None
    match_conditions = [
        {"key": "metadata.tags", "match": {"any": [tag]}} for tag in tags
    ]

    filter = {"must": match_conditions}
    return json.dumps(filter)


class SearchDocChatAgent(DocChatAgent):

    def init_state(self) -> None:
        super().init_state()
        self.original_docs = []
        self.tried_vecdb: bool = False

    def handle_message_fallback(self, msg: str | ChatDocument) -> Any:
        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            # no tool, so it must be meant for user
            return ForwardTool(agent="user")

    def llm_response(
        self,
        message: None | str | ChatDocument = None,
    ) -> ChatDocument | None:
        return ChatAgent.llm_response(self, message)

    def relevant_extracts(self, msg: RelevantExtractsTool) -> str:
        """Get docs/extracts relevant to the query, from vecdb"""
        self.tried_vecdb = True
        query = msg.query
        if msg.filter_tag != "":
            self.set_filter(tags_to_filter([msg.filter_tag]))
        _, extracts = self.get_relevant_extracts(query)
        if len(extracts) == 0:
            return """
            No extracts found! You can try doing a web search with the
            `relevant_search_extracts` tool/function-call.
            """
        return "\n".join(str(e) for e in extracts)

    def relevant_search_extracts(self, msg: RelevantSearchExtractsTool) -> str:
        """Get docs/extracts relevant to the query, from a web search"""
        # if not self.tried_vecdb and len(self.original_docs) > 0:
        #     return "Please try the `relevant_extracts` tool, before using this tool"
        self.tried_vecdb = False
        query = msg.query
        # if query contains a url, then no need to do web search --
        # just ingest the specific link in the query
        if "http" in query:
            # extract the URL from the query
            url = re.search(r"(?P<url>https?://[^\s]+)", query).group("url")
            links = [url]
            # remove the url from the query
            query = re.sub(r"http\S+", "", query)
        else:
            results = metaphor_search(query, msg.num_results)
            links = [r.link for r in results]
        self.ingest_doc_paths(links, metadata={"tags": [msg.tag]})
        if msg.tag != "":
            self.set_filter(tags_to_filter([msg.tag]))
        _, extracts = self.get_relevant_extracts(query)
        return "\n".join(str(e) for e in extracts)


def main(
    debug: bool = False,
    nocache: bool = False,
    model: str = "",
    fn_api: bool = True,
) -> None:

    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )

    print(
        """
        [blue]Welcome to the Internet Search chatbot!
        I will try to answer your questions, relying on (full content of links from) 
        Duckduckgo (DDG) Search when needed.
        
        Enter x or q to quit, or ? for evidence
        """
    )

    system_msg = Prompt.ask(
        """
    [blue] Tell me who I am (give me a role) by completing this sentence: 
    You are...
    [or hit enter for default]
    [blue] Human
    """,
        default="a helpful assistant.",
    )
    system_msg = re.sub("you are", "", system_msg, flags=re.IGNORECASE)

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        # or, other possibilities for example:
        # "litellm/bedrock/anthropic.claude-instant-v1"
        # "ollama/llama2"
        # "local/localhost:8000/v1"
        # "local/localhost:8000"
        chat_context_length=2048,  # adjust based on model
    )

    config = DocChatAgentConfig(
        use_functions_api=fn_api,
        use_tools=not fn_api,
        llm=llm_config,
        extraction_granularity=3,
        # for relevance extraction
        # relevance_extractor_config=None,  # set to None to disable relevance extraction
        # set it to > 0 to retrieve a window of k chunks on either side of a match
        n_neighbor_chunks=2,
        parsing=ParsingConfig(  # modify as needed
            splitter=Splitter.TOKENS,
            chunk_size=200,  # aim for this many tokens per chunk
            overlap=50,  # overlap between chunks
            max_chunks=10_000,
            n_neighbor_ids=5,  # store ids of window of k chunks around each chunk.
            # aim to have at least this many chars per chunk when
            # truncating due to punctuation
            min_chunk_chars=200,
            discard_chunk_chars=5,  # discard chunks with fewer than this many chars
            n_similar_docs=5,
            # NOTE: PDF parsing is extremely challenging, each library has its own
            # strengths and weaknesses. Try one that works for your use case.
            pdf=PdfParsingConfig(
                # alternatives: "unstructured", "docling", "fitz"
                library="fitz",
            ),
        ),
        system_message=f"""
        {system_msg} You will try your best to answer my questions,
        in this order of preference:
        1. If you can answer from your own knowledge, simply return the answer
        2. Otherwise:
         2.1 If the question contains a URL, then use the `relevant_search_extracts`
             tool/function with the `query` field set to 
             this EXACT QUESTION INTACT! (DO NOT REPHRASE IT),
             and set the appropriate `tag` to UNIQUELY identify 
             docs from this search, to be able to refer to docs from 
             this search in FUTURE uses of the `relevant_extracts` tool.
         2.1 Otherwise, 
             if you have previously used the `relevant_search_extracts` 
                tool/fn-call
             to do a web search, you can ask for some relevant text from those search
             results, using the `relevant_extracts` tool/function-call, 
             and you MUST ONLY use a PREVIOUSLY used tag to correctly identify
             the prior search results to narrow down the search,
             and you will receive relevant extracts, if any.
             If you receive {NO_ANSWER}, it means no relevant extracts exist,
             and you can try the next step 2.2, using a web search.
             
         2.2 otherwise, i.e. you have NOT YET done a web search, you can use
             the `relevant_search_extracts` tool/function-call to search the web,
             MAKING SURE YOU SET a UNIQUE TAG (LOWER CASE, short word or 
             phrase) in the `tag` field, to UNIQUELY identify the docs from 
             this search, to be able to refer to them in a future use of 
             `relevant_extracts` tool.
             You will then receive relevant extracts from these search results, 
             if any. 
        3. If you are still unable to answer, you can use the `relevant_search_extracts`
           tool/function-call to get some text from a web search. Once you receive the
           text, you can use it to answer my question.
        4. If you still can't answer, simply say {NO_ANSWER} 
        
        Remember these simple rules:
         (a) if a question contains a URL, simply use the `relevant_search_extracts`
                tool/function-call with the `query` field set to this EXACT QUESTION
         (b) else if you have ALREADY done a web-search 
         (using the `relevant_search_extracts` tool),
         you should FIRST try `relevant_extracts` to see if there are
         any relevant passages from PREVIOUS SEARCHES, before doing a new search.
         
         YOU CAN USE TOOLS MULTIPLE TIMES before composing your answer.
         For example, when asked to compare two things, you can use the
         `relevant_extracts` tool multiple times to get relevant extracts
         from different PRIOR search results, and THEN compose your answer!
        
        Be very concise in your responses, use no more than 1-2 sentences.
        When you answer based on provided documents, be sure to show me 
        the SOURCE(s) and EXTRACT(s), for example:
        
        SOURCE: https://www.wikihow.com/Be-a-Good-Assistant-Manager
        EXTRACT: Be a Good Assistant ... requires good leadership skills.
        
        For the EXTRACT, ONLY show up to first 3 words, and last 3 words.
        """,
    )

    agent = SearchDocChatAgent(config)
    agent.enable_message(RelevantExtractsTool)
    agent.enable_message(RelevantSearchExtractsTool)
    collection_name = Prompt.ask(
        "Name a collection to use",
        default="docqa-chat-search",
    )
    replace = (
        Prompt.ask(
            "Would you like to replace (i.e. erase) this collection?",
            choices=["y", "n"],
            default="n",
        )
        == "y"
    )

    print(f"[red]Using {collection_name}")

    agent.vecdb.set_collection(collection_name, replace=replace)

    task = Task(agent, interactive=False)
    task.run("Can you help me answer some questions, possibly using web search?")


if __name__ == "__main__":
    Fire(main)

>>>> examples/docqa/chat.py
"""
Single agent to use to chat with a Retrieval-augmented LLM.
Repeat: User asks question -> LLM answers.

Run like this, either with a document-path (can be URL, file-path, folder-path):

python3 examples/docqa/chat.py url-or-file-orfolder-path

(or run with no arguments to go through the dialog).

If a document-arg is provided, it will be ingested into the vector database.

To change the model, use the --model flag, e.g.:

python3 examples/docqa/chat.py --model ollama/mistral:7b-instruct-v0.2-q8_0

To change the embedding service provider, use the --embed and --embedconfig flags, e.g.:

For OpenAI
python3 examples/docqa/chat.py --embed openai

For Huggingface SentenceTransformers
python3 examples/docqa/chat.py --embed hf --embedconfig BAAI/bge-large-en-v1.5

For Llama.cpp Server
python3 examples/docqa/chat.py --embed llamacpp --embedconfig localhost:8000

See here for how to set up a Local LLM to work with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/

"""

import typer
from rich import print
import os

import langroid as lr
import langroid.language_models as lm
from langroid.agent.special.doc_chat_agent import (
    DocChatAgent,
    DocChatAgentConfig,
)

from langroid.parsing.parser import ParsingConfig, PdfParsingConfig, Splitter
from langroid.utils.configuration import set_global, Settings

app = typer.Typer()

os.environ["TOKENIZERS_PARALLELISM"] = "false"


@app.command()
def main(
    doc: str = typer.Argument("", help="url, file-path or folder to chat about"),
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
    vecdb: str = typer.Option(
        "qdrant", "--vecdb", "-v", help="vector db name (default: qdrant)"
    ),
    nostream: bool = typer.Option(False, "--nostream", "-ns", help="no streaming"),
    embed_provider: str = typer.Option(
        "openai",
        "--embed",
        "-e",
        help="Embedding service provider",
        # openai, hf, llamacpp
    ),
    embed_config: str = typer.Option(
        None,
        "--embedconfig",
        "-ec",
        help="Embedding service host/sentence transformer model",
    ),
    # e.g. NeuML/pubmedbert-base-embeddings
) -> None:
    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,  # adjust as needed
        temperature=0.2,
        max_output_tokens=300,
        timeout=60,
    )

    config = DocChatAgentConfig(
        llm=llm_config,
        n_query_rephrases=0,
        full_citations=True,
        hypothetical_answer=False,
        # how many sentences in each segment, for relevance-extraction:
        # increase this if you find that relevance extraction is losing context
        extraction_granularity=3,
        # for relevance extraction
        # relevance_extractor_config=None,  # set to None to disable relevance extraction
        # set it to > 0 to retrieve a window of k chunks on either side of a match
        n_neighbor_chunks=2,
        parsing=ParsingConfig(  # modify as needed
            splitter=Splitter.TOKENS,
            chunk_size=200,  # aim for this many tokens per chunk
            overlap=50,  # overlap between chunks
            max_chunks=10_000,
            n_neighbor_ids=5,  # store ids of window of k chunks around each chunk.
            # aim to have at least this many chars per chunk when
            # truncating due to punctuation
            min_chunk_chars=200,
            discard_chunk_chars=5,  # discard chunks with fewer than this many chars
            n_similar_docs=5,
            # NOTE: PDF parsing is extremely challenging, each library has its own
            # strengths and weaknesses. Try one that works for your use case.
            pdf=PdfParsingConfig(
                # see here for possible values:
                # https://github.com/langroid/langroid/blob/main/langroid/parsing/parser.py
                library="pymupdf4llm",
            ),
        ),
    )

    match embed_provider:
        case "hf":
            embed_cfg = lr.embedding_models.SentenceTransformerEmbeddingsConfig(
                model_type="sentence-transformer",
                model_name=embed_config,
            )
        case "llamacpp":
            embed_cfg = lr.embedding_models.LlamaCppServerEmbeddingsConfig(
                api_base=embed_config,
                dims=768,  # Change this to match the dimensions of your embedding model
            )
        case "gemini":
            embed_cfg = lr.embedding_models.GeminiEmbeddingsConfig(
                model_type="gemini", dims=768
            )
        case _:
            embed_cfg = lr.embedding_models.OpenAIEmbeddingsConfig()

    match vecdb:
        case "lance" | "lancedb":
            config.vecdb = lr.vector_store.LanceDBConfig(
                collection_name="doc-chat-lancedb",
                storage_path=".lancedb/data/",
                embedding=embed_cfg,
            )
        case "qdrant" | "qdrantdb":
            config.vecdb = lr.vector_store.QdrantDBConfig(
                cloud=False,
                storage_path=".qdrant/doc-chat",
                embedding=embed_cfg,
            )
        case "chroma" | "chromadb":
            config.vecdb = lr.vector_store.ChromaDBConfig(
                storage_path=".chroma/doc-chat",
                embedding=embed_cfg,
            )
        case "weaviate" | "weaviatedb":
            config.vecdb = lr.vector_store.WeaviateDBConfig(
                embedding=embed_cfg,
            )
        case "pinecone" | "pineconedb":
            config.vecdb = lr.vector_store.PineconeDBConfig(
                collection_name="doc-chat-pinecone-serverless",
                embedding=embed_cfg,
            )
        case "postgres" | "postgresdb":
            config.vecdb = lr.vector_store.PostgresDBConfig(
                embedding=embed_cfg, cloud=True
            )

    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
            stream=not nostream,
        )
    )

    agent = DocChatAgent(config)
    print("[blue]Welcome to the document chatbot!")

    if doc:
        # TODO - could save time by checking whether we've already ingested this doc(s)
        agent.ingest_doc_paths([doc])
    else:
        agent.user_docs_ingest_dialog()

    print("[cyan]Enter x or q to quit")

    task = lr.Task(
        agent,
        system_message="You are a helpful assistant, "
        "answering questions about some docs",
    )
    task.run()


if __name__ == "__main__":
    app()

>>>> examples/docqa/chat_multi_extract.py
"""
Two-agent chat with Retrieval-augmented LLM + function-call/tool.
ExtractorAgent (has no access to docs) is tasked with extracting structured
information from a commercial lease document, and must present the terms in
a specific nested JSON format.
This agent generates questions corresponding to each field in the JSON format,
and the RAG-enabled DocAgent (has access to the lease) answers the  questions.


Example:
python3 examples/docqa/chat_multi_extract.py

This uses a GPT4 model by default, but works very well with the `dolphin-mixtral`
local LLM, which you can specify via the -m arg:

```
ollama run dolphin-mixtral

python3 examples/docqa/chat_multi_extract.py -m ollama/dolphin-mixtral:latest
```

The challenging parts in this script are agent-to-agent delegation, and the extractor
agent planning out a sequence of questions to ask the doc agent, and finally presenting
the collected information in a structured format to the user using a Tool/Function-call.
The `dolphin-mixtral` model seems to handle this pretty well, however weaker models
may not be able to handle this.

For weaker LLMs, the script examples/docqa/chat-multi-extract-local.py performs a similar task
but uses a workflow where agents do not delegate to each other,
and uses more agents to break down tasks into smaller parts.

"""

import typer
from rich import print
from langroid.pydantic_v1 import BaseModel
from typing import List
import json
import os

import langroid.language_models as lm
from langroid.mytypes import Entity
from langroid.agent.special.doc_chat_agent import DocChatAgent, DocChatAgentConfig
from langroid.parsing.parser import ParsingConfig
from langroid.agent.chat_agent import ChatAgent, ChatAgentConfig
from langroid.agent.task import Task
from langroid.agent.tool_message import ToolMessage
from langroid.language_models.openai_gpt import OpenAIGPTConfig
from langroid.utils.configuration import set_global, Settings
from langroid.utils.constants import NO_ANSWER

app = typer.Typer()

os.environ["TOKENIZERS_PARALLELISM"] = "false"


class LeasePeriod(BaseModel):
    start_date: str
    end_date: str


class LeaseFinancials(BaseModel):
    monthly_rent: str
    deposit: str


class Lease(BaseModel):
    """
    Various lease terms.
    Nested fields to make this more interesting/realistic
    """

    period: LeasePeriod
    financials: LeaseFinancials
    address: str


class LeaseMessage(ToolMessage):
    """Tool/function to use to present details about a commercial lease"""

    request: str = "lease_info"
    purpose: str = """
        Collect information about a Commercial Lease.
        """
    terms: Lease
    result: str = ""

    @classmethod
    def examples(cls) -> List["LeaseMessage"]:
        return [
            cls(
                terms=Lease(
                    period=LeasePeriod(start_date="2021-01-01", end_date="2021-12-31"),
                    financials=LeaseFinancials(monthly_rent="$1000", deposit="$1000"),
                    address="123 Main St, San Francisco, CA 94105",
                ),
                result="",
            ),
            cls(
                terms=Lease(
                    period=LeasePeriod(start_date="2021-04-01", end_date="2022-04-28"),
                    financials=LeaseFinancials(monthly_rent="$2000", deposit="$2000"),
                    address="456 Main St, San Francisco, CA 94111",
                ),
                result="",
            ),
        ]


class LeaseExtractorAgent(ChatAgent):
    def __init__(self, config: ChatAgentConfig):
        super().__init__(config)

    def lease_info(self, message: LeaseMessage) -> str:
        print(
            f"""
        DONE! Successfully extracted Lease Info:
        {message.terms}
        """
        )
        return "DONE " + json.dumps(message.terms.dict())


@app.command()
def main(
    debug: bool = typer.Option(False, "--debug", "-d", help="debug mode"),
    model: str = typer.Option("", "--model", "-m", help="model name"),
    nocache: bool = typer.Option(False, "--nocache", "-nc", help="don't use cache"),
) -> None:
    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )
    llm_cfg = OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        chat_context_length=16_000,  # adjust based on model
        temperature=0,
        timeout=45,
    )
    doc_agent = DocChatAgent(
        DocChatAgentConfig(
            llm=llm_cfg,
            parsing=ParsingConfig(
                chunk_size=300,
                overlap=50,
                n_similar_docs=3,
            ),
            cross_encoder_reranking_model="",
        )
    )
    doc_agent.vecdb.set_collection("docqa-chat-multi-extract", replace=True)
    print("[blue]Welcome to the real-estate info-extractor!")
    doc_agent.config.doc_paths = [
        "examples/docqa/lease.txt",
    ]
    doc_agent.ingest()
    doc_task = Task(
        doc_agent,
        name="DocAgent",
        done_if_no_response=[Entity.LLM],  # done if null response from LLM
        done_if_response=[Entity.LLM],  # done if non-null response from LLM
        system_message="""You are an expert on Commercial Leases. 
        You will receive various questions about a Commercial 
        Lease contract, along with some excerpts from the Lease.
        Your job is to answer them concisely in at most 2 sentences.
        """,
    )

    lease_extractor_agent = LeaseExtractorAgent(
        ChatAgentConfig(
            llm=llm_cfg,
            vecdb=None,
        )
    )
    lease_extractor_agent.enable_message(LeaseMessage)

    lease_task = Task(
        lease_extractor_agent,
        name="LeaseExtractorAgent",
        interactive=False,  # set to True to slow it down (hit enter to progress)
        system_message=f"""
        You have to collect some SPECIFIC STRUCTURED information 
        about a Commercial Lease, as specified in the `lease_info` function/tool. 
        But you do not have access to the lease itself. 
        You can ask me questions about the lease, ONE AT A TIME, I will answer each 
        question. You only need to collect info to fill the fields in the 
        `lease_info` function/tool. 
        If I am unable to answer your question initially, try asking me 
        differently. If I am still unable to answer after 3 tries, fill in 
        {NO_ANSWER} for that field.
        When you have collected this info, present it to me using the 
        'lease_info' function/tool.
        DO NOT USE THIS Function/tool UNTIL YOU HAVE ASKED QUESTIONS 
        TO FILL IN ALL THE FIELDS.
        
        Start by asking me for the start date of the lease.
        """,
    )
    lease_task.add_sub_task(doc_task)
    lease_task.run()


if __name__ == "__main__":
    app()

>>>> examples/docqa/chat_search.py
"""
This is a single-agent question-answering system that has access to a Web-Search
Tool when needed,
and in case a web search is used, ingests scraped link contents into a vector-db,
and uses Retrieval Augmentation to answer the question.

Run like this:

    python3 examples/docqa/chat-search.py -m groq/llama-3.1-70b-versatile

The -m arg is optional, defaults to GPT4o

Optional args:
    -nc : turn off caching (i.e. don't retrieve cached LLM responses)
    -d: debug mode, to show all intermediate results
    -f: use OpenAI functions api instead of tools
    -m <model_name>:  run with a specific LLM
    (defaults to GPT4-Turbo if blank)
    -c <crawler_name>: specify a crawler to use for web search. Options are:
         "trafilatura" (default), "firecrawl"

See here for guide to using local LLMs with Langroid:
https://langroid.github.io/langroid/tutorials/local-llm-setup/
"""

import typer
import re
from typing import List, Any, Optional

from rich import print
from rich.prompt import Prompt
import logging
import langroid as lr
import langroid.language_models as lm
from langroid.agent.tools.orchestration import ForwardTool
from langroid.agent.tool_message import ToolMessage
from langroid.agent.chat_agent import ChatAgent, ChatDocument
from langroid.agent.special.doc_chat_agent import (
    DocChatAgent,
    DocChatAgentConfig,
)
from langroid.parsing.web_search import exa_search
from langroid.agent.task import Task
from langroid.utils.constants import NO_ANSWER
from langroid.utils.configuration import set_global, Settings
from fire import Fire
from langroid.parsing.url_loader import (
    TrafilaturaConfig,
    FirecrawlConfig,
    ExaCrawlerConfig,
)

logger = logging.getLogger(__name__)


class RelevantExtractsTool(ToolMessage):
    request = "relevant_extracts"
    purpose = "Get docs/extracts relevant to the <query>"
    query: str

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        return [
            cls(query="when was the Mistral LLM released?"),
        ]

    @classmethod
    def instructions(cls) -> str:
        return """
        IMPORTANT: You must include an ACTUAL query in the `query` field,
        """


class RelevantSearchExtractsTool(ToolMessage):
    request = "relevant_search_extracts"
    purpose = "Get docs/extracts relevant to the <query> from a web search"
    query: str
    num_results: int = 3

    @classmethod
    def examples(cls) -> List["ToolMessage"]:
        return [
            cls(
                query="when was the Mistral LLM released?",
                num_results=3,
            ),
        ]

    @classmethod
    def instructions(cls) -> str:
        return """
        IMPORTANT: You must include an ACTUAL query in the `query` field,
        """


class SearchDocChatAgent(DocChatAgent):
    tried_vecdb: bool = False
    crawler: Optional[str] = None

    def __init__(self, config: DocChatAgentConfig, crawler: Optional[str] = None):
        super().__init__(config)
        self.tried_vecdb = False
        self.crawler = crawler
        self.update_crawler_config(crawler)

    def update_crawler_config(self, crawler: Optional[str]):
        """Updates the crawler config based on the crawler argument."""
        if crawler == "firecrawl":
            self.config.crawler_config = FirecrawlConfig()
        elif crawler == "trafilatura" or crawler is None:
            self.config.crawler_config = TrafilaturaConfig()
        elif crawler == "exa":
            self.config.crawler_config = ExaCrawlerConfig()
        else:
            raise ValueError(
                f"Unsupported crawler {crawler}. Options are: 'trafilatura', 'firecrawl'"
            )

    def llm_response(
        self,
        message: None | str | ChatDocument = None,
    ) -> ChatDocument | None:
        # override llm_response of DocChatAgent to allow use of the tools.
        return ChatAgent.llm_response(self, message)

    def handle_message_fallback(self, msg: str | ChatDocument) -> Any:
        if isinstance(msg, ChatDocument) and msg.metadata.sender == lr.Entity.LLM:
            return ForwardTool(agent="user")

    def relevant_extracts(self, msg: RelevantExtractsTool) -> str:
        """Get docs/extracts relevant to the query, from vecdb"""
        self.tried_vecdb = True
        query = msg.query
        _, extracts = self.get_relevant_extracts(query)
        if len(extracts) == 0:
            return """
            No extracts found! You can try doing a web search with the
            `relevant_search_extracts` tool/function-call.
            """
        return "\n".join(str(e) for e in extracts)

    def relevant_search_extracts(self, msg: RelevantSearchExtractsTool) -> str:
        """Get docs/extracts relevant to the query, from a web search"""
        if not self.tried_vecdb and len(self.original_docs) > 0:
            return "Please try the `relevant_extracts` tool, before using this tool"
        self.tried_vecdb = False
        query = msg.query
        num_results = msg.num_results
        logger.warning("Trying exa search...")
        results = exa_search(query, num_results)
        links = [r.link for r in results]
        logger.warning(f"Found {len(links)} links, ingesting into vecdb...")
        self.config.doc_paths = links
        self.ingest()
        logger.warning(f"Ingested {len(links)} links into vecdb")
        _, extracts = self.get_relevant_extracts(query)
        return "\n".join(str(e) for e in extracts)


def cli():
    Fire(main)


app = typer.Typer()


@app.command()
def main(
    debug: bool = False,
    nocache: bool = False,
    model: str = "",
    fn_api: bool = True,
    crawler: Optional[str] = typer.Option(
        None,
        "--crawler",
        "-c",
        help="Specify a crawler to use (trafilatura, firecrawl)",
    ),
) -> None:
    """
    Main function to run the chatbot.

    Args:
        debug (bool): Enable debug mode.
        nocache (bool): Disable caching.
        model (str): Specify the LLM model to use.
        fn_api (bool): Use OpenAI functions API instead of tools.
        crawler (str): Specify the crawler to use for web search.
    """

    set_global(
        Settings(
            debug=debug,
            cache=not nocache,
        )
    )

    print(
        """
        [blue]Welcome to the Internet Search chatbot!
        I will try to answer your questions, relying on (full content of links from) 
        Duckduckgo (DDG) Search when needed.
        
        Enter x or q to quit, or ? for evidence
        """
    )

    system_msg = Prompt.ask(
        """
    [blue] Tell me who I am (give me a role) by completing this sentence: 
    You are...
    [or hit enter for default]
    [blue] Human
    """,
        default="a helpful assistant.",
    )
    system_msg = re.sub("you are", "", system_msg, flags=re.IGNORECASE)

    llm_config = lm.OpenAIGPTConfig(
        chat_model=model or lm.OpenAIChatModel.GPT4o,
        # or, other possibilities for example:
        # "litellm/bedrock/anthropic.claude-instant-v1"
        # "ollama/llama2"
        # "local/localhost:8000/v1"
        # "local/localhost:8000"
        chat_context_length=8000,  # adjust based on model
    )

    config = DocChatAgentConfig(
        use_functions_api=fn_api,
        use_tools=not fn_api,
        llm=llm_config,
        system_message=f"""
        {system_msg} You will try your best to answer my questions,
        in this order of preference:
        1. If you can answer from your own knowledge, simply return the answer
        2. Otherwise, ask me for some relevant text, and I will send you. Use the 
            `relevant_extracts` tool/function-call for this purpose. Once you receive 
            the text, you can use it to answer my question. 
            If I say {NO_ANSWER}, it means I found no relevant docs, and you can try 
            the next step, using a web search.
        3. If you are still unable to answer, you can use the `relevant_search_extracts`
           tool/function-call to get some text from a web search. Once you receive the
           text, you can use it to answer my question.
        5. If you still can't answer, simply say {NO_ANSWER} 
        
        Remember to always FIRST try `relevant_extracts` to see if there are already 
        any relevant docs, before trying web-search with `relevant_search_extracts`.
        
        Be very concise in your responses, use no more than 1-2 sentences.
        When you answer based on provided documents, be sure to show me 
        the SOURCE(s) and EXTRACT(s), for example:
        
        SOURCE: https://www.wikihow.com/Be-a-Good-Assistant-Manager
        EXTRACT: Be a Good Assistant ... requires good leadership skills.
        
        For the EXTRACT, ONLY show up to first 3 words, and last 3 words.
        """,
    )

    agent = SearchDocChatAgent(config, crawler=crawler)
    agent.enable_message(
        [
            RelevantExtractsTool,
            RelevantSearchExtractsTool,
        ]
    )
    collection_name = Prompt.ask(
        "Name a collection to use",
        default="docqa-chat-search",
    )
    replace = (
        Prompt.ask(
            "Would you like to replace (i.e. erase) this collection?",
            choices=["y", "n"],
            default="n",
        )
        == "y"
    )

    print(f"[red]Using {collection_name}")

    agent.vecdb.set_collection(collection_name, replace=replace)

    task = Task(agent, interactive=False)
    task.run(
        "Can you help me answer some questions, possibly using web search and crawling?"
    )


if __name__ == "__main__":
    app()

>>>> examples/docqa/data/imdb-drama.csv
movie,genre,runtime,certificate,rating,stars,description,votes,director
The Sixth Commandment,Drama            ,,,8.1,"['Adrian Rawlins, ', 'Amanda Root, ', 'Conor MacNeill, ', 'Éanna Hardwicke', '']","Follows the deaths of Peter Farquhar and Ann Moore-Martin in the village of Maids Moreton, Buckinghamshire, and the extraordinary events that unfolded in the following years.","1,801",
The Shawshank Redemption,Drama            ,142 min,A,9.3,"['Tim Robbins, ', 'Morgan Freeman, ', 'Bob Gunton, ', 'William Sadler', '']","Over the course of several years, two convicts form a friendship, seeking consolation and, eventually, redemption through basic compassion.",$28.34M,['Frank Darabont']
Euphoria,Drama            ,55 min,A,8.3,"['Zendaya, ', 'Hunter Schafer, ', 'Jacob Elordi, ', 'Maude Apatow', '']","A look at life for a group of high school students as they grapple with issues of drugs, sex, and violence.","2,14,007",
The Good Doctor,Drama            ,41 min,15+,8,"['Freddie Highmore, ', 'Hill Harper, ', 'Richard Schiff, ', 'Christina Chang', '']","Shaun Murphy, a young surgeon with autism and Savant syndrome, is recruited into the surgical unit of a prestigious hospital.","1,05,685",
Billions,Drama            ,60 min,15+,8.4,"['Paul Giamatti, ', 'Damian Lewis, ', 'Maggie Siff, ', 'David Costabile', '']","New money means no mercy as Mike Prince takes the Axe Capital throne. Chuck Rhoades is convinced no one should have that much wealth - or power. As all the players seek out new alliances, only one thing's for certain - wealth means war.","99,042",
Fight Club,Drama            ,139 min,A,8.8,"['Brad Pitt, ', 'Edward Norton, ', 'Meat Loaf, ', 'Zach Grenier', '']",An insomniac office worker and a devil-may-care soap maker form an underground fight club that evolves into much more.,$37.03M,['David Fincher']
Mad Men,Drama            ,47 min,16+,8.7,"['Jon Hamm, ', 'Elisabeth Moss, ', 'Vincent Kartheiser, ', 'January Jones', '']","A drama about one of New York's most prestigious ad agencies at the beginning of the 1960s, focusing on one of the firm's most mysterious but extremely talented ad executives, Donald Draper.","2,50,518",
The Whale,Drama            ,117 min,A,7.7,"['Brendan Fraser, ', 'Sadie Sink, ', 'Ty Simpkins, ', 'Hong Chau', '']","A reclusive, morbidly obese English teacher attempts to reconnect with his estranged teenage daughter.","1,65,378",['Darren Aronofsky']
The Morning Show,Drama            ,60 min,15+,8.2,"['Jennifer Aniston, ', 'Reese Witherspoon, ', 'Billy Crudup, ', 'Mark Duplass', '']","An inside look at the lives of the people who help America wake up in the morning, exploring the unique challenges faced by the team.","1,11,773",
The Beauty Queen of Jerusalem,Drama            ,28 min,,7.3,"['Michael Aloni, ', 'Swell Ariel Or, ', 'Hila Saada, ', 'Irit Kaplan', '']","A family living through the Ottoman Empire, The British Mandate and Israel's War of Independence. The multi-generational historical melodrama will shoot across the country in Hebrew, English, Ladino and Arabic.","1,224",
American Beauty,Drama            ,122 min,UA,8.3,"['Kevin Spacey, ', 'Annette Bening, ', 'Thora Birch, ', 'Wes Bentley', '']",A sexually frustrated suburban father has a mid-life crisis after becoming infatuated with his daughter's best friend.,$130.10M,['Sam Mendes']
House of Cards,Drama            ,51 min,16+,8.7,"['Kevin Spacey, ', 'Michel Gill, ', 'Robin Wright, ', 'Kate Mara', '']",A Congressman works with his equally conniving wife to exact revenge on the people who betrayed him.,"5,17,957",
There Will Be Blood,Drama            ,158 min,A,8.2,"['Daniel Day-Lewis, ', 'Paul Dano, ', 'Ciarán Hinds, ', 'Martin Stringer', '']","A story of family, religion, hatred, oil and madness, focusing on a turn-of-the-century prospector in the early days of the business.",$40.22M,['Paul Thomas Anderson']
Requiem for a Dream,Drama            ,102 min,A,8.3,"['Ellen Burstyn, ', 'Jared Leto, ', 'Jennifer Connelly, ', 'Marlon Wayans', '']",The drug-induced utopias of four Coney Island people are shattered when their addictions run deep.,$3.64M,['Darren Aronofsky']
One Flew Over the Cuckoo's Nest,Drama            ,133 min,A,8.7,"['Jack Nicholson, ', 'Louise Fletcher, ', 'Michael Berryman, ', 'Peter Brocco', '']","In the Fall of 1963, a Korean War veteran and criminal pleads insanity and is admitted to a mental institution, where he rallies up the scared patients against the tyrannical nurse.",$112.00M,['Milos Forman']
Dawn,Drama            ,,,5.9,"['Brec Bassinger, ', 'Khobe Clarke, ', 'Donna Mills, ', 'Elyse Maloway', '']","Follows the dark, twisted history of Dawn Longchamp and her family, along with the Cutler and Booth families.",231,['Linda-Lisa Hayter']
Salò o le 120 giornate di Sodoma,Drama            ,117 min,A,5.8,"['Paolo Bonacelli, ', 'Giorgio Cataldi, ', 'Uberto Paolo Quintavalle, ', 'Aldo Valletti', '']","In World War II Italy, four fascist libertines round up nine adolescent boys and girls and subject them to 120 days of physical, mental, and sexual torture.","63,298",['Pier Paolo Pasolini']
The Passion of the Christ,Drama            ,127 min,A,7.2,"['Jim Caviezel, ', 'Monica Bellucci, ', 'Maia Morgenstern, ', 'Christo Jivkov', '']","Depicts the final twelve hours in the life of Jesus of Nazareth, on the day of his crucifixion in Jerusalem.",$370.78M,['Mel Gibson']
The Fabelmans,Drama            ,151 min,UA,7.6,"['Michelle Williams, ', 'Gabriel LaBelle, ', 'Paul Dano, ', 'Judd Hirsch', '']","Growing up in post-World War II era Arizona, young Sammy Fabelman aspires to become a filmmaker as he reaches adolescence, but soon discovers a shattering family secret and explores how the power of films can help him see the truth.","97,298",['Steven Spielberg']
Troy,Drama            ,163 min,UA,7.3,"['Brad Pitt, ', 'Eric Bana, ', 'Orlando Bloom, ', 'Julian Glover', '']","An adaptation of Homer's great epic, the film follows the assault on Troy by the united Greek forces and chronicles the fates of the men involved.",$133.38M,['Wolfgang Petersen']
Aftersun,Drama            ,102 min,R,7.7,"['Paul Mescal, ', 'Frankie Corio, ', 'Celia Rowlson-Hall, ', 'Sally Messham', '']",Sophie reflects on the shared joy and private melancholy of a holiday she took with her father twenty years earlier. Memories real and imagined fill the gaps between as she tries to reconcile the father she knew with the man she didn't...,"69,877",['Charlotte Wells']
The West Wing,Drama            ,44 min,,8.9,"['Martin Sheen, ', 'Rob Lowe, ', 'Allison Janney, ', 'John Spencer', '']",Inside the lives of staffers in the West Wing of the White House.,"81,414",
Chicago Med,Drama            ,43 min,UA 16+,7.6,"['Nick Gehlfuss, ', 'Marlyne Barrett, ', 'S. Epatha Merkerson, ', 'Oliver Platt', '']","The city's most highly skilled medical team saves lives, while navigating their unique interpersonal relationships.","27,648",
Kids,Drama            ,91 min,A,7,"['Leo Fitzpatrick, ', 'Justin Pierce, ', 'Chloë Sevigny, ', 'Sarah Henderson', '']","A day in the life of a group of teens as they travel around New York City skating, drinking, smoking and deflowering virgins.",$7.42M,['Larry Clark']
The Queen's Gambit,Drama            ,60 min,18,8.6,"['Anya Taylor-Joy, ', 'Chloe Pirrie, ', 'Bill Camp, ', 'Marcin Dorocinski', '']","Orphaned at the tender age of nine, prodigious introvert Beth Harmon discovers and masters the game of chess in 1960s USA. But child stardom comes at a price.","5,01,575",
Jagten,Drama            ,115 min,7,8.3,"['Mads Mikkelsen, ', 'Thomas Bo Larsen, ', 'Annika Wedderkopp, ', 'Lasse Fogelstrøm', '']","A teacher lives a lonely life, all the while struggling over his son's custody. His life slowly gets better as he finds love and receives good news from his son, but his new luck is about to be brutally shattered by an innocent little lie.",$0.69M,['Thomas Vinterberg']
New Amsterdam,Drama            ,43 min,Not Rated,8,"['Ryan Eggold, ', 'Janet Montgomery, ', 'Jocko Sims, ', 'Tyler Labine', '']",A new medical director breaks the rules to heal the system at America's oldest public hospital.,"45,961",
Drops of God,Drama            ,,A,8.1,"['Tomohisa Yamashita, ', 'Fleur Geffrier, ', 'Tom Wozniczka, ', 'Stanley Weber', '']",A woman discovers the world's greatest wine collection that's left by her estranged father and competes against his protege to claim her inheritance.,"5,964",
All the Queen's Men,Drama            ,43 min,,6.7,"['Eva Marcille, ', 'Racquel Palmer, ', 'Candace Maxwell, ', 'Oshea Russell', '']","Centers around the life of Marilyn 'Madam' DeVille. Madam is a fierce businesswoman who is at the top of her game in the nightclub industry and surrounded by a band of trusted employees who...                See full summary »
","1,663",
Minari,Drama            ,115 min,UA,7.4,"['Steven Yeun, ', 'Yeri Han, ', 'Alan Kim, ', 'Noel Cho', '']","A Korean American family moves to an Arkansas farm in search of its own American dream. Amidst the challenges of new life in the strange and rugged Ozarks, they discover the undeniable resilience of family and what really makes a home.","89,110",['Lee Isaac Chung']
The Chi,Drama            ,60 min,,7.6,"['Jason Mitchell, ', 'Jacob Latimore, ', 'Ntare Guma Mbaho Mwine, ', 'Alex R. Hibbert', '']","From Emmy® winner Lena Waithe, The Chi is a timely coming-of-age drama series centered on a group of residents who become linked by coincidence but bonded by the need for connection and redemption.","6,910",
Unspeakable,Drama            ,47 min,,5.8,"['Indira Varma, ', 'Luke Treadaway, ', 'Kate Ashfield, ', 'Neil Maskell', '']","A single mum receives an anonymous text message, claiming her new boyfriend is having an inappropriate relationship with her 11 year old daughter. Over one weekend the accusation fractures the relationship between the couple.",567,['David Nath']
The Swimmer,Drama            ,95 min,M/PG,7.6,"['Burt Lancaster, ', 'Janet Landgard, ', 'Janice Rule, ', 'Tony Bickley', '']",A man spends a summer day swimming as many pools as he can all over a quiet suburban town.,"12,858",
The Help,Drama            ,146 min,UA,8.1,"['Viola Davis, ', 'Emma Stone, ', 'Octavia Spencer, ', 'Bryce Dallas Howard', '']","An aspiring author during the civil rights movement of the 1960s decides to write a book detailing the African American maids' point of view on the white families for which they work, and the hardships they go through on a daily basis.",$169.71M,['Tate Taylor']
Nymphomaniac: Vol. I,Drama            ,117 min,Not Rated,6.9,"['Charlotte Gainsbourg, ', 'Stellan Skarsgård, ', 'Stacy Martin, ', 'Shia LaBeouf', '']",A self-diagnosed nymphomaniac recounts her erotic experiences to the man who saved her after a beating.,$0.79M,['Lars von Trier']
Pretty Baby,Drama            ,110 min,A,6.5,"['Brooke Shields, ', 'Keith Carradine, ', 'Susan Sarandon, ', 'Frances Faye', '']",A preteen girl lives as a prostitute in New Orleans in 1917.,$5.79M,['Louis Malle']
Druk,Drama            ,117 min,16,7.7,"['Mads Mikkelsen, ', 'Thomas Bo Larsen, ', 'Magnus Millang, ', 'Lars Ranthe', '']",Four high-school teachers consume alcohol on a daily basis to see how it affects their social and professional lives.,"1,77,928",['Thomas Vinterberg']
The Resident,Drama            ,60 min,15+,7.8,"['Matt Czuchry, ', 'Manish Dayal, ', 'Bruce Greenwood, ', 'Malcolm-Jamal Warner', '']",A group of doctors at Chastain Memorial Hospital face personal and professional challenges on a daily basis.,"29,588",
A Good Person,Drama            ,128 min,R,7,"['Florence Pugh, ', 'Morgan Freeman, ', ""Celeste O'Connor, "", 'Molly Shannon', '']","Follows Allison, whose life falls apart following her involvement in a fatal accident.","12,072",['Zach Braff']
Dopesick,Drama            ,492 min,18,8.6,"['Michael Keaton, ', 'Peter Sarsgaard, ', 'Michael Stuhlbarg, ', 'Will Poulter', '']","The series takes viewers to the epicenter of America's struggle with opioid addiction, from the boardrooms of Purdue Pharma, to a distressed Virginia mining community, to the hallways of the DEA.","66,117",
Boogie Nights,Drama            ,155 min,18,7.9,"['Mark Wahlberg, ', 'Julianne Moore, ', 'Burt Reynolds, ', 'Luis Guzmán', '']","Back when sex was safe, pleasure was a business and business was booming, an idealistic porn producer aspires to elevate his craft to an art when he discovers a hot young talent.",$26.40M,['Paul Thomas Anderson']
The Perks of Being a Wallflower,Drama            ,103 min,UA,7.9,"['Logan Lerman, ', 'Emma Watson, ', 'Ezra Miller, ', 'Paul Rudd', '']","Charlie, a 15-year-old introvert, enters high school and is nervous about his new life. When he befriends his seniors, he learns to cope with his friend's suicide and his tumultuous past.",$17.74M,['Stephen Chbosky']
The Fallout,Drama            ,96 min,A,7,"['Jenna Ortega, ', 'Maddie Ziegler, ', 'Niles Fitch, ', 'Will Ropp', '']","High schooler Vada navigates the emotional fallout she experiences in the wake of a school tragedy. Relationships with her family, friends and view of the world are forever altered.","29,401",['Megan Park']
Skins,Drama            ,46 min,UA,8.2,"['Kaya Scodelario, ', 'Nicholas Hoult, ', 'Joe Dempsie, ', 'Hannah Murray', '']",The story of a group of British teens who are trying to grow up and find love and happiness despite questionable parenting and teachers who would rather be friends (and lovers) than authority figures.,"89,208",
Rain Man,Drama            ,133 min,U,8,"['Dustin Hoffman, ', 'Tom Cruise, ', 'Valeria Golino, ', 'Gerald R. Molen', '']","After a selfish L.A. yuppie learns his estranged father left a fortune to an autistic-savant brother in Ohio that he didn't know existed, he absconds with his brother and sets out across the country, hoping to gain a larger inheritance.",$178.80M,['Barry Levinson']
Showgirls,Drama            ,128 min,A,5,"['Elizabeth Berkley, ', 'Kyle MacLachlan, ', 'Gina Gershon, ', 'Glenn Plummer', '']","Carefree young drifter Nomi arrives in Las Vegas, Nevada to become a dancer and sets about clawing her way to the top of the Vegas showgirls.",$20.30M,['Paul Verhoeven']
Last Summer,Drama            ,95 min,,6.9,"['Barbara Hershey, ', 'Richard Thomas, ', 'Bruce Davison, ', 'Catherine Burns', '']","During summer vacation on Fire Island, three young people become very close. When an uncool girl tries to infiltrate the trio's newly found relationship, they construct an elaborate plot that has violent results.",$2.37M,['Frank Perry']
Manchester by the Sea,Drama            ,137 min,UA,7.8,"['Casey Affleck, ', 'Michelle Williams, ', 'Kyle Chandler, ', 'Lucas Hedges', '']",A depressed uncle is asked to take care of his teenage nephew after the boy's father dies.,$47.70M,['Kenneth Lonergan']
Trainspotting,Drama            ,93 min,A,8.1,"['Ewan McGregor, ', 'Ewen Bremner, ', 'Jonny Lee Miller, ', 'Kevin McKidd', '']","Renton, deeply immersed in the Edinburgh drug scene, tries to clean up and get out, despite the allure of the drugs and influence of friends.",$16.50M,['Danny Boyle']
The Newsroom,Drama            ,55 min,15+,8.6,"['Jeff Daniels, ', 'Emily Mortimer, ', 'John Gallagher Jr., ', 'Alison Pill', '']","A newsroom undergoes some changes in its workings and morals as a new team is brought in, bringing unexpected results for its existing news anchor.","1,20,491",
Thirteen,Drama            ,100 min,15+,6.8,"['Evan Rachel Wood, ', 'Holly Hunter, ', 'Nikki Reed, ', 'Vanessa Hudgens', '']","A thirteen-year-old girl's relationship with her mother is put to the test as she discovers drugs, sex, and petty crime in the company of her cool but troubled best friend.",$4.60M,['Catherine Hardwicke']
Kaalkoot,Drama            ,,,8.7,"['Rohan Verma, ', 'Vijay Varma, ', 'Shweta Tripathi, ', 'Suzanna Mukherjee', '']","A police officer must deal with society's and his mother's pressure to marry, as well as frequent bullying and pressure from his superiors.","4,514",
Goliath,Drama            ,60 min,18+,8.1,"['Billy Bob Thornton, ', 'Nina Arianda, ', 'Tania Raymonde, ', 'Diana Hopper', '']","A disgraced lawyer, now an ambulance chaser, gets a case that could bring him redemption or at least revenge on the firm which expelled him.","51,684",
Living,Drama            ,102 min,PG-13,7.3,"['Bill Nighy, ', 'Aimee Lou Wood, ', 'Alex Sharp, ', 'Adrian Rawlins', '']","In 1950s London, a humorless bureaucrat decides to take time off work to experience life after receiving a grim diagnosis.","24,130",['Oliver Hermanus']
Pleasure,Drama            ,109 min,R,6.4,"['Sofia Kappel, ', 'Zelda Morrison, ', 'Evelyn Claire, ', 'Chris Cock', '']","Bella Cherry arrives in Los Angeles with dreams of becoming an adult film star, but she soon learns that fame won't come easy as she harnesses her ambition and cunning to rise to the top of this mesmerizing and singular world.","20,174",['Ninja Thyberg']
Suits,Drama            ,40 min,UA 16+,7.4,"['Asser Yassin, ', 'Ahmed Dawood, ', 'Mohamed Shahin, ', 'Saba Mubarak', '']","Within the framework of the drama, the series deals with the story of Adam, who by chance turns into a lawyer in a large law firm when he reveals his secret to lawyer Zain, and together the duo handle many thorny cases.",582,
Big Love,Drama            ,60 min,,7.7,"['Bill Paxton, ', 'Jeanne Tripplehorn, ', 'Chloë Sevigny, ', 'Ginnifer Goodwin', '']",A Utah polygamist who owns home improvement stores in the Salt Lake City area juggles relationships with three wives while trying to keep his complex family life from becoming a public scandal.,"22,649",
The Great Escaper,Drama            ,,,,"['Michael Caine, ', 'Glenda Jackson, ', 'John Standing, ', 'Laura Marcus', '']",Bernard Jordan escapes from his care home to attend the 70th Anniversary of the D-Day Landings in France.,,['Oliver Parker']
Close,Drama            ,104 min,PG-13,7.8,"['Eden Dambrine, ', 'Gustav De Waele, ', 'Émilie Dequenne, ', 'Léa Drucker', '']","The intense friendship between two thirteen-year old boys Leo and Remi suddenly gets disrupted. Struggling to understand what has happened, Léo approaches Sophie, Rémi's mother. ""Close"" is a film about friendship and responsibility.","25,996",['Lukas Dhont']
Fleishman Is in Trouble,Drama            ,48 min,A,7.7,"['Jesse Eisenberg, ', 'Claire Danes, ', 'Lizzy Caplan, ', 'Adam Brody', '']","Toby Fleishman knew what to expect when he and his wife of almost 15 years separated: weekends and every other holiday with the kids, some residual bitterness, and the occasional moment of tension in their co-parenting negotiations.","13,033",
Fire Country,Drama            ,44 min,,7.2,"['Max Thieriot, ', 'Kevin Alejandro, ', 'Jordan Calloway, ', 'Stephanie Arcila', '']",A young convict joins a firefighting program looking for redemption and a shortened prison sentence. He and other inmates work alongside elite firefighters to extinguish massive blazes across the region.,"6,563",
Knokke Off,Drama            ,,,7.7,"['Pommelien Thijs, ', 'Willem De Schryver, ', 'Eliyha Altena, ', 'Anna Drijver', '']","Follows a group of teenagers as they spend the summer at the Belgian seaside while searching for love, friendship and most importantly, for themselves.",568,
Reality,Drama            ,83 min,,6.7,"['Sydney Sweeney, ', 'Josh Hamilton, ', 'Marchánt Davis, ', 'Benny Elledge', '']",A former American intelligence specialist was given the longest sentence for the unauthorized release of government information to the media about Russian interference in the 2016 United States elections via an email operation.,"9,977",['Tina Satter']
The Son,Drama            ,123 min,PG-13,6.4,"['Vanessa Kirby, ', 'Felix Goddard, ', 'Max Goddard, ', 'Hugh Jackman', '']","Peter has his busy life with new partner Beth and their baby thrown into disarray when his ex-wife Kate turns up with their teenage son, Nicholas.","11,739",['Florian Zeller']
Scent of a Woman,Drama            ,156 min,UA,8,"['Al Pacino, ', ""Chris O'Donnell, "", 'James Rebhorn, ', 'Gabrielle Anwar', '']","A prep school student needing money agrees to ""babysit"" a blind man, but the job is not at all what he anticipated.",$63.90M,['Martin Brest']
Maid,Drama            ,545 min,18,8.4,"['Margaret Qualley, ', 'Nick Robinson, ', 'Rylea Nevaeh Whittet, ', 'Andie MacDowell', '']","After fleeing an abusive relationship, a young mother finds a job cleaning houses as she fights to provide for her child and build them a better future.","91,814",
Magnolia,Drama            ,188 min,UA,8,"['Tom Cruise, ', 'Jason Robards, ', 'Julianne Moore, ', 'Philip Seymour Hoffman', '']","An epic mosaic of interrelated characters in search of love, forgiveness and meaning in the San Fernando Valley.",$22.46M,['Paul Thomas Anderson']
An Cailín Ciúin,Drama            ,95 min,PG-13,7.7,"['Carrie Crowley, ', 'Andrew Bennett, ', 'Catherine Clinch, ', 'Michael Patric', '']","Rural Ireland 1981. A quiet, neglected girl is sent away from her dysfunctional family to live with foster parents for the summer. She blossoms in their care, but in this house where there are meant to be no secrets, she discovers one.","15,572",['Colm Bairéad']
Y tu mamá también,Drama            ,106 min,A,7.7,"['Maribel Verdú, ', 'Gael García Bernal, ', 'Daniel Giménez Cacho, ', 'Ana López Mercado', '']","In Mexico, two teenage boys and an attractive older woman embark on a road trip and learn a thing or two about life, friendship, sex, and each other.",$13.62M,['Alfonso Cuarón']
The Gilded Age,Drama            ,81 min,UA 13+,8,"['Ben Ahlers, ', 'Celia Keenan-Bolger, ', 'Debra Monk, ', ""Kelli O'Hara"", '']","A wide-eyed young scion of a conservative family embarks on a mission to infiltrate the wealthy neighboring clan dominated by ruthless railroad tycoon George Russell, his rakish son, Larry, and his ambitious wife, Bertha.","27,061",
Women Talking,Drama            ,104 min,PG-13,6.9,"['Rooney Mara, ', 'Claire Foy, ', 'Jessie Buckley, ', 'Frances McDormand', '']","Do nothing, stay and fight, or leave. In 2010, the women of an isolated religious community grapple with reconciling a brutal reality with their faith.","32,837",['Sarah Polley']
Jesus Revolution,Drama            ,120 min,PG-13,7.1,"['Joel Courtney, ', 'Jonathan Roumie, ', 'Kimberly Williams-Paisley, ', 'Anna Grace Barlow', '']",The true story of a national spiritual awakening in the early 1970s and its origins within a community of teenage hippies in Southern California.,"9,161",
Brothers & Sisters,Drama            ,60 min,UA,7.4,"['Dave Annable, ', 'Calista Flockhart, ', 'Rachel Griffiths, ', 'Ron Rifkin', '']",The story of the drama surrounding a family's adult siblings.,"24,871",
Moonlight,Drama            ,111 min,A,7.4,"['Mahershala Ali, ', 'Naomie Harris, ', 'Trevante Rhodes, ', 'Alex R. Hibbert', '']","A young African-American man grapples with his identity and sexuality while experiencing the everyday struggles of childhood, adolescence, and burgeoning adulthood.",$27.85M,['Barry Jenkins']
Portrait de la jeune fille en feu,Drama            ,122 min,18,8.1,"['Noémie Merlant, ', 'Adèle Haenel, ', 'Luàna Bajrami, ', 'Valeria Golino', '']","On an isolated island in Brittany at the end of the eighteenth century, a female painter is obliged to paint a wedding portrait of a young woman.",$3.76M,['Céline Sciamma']
Crash,Drama            ,100 min,Not Rated,6.4,"['James Spader, ', 'Holly Hunter, ', 'Elias Koteas, ', 'Deborah Kara Unger', '']","After getting into a serious car accident, a TV director discovers an underground sub-culture of scarred, omnisexual car-crash victims who use car accidents and the raw sexual energy they produce to try to rejuvenate his sex life with his wife.",$2.04M,['David Cronenberg']
Bones of Crows,Drama            ,124 min,,6.5,"['Grace Dove, ', 'Phillip Forest Lewitski, ', 'Rémy Girard, ', 'Karine Vanasse', '']","Cree code talker Aline Spears survives her traumatic past in Canada's residential school system to continue her family's generational fight against systemic starvation, racism and sexual abuse.",290,['Marie Clements']
Prisoner's Daughter,Drama            ,100 min,R,6.4,"['Sarah Anderson, ', 'Maynard Bagang, ', 'Kate Beckinsale, ', 'Christopher Convery', '']","A father fights for the love of his daughter and grandson, after serving twelve years in prison.",837,['Catherine Hardwicke']
Capharnaüm,Drama            ,126 min,A,8.4,"['Zain Al Rafeea, ', 'Yordanos Shiferaw, ', 'Boluwatife Treasure Bankole, ', 'Kawsar Al Haddad', '']","While serving a five-year sentence for a violent crime, a 12-year-old boy sues his parents for neglect.",$1.66M,['Nadine Labaki']
Dronningen,Drama            ,127 min,18,7.1,"['Trine Dyrholm, ', 'Gustav Lindh, ', 'Magnus Krepper, ', 'Liv Esmår Dannemann', '']",A successful lawyer jeopardizes her career and threatens to tear her family apart after engaging in an affair with her teenage stepson.,"13,033",['May el-Toukhy']
Midnight Cowboy,Drama            ,113 min,A,7.8,"['Dustin Hoffman, ', 'Jon Voight, ', 'Sylvia Miles, ', 'John McGiver', '']","A naive hustler travels from Texas to New York City to seek personal fortune, finding a new friend in the process.",$44.79M,['John Schlesinger']
Pieces of a Woman,Drama            ,126 min,18,7,"['Vanessa Kirby, ', 'Shia LaBeouf, ', 'Ellen Burstyn, ', 'Iliza Shlesinger', '']","When a young mother's home birth ends in unfathomable tragedy, she begins a year-long odyssey of mourning that fractures relationships with loved ones in this deeply personal story of a woman learning to live alongside her loss.","53,463",['Kornél Mundruczó']
Pearson,Drama            ,42 min,,6.8,"['Gina Torres, ', 'Bethany Joy Lenz, ', 'Simon Kassianides, ', 'Eli Goree', '']",Attorney Jessica Pearson enters the complex and seedy world of Chicago politics.,"2,501",
The Kerala Story,Drama            ,138 min,A,7.2,"['Adah Sharma, ', 'Yogita Bihani, ', 'Sonia Balani, ', 'Siddhi Idnani', '']","A converted Muslim woman Fatima Ba narrates her ordeal of how she once wanted to become a nurse but was abducted from her home and manipulated by religious vanguards, turned into an ISIS terrorist and landed in Afghanistan jail.","64,354",
The Affair,Drama            ,60 min,18+,7.9,"['Dominic West, ', 'Ruth Wilson, ', 'Maura Tierney, ', 'Julia Goldani Telles', '']",A struggling novelist and a young waitress strike up an extramarital relationship that promises to forever change the course of their lives.,"47,713",
Disobedience,Drama            ,114 min,All,6.6,"['Rachel Weisz, ', 'Rachel McAdams, ', 'Alessandro Nivola, ', 'Anton Lesser', '']","A woman returns to her Orthodox Jewish community that shunned her for her attraction to a female childhood friend. Once back, their passions reignite as they explore the boundaries of faith and sexuality.",$3.48M,['Sebastián Lelio']
Jules,Drama            ,90 min,PG-13,8.6,"['Ben Kingsley, ', 'Harriet Sansom Harris, ', 'Zoe Winters, ', 'Jane Curtin', '']","Milton lives a quiet life of routine in a small western Pennsylvania town, but finds his day upended when a UFO and its extra-terrestrial passenger crash land in his backyard.",41,['Marc Turtletaub']
No Escape,Drama            ,,,6.8,"['Rhianne Barreto, ', 'Abigail Lawrie, ', 'Colette Dalal Tchantcho, ', 'Sean Keenan', '']","When a yacht is found adrift in the seas around Queensland, Australia- the galley fully stocked with plenty of food and everyone's personal items but with nobody onboard police launch an investigation.",710,
Reign,Drama            ,42 min,16,7.4,"['Adelaide Kane, ', 'Megan Follows, ', 'Celina Sinden, ', 'Torrance Coombs', '']","Mary, Queen of Scots, faces political and sexual intrigue in the treacherous world of the French court.","52,258",
What's Eating Gilbert Grape,Drama            ,118 min,U,7.7,"['Johnny Depp, ', 'Leonardo DiCaprio, ', 'Juliette Lewis, ', 'Mary Steenburgen', '']",A young man in a small Midwestern town struggles to care for his mentally-disabled younger brother and morbidly obese mother while attempting to pursue his own happiness.,$9.17M,['Lasse Hallström']
A Teacher,Drama            ,248 min,A,6.9,"['Kate Mara, ', 'Nick Robinson, ', 'Ashley Zukerman, ', 'Rya Kihlstedt', '']",A new teacher finds herself falling for one of her students.,"14,409",
Detachment,Drama            ,98 min,,7.7,"['Adrien Brody, ', 'Christina Hendricks, ', 'Marcia Gay Harden, ', 'Lucy Liu', '']",A substitute teacher who drifts from classroom to classroom finds a connection to the students and teachers during his latest assignment.,$0.07M,['Tony Kaye']
Nip/Tuck,Drama            ,44 min,,7.7,"['Dylan Walsh, ', 'Julian McMahon, ', 'Joely Richardson, ', 'John Hensley', '']",Two plastic surgeons--one a dedicated family man and one an unscrupulous playboy--strive to maintain their business whilst having to work their way through numerous hardships ranging from personal to clients with criminal connections.,"57,466",
The Florida Project,Drama            ,111 min,A,7.6,"['Brooklynn Prince, ', 'Bria Vinaite, ', 'Willem Dafoe, ', 'Christopher Rivera', '']","Set over one summer, the film follows precocious six-year-old Moonee as she courts mischief and adventure with her ragtag playmates and bonds with her rebellious but caring mother, all while living in the shadows of Walt Disney World.",$5.90M,['Sean Baker']
Shame,Drama            ,101 min,(Banned),7.2,"['Michael Fassbender, ', 'Carey Mulligan, ', 'James Badge Dale, ', 'Lucy Walters', '']",A sex addict's carefully cultivated private life falls apart after his sister arrives for an indefinite stay.,$4.00M,['Steve McQueen']
Boyhood,Drama            ,165 min,A,7.9,"['Ellar Coltrane, ', 'Patricia Arquette, ', 'Ethan Hawke, ', 'Elijah Smith', '']","The life of Mason, from early childhood to his arrival at college.",$25.38M,['Richard Linklater']
The Starling Girl,Drama            ,117 min,R,6.7,"['Eliza Scanlen, ', 'Lewis Pullman, ', 'Jimmi Simpson, ', 'Wrenn Schmidt', '']",17-year-old Jem Starling struggles with her place within her Christian fundamentalist community. But everything changes when her magnetic youth pastor Owen returns to their church.,901,['Laurel Parmet']
The Girlfriend Experience,Drama            ,27 min,18,7,"['Riley Keough, ', 'Paul Sparks, ', 'Julia Goldani Telles, ', 'Mary Lynn Rajskub', '']","Explores the relationships between exclusive escorts and their clients, for whom they provide far more than just sex. Known as GFEs, they are women who provide emotional and sexual relationships at a very high price.","11,361",
The Passion of the Christ: Resurrection,Drama            ,,,,"['Jim Caviezel, ', 'Maia Morgenstern, ', 'Francesco De Vito', '']",A sequel to The Passion of the Christ (2004) focuses on the events that occurred three days between the crucifixion and resurrection when Jesus Christ descended to Abraham's Bosom to preach and resurrect Old Testament saints.,,['Mel Gibson']
The Color Purple,Drama            ,154 min,U,7.7,"['Danny Glover, ', 'Whoopi Goldberg, ', 'Oprah Winfrey, ', 'Margaret Avery', '']",A black Southern woman struggles to find her identity after suffering abuse from her father and others over four decades.,$98.47M,['Steven Spielberg']
Sirf Ek Bandaa Kaafi Hai,Drama            ,132 min,UA,7.9,"['Manoj Bajpayee, ', 'Surya Mohan Kulshreshtha, ', 'Jai Hind Kumar, ', 'Nikhil Pandey', '']",A common man with honesty and integrity can take on the system when he has truth on his side.,"22,902",['Apoorv Singh Karki']
Pose,Drama            ,60 min,18,8.7,"['Michaela Jaé (MJ) Rodriguez, ', 'Dominique Jackson, ', 'Indya Moore, ', 'Angel Bismark Curiel', '']","In the New York of the late '80s and early '90s, this is a story of ball culture and the gay and trans community, the raging AIDS crisis, and capitalism.","31,163",
Tell Me Lies,Drama            ,49 min,A,6.7,"['Grace Van Patten, ', 'Jackson White, ', 'Catherine Missal, ', 'Spencer House', '']",The story of a young woman's obsession with a man who is good at being charming.,"5,424",
Term of Trial,Drama            ,130 min,,7.1,"['Laurence Olivier, ', 'Simone Signoret, ', 'Roland Culver, ', 'Frank Pettingell', '']","A British high-school girl becomes infatuated with her English teacher, but after he rejects her amorous advances, she goes to the police and accuses him of indecent assault.",782,['Peter Glenville']
"Paris, Texas",Drama            ,145 min,U,8.1,"['Harry Dean Stanton, ', 'Nastassja Kinski, ', 'Dean Stockwell, ', 'Sam Berry', '']","Travis Henderson, an aimless drifter who has been missing for four years, wanders out of the desert and must reconnect with society, himself, his life, and his family.",$2.18M,['Wim Wenders']
Gifted,Drama            ,101 min,15+,7.6,"['Chris Evans, ', 'Mckenna Grace, ', 'Lindsay Duncan, ', 'Octavia Spencer', '']","Frank, a single man raising his child prodigy niece Mary, is drawn into a custody battle with his mother.",$24.80M,['Marc Webb']
I-sang-han byeon-ho-sa U-yeong-u,Drama            ,75 min,UA 16+,8.7,"['Park Eun-bin, ', 'Kang Tae-oh, ', 'Kang Ki-young, ', 'Jeon Bae-soo', '']","Due to her 164 I.Q., impressive memory and creative thought process, autistic 27-year-old lawyer Woo Young Woo graduated at the top of her class from a prestigious law school.","21,117",
Gran Torino,Drama            ,116 min,UA,8.1,"['Clint Eastwood, ', 'Bee Vang, ', 'Christopher Carley, ', 'Ahney Her', '']","After a Hmong teenager tries to steal his prized 1972 Gran Torino, a disgruntled, prejudiced Korean War veteran seeks to redeem both the boy and himself.",$148.10M,['Clint Eastwood']
Nymphomaniac: Vol. II,Drama            ,124 min,Not Rated,6.6,"['Charlotte Gainsbourg, ', 'Stellan Skarsgård, ', 'Willem Dafoe, ', 'Jamie Bell', '']","The continuation of Joe's sexually dictated life delves into the darker aspects of her adulthood, obsessions and what led to her being in Seligman's care.",$0.33M,['Lars von Trier']
The Lost Flowers of Alice Hart,Drama            ,,,,"['Frankie Adams, ', 'Asher Keddie, ', 'Sigourney Weaver, ', 'Alyla Browne', '']","Follows a young girl, Alice Hart, whose violent childhood casts a dark shadow over her adult life.",,
Nomadland,Drama            ,107 min,UA,7.3,"['Frances McDormand, ', 'David Strathairn, ', 'Linda May, ', 'Gay DeForest', '']","A woman in her sixties, after losing everything in the Great Recession, embarks on a journey through the American West, living as a van-dwelling modern-day nomad.","1,72,620",['Chloé Zhao']
Cry Macho,Drama            ,104 min,13,5.7,"['Clint Eastwood, ', 'Dwight Yoakam, ', 'Daniel V. Graulau, ', 'Amber Lynn Ashley', '']","A one-time rodeo star and washed-up horse breeder takes a job to bring a man's young son home and away from his alcoholic mom. On their journey, the horseman finds redemption through teaching the boy what it means to be a good man.","30,390",['Clint Eastwood']
The Deuce,Drama            ,60 min,A,8.1,"['James Franco, ', 'Maggie Gyllenhaal, ', 'Lawrence Gilliard Jr., ', 'Margarita Levieva', '']","A look at life in New York City during the 1970s and '80s, when porn and prostitution were rampant in Manhattan.","30,624",
Palmer,Drama            ,110 min,A,7.2,"['Justin Timberlake, ', 'Juno Temple, ', 'Alisha Wainwright, ', 'Ryder Allen', '']",An ex-convict strikes up a friendship with a boy from a troubled home.,"39,355",['Fisher Stevens']
Bel-Air,Drama            ,51 min,,6.4,"['Jabari Banks, ', 'Cassandra Freeman, ', 'Jimmy Akingbola, ', 'Olly Sholotan', '']",The journey of a street-smart teen whose life is forever transformed when he moves from the streets of West Philadelphia to live with his relatives in one of LA's wealthiest suburbs.,"12,116",
Norma Rae,Drama            ,114 min,A,7.3,"['Sally Field, ', 'Beau Bridges, ', 'Ron Leibman, ', 'Pat Hingle', '']",A young single mother and textile worker agrees to help unionize her mill despite the problems and dangers involved.,$22.23M,['Martin Ritt']
Everwood,Drama            ,60 min,,7.5,"['Treat Williams, ', 'Gregory Smith, ', 'Emily VanCamp, ', 'Debra Mooney', '']","A widowed brain surgeon from Manhattan moves his two children to the small mountain town of Everwood, Colorado.","14,759",
Half Nelson,Drama            ,106 min,A,7.1,"['Ryan Gosling, ', 'Anthony Mackie, ', 'Shareeka Epps, ', 'Jeff Lima', '']",An inner-city junior high school teacher with a drug habit forms an unlikely friendship with one of his students after she discovers his secret.,$2.69M,['Ryan Fleck']
Philadelphia,Drama            ,125 min,UA,7.7,"['Tom Hanks, ', 'Denzel Washington, ', 'Roberta Maxwell, ', 'Buzz Kilman', '']","When a man with HIV is fired by his law firm because of his condition, he hires a homophobic small time lawyer as the only willing advocate for a wrongful dismissal suit.",$77.32M,['Jonathan Demme']
Aspirants,Drama            ,45 min,Not Rated,9.2,"['Naveen Kasturia, ', 'Shivankit Singh Parihar, ', 'Abhilash Thapliyal, ', 'Sunny Hinduja', '']",It is the story of the journey of three UPSC (public service competitive exams in India) aspirants and their friendship against all odds.,"3,03,498",
The Room,Drama            ,99 min,UA,3.6,"['Tommy Wiseau, ', 'Juliette Danielle, ', 'Greg Sestero, ', 'Philip Haldiman', '']","In San Francisco, an amiable banker's seemingly perfect life is turned upside down when his deceitful fiancée embarks on an affair with his best friend.",$0.56M,['Tommy Wiseau']
Lessons in Chemistry,Drama            ,,,,"['Brie Larson, ', 'Joy Jacobson, ', 'Yasir Hashim Lafond, ', 'Hero Hunter', '']","Set in the early 1960s, Elizabeth Zott's dream of being a chemist is put on hold when she finds herself pregnant, alone, and fired from her lab.",,
The Lost Daughter,Drama            ,121 min,18,6.7,"['Olivia Colman, ', 'Jessie Buckley, ', 'Dakota Johnson, ', 'Ed Harris', '']",A woman's beach vacation takes a dark turn when she begins to confront the troubles of her past.,"70,663",['Maggie Gyllenhaal']
To Leslie,Drama            ,119 min,R,7.1,"['Andrea Riseborough, ', 'Drew Youngblood, ', 'Tom Virtue, ', 'Lauren Letherer', '']","Inspired by true events. A West Texas single mother wins the lottery and squanders it just as fast, leaving behind a world of heartbreak. Years later, with her charm running out and nowhere to go, she fights to rebuild her life and find redemption.","13,657",['Michael Morris']
Halt and Catch Fire,Drama            ,60 min,,8.4,"['Lee Pace, ', 'Scoot McNairy, ', 'Mackenzie Davis, ', 'Kerry Bishé', '']",Follows some players in the 80s technological revolution that lead to information society.,"33,987",
Network,Drama            ,121 min,UA,8.1,"['Faye Dunaway, ', 'William Holden, ', 'Peter Finch, ', 'Robert Duvall', '']","A television network cynically exploits a deranged former anchor's ravings and revelations about the news media for its own profit, but finds that his message may be difficult to control.","1,64,739",['Sidney Lumet']
Monamour,Drama            ,104 min,,5.2,"['Anna Jimskaia, ', 'Riccardo Marino, ', 'Max Parodi, ', 'Nela Lucic', '']","A neglected homemaker has an affair behind her boring husband's back, triggering a passionate transformation. Now, a dash of infidelity awakens his dormant enthusiasm for her. But is his newfound interest a case of too little, too late?","5,952",['Tinto Brass']
Fried Green Tomatoes,Drama            ,130 min,U,7.7,"['Kathy Bates, ', 'Jessica Tandy, ', 'Mary Stuart Masterson, ', 'Mary-Louise Parker', '']",A housewife who is unhappy with her life befriends an old lady at a nursing home and is enthralled by the tales she tells of people she used to know.,$82.42M,['Jon Avnet']
Industry,Drama            ,50 min,A,7.2,"[""Myha'la Herrold, "", 'Marisa Abela, ', 'Harry Lawtey, ', 'Ken Leung', '']",Young bankers and traders make their way in the financial world in the aftermath of the 2008 collapse.,"11,482",
Armageddon Time,Drama            ,114 min,R,6.5,"['Anne Hathaway, ', 'Jeremy Strong, ', 'Banks Repeta, ', 'Jaylin Webb', '']",A deeply personal coming-of-age story about the strength of family and the generational pursuit of the American Dream.,"13,047",['James Gray']
Harlots,Drama            ,45 min,18,7.7,"['Lesley Manville, ', 'Kate Fleetwood, ', 'Holli Dempsey, ', 'Eloise Smyth', '']",Brothel owner Margaret Wells struggles to raise her daughters in London during the 18th century.,"9,874",
Locke,Drama            ,85 min,R,7.1,"['Tom Hardy, ', 'Olivia Colman, ', 'Ruth Wilson, ', 'Andrew Scott', '']","Ivan Locke, a dedicated family man and successful construction manager, receives a phone call on the eve of the biggest challenge of his career that sets in motion a series of events that threaten his carefully cultivated existence.",$1.36M,['Steven Knight']
Le otto montagne,Drama            ,147 min,,7.7,"['Lupo Barbiero, ', 'Cristiano Sassella, ', 'Elena Lietti, ', 'Chiara Jorrioz', '']","An epic journey of friendship and self-discovery set in the breathtaking Italian Alps, The Eight Mountains follows over four decades the profound, complex relationship between Pietro and Bruno.","8,464",
Dynasty,Drama            ,42 min,13,7.3,"['Elizabeth Gillies, ', 'Rafael de la Fuente, ', 'Robert Christopher Riley, ', 'Sam Adegoke', '']",Follows two of America's wealthiest families as they feud for control over their fortune and their children.,"23,980",
Heat,Drama            ,60 min,,5.3,"['Danny Dyer, ', 'Darren McMullen, ', 'Pia Miranda, ', 'Jane Allsop', '']","It centers on two families as they go to a secluded home for a vacation. Secrets and lies unravel, and not everyone will make it out alive",136,
Inventing Anna,Drama            ,65 min,18,6.8,"['Anna Chlumsky, ', 'Julia Garner, ', 'Arian Moayed, ', 'Katie Lowes', '']","A journalist with a lot to prove investigates the case of Anna Delvey, the Instagram-legendary German heiress who stole the hearts of New York's social scene - and stole their money as well.","74,064",
Carol,Drama            ,118 min,18,7.2,"['Cate Blanchett, ', 'Rooney Mara, ', 'Sarah Paulson, ', 'Kyle Chandler', '']",An aspiring photographer develops an intimate relationship with an older woman in 1950s New York.,$12.71M,['Todd Haynes']
Palitan,Drama            ,107 min,,5.3,"['Cara Gonzales, ', 'Jela Cuenca, ', 'Luis Hontiveros, ', 'Rash Flores', '']","When a dare pushes two couples into an orgy, suppressed feelings rekindle between the two ladies, who were once bestfriends and lovers.",203,['Brillante Mendoza']
Madre de alquiler,Drama            ,45 min,UA 16+,5.9,"['Shani Lozano, ', 'Marcela Guirado, ', 'Leticia Calderón, ', 'Luis Ernesto Franco', '']","A woman rents her womb to a powerful family of Mexican businessmen to save her father's life. After her delivery, she wakes up in a hospital where she is given a baby who was born with a ...                See full summary »
",393,
L'amica geniale,Drama            ,60 min,,8.6,"['Alba Rohrwacher, ', 'Margherita Mazzucco, ', 'Gaia Girace, ', 'Annarita Vitolo', '']",A woman recounts the lifelong friendship and conflicts with a girl she met at primary school in Naples during the early 1950s.,"16,579",
Mud,Drama            ,130 min,UA,7.4,"['Matthew McConaughey, ', 'Tye Sheridan, ', 'Jacob Lofland, ', 'Sam Shepard', '']",Two young boys encounter a fugitive and form a pact to help him evade the vigilantes that are on his trail and to reunite him with his true love.,$21.59M,['Jeff Nichols']
Causeway,Drama            ,94 min,A,6.6,"['Jennifer Lawrence, ', 'Brian Tyree Henry, ', 'Linda Emond, ', 'Danny Wolohan', '']",A US soldier suffers a traumatic brain injury while fighting in Afghanistan and struggles to adjust to life back home.,"19,708",['Lila Neugebauer']
Precious,Drama            ,110 min,R,7.3,"['Gabourey Sidibe, ', ""Mo'Nique, "", 'Paula Patton, ', 'Mariah Carey', '']","In New York City's Harlem circa 1987, an overweight, abused, illiterate teen who is pregnant with her second child is invited to enroll in an alternative school in hopes that she can re-route her life in a better direction.",$47.57M,['Lee Daniels']
The Deep End of the Ocean,Drama            ,106 min,UA,6.3,"['Michelle Pfeiffer, ', 'Treat Williams, ', 'Whoopi Goldberg, ', 'Jonathan Jackson', '']","A film about a family's reaction when Ben, the youngest son, is kidnapped and then found nine years later, living in the same town, where his family had just moved.",$13.38M,['Ulu Grosbard']
L'uomo che disegnò Dio,Drama            ,100 min,,5.6,"['Kevin Spacey, ', 'Faye Dunaway, ', 'Franco Nero, ', 'Robert Davi', '']","The rise and fall of a blind artist who has the extraordinary gift of making true-to-life portraits just by listening to human voices, and of becoming a TV-junk star. A fable on the need to...                See full summary »
",279,['Franco Nero']
Mignonnes,Drama            ,96 min,18+,3.6,"['Fathia Youssouf, ', 'Médina El Aidi-Azouni, ', 'Esther Gohourou, ', 'Ilanah Cami-Goursolas', '']","Amy, an 11-year-old girl, joins a group of dancers named ""the cuties"" at school, and rapidly grows aware of her burgeoning femininity - upsetting her mother and her values in the process.","32,016",['Maïmouna Doucouré']
Half CA,Drama            ,,,8.7,"['Ahsaas Channa, ', 'Gyanendra Tripathi, ', 'Anmol Kajani, ', 'Rohan Joshi', '']","Two CA Aspirants from two different ends of the spectrum of the course, Archie and Niraj embark on the journey of one of the toughest courses and face the obstacles it has to offer.","1,431",
Jodaeiye Nader az Simin,Drama            ,123 min,7,8.3,"['Payman Maadi, ', 'Leila Hatami, ', 'Sareh Bayat, ', 'Shahab Hosseini', '']",A married couple are faced with a difficult decision - to improve the life of their child by moving to another country or to stay in Iran and look after a deteriorating parent who has Alzheimer's disease.,$7.10M,['Asghar Farhadi']
The Serpent Queen,Drama            ,52 min,,7.7,"['Samantha Morton, ', 'Amrita Acharia, ', 'Enzo Cilenti, ', 'Sennia Nanua', '']","Eight-part series based on Leonie Frieda's book ""Catherine de Medici: Renaissance Queen of France.""","5,988",
Kramer vs. Kramer,Drama            ,105 min,U,7.8,"['Dustin Hoffman, ', 'Meryl Streep, ', 'Jane Alexander, ', 'Justin Henry', '']","After his wife leaves him, a work-obsessed Manhattan advertising executive is forced to learn long-neglected parenting skills, but a heated custody battle over the couple's young son deepens the wounds left by the separation.",$106.26M,['Robert Benton']
Small Things Like These,Drama            ,,,,"['Cillian Murphy, ', 'Ciarán Hinds, ', 'Emily Watson, ', ""Ian O'Reilly"", '']",Plot under wraps.,,['Tim Mielants']
Borgen,Drama            ,58 min,16,8.5,"['Sidse Babett Knudsen, ', 'Birgitte Hjort Sørensen, ', 'Søren Malling, ', 'Lisbeth Wulff', '']","A political drama about a prime minister's rise to power, and how power changes a prime minister.","28,543",
"Sex, Lies, and Videotape",Drama            ,100 min,A,7.2,"['James Spader, ', 'Andie MacDowell, ', 'Peter Gallagher, ', 'Laura San Giacomo', '']",A sexually repressed woman's husband is having an affair with her sister. The arrival of a visitor with a rather unusual fetish changes everything.,$24.74M,['Steven Soderbergh']
"Synecdoche, New York",Drama            ,124 min,R,7.5,"['Philip Seymour Hoffman, ', 'Samantha Morton, ', 'Michelle Williams, ', 'Catherine Keener', '']","A theatre director struggles with his work, and the women in his life, as he creates a life-size replica of New York City inside a warehouse as part of his new play.",$3.08M,['Charlie Kaufman']
My Own Private Idaho,Drama            ,104 min,R,7,"['River Phoenix, ', 'Keanu Reeves, ', 'James Russo, ', 'William Richert', '']",Two best friends living on the streets of Portland as hustlers embark on a journey of self discovery and find their relationship stumbling along the way.,$6.40M,['Gus Van Sant']
Paprika,Drama            ,99 min,,5.5,"['Debora Caprioglio, ', 'Stéphane Ferrara, ', 'Martine Brochard, ', 'Stéphane Bonnet', '']","A young country girl comes to town and works in a brothel in order to help her fiance get the money to start his own business. ""Paprika"" is the name given to her by the madam.","4,417",['Tinto Brass']
Flowers in the Attic: The Origin,Drama            ,85 min,,7.2,"['Jemima Rooper, ', 'Max Irons, ', ""T'Shan Williams, "", 'Evelyn Miller', '']",This limited series tells the origin story of Olivia and Malcolm Foxworth and how dark family secrets shaped the Foxworth family from the very beginning.,"1,255",
The Split,Drama            ,60 min,,7.9,"['Nicola Walker, ', 'Stephen Mangan, ', 'Annabel Scholey, ', 'Fiona Button', '']","The Defoes, a family of female divorce lawyers, are forced to face their past following the return of their estranged father after a 30-year absence.","9,357",
Alfred Hitchcock Presents,Drama            ,25 min,,8.5,"['Alfred Hitchcock, ', 'Harry Tyler, ', 'John Williams, ', 'Patricia Hitchcock', '']","Series of unrelated short stories covering elements of crime, horror, drama, and comedy about people of different backgrounds committing murders, suicides, thefts, and other sorts of crime caused by certain motivations, perceived or not.","18,420",
Ordinary People,Drama            ,124 min,U,7.7,"['Donald Sutherland, ', 'Mary Tyler Moore, ', 'Judd Hirsch, ', 'Timothy Hutton', '']","The accidental death of the older son of an affluent family deeply strains the relationships among the bitter mother, the good-natured father and the guilt-ridden younger son.",$54.80M,['Robert Redford']
Casualty,Drama            ,50 min,,6,"['Derek Thompson, ', 'Tony Marshall, ', 'Suzanne Packer, ', 'Ian Bleasdale', '']",The everyday lives of the people frequenting the frenetic Accident and Emergency department of Holby City Hospital.,"3,492",
Babel,Drama            ,143 min,A,7.5,"['Brad Pitt, ', 'Cate Blanchett, ', 'Gael García Bernal, ', 'Mohamed Akhzam', '']","Tragedy strikes a married couple on vacation in the Moroccan desert, touching off an interlocking story involving four different families.",$34.30M,['Alejandro G. Iñárritu']
Doraibu mai kâ,Drama            ,179 min,,7.6,"['Hidetoshi Nishijima, ', 'Tôko Miura, ', 'Reika Kirishima, ', 'Masaki Okada', '']",A renowned stage actor and director learns to cope with a big personal loss when he receives an offer to direct a production of Uncle Vanya in Hiroshima.,"58,909",['Ryûsuke Hamaguchi']
Waco: The Aftermath,Drama            ,,,7.3,"['Michael Shannon, ', 'Giovanni Ribisi, ', 'Keean Johnson, ', 'Abbey Lee', '']",Five-part drama series portraying the searing aftermath of the disastrous Waco standoff at the Branch Davidian compound - an event that galvanized American militia movements and helped radicalize Timothy McVeigh and Terry Nichols.,"2,385",
Pachinko,Drama            ,55 min,A,8.3,"['Lee Min-Ho, ', 'Soji Arai, ', 'Jin Ha, ', 'Minha Kim', '']","Based on the New York Times bestseller, this sweeping saga chronicles the hopes and dreams of a Korean immigrant family across four generations as they leave their homeland in an indomitable quest to survive and thrive.","10,352",
No Disrespect,Drama            ,93 min,,5.5,"['Miles Triplett, ', 'DeMarcus Curry, ', 'Lj Scott, ', 'Phoenix Washington', '']","Milk, a 25 year old drug dealer, has had a successful and low-key life as an outlaw. His world gets turned upside down when his father, Bull, a known drug lord who controlled the streets ...                See full summary »
",6,['Miles Triplett']
Trial,Drama            ,105 min,,6.8,"['Glenn Ford, ', 'Dorothy McGuire, ', 'Arthur Kennedy, ', 'John Hodiak', '']",Courtroom drama set in 1947 and underlying post-WW2 acute problems facing the USA such as stormy race relations and the growing threat of local communism.,"1,105",['Mark Robson']
Home Service,Drama            ,114 min,,4.9,"['Angelica Cervantes, ', 'Hershie De Leon, ', 'Mon Mendoza, ', 'Chloe Mendoza', '']","A nursing student by day, massage therapist by night named Precious meets a client named Happy that leads her to the shady world of pornography.",83,['Ma-an L. Asuncion-Dagñalan']
The Goldfinch,Drama            ,149 min,A,6.4,"['Oakes Fegley, ', 'Ansel Elgort, ', 'Nicole Kidman, ', 'Jeffrey Wright', '']","A boy in New York is taken in by a wealthy family after his mother is killed in a bombing at the Metropolitan Museum of Art. In a rush of panic, he steals 'The Goldfinch', a painting that eventually draws him into a world of crime.",$5.33M,['John Crowley']
Wij,Drama            ,100 min,,5.6,"['Aimé Claeys, ', 'Tijmen Govaerts, ', 'Pauline Casteleyn, ', 'Maxime Jacobs', '']","Eight teens - four guys and four girls - are the best of friends. One summer, out of boredom they experiment with all manner of new means to entertain themselves. This degenerates into some extreme behaviour and will lead to tragedy.","3,114",['Rene Eller']
Mommy,Drama            ,139 min,R,8,"['Anne Dorval, ', 'Antoine Olivier Pilon, ', 'Suzanne Clément, ', 'Patrick Huard', '']","A widowed single mother, raising her violent son alone, finds new hope when a mysterious neighbor inserts herself into their household.",$3.49M,['Xavier Dolan']
Sling Blade,Drama            ,135 min,A,8,"['Billy Bob Thornton, ', 'Dwight Yoakam, ', 'J.T. Walsh, ', 'John Ritter', '']","Karl Childers, a simple man hospitalized since his childhood murder of his mother and her lover, is released to start a new life in a small town.",$24.48M,['Billy Bob Thornton']
Rebel Without a Cause,Drama            ,111 min,U,7.6,"['James Dean, ', 'Natalie Wood, ', 'Sal Mineo, ', 'Jim Backus', '']","A rebellious young man with a troubled past comes to a new town, finding friends and enemies.","94,914",['Nicholas Ray']
The Brown Bunny,Drama            ,93 min,,4.9,"['Vincent Gallo, ', 'Chloë Sevigny, ', 'Cheryl Tiegs, ', 'Elizabeth Blake', '']","Professional motorcycle racer Bud Clay heads from New Hampshire to California to race again. Along the way he meets various needy women who provide him with the cure to his own loneliness, but only a certain woman from his past will truly satisfy him.",$0.37M,['Vincent Gallo']
Impact Winter,Drama            ,,,8.7,"['Liam Cunningham, ', 'Himesh Patel, ', 'Holliday Grainger, ', 'Esme Creed-Miles', '']","More than a decade after a comet strike has inflicted an ""impact winter"" and blacked out the sun, vampires have emerged in the darkness to take over what remains of the world. Humans have ...                See full summary »
",358,
The Verdict,Drama            ,129 min,U,7.7,"['Paul Newman, ', 'Charlotte Rampling, ', 'Jack Warden, ', 'James Mason', '']","An outcast, alcoholic Boston lawyer sees the chance to salvage his career and self-respect by taking a medical malpractice case to trial rather than settling.",$54.00M,['Sidney Lumet']
Roma,Drama            ,135 min,16,7.7,"['Yalitza Aparicio, ', 'Marina de Tavira, ', 'Diego Cortina Autrey, ', 'Carlos Peralta', '']",A year in the life of a middle-class family's maid in Mexico City in the early 1970s.,"1,64,789",['Alfonso Cuarón']
The Babysitters,Drama            ,88 min,R,5.6,"['Lauren Birkell, ', 'Paul Borghese, ', 'Chira Cassel, ', 'Anthony Cirillo', '']","After fooling around with one of her customers, a teenager turns her babysitting service into a call-girl service for married guys.",$0.04M,['David Ross']
The Believer,Drama            ,98 min,R,7.1,"['Ryan Gosling, ', 'Summer Phoenix, ', 'Peter Meadows, ', 'Garret Dillahunt', '']",A young Jewish man develops a fiercely anti-Semitic philosophy. Based on the factual story of a K.K.K. member in the 1960s who was revealed to be Jewish by a New York Times reporter.,$0.41M,['Henry Bean']
La Belle Noiseuse,Drama            ,238 min,,7.5,"['Michel Piccoli, ', 'Jane Birkin, ', 'Emmanuelle Béart, ', 'Marianne Denicourt', '']","The former famous painter Frenhofer revisits an abandoned project using the girlfriend of a young visiting artist. Questions about truth, life, and artistic limits are explored.",$0.41M,['Jacques Rivette']
Joyland,Drama            ,126 min,,7.7,"['Ali Junejo, ', 'Rasti Farooq, ', 'Alina Khan, ', 'Sarwat Gilani', '']",The youngest son in a traditional Pakistani family takes a job as a backup dancer in a Bollywood-style burlesque and quickly becomes infatuated with the strong-willed trans woman who runs the show.,"4,239",['Saim Sadiq']
A River Runs Through It,Drama            ,123 min,U,7.2,"['Craig Sheffer, ', 'Brad Pitt, ', 'Tom Skerritt, ', 'Brenda Blethyn', '']","Two sons of a stern minister - one reserved, one rebellious - grow up in rural 1920s Montana while devoted to fly fishing.",$43.44M,['Robert Redford']
Scenes from a Marriage,Drama            ,296 min,UA 16+,8.1,"['Jessica Chastain, ', 'Oscar Isaac, ', 'Sophia Kopera, ', 'Nicole Beharie', '']","Television drama miniseries which re-examines the original's iconic depiction of love, hatred, desire, monogamy, marriage and divorce through the lens of a contemporary American couple, played by Oscar Isaac and Jessica Chastain.","25,822",
The Last Temptation of Christ,Drama            ,164 min,A,7.5,"['Willem Dafoe, ', 'Harvey Keitel, ', 'Barbara Hershey, ', 'Paul Greco', '']","The life of Jesus Christ, his journey through life as he faces the struggles all humans do, and his final temptation on the cross.",$7.63M,['Martin Scorsese']
Mysterious Skin,Drama            ,105 min,Unrated,7.6,"['Brady Corbet, ', 'Joseph Gordon-Levitt, ', 'Elisabeth Shue, ', 'Chase Ellison', '']","A teenage hustler and a young man obsessed with alien abductions cross paths, together discovering a horrible, liberating truth.",$0.70M,['Gregg Araki']
C'mon C'mon,Drama            ,109 min,R,7.4,"['Joaquin Phoenix, ', 'Gaby Hoffmann, ', 'Woody Norman, ', 'Scoot McNairy', '']","When his sister asks him to look after her son, a radio journalist embarks on a cross-country trip with his energetic nephew to show him life away from Los Angeles.","35,274",['Mike Mills']
Rabo de Peixe,Drama            ,47 min,A,7.6,"['José Condessa, ', 'Helena Caldeira, ', 'André Leitão, ', 'Rodrigo Tomás', '']",Four friends whose lives changed forever with the arrival of a ton of cocaine.,"5,055",
Ten Pound Poms,Drama            ,,,6.8,"['Warren Brown, ', 'Faye Marsay, ', 'Hattie Hook, ', 'Michelle Keegan', '']","A group of Brits leave post-war Britain in 1956 to embark on an adventure. The Roberts family tries to make the best of their situation, but life at the shelter tests them, but they're not the only ones avoiding the truth.","1,385",
A Covenant with Death,Drama            ,97 min,,6.1,"['George Maharis, ', 'Laura Devon, ', 'Katy Jurado, ', 'Earl Holliman', '']",A convicted murderer kills his hangman. Then it is discovered that he actually didn't commit the murder he was convicted for.,329,['Lamont Johnson']
Sullivan's Crossing,Drama            ,,,6.9,"['Morgan Kohan, ', 'Scott Patterson, ', 'Chad Michael Murray, ', 'Reid Price', '']","Neurosurgeon Maggie Sullivan, reconnects with her small-town past after a scandal causes her to leave her professional and personal life behind in the city.",668,
Fences,Drama            ,139 min,UA,7.2,"['Denzel Washington, ', 'Viola Davis, ', 'Stephen McKinley Henderson, ', 'Jovan Adepo', '']","A working-class African-American father tries to raise his family in the 1950s, while coming to terms with the events of his life.",$57.68M,['Denzel Washington']
The Crowded Room,Drama            ,,,,"['Leonardo DiCaprio', '']","The true story of Billy Milligan, who developed twenty-four different personalities during his horrific childhood, and who would go on to commit several robberies and rapes.",,
DogMan,Drama            ,113 min,R,,"['Christopher Denham, ', 'Caleb Landry Jones, ', 'Marisa Berenson, ', 'Michael Garza', '']","A boy, bruised by life, finds his salvation through the love of his dogs.",,['Luc Besson']
On a Wing and a Prayer,Drama            ,102 min,UA 13+,5.5,"['Dennis Quaid, ', 'Heather Graham, ', 'Jesse Metcalfe, ', 'Tonglan Qiu', '']","After their pilot dies unexpectedly mid-flight, Doug White (Dennis Quaid) has to safely land the plane and save his entire family from insurmountable danger.","4,074",['Sean McNamara']
Hotel Portofino,Drama            ,54 min,,6.7,"['Natascha McElhone, ', 'Oliver Dench, ', 'Louisa Binder, ', 'Carolina Gonnelli', '']","A glamorous period drama about an English hotel in 1920s Italy, when Benito Mussolini's brand of fascism was on the rise.","2,251",
Kuru Otlar Üstüne,Drama            ,197 min,,8.1,"['Deniz Celiloglu, ', 'Merve Dizdar, ', 'Musab Ekici, ', 'Ece Bagci', '']","A young teacher hopes to be appointed to Istanbul after mandatory duty at a small village. After a long time waiting he loses all hope of escaping from this gloomy life. However, his colleague Nuray helps him to regain perspective.",501,['Nuri Bilge Ceylan']
The Tender Bar,Drama            ,106 min,UA 16+,6.7,"['Ben Affleck, ', 'Tye Sheridan, ', 'Daniel Ranieri, ', 'Lily Rabe', '']",A boy growing up on Long Island seeks out father figures among the patrons at his uncle's bar.,"31,382",['George Clooney']
Naked Lunch,Drama            ,115 min,Not Rated,6.9,"['Peter Weller, ', 'Judy Davis, ', 'Ian Holm, ', 'Julian Sands', '']","After developing an addiction to the substance he uses to kill bugs, an exterminator accidentally kills his wife, and becomes involved in a secret government plot being orchestrated by giant bugs in a port town in North Africa.",$2.54M,['David Cronenberg']
Rectify,Drama            ,60 min,,8.3,"['Aden Young, ', 'Abigail Spencer, ', 'J. Smith-Cameron, ', 'Adelaide Clemens', '']",Daniel Holden must put his life back together after serving 19 years on Georgia's Death Row before DNA evidence calls his conviction into question.,"27,058",
The Cincinnati Kid,Drama            ,102 min,,7.2,"['Steve McQueen, ', 'Ann-Margret, ', 'Edward G. Robinson, ', 'Karl Malden', '']",An up-and-coming poker player tries to prove himself in a high-stakes match against a long-time master of the game.,$15.26M,
Wanderlust,Drama            ,60 min,18,7,"['Toni Collette, ', 'Steven Mackintosh, ', 'Joe Hurst, ', ""Emma D'Arcy"", '']",A therapist tries to save her marriage after a cycling accident causes them to reassess their relationship.,"5,754",
I Am Sam,Drama            ,132 min,U,7.6,"['Sean Penn, ', 'Michelle Pfeiffer, ', 'Dakota Fanning, ', 'Dianne Wiest', '']",A mentally handicapped man fights for custody of his 7-year-old daughter and in the process teaches his cold-hearted lawyer the value of love and family.,$40.31M,['Jessie Nelson']
Vivir sin permiso,Drama            ,75 min,18,7.4,"['Jose Coronado, ', 'Álex González, ', 'Claudia Traisac, ', 'Luis Zahera', '']","Nemo Bandeira, a dealer with a clean businessman facade, is diagnosed with Alzheimer's disease and tries to keep it from his family while he starts to think about who might be his successor.","5,550",
Ken Park,Drama            ,93 min,,5.8,"['Adam Chubbuck, ', 'James Bullard, ', 'Seth Gray, ', 'Eddie Daniels', '']",Ken Park is about several Californian skateboarders' lives and relationships with and without their parents.,"30,376",
Ikiru,Drama            ,143 min,U,8.3,"['Takashi Shimura, ', 'Nobuo Kaneko, ', ""Shin'ichi Himori, "", 'Haruo Tanaka', '']",A bureaucrat tries to find meaning in his life after he discovers he has terminal cancer.,$0.06M,['Akira Kurosawa']
School Ties,Drama            ,106 min,PG-13,6.9,"['Brendan Fraser, ', 'Matt Damon, ', ""Chris O'Donnell, "", 'Randall Batinkoff', '']","In 1959, a star quarterback from a working-class family is given an opportunity to attend an elite New England preparatory school, but he is conflicted about whether or not to tell his Evangelical classmates that he is Jewish.",$14.72M,['Robert Mandel']
Queer as Folk,Drama            ,49 min,,5.9,"['Fin Argus, ', 'CG, ', 'Jesse James Keitel, ', ""Ryan O'Connell"", '']",It centers on a group of club-going friends who find support in the gay community following a tragedy.,"2,757",
A Place to Call Home,Drama            ,60 min,,8.3,"['Marta Dusseldorp, ', 'Noni Hazlehurst, ', 'Brett Climo, ', 'Craig Hall', '']","Sarah Adams returns to Australia post World War II to start anew. She begins working in a hospital, much to the dismay of Elizabeth Bligh, a wealthy matriarch.","5,941",
The Movie Critic,Drama            ,,,,,"Add a Plot
",,['Quentin Tarantino']
La grande bellezza,Drama            ,141 min,,7.7,"['Toni Servillo, ', 'Carlo Verdone, ', 'Sabrina Ferilli, ', 'Carlo Buccirosso', '']","Jep Gambardella has seduced his way through the lavish nightlife of Rome for decades, but after his 65th birthday and a shock from the past, Jep looks past the nightclubs and parties to find a timeless landscape of absurd, exquisite beauty.",$2.85M,['Paolo Sorrentino']
Greenleaf,Drama            ,60 min,,7.5,"['Merle Dandridge, ', 'Kim Hawthorne, ', 'Desiree Ross, ', 'Lamman Rucker', '']","The unscrupulous world of the Greenleaf family and their sprawling Memphis megachurch, dark secrets, and lies.","5,667",
Além do Guarda-Roupa,Drama            ,,,9.1,"['Woojin, ', 'Sharon Blanche, ', 'Soo-jin Kwon, ', 'Gabriel Coppola', '']","Carol, is a 17-year-old teenager, the daughter of a Brazilian dancer and a South Korean, who lives a challenging journey of overcoming, acceptance and self-knowledge after the death of her ...                See full summary »
",83,
The Last Vermeer,Drama            ,118 min,R,6.7,"['Guy Pearce, ', 'Claes Bang, ', 'Vicky Krieps, ', 'Roland Møller', '']","An artist is suspected of selling a valuable painting to the Nazis, but there is more to the story than meets the eye.","4,756",['Dan Friedkin']
Aloft,Drama            ,112 min,R,5.3,"['Jennifer Connelly, ', 'Cillian Murphy, ', 'Mélanie Laurent, ', 'Oona Chaplin', '']",A struggling mother encounters the son she abandoned 20 years earlier.,$0.05M,['Claudia Llosa']
99 Moons,Drama            ,110 min,,5.1,"['Valentina Di Pace, ', 'Dominik Fellmann, ', 'Danny Exnar, ', 'Jessica Huber', '']",Bigna and Frank are two people of different thoughts. When their different worlds collide they become obsessively entwined in a passionate affair.,"1,505",['Jan Gassmann']
Fanchon the Cricket,Drama            ,75 min,,6.5,"['Mary Pickford, ', 'Jack Standing, ', 'Lottie Pickford, ', 'Dick Lee', '']","Young and wild Fanchon lives in a forest with her eccentric grandmother who is suspected by the villagers of being a witch. The unkempt girl suffers from her grandmother's sorceress ...                See full summary »
",270,['James Kirkwood']
Retour à Séoul,Drama            ,119 min,R,7,"['Park Ji-min, ', 'Oh Kwang-rok, ', 'Guka Han, ', 'Kim Sun-young', '']","A twenty-five-year-old French woman returns to Korea, the country she was born in before being adopted by a French couple, for the very first time. She decides to track down her biological parents, but her journey takes a surprising turn.","4,671",['Davy Chou']
Hillbilly Elegy,Drama            ,116 min,18,6.7,"['Amy Adams, ', 'Glenn Close, ', 'Gabriel Basso, ', 'Haley Bennett', '']","An urgent phone call pulls a Yale Law student back to his Ohio hometown, where he reflects on three generations of family history and his own future.","44,690",['Ron Howard']
North of Normal,Drama            ,90 min,,9,"[""James D'Arcy, "", 'Sarah Gadon, ', 'Robert Carlyle, ', 'Benedict Samuel', '']","After being raised in the wilderness, a teenage girl moves to the city hoping for a normal life with her anything but normal mother.",81,['Carly Stone']
Now & Later,Drama            ,99 min,,5.1,"['Keller Wortham, ', 'Shari Solanis, ', 'Luis Fernandez-Gil, ', 'Adrian Quiñonez', '']","Angela an illegal immigrant living in Los Angeles stumbles across Bill, a disgraced banker on the run.Through sex, conversation ranging from politics to philosophy, and other worldly pleasures, Angela introduces Bill to another worldview.",$0.00M,['Philippe Diaz']
The Royal,Drama            ,60 min,,7.5,"['Linda Armstrong, ', 'Robert Daws, ', 'Wendy Craig, ', 'Michelle Hardwick', '']","Set in the 1960s, this British medical drama follows the staff and patients of St Aidan's Royal Free Hospital.","1,116",
There She Goes,Drama            ,30 min,,8.1,"['David Tennant, ', 'Jessica Hynes, ', 'Miley Locke, ', 'Edan Hayhurst', '']",A young girl with a learning disability makes her way through life.,"1,246",
Sex,Drama            ,15 min,,6,"['Asta Kamma August, ', 'Sara Fanta Traore, ', 'Jonathan Bergholdt Jørgensen, ', 'Kitt Maiken Mortensen', '']","At a call center, Cathrine gives advice on sex and love, but is herself at a loss. After a kiss, she wants more from her colleague Selma. While her boyfriend Simon has lack of sexual drive. But what if that's not enough?",596,
Riches,Drama            ,46 min,,7.2,"['Deborah Ayorinde, ', 'Sarah Niles, ', 'CJ Beckford, ', 'Adeyinka Akinrinade', '']","Stephen Richards has built a cosmetics empire, but when he suffers a stroke, his family's secrets and lies rise to the surface and the future of his multi-million-pound company is at stake.","1,695",
Lean on Me,Drama            ,108 min,Not Rated,7.4,"['Morgan Freeman, ', 'Beverly Todd, ', 'Robert Guillaume, ', 'Alan North', '']",The dedicated but tyrannical Joe Clark is appointed the principal of a decaying inner-city school he is determined to improve by any and all means.,$31.91M,['John G. Avildsen']
I Know This Much Is True,Drama            ,378 min,18,8.1,"['Mark Ruffalo, ', 'John Procaccino, ', 'Rob Huebel, ', 'Gabe Fazio', '']","Following the parallel lives of identical twin brothers Dominick and Thomas Birdsey in a story of betrayal, sacrifice, and forgiveness.","21,672",
Mona Lisa Smile,Drama            ,117 min,UA,6.5,"['Julia Roberts, ', 'Kirsten Dunst, ', 'Julia Stiles, ', 'Maggie Gyllenhaal', '']",A free-thinking art professor teaches conservative 1950s Wellesley girls to question their traditional social roles.,$63.86M,['Mike Newell']
The Forgiven,Drama            ,117 min,R,6.1,"['Jessica Chastain, ', 'Ralph Fiennes, ', 'Christopher Abbott, ', 'Abbey Lee', '']","A fatal accident disrupts the lives of Western visitors to a lavish party in the High Atlas Mountains of Morocco, and will ultimately lead to a reckoning in the desert.","7,519",['John Michael McDonagh']
Life Unexpected,Drama            ,60 min,,7.5,"['Shiri Appleby, ', 'Kristoffer Polaha, ', 'Britt Robertson, ', 'Kerr Smith', '']","After 15 years in foster homes, Lux decides to get emancipated, which leads to her meeting her birth parents.","15,149",
The Winter King,Drama            ,,,,"['Eddie Marsan, ', 'Iain De Caestecker, ', 'Nathaniel Martello-White, ', 'Valene Kane', '']","A former warrior now turned monk, tells the story of how Arthur became the lord of war despite the illegitimacy of his throne.",,
Eo,Drama            ,88 min,,6.8,"['Hola, ', 'Tako, ', 'Marietta, ', 'Ettore', '']","Follows a donkey who encounters on his journeys good and bad people, experiences joy and pain, exploring a vision of modern Europe through his eyes.","11,530",['Jerzy Skolimowski']
"Not Tonight, Darling",Drama            ,90 min,,3.8,"['Luan Peters, ', 'Vincent Ball, ', 'Jason Twelvetrees, ', 'James Hayter', '']","A lonely 'Stay-at-Home' Housewife is being watched every night through the bathroom window by a 'Peeping Tom', who is being put up to it by his friend. She eventually finds out and gets her revenge on them.",189,['Anthony Sloman']
Sounds of Freedom,Drama            ,,,8.8,"['Katherine Celio, ', 'Bruce Weech, ', 'Relda E. White-Weagant, ', 'James Weagant', '']","Two veterans suffering with PTSD meet while employed by a newspaper on Whidbey Island, WA. Julia is an Iraqi war vet having difficulty adjusting back to civilian life after several tours in...                See full summary »
",106,
Secrets of the Morning,Drama            ,,,7.5,"['Brec Bassinger, ', 'Khobe Clarke, ', 'Fran Drescher, ', 'Joey McIntyre', '']","Dawn gets off to a good start at a New York City performing-arts school, then risks everything by falling for her gorgeous, charming music teacher; meanwhile, Jimmy works toward his future.",68,['Linda-Lisa Hayter']
25th Hour,Drama            ,135 min,R,7.6,"['Edward Norton, ', 'Barry Pepper, ', 'Philip Seymour Hoffman, ', 'Rosario Dawson', '']","Cornered by the DEA, convicted New York drug dealer Montgomery Brogan reevaluates his life in the 24 remaining hours before facing a seven-year jail term.",$13.06M,['Spike Lee']
Serial Lover,Drama            ,,,,"['Jonathan Zaccaï, ', 'Odile Vuillemin, ', 'Flore Bonaventura, ', 'Élodie Frégé', '']","A shrewd man who lives many different lives - a pilot, a surgeon, a broker, a journalist; developing a new personality for every identity and deceiving experts in each field. Handsome, ...                See full summary »
",,
Best Interests,Drama            ,,,7.6,"['Sharon Horgan, ', 'Niamh Moriarty, ', 'Michael Sheen, ', 'Alison Oliver', '']",Follows a family driven apart by having to make choices no parent would ever want to make.,583,
The Picasso Summer,Drama            ,90 min,,5.3,"['Albert Finney, ', 'Yvette Mimieux, ', 'Luis Miguel Dominguín, ', 'Theodore Marcuse', '']",A San Francisco couple travels to France in search of Pablo Picasso.,339,
Unorthodox,Drama            ,53 min,18,8,"['Shira Haas, ', 'Amit Rahav, ', 'Jeff Wilbusch, ', 'Alex Reid', '']",Story of a young ultra-Orthodox Jewish woman who flees her arranged marriage and religious community to start a new life abroad.,"87,378",
Still Alice,Drama            ,101 min,PG-13,7.5,"['Julianne Moore, ', 'Alec Baldwin, ', 'Kristen Stewart, ', 'Kate Bosworth', '']",A linguistics professor and her family find their bonds tested when she is diagnosed with Alzheimer's Disease.,$18.75M,
Vanskabte land,Drama            ,143 min,,7.2,"['Elliott Crosset Hove, ', 'Ingvar Sigurdsson, ', 'Vic Carmen Sonne, ', 'Jacob Lohmann', '']","At the end of the 19th century, a young Danish priest is sent to a remote part of Iceland. The deeper he travels into the Icelandic landscape, the more he loses a sense of his own reality, his mission and his sense of duty.","3,726",['Hlynur Pálmason']
Pay It Forward,Drama            ,123 min,UA,7.2,"['Kevin Spacey, ', 'Haley Joel Osment, ', 'Helen Hunt, ', 'Jay Mohr', '']",A young boy attempts to make the world a better place after his teacher gives him that chance.,$33.52M,['Mimi Leder']
The L Word: Generation Q,Drama            ,55 min,18,7.5,"['Jennifer Beals, ', 'Kate Moennig, ', 'Leisha Hailey, ', 'Arienne Mandi', '']","Bette Porter, Shane McCutcheon and Alice Pieszecki intermingle with a younger generation of Los Angelenos experiencing love, heartbreak, sex, setbacks and success.","8,008",
A Streetcar Named Desire,Drama            ,122 min,A,7.9,"['Vivien Leigh, ', 'Marlon Brando, ', 'Kim Hunter, ', 'Karl Malden', '']",Disturbed Blanche DuBois moves in with her sister in New Orleans and is tormented by her brutish brother-in-law while her reality crumbles around her.,$8.00M,['Elia Kazan']
Hamlet,Drama            ,154 min,,7.6,"['Laurence Olivier, ', 'Jean Simmons, ', 'John Laurie, ', 'Esmond Knight', '']","Prince Hamlet struggles over whether or not he should kill his uncle, whom he suspects has murdered his father, the former king.","17,809",['Laurence Olivier']
God's Own Country,Drama            ,104 min,,7.6,"[""Josh O'Connor, "", 'Alec Secareanu, ', 'Gemma Jones, ', 'Ian Hart', '']","Spring. Yorkshire. Young farmer Johnny Saxby numbs his daily frustrations with binge drinking and casual sex, until the arrival of a Romanian migrant worker for lambing season ignites an intense relationship that sets Johnny on a new path.",$0.34M,['Francis Lee']
You Can Live Forever,Drama            ,96 min,,6.9,"[""Anwen O'Driscoll, "", 'June Laporte, ', 'Liane Balaban, ', 'Antoine Yared', '']","When lesbian teen Jaime is sent to live in a Jehovah's Witness community, she falls hard for a devout Witness girl and the two embark on an intense affair with consequences that will reshape the rest of their lives.","1,817",
L'immensità,Drama            ,99 min,,6.4,"['Penélope Cruz, ', 'Vincenzo Amato, ', 'Luana Giuliani, ', 'Patrizio Francioni', '']","The story of love between Clara and her children, set in Rome in the '70s.","1,743",['Emanuele Crialese']
Tayuan,Drama            ,102 min,,4.6,"['Angeli Khang, ', 'Stephanie Raz, ', 'Chester Grecia, ', 'Francine Garcia', '']","Ella meets Rico, a bus conductor, on her way to work. Even after finding out that Rico is married, she still pursues him. As their affair turns to adoration, it becomes harder for them to let go.",134,['Topel Lee']
The House of Eliott,Drama            ,50 min,,8.1,"['Stella Gonet, ', 'Louise Lombard, ', 'Aden Gillett, ', 'Cathy Murphy', '']",Two sisters in 1920s London work to achieve success in the dressmaking business.,"1,526",
Bump,Drama            ,30 min,,7.6,"['Nathalie Morris, ', 'Claudia Karvan, ', 'Carlos Sanson Jr., ', 'Angus Sampson', '']","An unexpected pregnancy complicates the lives of two families. The series centers around Oly, an ambitious and high-achieving teenage girl who has a surprise baby.","2,000",
Dekalog,Drama            ,572 min,,9,"['Artur Barcis, ', 'Olgierd Lukaszewicz, ', 'Olaf Lubaszenko, ', 'Aleksander Bardini', '']","Ten television drama films, each one based on one of the Ten Commandments.",$0.10M,
Jubilee,Drama            ,,A,8.4,"['Prasenjit Chatterjee, ', 'Aditi Rao Hydari, ', 'Wamiqa Gabbi, ', 'Aparshakti Khurana', '']","Thrilling yet poetic tale woven around an ensemble of characters and the gambles they're willing to take, in pursuit of their dreams, passion, ambition and love","3,904",
Little Women,Drama            ,180 min,,7.2,"['Maya Hawke, ', 'Kathryn Newton, ', 'Dylan Baker, ', 'Willa Fitzgerald', '']","Dramatization of Louisa May Alcott's novel about the lives of the four March sisters during the American Civil War as they learn to navigate love, loss, and the trials of growing up.","4,598",
On Golden Pond,Drama            ,109 min,UA,7.6,"['Katharine Hepburn, ', 'Henry Fonda, ', 'Jane Fonda, ', 'Doug McKeon', '']","Norman is a curmudgeon with an estranged relationship with his daughter Chelsea. At Golden Pond, he and his wife nevertheless agree to care for Billy, the son of Chelsea's new boyfriend, and a most unexpected relationship blooms.",$119.29M,['Mark Rydell']
Honey Boy,Drama            ,94 min,R,7.2,"['Shia LaBeouf, ', 'Lucas Hedges, ', 'Noah Jupe, ', 'Byron Bowers', '']",A young actor's stormy childhood and early adult years as he struggles to reconcile with his father and deal with his mental health.,"39,601","[""Alma Har'el""]"
8½,Drama            ,138 min,,8,"['Marcello Mastroianni, ', 'Anouk Aimée, ', 'Claudia Cardinale, ', 'Sandra Milo', '']",A harried movie director retreats into his memories and fantasies.,$0.05M,['Federico Fellini']
I May Destroy You,Drama            ,30 min,18,8.1,"['Michaela Coel, ', 'Weruche Opia, ', 'Paapa Essiedu, ', 'Stephen Wight', '']","The question of sexual consent in contemporary life and how, in the new landscape of dating and relationships, we make the distinction between liberation and exploitation.","24,415",
Miss Sloane,Drama            ,132 min,UA,7.5,"['Jessica Chastain, ', 'Mark Strong, ', 'Gugu Mbatha-Raw, ', 'Michael Stuhlbarg', '']","In the high-stakes world of political power-brokers, Elizabeth Sloane is the most sought after and formidable lobbyist in D.C. But when taking on the most powerful opponent of her career, she finds winning may come at too high a price.",$3.50M,['John Madden']
The Long Home,Drama            ,96 min,R,,"['Josh Hartnett, ', 'Lio Tipton, ', 'Josh Hutcherson, ', 'James Franco', '']",A young contractor is hired to build a honky-tonk in Tennessee by the man who killed his father.,,['James Franco']
À ma soeur!,Drama            ,95 min,,6.4,"['Anaïs Reboux, ', 'Roxane Mesquida, ', 'Libero De Rienzo, ', 'Arsinée Khanjian', '']",Two sisters confront their sexual attitudes and experiences while on a family holiday.,$0.72M,['Catherine Breillat']
Anatomie de l'enfer,Drama            ,77 min,,4.4,"['Amira Casar, ', 'Rocco Siffredi, ', 'Alexandre Belin, ', 'Manuel Taglang', '']","A woman employs a gay man to spend four nights at her house to watch her when she's ""unwatchable"".","5,910",['Catherine Breillat']
Baby,Drama            ,50 min,18,6.8,"['Benedetta Porcaroli, ', 'Alice Pagani, ', 'Riccardo Mandolini, ', 'Chabeli Sastre', '']","A coming-of-age story that explores the unseen lives of Roman high schoolers. Loosely inspired by a true story, the series follows a group of Parioli teenagers as they defy society in their search for identity and independence","12,397",
Taps,Drama            ,126 min,U,6.7,"['George C. Scott, ', 'Timothy Hutton, ', 'Ronny Cox, ', 'Sean Penn', '']",Military cadets take extreme measures to ensure the future of their academy when its existence is threatened by local condo developers.,$35.86M,['Harold Becker']
L.A. Law,Drama            ,46 min,,7.1,"['Corbin Bernsen, ', 'Jill Eikenberry, ', 'Alan Rachins, ', 'Michael Tucker', '']",The lives and work of the staff of a major Los Angeles law firm.,"5,919",
War Pony,Drama            ,115 min,R,7.1,"['Iona Red Bear, ', 'Ta-Yamni Long Black Cat, ', 'Wilma Colhof, ', 'Jeremy Corbin Cottier', '']",The interlocking stories of two young Oglala Lakota men growing up on the Pine Ridge Reservation.,"1,386",
Yargi,Drama            ,150 min,,8.3,"['Kaan Urgancioglu, ', 'Pinar Deniz, ', 'Hüseyin Avni Danyal, ', 'Zeyno Eracar', '']","A lawyer and a prosecutor, whose paths cross with a murder case, will have to work together to find the murderer, and this will create an irreversible breaking point in their lives.","4,274",
Secret Diary of a Call Girl,Drama            ,30 min,,7.3,"['Billie Piper, ', 'Iddo Goldberg, ', 'Cherie Lunghi, ', 'Ashley Madekwe', '']",Based on the popular diary of the anonymous sex worker known only as Belle de Jour.,"13,974",
Le bleu du caftan,Drama            ,122 min,,7.6,"['Lubna Azabal, ', 'Saleh Bakri, ', 'Ayoub Missioui, ', 'Mounia Lamkimel', '']",A middle-aged tailor and his wife find their relationship turned upside down by the arrival of a handsome new apprentice.,"3,095",['Maryam Touzani']
Savage Grace,Drama            ,97 min,,5.7,"['Julianne Moore, ', 'Eddie Redmayne, ', 'Stephen Dillane, ', 'Anne Reid', '']","A dramatization of the shocking Barbara Daly Baekeland murder case, which happened in a posh London flat on Friday 17 November 1972. The bloody crime caused a stir on both sides of the Atlantic and remains one of the most memorable American Tragedies...",$0.43M,['Tom Kalin']
Nowhere Special,Drama            ,96 min,,7.4,"['James Norton, ', 'Daniel Lamont, ', 'Carol Moore, ', 'Valene Kane', '']","When John, a thirty-five-year-old window cleaner, is given only a few months to live, he attempts to find a new, perfect family for his three-year-old son, determined to shield him from the terrible reality of the situation.","5,512",['Uberto Pasolini']
Code Black,Drama            ,42 min,,8,"['Marcia Gay Harden, ', 'Harry Ford, ', 'Benjamin Hollingsworth, ', 'Luis Guzmán', '']",The staff of the L.A. County Hospital emergency room treats patients under difficult circumstances.,"12,767",
Große Freiheit,Drama            ,116 min,,7.5,"['Franz Rogowski, ', 'Georg Friedrich, ', 'Anton von Lucke, ', 'Thomas Prenn', '']","In post-war Germany, liberation by the Allies does not mean freedom for everyone. Hans is repeatedly imprisoned under Paragraph 175, which criminalizes homosexuality. Over the decades, he develops an unlikely bond with his cellmate Viktor.","6,150",['Sebastian Meise']
È stata la mano di Dio,Drama            ,130 min,18,7.3,"['Filippo Scotti, ', 'Toni Servillo, ', 'Teresa Saponangelo, ', 'Marlon Joubert', '']","In 1980s Naples, young Fabietto pursues his love for football as family tragedy strikes, shaping his uncertain but promising future as a filmmaker.","46,690",['Paolo Sorrentino']
Five Easy Pieces,Drama            ,98 min,U,7.4,"['Jack Nicholson, ', 'Karen Black, ', 'Billy Green Bush, ', 'Fannie Flagg', '']","A dropout from upper-class America picks up work along the way on oil rigs when his life isn't spent in a squalid succession of bars, motels, and other points of interest.",$19.40M,['Bob Rafelson']
Vernost,Drama            ,82 min,,5.7,"['Evgeniya Gromova, ', 'Aleksandr Pal, ', 'Marina Vasileva, ', 'Aleksey Agranovich', '']","Midwife Lena, a loving wife, is driven towards a string of infidelities after her husband continues to neglect her.","2,558",['Nigina Sayfullaeva']
Gravesend,Drama            ,,,6.1,"['William DeMeo, ', ""Joseph D'Onofrio, "", 'Christopher Mormando, ', 'Sofia Milos', '']","A 1980's series of events revolving around Benny Zerletta (William DeMeo), a Brooklyn based Italian-American, soldier in the Colezzo crime family. Benny depicts the difficulties that he ...                See full summary »
",256,
All About Eve,Drama            ,138 min,,8.2,"['Bette Davis, ', 'Anne Baxter, ', 'George Sanders, ', 'Celeste Holm', '']",A seemingly timid but secretly ruthless ingénue insinuates herself into the lives of an aging Broadway star and her circle of theater friends.,$0.01M,['Joseph L. Mankiewicz']
Aristotle and Dante Discover the Secrets of the Universe,Drama            ,96 min,PG-13,7.4,"['Luna Blaise, ', 'Eva Longoria, ', 'Kevin Alejandro, ', 'Eugenio Derbez', '']","Based on the book by Benjamin Alire Sáenz, set in 1987 El Paso, it's the tale of two teenage Mexican-American loners as they explore their friendship and the difficult road to self-discovery.",184,['Aitch Alberto']
Tierra de esperanza,Drama            ,60 min,,9,"['Carolina Miranda, ', 'Andrés Palacios, ', 'Luis Roberto Guzmán, ', 'Mariana Seoane', '']","Add a Plot
",81,
Maryland,Drama            ,47 min,,6.5,"['Suranne Jones, ', 'Eve Best, ', 'Stockard Channing, ', 'Hugh Quarshie', '']","Follows Becca and Rosaline, two sisters that were distanced, but that through tragic events, learn to love and respect each other again.",953,
Breaking the Waves,Drama            ,159 min,R,7.8,"['Emily Watson, ', 'Stellan Skarsgård, ', 'Katrin Cartlidge, ', 'Jean-Marc Barr', '']","Oilman Jan is paralyzed in an accident. His wife, who prayed for his return, feels guilty; even more, when Jan urges her to have sex with another.",$4.04M,['Lars von Trier']
Mildred Pierce,Drama            ,336 min,,7.6,"['Kate Winslet, ', 'Guy Pearce, ', 'Evan Rachel Wood, ', ""Brían F. O'Byrne"", '']","Divorced single mom Mildred Pierce decides to open a restaurant business, which tears at the already-strained relationship with her ambitious elder daughter, Veda.","22,934",
The Kashmir Files,Drama            ,170 min,A,8.7,"['Mithun Chakraborty, ', 'Anupam Kher, ', 'Darshan Kumaar, ', 'Pallavi Joshi', '']","A heart-wrenching tale that captures the pain, suffering, and struggle of the Kashmiri Pandit community in 1990 and leads Krishna, a young college student, to set out on a quest to uncover the truth.","5,70,600",['Vivek Agnihotri']
"My Sailor, My Love",Drama            ,103 min,,7.1,"['James Cosmo, ', 'Brid Brennan, ', 'Catherine Walker, ', 'Nora-Jane Noone', '']",A retired sea captain and his daughter must reassess their strained relationship after he begins a new romance with a widowed housekeeper.,442,['Klaus Härö']
Banshee Origins,Drama            ,,,8.6,"['Frankie Faison, ', 'Antony Starr, ', 'Ivana Milicevic, ', 'Ulrich Thomsen', '']","Fresh out of prison after 15 years, a master thief assumes the identity of a dead sheriff in Banshee, PA. After tracking down the woman he loves they try to avoid detection from her father; a Ukrainian mobster looking to kill them for double crossing him.","5,401",
Boze Cialo,Drama            ,115 min,,7.7,"['Bartosz Bielenia, ', 'Aleksandra Konieczna, ', 'Eliza Rycembel, ', 'Tomasz Zietek', '']","Daniel experiences a spiritual transformation in a detention center. Although his criminal record prevents him from applying to the seminary, he has no intention of giving up his dream and decides to minister a small-town parish.","20,542",['Jan Komasa']
Histoire d'O,Drama            ,105 min,A,5.3,"['Corinne Cléry, ', 'Udo Kier, ', 'Anthony Steel, ', 'Jean Gaven', '']","Photographer O's lover takes her to a Château, where she is, like other women there, naked, humiliated by whipping, sexual abuse by men etc. When O leaves, her lover gives her to his much older step-brother.","6,691",['Just Jaeckin']
Lost Girls and Love Hotels,Drama            ,97 min,R,4.7,"['Alexandra Daddario, ', 'Takehiro Hira, ', 'Carice van Houten, ', 'Andrew Rothney', '']","Haunted by her past, an English teacher explores love and dust with a dashing yakuza gangster in Tokyo.","4,968",['William Olsson']
Magazine Dreams,Drama            ,124 min,,7,"['Jonathan Majors, ', 'Harrison Page, ', 'Harriet Sansom Harris, ', 'Haley Bennett', '']",A Black amateur bodybuilder struggles to find human connection in this exploration of celebrity and violence.,279,['Elijah Bynum']
The Absence of Eden,Drama            ,,,7.7,"['Zoe Saldana, ', 'Adria Arjona, ', 'Garrett Hedlund, ', 'Tom Waits', '']",An ICE Agent struggling with the moral dilemmas of border security and an undocumented woman fighting to escape a ruthless cartel cross paths and work together to save the life of an innocent girl.,21,['Marco Perego']
Hamlet,Drama            ,242 min,PG-13,7.7,"['Kenneth Branagh, ', 'Julie Christie, ', 'Derek Jacobi, ', 'Kate Winslet', '']","Hamlet, Prince of Denmark, returns home to find his father murdered and his mother remarrying the murderer, his uncle. Meanwhile, war is brewing.",$4.41M,['Kenneth Branagh']
Scarecrow,Drama            ,112 min,A,7.2,"['Gene Hackman, ', 'Al Pacino, ', 'Dorothy Tristan, ', 'Ann Wedgeworth', '']","An ex-con drifter with a penchant for brawling is amused by a homeless ex-sailor, so they partner up as they head east together.",$9.00M,['Jerry Schatzberg']
L'Événement,Drama            ,100 min,R,7.4,"['Anamaria Vartolomei, ', 'Kacey Mottet Klein, ', 'Luàna Bajrami, ', 'Louise Orry-Diquéro', '']","An adaptation of Annie Ernaux's novel of the same name, looking back on her experience with abortion when it was still illegal in France in the 1960s.","10,194",['Audrey Diwan']
Festen,Drama            ,105 min,R,8.1,"['Ulrich Thomsen, ', 'Henning Moritzen, ', 'Thomas Bo Larsen, ', 'Paprika Steen', '']","At Helge's 60th birthday party, some unpleasant family truths are revealed.",$1.65M,['Thomas Vinterberg']
Four Good Days,Drama            ,100 min,R,6.5,"['Mila Kunis, ', 'Carla Gallo, ', 'Glenn Close, ', 'Stephen Root', '']",A mother helps her daughter work through four crucial days of recovery from substance abuse.,"10,528",['Rodrigo García']
One Night in Miami...,Drama            ,114 min,18,7.1,"['Kingsley Ben-Adir, ', 'Eli Goree, ', 'Aldis Hodge, ', 'Leslie Odom Jr.', '']","A fictional account of one incredible night where icons Muhammad Ali, Malcolm X, Sam Cooke, and Jim Brown gathered discussing their roles in the Civil Rights Movement and cultural upheaval of the 60s.","33,386",['Regina King']
Passions,Drama            ,60 min,,5.9,"['Lindsay Hartley, ', 'McKenzie Westmore, ', 'Galen Gering, ', 'Juliet Mills', '']","In the world of power and money, the wealthy and powerful Crane family rule the town of Harmony from their mansion on Raven Hill.","5,027",
The Royals,Drama            ,42 min,UA 13+,7.4,"['Joan Collins, ', 'Alexandra Park, ', 'Elizabeth Hurley, ', 'William Moseley', '']",Drama about a fictional British royal family in modern-day London.,"13,744",
Alaska Daily,Drama            ,47 min,,7.6,"['Hilary Swank, ', 'Jeff Perry, ', 'Grace Dove, ', 'Meredith Holzman', '']",A journalist seeks a fresh start in Alaska working for a newspaper in Anchorage.,"8,710",
Dear Edward,Drama            ,50 min,A,7.2,"['Taylor Schilling, ', ""Colin O'Brien, "", 'Anna Uzele, ', 'Idris Debrand', '']","A 12-year-old boy becomes the lone survivor of a plane crash. As he and others affected by the tragedy try to make sense of what happened, unexpected friendships, romances, and communities are formed.","3,136",
Olive Kitteridge,Drama            ,239 min,,8.3,"['Frances McDormand, ', 'Richard Jenkins, ', 'Ann Dowd, ', 'Ken Cheeseman', '']",A middle-school math teacher Olive and her marriage with Henry which spans 25 years.,"24,534",
Exotica,Drama            ,103 min,A,7,"['Bruce Greenwood, ', 'Elias Koteas, ', 'Don McKellar, ', 'Mia Kirshner', '']","A man plagued by neuroses frequents the club Exotica in an attempt to find solace, but even there his past is never far away.",$4.18M,['Atom Egoyan']
Tales of the City,Drama            ,60 min,18,7.4,"['Laura Linney, ', 'Elliot Page, ', 'Paul Gross, ', 'Murray Bartlett', '']","A middle-aged Mary Ann returns to San Francisco and reunites with the eccentric friends she left behind. ""Tales of the City"" focuses primarily on the people who live in a boardinghouse turned apartment complex owned by Anna Madrigal at 28 Barbary Lane, all of whom quickly become part of what Maupin coined a ""logical family"". It's no longer a secret that Mrs. Madrigal is transgender. Instead, she ...                See full summary »
","8,670",
In Treatment,Drama            ,30 min,UA 16+,8.3,"['Gabriel Byrne, ', 'Uzo Aduba, ', 'Dianne Wiest, ', 'Michelle Forbes', '']","A psychotherapist questions his abilities and gets help by reuniting with his old therapist, whom he has not seen for ten years.","17,861",
Kadin,Drama            ,120 min,,6.7,"['Özge Özpirinçci, ', 'Seray Kaya, ', 'Kubra Suzgun, ', 'Ali Semi Sefil', '']","Bahar, a loving mother who struggles to maintain a life with her two children, must deal with life's challenges and uncover the hidden truths of the past.","1,496",
All Rise,Drama            ,44 min,,7,"['Simone Missick, ', 'Wilson Bethel, ', 'Jessica Camacho, ', 'J. Alex Brinson', '']","A look at the personal and professional lives of the judges, lawyers, clerks, bailiffs and cops who work at an L.A. County courthouse.","5,512",
East of Eden,Drama            ,118 min,U,7.8,"['James Dean, ', 'Raymond Massey, ', 'Julie Harris, ', 'Burl Ives', '']","Two brothers in 1910s California struggle to maintain their strict, Bible-toting father's favor as an old secret about their long-absent mother comes to light.","47,493",['Elia Kazan']
The Inspection,Drama            ,95 min,A,6.7,"['Jeremy Pope, ', 'Gabrielle Union, ', 'Bokeem Woodbine, ', 'Raúl Castillo', '']","A young, gay Black man, rejected by his mother and with few options for his future, decides to join the Marines, doing whatever it takes to succeed in a system that would cast him aside.","3,651",['Elegance Bratton']
To the Bone,Drama            ,107 min,,6.8,"['Rebekah Kennedy, ', 'Lily Collins, ', 'Dana L. Wilson, ', 'Ziah Colon', '']","A young woman, dealing with anorexia, meets an unconventional doctor who challenges her to face her condition and embrace life.","52,675",['Marti Noxon']
Deadlock,Drama            ,,,7.9,"['Luca Asta Sardelis, ', 'Bijou Gracie Henry, ', 'Thomas Weatherall, ', 'Amit Pala', '']","DEADLOCK crashes though the incredible highs, heartbreak, camaraderie, laughs, and bittersweet sorrow of what it is to be a teenager. When a mysterious car crash exposes the dark underbelly...                See full summary »
",58,
Baradaran-e Leila,Drama            ,165 min,,7.9,"['Saeed Poursamimi, ', 'Taraneh Alidoosti, ', 'Navid Mohammadzadeh, ', 'Payman Maadi', '']","Leila, who has spent her entire life caring for her family, makes a plan as her brothers are struggling to make ends meet.","10,371",['Saeed Roustayi']
The Cement Garden,Drama            ,105 min,,7,"['Charlotte Gainsbourg, ', 'Andrew Robertson, ', 'Alice Coulthard, ', 'Ned Birkin', '']","Four children live with their terminally ill mother. After she dies, they try to hold things together. In their isolated house, they begin to deteriorate mentally, whilst they hide their mom's decomposing corpse in a makeshift concrete sarcophagus.",$0.32M,['Andrew Birkin']
Short Term 12,Drama            ,96 min,R,7.9,"['Brie Larson, ', 'Frantz Turner, ', 'John Gallagher Jr., ', 'Kaitlyn Dever', '']",A 20-something supervising staff member of a residential treatment facility navigates the troubled waters of that world alongside her co-worker and longtime boyfriend.,$1.01M,['Destin Daniel Cretton']
Twilight's Child,Drama            ,,,7.7,"['Brec Bassinger, ', 'Khobe Clarke, ', 'Joey McIntyre, ', 'Donna Mills', '']","Dawn gets her baby daughter Christie back and prepares to marry Jimmy. But as she settles in as owner of the Cutler's Cove Resort, she's haunted by visions of Grandmother Cutler",47,['Jacquie Gould']
MVP,Drama            ,112 min,,6.8,"['Mo McRae, ', 'Nate Boyer, ', 'Christina Ochoa, ', 'Dina Shihabi', '']","On the streets of Hollywood, a recently retired NFL player is saved from scandal by a homeless veteran. With their ""glory days"" behind them, the two men bond in search of purpose and identity.",279,['Nate Boyer']
...One Third of a Nation...,Drama            ,79 min,,6.2,"['Sylvia Sidney, ', 'Leif Erickson, ', 'Myron McCormick, ', 'Hiram Sherman', '']","A fire in a run-down tenement building injures young Joey Rogers. Wealthy passerby Peter Cortlant rushes the boy and his attractive older sister Mary to the hospital and pays the medical ...                See full summary »
",293,['Dudley Murphy']
Fanny och Alexander,Drama            ,188 min,A,8.1,"['Bertil Guve, ', 'Pernilla Allwin, ', 'Kristina Adolphson, ', 'Börje Ahlstedt', '']","Two young Swedish children in the 1900s experience the many comedies and tragedies of their lively and affectionate theatrical family, the Ekdahls.",$4.97M,['Ingmar Bergman']
Partner Track,Drama            ,60 min,A,6.7,"['Arden Cho, ', 'Alexandra Turshen, ', 'Bradley Gibson, ', 'Dominic Sherwood', '']","Centers on Ingrid Yun, an idealistic young lawyer, struggles with her moral compass and her passions as she fights to climb the partner track at an elite New York City law firm.","6,774",
Vortex,Drama            ,142 min,,7.4,"['Dario Argento, ', 'Françoise Lebrun, ', 'Alex Lutz, ', 'Kylian Dheret', '']",The last days of an elderly couple stricken by dementia.,"7,888",['Gaspar Noé']
Stateless,Drama            ,316 min,16,7.5,"['Yvonne Strahovski, ', 'Jai Courtney, ', 'Asher Keddie, ', 'Fayssal Bazzi', '']","Inspired by true events; a woman escaping a cult, a refugee fleeing with his family, a father trapped in a dead-end job and a bureaucrat on the verge of a national scandal find their lives intertwined in an immigration detention center.","10,292",
The Secret Lives of Cheerleaders,Drama            ,87 min,,5.2,"['Denise Richards, ', 'Savannah Lee May, ', 'Alexandria DeBerry, ', 'Josie Davis', '']","A pretty and talented cheerleader, Ava, finds herself embroiled in a petty feud with a more popular and ruthless fellow cheerleader who wants nobody else stealing her spotlight.",447,['Peter Sullivan']
Farming,Drama            ,101 min,R,6.2,"['Leke Adebayo, ', 'Ademola Adedoyin, ', 'Adejola Adeyemi, ', 'Adewale Akinnuoye-Agbaje', '']","Based on the writer/director's childhood, FARMING tells story of a young Nigerian boy, 'farmed out' by his parents to a white British family in the hope of a better future. Instead, he becomes the feared leader of a white skinhead gang.","1,809",['Adewale Akinnuoye-Agbaje']
Ladri di biciclette,Drama            ,89 min,U,8.3,"['Lamberto Maggiorani, ', 'Enzo Staiola, ', 'Lianella Carell, ', 'Elena Altieri', '']","In post-war Italy, a working-class man's bicycle is stolen, endangering his efforts to find work. He and his son set out to find it.",$0.33M,['Vittorio De Sica']
Bloomington,Drama            ,83 min,,5.8,"['Allison McAtee, ', 'Sarah Stouffer, ', 'Katherine Ann McGregor, ', 'Ray Zupp', '']",A coming-of-age drama about a former child actress attending college in search of independence and who ends up becoming romantically involved with a female professor.,"5,625",['Fernanda Cardoso']
Klip,Drama            ,102 min,,5.6,"['Isidora Simijonovic, ', 'Vukasin Jasnic, ', 'Sanja Mikitisin, ', 'Jovo Maksic', '']","In the face of her family life falling to pieces, a social-media-obsessed teenage girl falls into a hedonistic world of sex, drugs, and abuse.","7,049",['Maja Milos']
Angela Black,Drama            ,,,6.4,"['Joanne Froggatt, ', 'Michiel Huisman, ', 'Samuel Adewunmi, ', 'Seth Stokes', '']","Trapped in a relationship she cannot escape, Angela is approached out of the blue by Ed, a private investigator, who spills her husband's darkest secrets.","3,392",
"Jeanne Dielman, 23 quai du Commerce, 1080 Bruxelles",Drama            ,202 min,,7.6,"['Delphine Seyrig, ', 'Jan Decorte, ', 'Henri Storck, ', 'Jacques Doniol-Valcroze', '']","A lonely widowed housewife does her daily chores, takes care of her apartment where she lives with her teenage son, and turns the occasional trick to make ends meet. However, something happens that changes her safe routine.",$0.02M,['Chantal Akerman']
Transplant,Drama            ,60 min,,7.9,"['Hamza Haq, ', 'Laurence Leboeuf, ', 'John Hannah, ', 'Ayisha Issa', '']","An ER doctor, who fled his native Syria to come to Canada, must overcome numerous obstacles to resume a career in the high stakes world of emergency medicine.","4,735",
Tôkyô monogatari,Drama            ,136 min,U,8.2,"['Chishû Ryû, ', 'Chieko Higashiyama, ', 'Sô Yamamura, ', 'Setsuko Hara', '']","An old couple visit their children and grandchildren in the city, but receive little attention.","64,975",['Yasujirô Ozu']
The Way Home,Drama            ,42 min,,7.9,"['Chyler Leigh, ', 'Evan Williams, ', 'Sadie Laflamme-Snow, ', 'Andie MacDowell', '']",Three generations of strong and independent women living together in the small farm town of Port Haven embark on an enlightening journey none of them could have imagined as they learn how to find their way back to each other.,"1,542",
God's Creatures,Drama            ,100 min,R,6,"['Seán T. Ó Meallaigh, ', 'Paul Mescal, ', 'Emily Watson, ', 'Declan Conlon', '']","In a windswept fishing village, a mother is torn between protecting her beloved son and her own sense of right and wrong. A lie she tells for him rips apart their family and close-knit community in this tense, sweepingly emotional epic.","2,519",
The Grapes of Wrath,Drama            ,129 min,,8.1,"['Henry Fonda, ', 'Jane Darwell, ', 'John Carradine, ', 'Charley Grapewin', '']","An Oklahoma family, driven off their farm by the poverty and hopelessness of the Dust Bowl, joins the westward migration to California, suffering the misfortunes of the homeless in the Great Depression.",$0.06M,['John Ford']
The Other Side of the Wind,Drama            ,122 min,R,6.7,"['John Huston, ', 'Oja Kodar, ', 'Peter Bogdanovich, ', 'Susan Strasberg', '']","At a media-swamped party to celebrate his 70th birthday and screen his avant-garde film-in-progress, a legendary but jaded Hollywood director is faced both with voracious fans and unsettling questions about what became of his lead actor.","7,765",['Orson Welles']
Vida,Drama            ,35 min,18,7.4,"['Melissa Barrera, ', 'Mishel Prada, ', 'Ser Anzoategui, ', 'Chelsea Rendon', '']","Two sisters, who could not be more different or distanced from each other, are forced to move back to their childhood neighborhood, after the death of their mother, only to discover her past and the shocking truth about her identity.","3,338",
Judging Amy,Drama            ,60 min,,7,"['Amy Brenneman, ', 'Tyne Daly, ', 'Karle Warren, ', 'Richard T. Jones', '']","A family drama focused on three generations of women living together in Hartford, Connecticut.","6,742",
Columbus,Drama            ,104 min,,7.2,"['John Cho, ', 'Haley Lu Richardson, ', 'Parker Posey, ', 'Michelle Forbes', '']","A Korean-born man finds himself stuck in Columbus, Indiana, where his architect father is in a coma. The man meets a young woman who wants to stay in Columbus with her mother, a recovering addict, instead of pursuing her own dreams.",$1.02M,['Kogonada']
Miracle in Cell No. 7,Drama            ,132 min,,8.2,"['Aras Bulut Iynemli, ', 'Nisa Sofiya Aksongur, ', 'Deniz Baysal, ', 'Celile Toyon Uysal', '']",A story of love between a mentally-ill father who was wrongly accused of murder and his lovely six year old daughter. Prison will be their home. Based on the 2013 Korean movie 7-beon-bang-ui seon-mul (2013).,"52,435",['Mehmet Ada Öztekin']
Life,Drama            ,355 min,,7.7,"['Rachael Stirling, ', 'Victoria Hamilton, ', 'Peter Davison, ', 'Melissa Johns', '']","Gail, Belle, David, and Hannah all encounter new and disruptive influences in their lives, kicking off interweaving stories set in a house in Manchester, England, UK, divided into four flats.","2,299",
I Am...,Drama            ,47 min,,7.1,"['Samantha Morton, ', 'Gemma Chan, ', 'Vicky McClure, ', 'Lesley Manville', '']",A trilogy that explores the experiences of three women in personal and emotional moments.,783,
Do-ga-ni,Drama            ,125 min,,8,"['Gong Yoo, ', 'Jung Yu-mi, ', 'Hyeon-soo Kim, ', 'Jee-Young Kim', '']","Based on real events, this film depicts the story of a school for the hearing-impaired where young deaf students were sexually assaulted by the faculty members over a long period of time.","19,526",['Hwang Dong-hyuk']
R.M.N.,Drama            ,125 min,,7.3,"['Marin Grigore, ', 'Judith State, ', 'Macrina Barladeanu, ', 'Orsolya Moldován', '']","A non-judgmental analysis of the driving forces of human behavior when confronted with the unknown, of the way we perceive the other and on how we relate to an unsettling future.","3,479",['Cristian Mungiu']
Earth Mama,Drama            ,97 min,R,7.3,"['Tia Nomore, ', 'Erika Alexander, ', 'Keta Price, ', 'Doechii', '']",An intimate coming of age story of a pregnant single mother who embraces her Bay Area community as she determines the fate of her family.,104,['Savanah Leaf']
Nebraska,Drama            ,115 min,UA,7.7,"['Bruce Dern, ', 'Will Forte, ', 'June Squibb, ', 'Bob Odenkirk', '']","An aging, booze-addled father makes the trip from Montana to Nebraska with his estranged son in order to claim a million-dollar Mega Sweepstakes Marketing prize.",$17.65M,['Alexander Payne']
Dear Zoe,Drama            ,94 min,R,5.6,"['Sadie Sink, ', 'Theo Rossi, ', 'Jessica Capshaw, ', 'Justin Bartha', '']","When Tess and her family suffer an unimaginable loss, she finds support from a surprising source: her biological father - a lovable slacker from the wrong side of the tracks - and the charming but dangerous juvenile delinquent next door.","1,030",['Gren Wells']
Girl,Drama            ,105 min,R,7.2,"['Victor Polster, ', 'Arieh Worthalter, ', 'Oliver Bodart, ', 'Tijmen Govaerts', '']",A promising teenage dancer enrolls at a prestigious ballet school while grappling with her gender dysphoria.,"16,316",['Lukas Dhont']
The Minx,Drama            ,84 min,,4.6,"['Jan Sterling, ', 'Robert Rodan, ', 'Shirley Parker, ', 'Michael Beirne', '']","A businessman hosts a hunting party at a remote lodge, and hires three prostitutes to take care of his clients. However, the girls have their own plans and secretly install cameras in the bedrooms to record the activities for future use.",$0.73M,['Raymond Jacobs']
The Family That Preys,Drama            ,111 min,PG-13,5.9,"['Kathy Bates, ', 'Alfre Woodard, ', 'Sanaa Lathan, ', 'Rockmond Dunbar', '']",Two families from different walks of life learn to work together.,$37.02M,['Tyler Perry']
The Blind,Drama            ,108 min,PG-13,,"['Kerry Knuppe, ', 'Amelia Eve, ', 'John Ales, ', 'Aaron Dalla Villa', '']","In the 1960s Deep South, a man struggles with the shame of his past while navigating his own alcoholism and complicated family dynamics as a husband and father.",,['Andrew Hyatt']
Sorry for Your Loss,Drama            ,30 min,,7.5,"['Elizabeth Olsen, ', 'Kelly Marie Tran, ', 'Jovan Adepo, ', 'Mamoudou Athie', '']",Her husband's sudden death upends and transforms relationships in Leigh Shaw's life and also forces her to realize how much she didn't know about him.,"3,112",
All Saints,Drama            ,60 min,,7.1,"['Judith McGrath, ', 'Georgie Parker, ', 'Tammy Macintosh, ', 'Martin Lynes', '']",A drama series centred on the lives of the nurses at All Saints Western General Hospital.,"1,553",
The Magdalene Sisters,Drama            ,114 min,R,7.7,"['Eileen Walsh, ', 'Dorothy Duffy, ', 'Nora-Jane Noone, ', 'Anne-Marie Duff', '']",Three young Irish women struggle to maintain their spirits while they endure dehumanizing abuse as inmates of a Magdalene Sisters Asylum.,$4.89M,['Peter Mullan']
Who's Afraid of Virginia Woolf?,Drama            ,131 min,A,8,"['Elizabeth Taylor, ', 'Richard Burton, ', 'George Segal, ', 'Sandy Dennis', '']","A bitter, aging couple, with the help of alcohol, use their young houseguests to fuel anguish and emotional pain towards each other over the course of a distressing night.","77,969",['Mike Nichols']
Holby City,Drama            ,60 min,,5.8,"['Hugh Quarshie, ', 'Rosie Marcel, ', 'Jaye Jacobs, ', 'Bob Barrett', '']","The everyday lives, professional and personal, of the doctors, nurses and patients who find themselves, for various reasons, in the wards of the frenetic cardiac unit of Holby City General Hospital.","2,370",
Ordinary Angels,Drama            ,116 min,,,"['Alan Ritchson, ', 'Amy Acker, ', 'Hilary Swank, ', 'Nancy Travis', '']",Inspired by the incredible true story of a hairdresser who single-handedly rallies an entire community to help a widowed father save the life of his critically ill young daughter.,,['Jon Gunn']
Family Life,Drama            ,108 min,,7.6,"['Sandy Ratcliff, ', 'Bill Dean, ', 'Grace Cave, ', 'Malcolm Tierney', '']","A family is shattered over the daughter's forced abortion. As she rebels against her family and their traditional, authoritarian, typical-of-the-time norms, she is hospitalized and otherwise mistreated.","1,972",['Ken Loach']
Ride,Drama            ,,,6.4,"['Nancy Travis, ', 'Tiera Skovbye, ', 'Beau Mirchoff, ', 'Sara Garcia', '']",Follows the lives of the McMurrays as they struggle to keep their beloved ranch afloat.,634,
The Sweet Hereafter,Drama            ,112 min,R,7.5,"['Ian Holm, ', 'Sarah Polley, ', 'Caerthan Banks, ', 'Tom McCamus', '']","A bus crash in a small town brings a lawyer to defend the families, but he discovers everything isn't what it seems.",$3.25M,['Atom Egoyan']
Malpractice,Drama            ,240 min,,7,"['Niamh Algar, ', 'James Purefoy, ', 'Hannah Walters, ', 'Lorne MacFadyen', '']","When the respected Dr. Lucinda Edwards loses an opioid overdose patient, an investigation is started, probing into her conduct on that night.","1,372",
Life Goes On,Drama            ,60 min,,7.1,"['Kellie Martin, ', 'Chris Burke, ', 'Patti LuPone, ', 'Bill Smitrovich', '']",A modern All-American family deals with the struggles of life and love in mid-western suburbia.,"2,780",
The Unlikely Pilgrimage of Harold Fry,Drama            ,108 min,,6.8,"['Jim Broadbent, ', 'Penelope Wilton, ', 'Earl Cave, ', 'Linda Bassett', '']","Harold is an ordinary man who has passed through life, living on the side lines, until he goes to post a letter one day...and just keeps walking.","1,119",['Hettie Macdonald']
Il conformista,Drama            ,113 min,UA,7.9,"['Jean-Louis Trintignant, ', 'Stefania Sandrelli, ', 'Gastone Moschin, ', 'Enzo Tarascio', '']","A weak-willed Italian man becomes a fascist flunky who goes abroad to arrange the assassination of his old teacher, now a political dissident.",$0.54M,['Bernardo Bertolucci']
Perfect Days,Drama            ,123 min,,7.8,"['Yumi Asô, ', 'Tokio Emoto, ', 'Sayuri Ishikawa, ', 'Tomokazu Miura', '']",A janitor in Japan drives between jobs listening to rock music.,257,['Wim Wenders']
Move to Heaven,Drama            ,60 min,18,8.5,"['Adam McArthur, ', 'Lee Jehoon, ', 'Tang Joon-sang, ', 'Olivia Castanho', '']","Working as trauma cleaners, both Gu-ru and Sang-gu uncover various stories of the deceased while experiencing different emotions and sentiments toward life, death and family.","7,892",
Burden of Truth,Drama            ,44 min,,7.3,"['Kristin Kreuk, ', 'Peter Mooney, ', 'Meegwun Fairbrother, ', 'Star Slade', '']",Big city lawyer Joanna Hanley returns to her hometown to take the case of a group of girls suffering from a mysterious illness.,"4,727",
How to Have Sex,Drama            ,98 min,,6.8,"['Mia McKenna-Bruce, ', 'Shaun Thomas, ', 'Lara Peake, ', 'Enva Lewis', '']","Three British teenage girls go on a rites-of-passage holiday - drinking, clubbing and hooking up, in what should be the best summer of their lives.",174,['Molly Manning Walker']
The Madame Blanc Mysteries,Drama            ,60 min,,7.2,"['Steve Edge, ', 'Sally Lindsay, ', 'Alex Gaumond, ', 'Sue Vincent', '']",Antiques expert moves to France suspicious of how her husband died and uses her skills to become a PI aiding the local police and simultaneously bonding with the town's popular taxi driver.,"2,478",
The Ice Storm,Drama            ,112 min,A,7.4,"['Kevin Kline, ', 'Joan Allen, ', 'Sigourney Weaver, ', 'Henry Czerny', '']","In suburban New Canaan, Connecticut, 1973, middle-class families experimenting with casual sex and substance abuse find their lives beyond their control.",$7.84M,['Ang Lee']
Memory,Drama            ,100 min,,,"['Elsie Fisher, ', 'Jessica Chastain, ', 'Peter Sarsgaard, ', 'Merritt Wever', '']",A love-struck couple attempt to build a relationship while dealing with trauma and dementia.,,['Michel Franco']
Midnight Whispers,Drama            ,,,6.5,"['Brec Bassinger, ', 'Megan Best, ', 'Khobe Clarke, ', 'Joey McIntyre', '']","After the tragic deaths of Dawn and Jimmy, Christie goes in search of her birth father. After a brief respite, she returns home to defy the curse that has haunted the Booth, Cutler, and Longchamp families.",27,['Jacquie Gould']
Speak,Drama            ,89 min,PG-13,7.2,"['Kristen Stewart, ', 'Elizabeth Perkins, ', 'Richard Hagerman, ', 'Allison Siko', '']","After a blurred trauma over the summer, Melinda enters high school a selective mute. Struggling with school, friends, and family, she tells the dark tale of her experiences, and why she has chosen not to speak.","28,408",['Jessica Sharzer']
An Education,Drama            ,100 min,PG-13,7.3,"['Carey Mulligan, ', 'Peter Sarsgaard, ', 'Alfred Molina, ', 'Olivia Williams', '']","A coming-of-age story about a teenage girl in 1960s suburban London, and how her life changes with the arrival of a playboy nearly twice her age.",$12.57M,['Lone Scherfig']
Vi,Drama            ,92 min,,5.3,"['Gustaf Skarsgård, ', 'Anna Åström, ', 'Rebecca Ferguson, ', 'Kevin Vaz', '']",This is a story of IDA and KRISTER. It's about a relationship that goes to hell. They are both crazy in love but manage to strangle the supply of oxygen and adapt to each other in a way that will lead to catastrophic consequences.,"1,019",['Mani Maserrat-Agah']
Happiest Season,Drama            ,102 min,13,6.6,"['Kristen Stewart, ', 'Mackenzie Davis, ', 'Mary Steenburgen, ', 'Victor Garber', '']","A holiday romantic comedy that captures the range of emotions tied to wanting your family's acceptance, being true to yourself, and trying not to ruin Christmas.","44,120",['Clea DuVall']
Las chicas del cable,Drama            ,50 min,18,7.5,"['Blanca Suárez, ', 'Yon González, ', 'Ana Fernández, ', 'Nadia de Santiago', '']","Set in the 1920s, this is the story of four women from different backgrounds newly hired as operators for a phone company.","15,469",
Sacrifice,Drama            ,149 min,U,7.9,"['Erland Josephson, ', 'Susan Fleetwood, ', 'Allan Edwall, ', 'Guðrún Gísladóttir', '']","At the dawn of World War III, a man searches for a way to restore peace to the world and finds he must give something in return.",$0.30M,['Andrei Tarkovsky']
Lonesome,Drama            ,95 min,,6.5,"['Josh Lavery, ', 'Julian Oliver, ', 'Mathew Waters, ', 'Ally Morgan', '']","Casey, a country lad running from a small-town scandal, finds himself down and out in big city Sydney. When he meets city lad Tib both men find something they have been missing but neither of them knows quite how to negotiate it.",593,['Craig Boreham']
Doctors,Drama            ,30 min,,4.6,"['Adrian Lewis Morgan, ', 'Jan Pearson, ', 'Matthew Chambers, ', 'Diane Keen', '']","The daily lives of staff at a Birmingham medical practice, including their often-dramatic involvements with their patients.","1,571",
North Star,Drama            ,95 min,,,"['Scarlett Johansson, ', 'Sienna Miller, ', 'Kristin Scott Thomas, ', 'Freida Pinto', '']","Three sisters return to their home for the third wedding of their twice-widowed mother. But the mother and daughters are forced to revisit the past and confront the future, with help from a colorful group of unexpected wedding guests.",,['Kristin Scott Thomas']
Marriage,Drama            ,57 min,,6.3,"['Sean Bean, ', 'Nicola Walker, ', 'Henry Lloyd-Hughes, ', 'Chantelle Alle', '']","Follows Ian and Emma, a married couple, who deal with the ups and downs of their 30-year long marriage.","2,206",
Born and Bred,Drama            ,55 min,,7.6,"['Jenna Russell, ', 'Maggie Steed, ', 'Clive Swift, ', 'Naomi Radcliffe', '']","A 1950s set, British drama series about life in the fictional Lancashire village of Ormston. The main focus of the series was the two doctors, father and son, who run the cottage hospital under the new National Health Service.",367,
Beach Rats,Drama            ,98 min,R,6.4,"['Harris Dickinson, ', 'Madeline Weinstein, ', 'Kate Hodge, ', 'Neal Huff', '']",A Brooklyn teenager spends his days experimenting with drugs and looking online for older men to meet.,$0.47M,['Eliza Hittman']
The Last Days of Ptolemy Grey,Drama            ,311 min,A,7.8,"['Samuel L. Jackson, ', 'Dominique Fishback, ', 'Cynthia Kaye McWilliams, ', 'Damon Gupton', '']","Suddenly left without his trusted caretaker, Ptolemy Grey is assigned to the care of orphaned teenager, Robyn. When they learn about a treatment that will restore Ptolemy's memories, it begins a journey towards shocking truths.","5,311",
Little Bird,Drama            ,,,7.9,"['Janet Kidder, ', 'Alanna Bale, ', 'Ellyn Jade, ', 'Darla Contois', '']",Follow six parts about Sixties Scoop and a woman who is finding her family.,380,
The Paradise,Drama            ,60 min,,7.7,"['Joanna Vanderham, ', 'Emun Elliott, ', 'Stephen Wight, ', 'Sonya Cassidy', '']",The story of a young woman who works in a department store and gets caught up in the charms of the modern world.,"12,221",
UnREAL,Drama            ,42 min,,7.8,"['Shiri Appleby, ', 'Craig Bierko, ', 'Jeffrey Bowyer-Chapman, ', 'Brennan Elliott', '']",A behind-the-scenes look at the chaos surrounding the production of a dating competition program.,"15,165",
Fathers & Daughters,Drama            ,116 min,A,7,"['Russell Crowe, ', 'Amanda Seyfried, ', 'Aaron Paul, ', 'Diane Kruger', '']","A Pulitzer-winning writer grapples with being a widower and father after a mental breakdown, while, 27 years later, his grown daughter struggles to forge connections of her own.","27,875",['Gabriele Muccino']
Grand Army,Drama            ,,18,7.5,"['Odessa A’zion, ', 'Odley Jean, ', 'Amir Bageria, ', 'Maliq Johnson', '']","The drama series tells the story of five high school students as they struggle with sexual, racial and economic politics and fight to succeed and become somebody.","8,320",
Queen Sugar,Drama            ,60 min,,7.8,"['Rutina Wesley, ', 'Kofi Siriboe, ', 'Omar J. Dorsey, ', 'Nicholas L. Ashe', '']","Follows the life of three siblings, one of whom moves from Los Angeles to Louisiana, to claim a shared inheritance from their recently departed father - an 800-acre sugarcane farm.","5,421",
"Promiscuidade, os Pivetes de Kátia",Drama            ,90 min,,3.8,"['Cristina Martinez, ', 'Ênio Gonçalves, ', 'Sérgio Hingst, ', 'José Lucas', '']",A young woman cheats her impotent husband with the surrounding teenagers.,135,['Fauzi Mansur']
Wielka woda,Drama            ,45 min,UA 16+,7.1,"['Agnieszka Zulewska, ', 'Tomasz Schuchardt, ', 'Ireneusz Czop, ', 'Marta Nieradkiewicz', '']","When the flood wave approaches the capital of Lower Silesia, a decision is made to save the city from the destructive elements, the surrounding villages and fields should be sacrificed.","5,718",
Fish Tank,Drama            ,123 min,,7.3,"['Katie Jarvis, ', 'Michael Fassbender, ', 'Kierston Wareing, ', 'Rebecca Griffiths', '']",Everything changes for 15-year-old Mia when her mum brings home a new boyfriend.,$0.37M,['Andrea Arnold']
The Joy Luck Club,Drama            ,139 min,Not Rated,7.7,"['Tamlyn Tomita, ', 'Rosalind Chao, ', 'Kieu Chinh, ', 'Tsai Chin', '']",The life histories of four East Asian women and their daughters reflect and guide each other.,$32.86M,['Wayne Wang']
Kodachrome,Drama            ,105 min,18,6.8,"['Ed Harris, ', 'Jason Sudeikis, ', 'Elizabeth Olsen, ', 'Bruce Greenwood', '']","Set during the final days of the admired photo development system known as Kodachrome, a father and son hit the road in order to reach the Kansas photo lab before it closes its doors for good.","18,639",['Mark Raso']
V.C. Andrews' Landry Family,Drama            ,,,6.7,"['Raechelle Banno, ', 'Karina Banno, ', 'Sam Duke, ', 'Ty Wood', '']","The V.C. Andrews Ruby Movie Series Event follows Ruby Landry as she explores the depths of her curious family tree, including her wealthy and mysterious estranged father.",110,
Dolor y gloria,Drama            ,113 min,A,7.5,"['Antonio Banderas, ', 'Asier Etxeandia, ', 'Leonardo Sbaraglia, ', 'Nora Navas', '']",A film director reflects on the choices he's made in life as the past and present come crashing down around him.,"61,032",['Pedro Almodóvar']
"I, Daniel Blake",Drama            ,100 min,UA,7.8,"['Dave Johns, ', 'Hayley Squires, ', 'Sharon Percy, ', 'Briana Shann', '']","After surviving a heart-attack, a 59-year-old carpenter must fight bureaucratic forces to receive Employment and Support Allowance.",$0.26M,['Ken Loach']
Grand Jeté,Drama            ,105 min,,5.1,"['Sarah Nevada Grether, ', 'Emil von Schönfels, ', 'Susanne Bredehöft, ', 'Stefan Rudolf', '']","In order to concentrate on her career, a ballet teacher lives estranged from her young son, who grew up with her mother. When she meets him again after years, an affection develops that goes far beyond maternal love.",476,['Isabelle Stever']
The White Storm 3: Heaven or Hell,Drama            ,125 min,,6.1,"['Alex Fong, ', 'Louis Koo, ', 'Aaron Kwok, ', 'Suet Lam', '']","An undercover cop who invade a drug cartel led by a notorious Thai drug lord. In classic heroic bloodshed fashion, the two develop a bond of brotherhood.",65,['Herman Yau']
Patrick Melrose,Drama            ,302 min,,8,"['Benedict Cumberbatch, ', 'Jennifer Jason Leigh, ', 'Hugo Weaving, ', 'Sebastian Maltz', '']",This series depicts how the son of an aristocratic family seeks redemption and recovery.,"31,134",
Nostalgia,Drama            ,125 min,,8,"['Oleg Yankovskiy, ', 'Erland Josephson, ', 'Domiziana Giordano, ', 'Patrizia Terreno', '']","A Russian poet and his interpreter travel to Italy researching the life of an 18th-century composer, and instead meet a ruminative madman who tells the poet how the world may be saved.",$0.01M,['Andrei Tarkovsky']
The Only Living Boy in New York,Drama            ,89 min,R,6.3,"['Callum Turner, ', 'Kate Beckinsale, ', 'Pierce Brosnan, ', 'Cynthia Nixon', '']","Adrift in New York City, a recent college graduate's life is upended by his father's mistress.",$0.62M,['Marc Webb']
Zetchô kazoku: Aijin-darake,Drama            ,70 min,,8.2,"['Meguri, ', 'Mai Tamaki, ', 'Mayuko Sasaki, ', 'Sôsuke Yamamoto', '']","A father, who runs a real estate agency in town, is having an affair with a pretty office worker, Yuki. His daughter Hitomi returns home for a long time after receiving news that he had collapsed from a heart attack during.",107,['Yoshikazu Katô']
So-won,Drama            ,122 min,,8.2,"['Re Lee, ', 'Sol Kyung-gu, ', 'Uhm Ji-won, ', 'Kim Hae-sook', '']","Story of an 8 year old girl coping with a gruesome rape damaging her internally and affecting emotionally, trying to overcome all obstacles in the aftermath of the incident with a good support from those around her.","8,825",['Joon-ik Lee']
Arrête avec tes mensonges,Drama            ,98 min,,7.5,"['Guillaume de Tonquédec, ', 'Victor Belmondo, ', 'Guilaine Londez, ', 'Jérémy Gillet', '']",An author returns to his hometown of Cognac for the first time in 35 years to help promote a distillery. He is also there to face the memories of his first love. The people & places he returns to evoke many feelings from the past.,528,['Olivier Peyon']
The Panic in Needle Park,Drama            ,110 min,PG,7.1,"['Al Pacino, ', 'Kitty Winn, ', 'Alan Vint, ', 'Richard Bright', '']","Follows the lives of heroin addicts who frequent ""Needle Park"" in New York City.","19,313",['Jerry Schatzberg']
Reign Over Me,Drama            ,124 min,R,7.4,"['Adam Sandler, ', 'Don Cheadle, ', 'Jada Pinkett Smith, ', 'Liv Tyler', '']",A man who lost his family in the September 11 attack on New York City runs into his old college roommate. Rekindling the friendship is the one thing that appears able to help the man recover from his grief.,$19.66M,['Mike Binder']
Dünyayla Benim Aramda,Drama            ,60 min,,5.6,"['Demet Özdemir, ', 'Bugra Gülsoy, ', 'Hafsanur Sancaktutan, ', 'Zerrin Tekindor', '']","Ilkin worries that her boyfriend, a famous actor, is no longer in love with her. One day, she decides to reach out to him from a fake social media account and almost creates the woman who can seduce her lover with her own hands.","2,075",
Selina's Gold,Drama            ,113 min,,6.5,"['Angeli Khang, ', 'Gold Azeron, ', 'Jay Manalo, ', 'Azi Acosta', '']","Selina's father sells her to Tiago who makes her a sex slave. With the help of Domeng, Tiago's blind slave, she plans their way out of this living hell.",959,['Mac Alejandre']
Jolene,Drama            ,121 min,R,6.4,"['Jessica Chastain, ', 'Frances Fisher, ', 'Rupert Friend, ', 'Dermot Mulroney', '']","A teenage orphan spends ten years traveling cross-country experiencing life, love and heartbreak.","5,006",['Dan Ireland']
Gore,Drama            ,,,,"['Kevin Spacey, ', 'Michael Stuhlbarg, ', 'Douglas Booth, ', 'Freya Mavor', '']","A young man spends a summer in Italy where he meets his idol, Gore Vidal, who teaches him about life, love, and politics.",,['Michael Hoffman']
Emanuelle nera,Drama            ,96 min,A,4.5,"['Laura Gemser, ', 'Karin Schubert, ', 'Angelo Infanti, ', 'Isabelle Marchall', '']","While on assignment in Nairobi, a photojournalist questions her racial and sexual identity when she engages in affairs with her wealthy hosts.","1,617",['Bitto Albertini']
Madres paralelas,Drama            ,123 min,R,7.1,"['Penélope Cruz, ', 'Milena Smit, ', 'Israel Elejalde, ', 'Aitana Sánchez-Gijón', '']",The story of two mothers who bond in unexpected way after giving birth the same day.,"33,237",['Pedro Almodóvar']
The Humans,Drama            ,108 min,R,6.2,"['Richard Jenkins, ', 'Jayne Houdyshell, ', 'Amy Schumer, ', 'Beanie Feldstein', '']","During one evening, the Blake family gathers to celebrate thanksgiving in a broken-down flat newly rented by the daughter and her new man. As the darkness falls, we find that all have less to be thankful about.","9,676",['Stephen Karam']
The Kindness of Strangers,Drama            ,112 min,,6.5,"['Zoe Kazan, ', 'Esben Smed, ', 'Jack Fulton, ', 'Finlay Wojtak-Hissong', '']",The story of people whose lives intertwine during a dramatic winter in New York City.,"4,776",['Lone Scherfig']
About Schmidt,Drama            ,125 min,U,7.2,"['Jack Nicholson, ', 'Hope Davis, ', 'Dermot Mulroney, ', 'Kathy Bates', '']","A recently retired man embarks on a journey to his estranged daughter's wedding, only to discover more about himself and life than he ever expected.",$65.02M,['Alexander Payne']
Rabbit Hole,Drama            ,91 min,PG-13,7,"['Nicole Kidman, ', 'Aaron Eckhart, ', 'Dianne Wiest, ', 'Miles Teller', '']",Life for a happy couple is turned upside down after their young son dies in an accident.,$2.23M,['John Cameron Mitchell']
The Young Pope,Drama            ,546 min,A,8.3,"['Jude Law, ', 'Diane Keaton, ', 'Silvio Orlando, ', 'Javier Cámara', '']","The beginning of the pontificate of Lenny Belardo, alias Pius XIII, the first American Pope in history.","46,001",
Tell It to the Bees,Drama            ,108 min,,6.4,"['Billy Boyd, ', 'Gregor Selkirk, ', 'Anna Paquin, ', 'Euan Mason', '']","In 1950s small town Britain, a doctor develops a relationship with her young patient's mother.","6,166",['Annabel Jankel']
Alcarràs,Drama            ,120 min,,7,"['Josep Abad, ', 'Jordi Pujol Dolcet, ', 'Anna Otin, ', 'Albert Bosch', '']","The life of a family of peach farmers in a small village in Catalonia changes when the owner of their large estate dies and his lifetime heir decides to sell the land, suddenly threatening their livelihood.","6,715",['Carla Simón']
The Good Karma Hospital,Drama            ,60 min,,7.9,"['Amanda Redman, ', 'Darshan Jariwala, ', 'Nimmi Harasgama, ', 'Neil Morrissey', '']","Doctor Ruby Walker arrives in India looking for a job and a distraction from her heartbreak. She anticipates the sunshine and picture-perfect beaches, but not the realities of work at an under-resourced hospital.","2,728",
Palm Trees and Power Lines,Drama            ,110 min,R,6.5,"['Lily McInerny, ', 'Gretchen Mol, ', 'Emily Jackson, ', 'Quinn Frankel', '']","A disconnected teenage girl enters a relationship with a man twice her age. She sees him as the solution to all her problems, but his intentions are not what they seem.","2,054",['Jamie Dack']
"Endings, Beginnings",Drama            ,110 min,,5.6,"['Shailene Woodley, ', 'Jamie Dornan, ', 'Sebastian Stan, ', 'Matthew Gray Gubler', '']","A 30-something woman navigating through love and heartbreak over the course of one year. During that time, she will unlock the secrets to her life in a sudden turn of events and in the most surprising of places.","6,753",['Drake Doremus']
L'Apollonide (Souvenirs de la maison close),Drama            ,122 min,,6.7,"['Noémie Lvovsky, ', 'Hafsia Herzi, ', 'Céline Sallette, ', 'Jasmine Trinca', '']","At an elegant Parisian bordello at the dawn of the 20th century exists a cloistered world of pleasure, pain, hope, rivalries--and, most of all, slavery.",$0.02M,['Bertrand Bonello']
Es war nicht die Nachtigall,Drama            ,88 min,,4.7,"['Jean-Claude Bouillon, ', 'Sylvia Kristel, ', 'Teri Tordai, ', 'Ekkehardt Belle', '']","Pauli is a sexually frustrated young man who's surrounded by sexually liberated women who will not give him the time of day. He meets a beautiful virgin woman, Andrea, who strongly resists his charms, which compounds his frustrations.",508,['Sigi Rothemund']
Reasonable Doubt,Drama            ,53 min,A,6.2,"['Emayatzy Corinealdi, ', 'McKinley Freeman, ', 'Tim Jo, ', 'Angela Grovey', '']","Jax Stewart juggles work, family, friends, and a complicated personal life as a brilliant and fearless defense attorney in Los Angeles who bucks the justice system every chance she gets.","1,855",
Threesome,Drama            ,,,7,"['Matilda Källström, ', 'Simon Lööf, ', 'Kitt Walker, ', 'Emily Renée', '']","The young Swedish couple David and Siri who have been together since high school have the love that is self-evident and strong, until they meet French art student Camille on a rainy night out.","1,125",
A Little Life,Drama            ,,,,"['James Norton, ', 'Luke Thompson, ', 'Omari Douglas, ', 'Zach Wyatt', '']","A LITTLE LIFE follows four college friends in New York City: aspiring actor Willem, successful architect Malcolm, struggling artist JB, and prodigious lawyer Jude. As ambition, addiction, ...                See full summary »
",,['Ivo van Hove']
Paradies: Liebe,Drama            ,120 min,,7,"['Margarete Tiesel, ', 'Peter Kazungu, ', 'Inge Maux, ', 'Dunja Sowinetz', '']","Teresa, a fifty-year-old Austrian mother, travels to the paradise of the beaches of Kenya, seeking out love from African boys. But she must confront the hard truth that on the beaches of Kenya, love is a business.",$0.02M,['Ulrich Seidl']
Yin ru chen yan,Drama            ,131 min,,7.6,"['Renlin Wu, ', 'Hai-Qing, ', 'Guangrui Yang, ', 'Dengping Zhao', '']","The humble, unassuming Ma and timid Cao have been cast off by their families and forced into an arranged marriage. To survive, they have to come together and build a home for themselves.","1,739",['Ruijun Li']
Vår tid är nu,Drama            ,60 min,,8.2,"['Hedda Stiernstedt, ', 'Charlie Gustafsson, ', 'Anna Bjelkerud, ', 'Adam Lundgren', '']","Stockholm, the day of peace in Europe 1945. A spontaneous kiss between two strangers, during the celebration at Kungsgatan, will have major consequences.","5,274",
Je t'aime moi non plus,Drama            ,89 min,,5.9,"['Jane Birkin, ', 'Joe Dallesandro, ', 'Hugues Quester, ', 'Reinhard Kolldehoff', '']","The petite waitress Johnny works and lives in a truck-stop, where she's lonely and longs for love. She develops a crush on the garbage truck driver Krassky, although her sleazy boss Boris warns her that he's gay.","2,232",['Serge Gainsbourg']
Cat on a Hot Tin Roof,Drama            ,108 min,A,7.9,"['Elizabeth Taylor, ', 'Paul Newman, ', 'Burl Ives, ', 'Jack Carson', '']",Brick is an alcoholic ex-football player who drinks his days away and resists the affections of his wife. A reunion with his terminal father jogs a host of memories and revelations for both father and son.,$17.57M,['Richard Brooks']
Finding Forrester,Drama            ,136 min,U,7.3,"['Sean Connery, ', 'Rob Brown, ', 'F. Murray Abraham, ', 'Anna Paquin', '']",A young writing prodigy finds a mentor in a reclusive author.,$66.40M,['Gus Van Sant']
Amour,Drama            ,127 min,UA,7.9,"['Jean-Louis Trintignant, ', 'Emmanuelle Riva, ', 'Isabelle Huppert, ', 'Alexandre Tharaud', '']","Georges and Anne are an octogenarian couple. They are cultivated, retired music teachers. Their daughter, also a musician, lives in Britain with her family. One day, Anne has a stroke, and the couple's bond of love is severely tested.",$6.74M,['Michael Haneke']
"Upstairs, Downstairs",Drama            ,60 min,,8.4,"['Gordon Jackson, ', 'David Langton, ', 'Jean Marsh, ', 'Angela Baddeley', '']","The lives and fortunes of the Bellamy family and their below-stairs servant staff at 165 Eaton Place play out against the social, political and historical backdrop of Edwardian London from 1903 to 1930.","3,414",
Le paradis,Drama            ,83 min,,7,"['Khalil Ben Gharbia, ', 'Julien De Saint Jean, ', 'Eye Haidara, ', 'Jonathan Couzinié', '']","In a juvenile reform center, a place governed by the prohibition of physical contact, Joe and William fall in love. To love each other, they will have to break the law.",302,['Zeno Graton']
The Line,Drama            ,100 min,,7,"['Alex Wolff, ', 'Bo Mitchell, ', 'Halle Bailey, ', 'Austin Abrams', '']",A university student lives life without fear of consequences.,148,['Ethan Berger']
Revoir Paris,Drama            ,105 min,,6.8,"['Virginie Efira, ', 'Benoît Magimel, ', 'Grégoire Colin, ', 'Maya Sansa', '']","Three months after surviving a terrorist attack in a bistro, Mia is still traumatized and unable to recall the events of that night. In an effort to move forward, she investigates her memories and retraces her steps.","1,996",['Alice Winocour']
Dziewczyny z Dubaju,Drama            ,146 min,,5.3,"['Paulina Galazka, ', 'Katarzyna Figura, ', 'Katarzyna Sawczuk, ', 'Olga Kalicka', '']","It follows a young woman who becomes an escort as a way of getting out of her small town, but she soon discovers she has no control over her situation.","2,320",['Maria Sadowska']
We Are Who We Are,Drama            ,462 min,,7.3,"['Jack Dylan Grazer, ', 'Jordan Kristine Seamón, ', 'Chloë Sevigny, ', 'Alice Braga', '']","Two American kids who live on a U.S. military base in Italy explore friendship, first love, identity, and all the messy exhilaration and anguish of being a teenager.","9,306",
Wildlife,Drama            ,105 min,PG-13,6.8,"['Ed Oxenbould, ', 'Jake Gyllenhaal, ', 'Carey Mulligan, ', 'Travis W Bruyer', '']",A teenage boy must deal with his mother's complicated response after his father temporarily abandons them to take a menial and dangerous job.,$1.03M,['Paul Dano']
Fireflies in the Garden,Drama            ,99 min,R,6.4,"['Ryan Reynolds, ', 'Willem Dafoe, ', 'Emily Watson, ', 'Carrie-Anne Moss', '']",The Taylor family is devastated by an accident that takes place on the day their matriarch is due to graduate from college -- decades after leaving to raise her children.,$3.39M,['Dennis Lee']
Certain Women,Drama            ,107 min,R,6.4,"['Michelle Williams, ', 'Kristen Stewart, ', 'Laura Dern, ', 'James Le Gros', '']","The lives of three women intersect in small-town America, where each is imperfectly blazing a trail.",$1.03M,['Kelly Reichardt']
Pather Panchali,Drama            ,125 min,U,8.2,"['Kanu Bannerjee, ', 'Karuna Bannerjee, ', 'Subir Banerjee, ', 'Chunibala Devi', '']","Impoverished priest Harihar Ray, dreaming of a better life for himself and his family, leaves his rural Bengal village in search of work.",$0.54M,['Satyajit Ray']
Il portiere di notte,Drama            ,118 min,,6.6,"['Dirk Bogarde, ', 'Charlotte Rampling, ', 'Philippe Leroy, ', 'Gabriele Ferzetti', '']","A concentration camp survivor rekindles her sadomasochistic relationship with her lover, a former SS officer - now working as a night porter at a Vienna hotel - but his former Nazi associates begin stalking them.",$0.63M,['Liliana Cavani']
Swimming with Sharks,Drama            ,52 min,A,6.4,"['Diane Kruger, ', 'Kiernan Shipka, ', 'Finn Jones, ', 'Gerardo Celasco', '']","A young female assistant who is at the center of a studio filled with manipulators, schemers and intrigue. Little do they know she is poised to outwit them all.","1,589",
Papadag,Drama            ,50 min,,7.6,"['Ellen Parren, ', 'Hassan Slaby, ', 'Guido Pollemans, ', 'Ruben van der Meer', '']",Four fathers meet at the sandbox and decide to spend part of their 'daddy's day' together in the park every week.,224,
Eve's Bayou,Drama            ,108 min,R,7.2,"['Samuel L. Jackson, ', 'Jurnee Smollett, ', 'Meagan Good, ', 'Lynn Whitfield', '']","What did little Eve see--and how will it haunt her? Husband, father and womanizer Louis Batiste is the head of an affluent family, but it's the women who rule this gothic world of secrets, lies and mystic forces.",$14.82M,['Kasi Lemmons']
The Comey Rule,Drama            ,210 min,,7.5,"['Jeff Daniels, ', 'Holly Hunter, ', 'Michael Kelly, ', 'Jennifer Ehle', '']","Jeff Daniels and Brendan Gleeson star as former FBI Dir. James Comey and President Donald J. Trump in this limited series of the story of two powerful men, whose strikingly different ethics and loyalties put them on a collision course.","9,641",
Do Gubbare,Drama            ,,,9.1,"['Siddharth Shaw, ', 'Mohan Agashe, ', 'Ashok Kumar Beniwal, ', 'Hemangi Kavi', '']",Rohit moves from the city of Indore to the metropolis of Pune where he becomes a paying guest at Ajobaas Place.,134,['Varun Narvekar']
A Million Little Pieces,Drama            ,113 min,R,6.2,"['Aaron Taylor-Johnson, ', 'Billy Bob Thornton, ', 'Odessa Young, ', 'Giovanni Ribisi', '']",A drug-dependent young man faces his past and his inner demons after he is interned in an institution for addicted.,"3,829",['Sam Taylor-Johnson']
Cranford,Drama            ,469 min,,8.3,"['Judi Dench, ', 'Imelda Staunton, ', 'Julia McKenzie, ', 'Lisa Dillon', '']","In the 1840s, Cranford is ruled by the ladies. They adore good gossip, and romance and change is in the air, as the unwelcome grasp of the Industrial Revolution rapidly approaches their beloved rural market-town.","10,217",
Dare mo shiranai,Drama            ,141 min,PG-13,8,"['Yûya Yagira, ', 'Ayu Kitaura, ', 'Hiei Kimura, ', 'Momoko Shimizu', '']","In a small Tokyo apartment, twelve-year-old Akira must care for his younger siblings after their mother leaves them and shows no sign of returning.",$0.68M,['Hirokazu Koreeda']
Life as a House,Drama            ,125 min,UA,7.5,"['Hayden Christensen, ', 'Kevin Kline, ', 'Kristin Scott Thomas, ', 'Jena Malone', '']","When a man is diagnosed with terminal cancer, he takes custody of his misanthropic teenage son, for whom quality time means getting high, engaging in small-time prostitution, and avoiding his father.",$15.65M,['Irwin Winkler']
Anchiporuno,Drama            ,76 min,,6.4,"['Ami Tomite, ', 'Mariko Tsutsui, ', 'Fujiko, ', 'Sayaka Kotani', '']",Japan's oldest major movie studio asks a batch of venerable filmmakers to revive its high-brow soft-core Roman Porno series.,"4,630",['Sion Sono']
La disubbidienza,Drama            ,98 min,,5.2,"['Stefania Sandrelli, ', 'Teresa Ann Savoy, ', 'Mario Adorf, ', 'Marie-José Nat', '']","Northern Italy under fascist rule: Luca becomes a partisan, but after the war ends things are not as he had hoped for him and he decides to die. Then he meets women.",277,['Aldo Lado']
Charter,Drama            ,94 min,,6.2,"['Ane Dahl Torp, ', 'Sverrir Gudnason, ', 'Troy Lundkvist, ', 'Tintin Poggats Sarri', '']","After a divorce, Alice hasn't seen her children in two months as she awaits a custody verdict. When her son calls her in the middle of the night, Alice takes action, abducting the children on an illicit charter trip to the Canary Islands.","1,419",['Amanda Kernell']
Litsoneras,Drama            ,105 min,,6.8,"['Yen Durano, ', 'Jamilla Obispo, ', 'VR Relosa, ', 'Joko Diaz', '']",Elria finds out her mother Minerva is having an affair with their worker named Jonas. She plans a dark scheme to break their relationship without knowing she'll be burnt by temptation.,16,['Roman Perez Jr.']
Waiting for the Barbarians,Drama            ,112 min,,5.9,"['Mark Rylance, ', 'Johnny Depp, ', 'Robert Pattinson, ', 'Gana Bayarsaikhan', '']","At an isolated frontier outpost, a colonial magistrate suffers a crisis of conscience when an army colonel arrives looking to interrogate the locals about an impending uprising, using cruel tactics that horrify the magistrate.","13,681",['Ciro Guerra']
Help,Drama            ,98 min,,7.6,"['Jodie Comer, ', 'Stephen Graham, ', 'Lesley Sharp, ', 'Ian Hart', '']","Sarah seems to have found her calling working in a Liverpool care home where she has a special talent for connecting with the residents. Then, in March 2020, the Coronavirus pandemic hits.","11,172",['Marc Munden']
The Glass Room,Drama            ,104 min,,5.5,"['Carice van Houten, ', 'Hanna Alström, ', 'Claes Bang, ', 'Alexandra Borbély', '']","Liesel Landauer and her friend Hana are linked by a lifelong relationship and an exceptional house built by the architect Von Abt for Liesel and her husband Viktor in Czechoslovakia in the ...                See full summary »
",947,['Julius Sevcík']
In-gan-jung-dok,Drama            ,132 min,,6.2,"['Song Seung-heon, ', 'Lim Ji-yeon, ', 'Cho Yeo-jeong, ', 'Joo-Wan On', '']","A secret, passionate affair happens in the summer of 1969 between Colonel Jin Pyeong, trapped in a loveless marriage with Soo Jin, and Jong Ga Heun, the Chinese-Korean wife of Captain Kyung Woo Jin.","2,148",['Dae-woo Kim']
Blue Bayou,Drama            ,117 min,R,7.1,"['Justin Chon, ', 'Alicia Vikander, ', ""Mark O'Brien, "", 'Linh-Dan Pham', '']","As a Korean-American man raised in the Louisiana bayou works hard to make a life for his family, he must confront the ghosts of his past as he discovers that he could be deported from the only country he has ever called home.","9,162",['Justin Chon']
A Mouthful of Air,Drama            ,105 min,R,6,"['Amanda Seyfried, ', 'Olivia Katz, ', 'Christian Kutz, ', 'Finn Wittrock', '']","Julie Davis writes bestselling children's books about unlocking your fears, but has yet to unlock her own. When her daughter is born, that trauma is brought to the fore, and with it, a crushing battle to survive.","2,175",['Amy Koppelman']
As They Made Us,Drama            ,100 min,R,5.8,"['Dustin Hoffman, ', 'Dianna Agron, ', 'Simon Helberg, ', 'Candice Bergen', '']",A divorced mom tries to make peace with her dysfunctional family as she finds a second chance at love.,"1,395",['Mayim Bialik']
Hillside,Drama            ,25 min,,7,"['Laura Harris, ', 'Chris William Martin, ', 'Todd Talbot, ', 'Andrew Baskin', '']","'Fifteen' follows the students of fictional Hillside School and dealt with a variety of issues including dating, divorce, alcohol abuse, and friendship. The show played heavily into ...                See full summary »
",494,
Places in the Heart,Drama            ,111 min,,7.4,"['Sally Field, ', 'Lindsay Crouse, ', 'Ed Harris, ', 'Amy Madigan', '']","In central Texas in the 1930s, a widow with two small children tries to save her small 40-acre farm with the help of a blind boarder and an itinerant black handyman.",$34.90M,['Robert Benton']
SK Sir Ki Class,Drama            ,29 min,Not Rated,8.3,"['Abhilash Thapliyal, ', 'Gagan Arora, ', 'Rajesh Jais, ', 'Venus Singh', '']","It is often said that UPSC is not a race, but a marathon that prepares you for your life. Will Ashish succeed in winning the marathon of his life under the guidance of SK Sir and his lessons of patience, perseverance and dedication?","6,045",
"To Sir, with Love",Drama            ,105 min,U,7.6,"['Sidney Poitier, ', 'Judy Geeson, ', 'Christian Roberts, ', 'Suzy Kendall', '']",Idealistic engineer-trainee and his experiences in teaching a group of rambunctious white high school students from the slums of London's East End.,$42.43M,['James Clavell']
Palo Alto,Drama            ,100 min,R,6.2,"['Emma Roberts, ', 'James Franco, ', 'Jack Kilmer, ', 'Zoe Levin', '']","An unflinching portrait of adolescent lust, boredom, and self-destruction that centers around a shy young girl on the cusp of an illicit relationship with her soccer coach.",$0.75M,['Gia Coppola']
Masaan,Drama            ,109 min,A,8.1,"['Richa Chadha, ', 'Sanjay Mishra, ', 'Vicky Kaushal, ', 'Pankaj Tripathi', '']","Along India's Ganges River, four people face prejudice, a strict moral code and a punishing caste system as they confront personal tragedies.","29,623",['Neeraj Ghaywan']
About Cherry,Drama            ,98 min,R,4.8,"['Ashley Hinshaw, ', 'James Franco, ', 'Heather Graham, ', 'Lili Taylor', '']","A troubled young woman moves to San Francisco, where she becomes involved in pornography and aligns herself with a cocaine-addicted lawyer.",$0.00M,['Stephen Elliott']
The Client List,Drama            ,88 min,,5.6,"['Jennifer Love Hewitt, ', 'Teddy Sears, ', 'Sonja Bennett, ', 'Lynda Boyd', '']","A young woman takes a job at a massage parlor to support her family when her husband is unable to work, and soon finds her life spiraling out of control.","7,766",['Eric Laneuville']
North Country,Drama            ,126 min,7,7.3,"['Charlize Theron, ', 'Jeremy Renner, ', 'Frances McDormand, ', 'Thomas Curtis', '']","A fictionalized account of the first major successful sexual harassment case in the United States, Jenson vs. Eveleth Mines, where a woman who endured a range of abuse while working as a miner filed and won the landmark 1984 lawsuit.",$18.32M,['Niki Caro']
Cruel Intentions 2,Drama            ,87 min,R,4.4,"['Robin Dunne, ', 'Sarah Thompson, ', 'Keri Lynn Pratt, ', 'Amy Adams', '']","This takes place several years before Cruel Intentions (1999), back to when Kathryn first meets Sebastian, their sexual attraction to each other and their enjoyment in destroying the lives of their peers.","15,922",['Roger Kumble']
Outside In,Drama            ,109 min,,6.7,"['Edie Falco, ', 'Jay Duplass, ', 'Louis Hobson, ', 'Alycia Delmore', '']",An ex-con struggling to readjust to life in his small town forms an intense bond with his former high school teacher.,$0.07M,['Lynn Shelton']
Amanda,Drama            ,107 min,,7,"['Vincent Lacoste, ', 'Isaure Multrier, ', 'Stacy Martin, ', 'Ophélia Kolb', '']","After his sister is brutally killed, David finds himself in charge of his 7 year old niece, Amanda.","3,216",['Mikhaël Hers']
On the Edge,Drama            ,85 min,R,6.9,"['Cillian Murphy, ', 'Tricia Vessey, ', 'Martin Carney, ', 'Paul Hickey', '']",On the Edge is about suicidal patients discovering their true selves while going through therapy in a treatment center.,"4,551",['John Carney']
Doctor Cha,Drama            ,60 min,UA,7.5,"['Uhm Junghwa, ', 'Kim Mi-kyung, ', 'Kim Byeong-cheol, ', 'Min Woo-Hyuk', '']","It tells the story of a medical graduate turned housewife but decided to return to the medical field, and a doctor husband who maintains a perfect dual life. He is great at his job and he is also great at cheating on his wife.","1,280",
The Secret Life of Bees,Drama            ,114 min,PG-13,7.2,"['Dakota Fanning, ', 'Jennifer Hudson, ', 'Queen Latifah, ', 'Alicia Keys', '']","In 1964, a teenage girl in search of the truth about her mother runs away to a small town in South Carolina and finds a family of independent women who can connect her to her past.",$37.77M,['Gina Prince-Bythewood']
The Girlfriend Experience,Drama            ,77 min,R,5.5,"['Sasha Grey, ', 'Chris Santos, ', 'Philip Eytan, ', 'Colby Trane', '']","A drama set in the days leading up to the 2008 Presidential election, and centered on a high-end Manhattan call girl meeting the challenges of her boyfriend, her clients, and her work.",$0.70M,['Steven Soderbergh']
Ode to Billy Joe,Drama            ,106 min,,6.5,"['Robby Benson, ', ""Glynnis O'Connor, "", 'Joan Hotchkis, ', 'Sandy McPeak', '']","In 1950s Mississippi, teenager Bobbie Lee Hartley navigates her blossoming hormones as she is courted by Billy Joe McAllister, who is headed for tragedy.","1,989",['Max Baer Jr.']
Come Home,Drama            ,60 min,,6.9,"['Christopher Eccleston, ', 'Paula Malcomson, ', 'Anthony Boyle, ', 'Kerri Quinn', '']","Greg and Marie have been married for nineteen years, when, seemingly out of the blue, Marie walks out on him and her three children - the last taboo of parenting.",789,
The Mustang,Drama            ,96 min,R,6.8,"['Matthias Schoenaerts, ', 'Jason Mitchell, ', 'Bruce Dern, ', 'Gideon Adlon', '']","While participating in a rehabilitation program training wild mustangs, a convict at first struggles to connect with the horses and his fellow inmates, but he learns to confront his violent past as he soothes an especially feisty horse.",$5.04M,['Laure de Clermont-Tonnerre']
Brookside,Drama            ,25 min,,6.6,"['Alexandra Fletcher, ', 'Dean Sullivan, ', 'Paul Byatt, ', 'Claire Sweeney', '']","The everyday life and times of the residents, friends and enemies who live in a suburban street in the city of Liverpool in the north of England.",878,
"Rich Man, Poor Man",Drama            ,566 min,,8.2,"['Peter Strauss, ', 'Nick Nolte, ', 'Susan Blakely, ', 'Dorothy McGuire', '']","An examination of the trials and tribulations of the Jordache family, from the period following World War II to the late 1960s.","3,264",
The Assistant,Drama            ,87 min,R,6.4,"['Julia Garner, ', 'Owen Holland, ', 'Jon Orsini, ', 'Rory Kulz', '']","A searing look at a day in the life of an assistant to a powerful executive. As Jane follows her daily routine, she grows increasingly aware of the insidious abuse that threatens every aspect of her position.","24,393",['Kitty Green']
Sisters,Drama            ,60 min,,7.5,"['Swoosie Kurtz, ', 'Patricia Kalember, ', 'Sela Ward, ', 'Elizabeth Hoffman', '']","Follows the lives and loves of four close, but very different, sisters of the Reed family living in Winnetka, Illinois.","2,193",
Monica,Drama            ,106 min,R,6.2,"['Trace Lysette, ', 'Patricia Clarkson, ', 'Emily Browning, ', 'Joshua Close', '']","The intimate portrait of a woman who returns home to care for her dying mother. A delicate and nuanced story of a fractured family, the story explores universal themes of abandonment, aging, acceptance, and redemption.",724,['Andrea Pallaoro']
On Swift Horses,Drama            ,,,,"['Daisy Edgar-Jones, ', 'Jacob Elordi, ', 'Will Poulter, ', 'Diego Calva', '']","Muriel and her husband Lee who are about to begin a bright new life is upended by arrival of Lee's brother. Muriel embarks a secret life, gambling on racehorses and discovering a love she never thought possible.",,['Daniel Minahan']
Elles,Drama            ,99 min,NC-17,5.6,"['Juliette Binoche, ', 'Anaïs Demoustier, ', 'Joanna Kulig, ', 'Louis-Do de Lencquesaing', '']","On her latest assignment, a journalist for Elle immerses herself in a prostitution ring run by university students.",$0.16M,['Malgorzata Szumowska']
Juste la fin du monde,Drama            ,97 min,,6.8,"['Gaspard Ulliel, ', 'Marion Cotillard, ', 'Léa Seydoux, ', 'Vincent Cassel', '']","Louis (Gaspard Ulliel), a terminally ill writer, returns home after a long absence to tell his family that he is dying.","24,578",['Xavier Dolan']
Leave the World Behind,Drama            ,,R,,"['Julia Roberts, ', 'Ethan Hawke, ', 'Kevin Bacon, ', ""Myha'la Herrold"", '']",Family drama based on the upcoming novel by Rumaan Alam.,,['Sam Esmail']
Safe,Drama            ,119 min,R,7.1,"['Julianne Moore, ', 'Xander Berkeley, ', 'Dean Norris, ', 'Julie Burgess', '']",An affluent and unexceptional homemaker in the suburbs develops multiple chemical sensitivity.,$0.51M,['Todd Haynes']
Looking for Mr. Goodbar,Drama            ,136 min,,6.7,"['Diane Keaton, ', 'Richard Gere, ', 'Tuesday Weld, ', 'William Atherton', '']","A dedicated schoolteacher spends her nights cruising bars, looking for abusive men with whom she can engage in progressively extreme sexual encounters.",$16.90M,['Richard Brooks']
Valor,Drama            ,42 min,,6,"['Christina Ochoa, ', 'Matt Barr, ', 'Charlie Barnett, ', 'Nigel Thatch', '']",A United States Army base serves as home to an elite unit of helicopter pilots trained to perform clandestine international and domestic missions.,"3,336",
The Path,Drama            ,60 min,,7.2,"['Aaron Paul, ', 'Michelle Monaghan, ', 'Emma Greenwell, ', 'Kyle Allen', '']",A man who converts to a controversial following suffers from a crisis of faith.,"9,145",
Wall Street: Money Never Sleeps,Drama            ,133 min,PG-13,6.2,"['Shia LaBeouf, ', 'Michael Douglas, ', 'Carey Mulligan, ', 'Josh Brolin', '']","Now out of prison but still disgraced by his peers, Gordon Gekko works his future son-in-law, an idealistic stock broker, when he sees an opportunity to take down a Wall Street enemy and rebuild his empire.",$52.47M,['Oliver Stone']
Black Narcissus,Drama            ,101 min,,7.7,"['Deborah Kerr, ', 'David Farrar, ', 'Flora Robson, ', 'Jenny Laird', '']","A group of nuns struggle to establish a convent in the Himalayas, while isolation, extreme weather, altitude, and culture clashes all conspire to drive the well-intentioned missionaries mad.","26,415",
À plein temps,Drama            ,88 min,,7.4,"['Laure Calamy, ', 'Anne Suarez, ', 'Geneviève Mnich, ', 'Nolan Arizmendi', '']","Just when Julie finally gets an interview for a job that will let her raise her children better, she runs into a national transit strike.","3,189",['Eric Gravel']
The Burial,Drama            ,126 min,R,,"['Jamie Foxx, ', 'Tommy Lee Jones, ', 'Bill Camp, ', 'Alan Ruck', '']","Inspired by true events, a lawyer helps a funeral home owner save his family business from a corporate behemoth, exposing a complex web of race, power, and injustice.",,['Maggie Betts']
Sátántangó,Drama            ,439 min,,8.2,"['Mihály Vig, ', 'Putyi Horváth, ', 'László feLugossy, ', 'Éva Almássy Albert', '']","On the eve of a large payment, residents of a collapsing collective farm see their plans turn into desolation when they discover that Irimiás, a former co-worker who they thought was dead, is returning to the community.","11,985",['Béla Tarr']
Twirl,Drama            ,59 min,,6.4,"['Bev Adams, ', 'Jennifer Aileen, ', 'Jill Anton, ', 'Bill Blont', '']",Some are addicted to drugs - Some Food - Some their career But then others are addicted to SEX.,10,['Joey Harlow']
Ragtime,Drama            ,155 min,,7.3,"['James Cagney, ', 'Elizabeth McGovern, ', 'Howard E. Rollins Jr., ', 'Brad Dourif', '']","A young black pianist becomes embroiled in the lives of an upper-class white family set among the racial tensions, infidelity, violence and other nostalgic events in early 1900s New York City.",$21.02M,['Milos Forman']
Juniper,Drama            ,94 min,,6.5,"['Charlotte Rampling, ', 'Marton Csokas, ', 'George Ferrier, ', 'Edith Poor', '']","When a self-destructive teenager is suspended from school and asked to look after his feisty alcoholic grandmother as a punishment, the crazy time they spend together turns his life around.","1,429",['Matthew J. Saville']
"Oslo, 31. august",Drama            ,95 min,,7.6,"['Anders Danielsen Lie, ', 'Hans Olav Brenner, ', 'Ingrid Olava, ', 'Malin Crépin', '']","One day in the life of Anders, a young recovering drug addict, who takes a brief leave from his treatment center to interview for a job and catch up with old friends in Oslo.",$0.10M,['Joachim Trier']
Dickensian,Drama            ,60 min,,7.6,"['Tuppence Middleton, ', 'Sophie Rundle, ', 'Alexandra Moen, ', 'Joseph Quinn', '']","Drama set within the fictional realms of Charles Dickens critically acclaimed novels, bringing together some of his most iconic characters as their lives intertwine in 19th century London.","3,753",
Sweetbitter,Drama            ,29 min,,7,"['Ella Purnell, ', 'Tom Sturridge, ', 'Evan Jonigkeit, ', 'Eden Epstein', '']",A young woman learns how crazy it is to work in a restaurant.,"4,777",
Kyss mig,Drama            ,105 min,,6.8,"['Ruth Vega Fernandez, ', 'Liv Mjönes, ', 'Krister Henriksson, ', 'Lena Endre', '']",A young woman engaged to be married finds herself in an affair with her soon-to-be stepmother's lesbian daughter.,"11,558",['Alexandra-Therese Keining']
Seven Veils,Drama            ,107 min,,,"['Amanda Seyfried, ', 'Douglas Smith, ', 'Rebecca Liddiard, ', 'Maia Jae Bastidas', '']","An earnest theater director has the task of remounting her former mentor's most famous work, the opera Salome. Some disturbing memories from her past will allow her repressed trauma to color the present.",,['Atom Egoyan']
The Unknown Country,Drama            ,85 min,,7.8,"['Lily Gladstone, ', 'Raymond Lee, ', 'Richard Ray Whitman, ', 'Lainey Bearkiller Shangreaux', '']",An unexpected invitation rushes a grieving young woman into a lonely road trip through the American Midwest towards the border between Texas and Mexico.,69,['Morrisa Maltz']
Baby the Rain Must Fall,Drama            ,100 min,,6.3,"['Lee Remick, ', 'Steve McQueen, ', 'Don Murray, ', 'Paul Fix', '']","In Texas, a woman and her young daughter head down to another town where the girl's irresponsible, hotheaded and immature father has just been released from prison on parole.","1,870",['Robert Mulligan']
Amanda,Drama            ,93 min,,6.6,"['Benedetta Porcaroli, ', 'Galatéa Bellugi, ', 'Giovanna Mezzogiorno, ', 'Michele Bravi', '']","Amanda, 24, lives mostly isolated and has never had any friends, even if it's the thing she wants the most. Amanda chooses as her new mission to convince her childhood friend that they are still best friends.",350,['Carolina Cavalli']
Birth of a MURDERER,Drama            ,87 min,,,"['Michael Bundy II, ', 'Emmy Robinson', '']","Birth of a MURDERER: A Black male college student falls haplessly in love with a white coed and discovers she isn't how she appears. Slowly but surely, he begins to unravel and the result is both shocking and perplexing.",,['Darian Lane']
Allelujah,Drama            ,99 min,,6,"['Jesse Akele, ', 'Louis Ashbourne Serkis, ', 'Lorraine Ashbourne, ', 'Jessica Baglow', '']",The story of a geriatric ward in a small Yorkshire hospital threatened with closure.,"1,008",['Richard Eyre']
All the World Is Sleeping,Drama            ,110 min,,5.3,"['Melissa Barrera, ', 'Jackie Cruz, ', 'Kristen Gutoskie, ', 'Luis Bordonada', '']","Fighting for her own life and the ones she loves, a Mother in New Mexico sinks deeper in her addiction while struggling to surface for her daughter.",202,['Ryan Lacen']
The Cobweb,Drama            ,134 min,,6.3,"['Richard Widmark, ', 'Lauren Bacall, ', 'Charles Boyer, ', 'Gloria Grahame', '']","At a private psychiatric clinic, the daily dramas and interactions between the doctors, nurses, administrators, benefactors and patients are accentuated by the personal and family crises of these individuals.","1,986",['Vincente Minnelli']
The Kite Runner,Drama            ,128 min,PG-13,7.6,"['Khalid Abdalla, ', 'Ahmad Khan Mahmoodzada, ', 'Atossa Leoni, ', 'Shaun Toub', '']","After spending years in California, Amir returns to his homeland in Afghanistan to help his old friend Hassan, whose son is in trouble.",$15.80M,['Marc Forster']
Mary Kills People,Drama            ,44 min,,7.5,"['Caroline Dhavernas, ', 'Jay Ryan, ', 'Richard Short, ', 'August Winter', '']","Single mother Mary Harris is an ER doctor by day, but by night she and her partner, a former plastic surgeon, moonlight as underground angels of death who help terminally ill patients slip away on their own terms.","4,487",
Minamata,Drama            ,115 min,R,7.2,"['Akiko Iwase, ', 'Kogarashi Wakasugi, ', 'Johnny Depp, ', 'Katherine Jenkins', '']",War photographer W. Eugene Smith travels back to Japan where he documents the devastating effect of mercury poisoning in coastal communities.,"21,892",['Andrew Levitas']
Marvellous,Drama            ,90 min,,7.8,"['Toby Jones, ', 'Gemma Jones, ', 'Tony Curran, ', 'Nicholas Gleaves', '']","The life of Neil Baldwin, a man who has shrugged off his perceived limitations to live an incredible life.","6,375",['Julian Farino']
AlRawabi School for Girls,Drama            ,291 min,UA 16+,7.3,"['Rakeen Saad, ', 'Noor Taher, ', 'Joanna Arida, ', 'Andria Tayeh', '']",The bullied outcasts at prestigious Al Rawabi School for Girls plot a series of risky takedowns to get back at their tormentors.,"6,681",
Falling,Drama            ,112 min,Not Rated,6.5,"['Viggo Mortensen, ', 'Lance Henriksen, ', 'Laura Linney, ', 'Terry Chen', '']","John Peterson lives with his partner Eric and their adopted daughter in Southern California. When he is visited by his aging father who is searching for a place to retire, their two very different worlds collide.","6,597",['Viggo Mortensen']
Peak Practice,Drama            ,50 min,,6.4,"['Gary Mavers, ', 'Simon Shepherd, ', 'Esther Coles, ', 'Margery Mason', '']",Beth Glover and Will Preston are doctors in partnership at a Derbyshire clinic when they hire Jack who's returned from Africa. The next several years deal with their personal and professional lives with Jack and Beth marrying.,470,
"The Long, Hot Summer",Drama            ,115 min,,7.3,"['Paul Newman, ', 'Joanne Woodward, ', 'Anthony Franciosa, ', 'Orson Welles', '']","Accused barn burner and conman Ben Quick arrives in a small Mississippi town and quickly ingratiates himself with its richest family, the Varners.","11,805",['Martin Ritt']
The Oval,Drama            ,60 min,,4.4,"['Ed Quinn, ', 'Kron Moore, ', 'Ptosha Storey, ', 'Vaughn W. Hebron', '']",Newly-elected U.S. President Hunter Franklin and his family move into the White House.,"1,648",
The New Pope,Drama            ,60 min,,8.1,"['Jude Law, ', 'John Malkovich, ', 'Silvio Orlando, ', 'Cécile de France', '']",Two Popes. Only one Vatican. A holy war to come.,"17,615",
Here,Drama            ,,,,"['Kelly Reilly, ', 'Tom Hanks, ', 'Robin Wright, ', 'Jonathan Aris', '']","Set in one single room, follows the many people who inhabit it over years and years, from the past to the future.",,['Robert Zemeckis']
Cake,Drama            ,102 min,R,6.4,"['Jennifer Aniston, ', 'Adriana Barraza, ', 'Anna Kendrick, ', 'Sam Worthington', '']","The acerbic, hilarious Claire Bennett becomes fascinated by the suicide of a woman in her chronic pain support group. As she uncovers the details of Nina's suicide and develops a poignant relationship with Nina's husband, she also grapples with her own, very raw personal tragedy.",$1.87M,['Daniel Barnz']
Sanglyusahoe,Drama            ,120 min,18,5.6,"['Park Hae-il, ', 'Soo Ae, ', 'Kim Gyu-Sun, ', 'Lee Jin-Wook', '']","A deputy curator of a chaebol-funded art gallery and her husband, a politically ambitious economics professor, will do anything to join the über-elite.","1,179",['Hyuk Byun']
Imitation of Life,Drama            ,125 min,,7.8,"['Lana Turner, ', 'John Gavin, ', 'Sandra Dee, ', 'Susan Kohner', '']",An aspiring white actress takes in an African American widow whose mixed-race daughter is desperate to be seen as white.,$13.99M,['Douglas Sirk']
"They Shoot Horses, Don't They?",Drama            ,129 min,A,7.8,"['Jane Fonda, ', 'Michael Sarrazin, ', 'Susannah York, ', 'Gig Young', '']",The lives of a disparate group of contestants intertwine in an inhumanely grueling dance marathon.,$12.60M,['Sydney Pollack']
RFDS,Drama            ,,,7.9,"['Emma Hamilton, ', 'Rob Collins, ', 'Stephen Peacocke, ', 'Justine Clarke', '']",RFDS is an Australian drama television series which centres around the lives of workers for the Royal Flying Doctor Service of Australia.,936,
The Visitor,Drama            ,104 min,PG-13,7.6,"['Richard Jenkins, ', 'Haaz Sleiman, ', 'Danai Gurira, ', 'Hiam Abbass', '']",A college professor travels to New York City to attend a conference and finds a young couple living in his apartment.,$9.42M,['Tom McCarthy']
White Oleander,Drama            ,109 min,UA,7.1,"['Michelle Pfeiffer, ', 'Renée Zellweger, ', 'Robin Wright, ', 'Alison Lohman', '']",A teenager journeys through a series of foster homes after her mother goes to prison for committing a crime of passion.,$16.35M,['Peter Kosminsky']
Titanic: Blood and Steel,Drama            ,55 min,,7.2,"['Kevin Zegers, ', 'Alessandra Mastronardi, ', 'Derek Jacobi, ', 'Billy Carter', '']","The construction of the R.M.S. Titanic at the Harland and Wolff shipyard in Belfast against the background of union riots, political and religious conflicts, and a romance between a young ambitious engineer and an Italian immigrant.","2,091",
The Old Oak,Drama            ,113 min,,7.3,"['Trevor Fox, ', 'Debbie Honeywood, ', 'Laura Lee Daly, ', 'Neil Leiper', '']","The future for the last remaining pub, The Old Oak in a village of the Northeast England, where people are leaving the land as the mines are closed. Houses are cheap and available thus making it an ideal location for the Syrian refugees.",86,['Ken Loach']
The Idea of You,Drama            ,,,,"['Anne Hathaway, ', 'Nicholas Galitzine, ', 'Reid Scott, ', 'Perry Mattfeld', '']","Solène Marchand (Anne Hathaway), a 40-year-old single mother, begins an unexpected romance with 24-year-old Hayes Campbell (Nicholas Galitzine), the lead singer of the hottest boy band on the planet, August Moon.",,['Michael Showalter']
Camdaki Kiz,Drama            ,120 min,Not Rated,5.5,"['Burcu Biricik, ', 'Selma Ergeç, ', 'Feyyaz Serifoglu, ', 'Enis Arikan', '']","Nalan is a beautiful young woman who earns everyone's love at first sight with her warmth. As the only child of the family enlarged hand baby, baby roses, lived in the existence of life and...                See full summary »
","1,329",
Saint Omer,Drama            ,122 min,PG-13,6.9,"['Kayije Kagame, ', 'Guslagie Malanda, ', 'Valérie Dréville, ', 'Aurélia Petit', '']","Follows Rama, a novelist who attends the trial of Laurence Coly at the Saint-Omer Criminal Court to use her story to write a modern-day adaptation of the ancient myth of Medea, but things don't go as expected.","3,474",['Alice Diop']
Los pacientes del doctor García,Drama            ,60 min,A,6.8,"['Javier Rey, ', 'Tamar Novas, ', 'Verónica Echegui, ', 'Eva Llorach', '']","Doctor Guillermo Garcia and Manuel Arroyo, a Republican diplomat infiltrate a clandestine network that helps Nazis settle in Spain and Latin America.",666,
The Toy Soldiers,Drama            ,143 min,R,5.4,"['Najarra Townsend, ', 'Constance Brenneman, ', 'Chandler Rylko, ', 'Jeanette May Steiner', '']","On one evening in a decade of sex, drugs and rock 'n' roll, the innocence of youth and family unravels. Five lives will change forever on this final evening before their hangout, The Toy Soldiers Roller Rink, closes its doors.","1,570",['Erik Peter Carlson']
Rare Objects,Drama            ,123 min,R,5.2,"['Julia Mayorga, ', 'Katie Holmes, ', 'Saundra Santiago, ', 'Candy Buckley', '']","""Rare Objects"" tells the story of a young woman who seeks to rebuild her life when she takes work at an antique store. She regains her confidence from the kind souls who own the shop, until those from her traumatic past begin to resurface.",209,['Katie Holmes']
Everything Must Go,Drama            ,97 min,R,6.4,"['Will Ferrell, ', 'Rebecca Hall, ', 'Christopher Jordan Wallace, ', 'Michael Peña', '']","When an alcoholic relapses, causing him to lose his wife and his job, he holds a yard sale on his front lawn in an attempt to start over. A new neighbor might be the key to his return to form.",$2.71M,['Dan Rush']
Mass,Drama            ,111 min,PG-13,7.6,"['Jason Isaacs, ', 'Martha Plimpton, ', 'Ann Dowd, ', 'Reed Birney', '']",The parents of both the shooter and one of the victims of a school shooting tragedy agree to meet and talk in an attempt to move forward.,"16,353",['Fran Kranz']
The Night of the Iguana,Drama            ,125 min,,7.6,"['Richard Burton, ', 'Ava Gardner, ', 'Deborah Kerr, ', 'Sue Lyon', '']",An ostracized Episcopal clergyman leads a busload of middle-aged Baptist women on a tour of the Mexican coast and comes to terms with the failure haunting his life.,$9.43M,['John Huston']
Promised Land,Drama            ,106 min,R,6.6,"['Matt Damon, ', 'Frances McDormand, ', 'John Krasinski, ', 'Hal Holbrook', '']","A salesman for a natural gas company experiences life-changing events after arriving in a small town, where his corporation wants to tap into the available resources.",$7.60M,['Gus Van Sant']
Cigare au miel,Drama            ,100 min,,6.1,"['Zoé Adjani, ', 'Amira Casar, ', 'Lyès Salem, ', 'Louis Peres', '']","Selma, 17, who lives in a bourgeois and secular Berber family. When she meets Julien in college, she realizes for the first time the impact of patriarchal rules on her intimacy.",642,['Kamir Aïnouz']
Sublime,Drama            ,100 min,,6.4,"['Martín Miller, ', 'Teo Inama Chiabrando, ', 'Azul Mazzeo, ', 'Joaquín Arana', '']","Manuel lives in a small coastal town. He plays bass in a band with his best friends. One of them is Felipe, with whom he shares a strong friendship. Unbreakable bond. Until the time comes to put it to test.",704,['Mariano Biasin']
Shtisel,Drama            ,45 min,13,8.6,"[""Doval'e Glickman, "", 'Michael Aloni, ', 'Neta Riskin, ', 'Shira Haas', '']","A Haredi family living in an ultra-Orthodox neighborhood of Jerusalem reckons with love, loss and the doldrums of daily life.","7,842",
The Romanoffs,Drama            ,60 min,16,7,"['Diane Lane, ', 'JJ Feild, ', 'Aaron Eckhart, ', 'Louise Bourgoin', '']",Anthology of eight stories about people who believe themselves to be descendant of the Russian Royal family.,"6,204",
X/Y,Drama            ,82 min,,4.2,"['Ryan Piers Williams, ', 'America Ferrera, ', 'Jon Paul Phillips, ', 'David Harbour', '']",A look at the lives and interactions of a group of friends living in New York.,682,['Ryan Piers Williams']
Marseille,Drama            ,41 min,18,6.9,"['Gérard Depardieu, ', 'Benoît Magimel, ', 'Géraldine Pailhas, ', 'Stéphane Caillard', '']","A tale of power, corruption and redemption set against the rich backdrop of the French port city of Marseille.","5,441",
Zalim Istanbul,Drama            ,120 min,18,5.7,"['Fikret Kuskan, ', 'Deniz Ugur, ', 'Ozan Dolunay, ', 'Sera Kutlubey', '']","Seher starts working at Agah Bey's house with her children. Curious love triangles form between the children of the two families, and the terrible secrets in the mansion begin to be revealed.","1,109",
Rivals,Drama            ,,,,"['David Tennant, ', 'Aidan Turner, ', 'Katherine Parkinson, ', 'Danny Dyer', '']",It follows Rupert Campbell-Black and Tony Baddingham as they have a longstanding rivalry that comes to a head.,,
The Company Men,Drama            ,104 min,R,6.7,"['Ben Affleck, ', 'Chris Cooper, ', 'Tommy Lee Jones, ', 'Suzanne Rico', '']","The story centers on a year in the life of three men trying to survive a round of corporate downsizing at a major company - and how that affects them, their families, and their communities.",$4.44M,['John Wells']
Berdreymi,Drama            ,123 min,,7.5,"['Birgir Dagur Bjarkason, ', 'Áskell Einar Pálmason, ', 'Viktor Benóný Benediktsson, ', 'Snorri Rafn Frímannsson', '']","Addi, a gifted boy raised by a clairvoyant mother, decides to adopt a bullied misfit into his gang of outsiders. Left to their own devices, the boys discover aggression, violence, loyalty, and love.","1,744",['Guðmundur Arnar Guðmundsson']
Marvin's Room,Drama            ,98 min,U,6.7,"['Meryl Streep, ', 'Leonardo DiCaprio, ', 'Diane Keaton, ', 'Robert De Niro', '']","After seventeen years, a fiercely independent woman and her rebellious son return home and together they turn the family she left behind upside down.",$12.78M,['Jerry Zaks']
Tori et Lokita,Drama            ,88 min,,7.1,"['Pablo Schils, ', 'Joely Mbundu, ', 'Alban Ukaj, ', 'Tijmen Govaerts', '']","From two-time Palme d'Or-winners Jean-Pierre and Luc Dardenne, Tori and Lokita is a heart-stopping thriller that casts an unflinching eye on the trials of the young and dispossessed.","2,189",
To Die For,Drama            ,100 min,,4,"['John Schneider, ', 'Cody McCarver, ', 'Quinton Aaron, ', 'Becky Andrews', '']",What can one man do to fight the intentional decay of the greatest country the world has ever known?,291,['John Schneider']
Kis Uykusu,Drama            ,196 min,,8.1,"['Haluk Bilginer, ', 'Melisa Sözen, ', 'Demet Akbag, ', 'Ayberk Pekcan', '']",A hotel owner and landlord in a remote Turkish village deals with conflicts within his family and a tenant behind on his rent.,$0.17M,['Nuri Bilge Ceylan']
Satisfaction,Drama            ,60 min,,7.3,"['Kestie Morassi, ', 'Madeleine West, ', 'Alison Whyte, ', 'Diana Glenn', '']","Set in a high-class brothel, this new series creates a hyper-reality in which the viewer is privy to the private lives and emotions of five beautiful young women.","1,429",
"Trapper John, M.D.",Drama            ,60 min,,6.6,"['Pernell Roberts, ', 'Brian Stokes Mitchell, ', 'Charles Siebert, ', 'Gregory Harrison', '']",The Korean War M*A*S*H unit veteran operates as Chief Surgeon in a major city hospital with his colleagues.,"2,115",
Ondskan,Drama            ,113 min,,7.7,"['Andreas Wilson, ', 'Henrik Lundström, ', 'Gustaf Skarsgård, ', 'Linda Zilliacus', '']","A teenage boy expelled from school for fighting arrives at a boarding school where the systematic bullying of younger students is encouraged as a means to maintain discipline, and decides to fight back.",$0.02M,['Mikael Håfström']
Nell,Drama            ,112 min,PG-13,6.5,"['Jodie Foster, ', 'Liam Neeson, ', 'Natasha Richardson, ', 'Richard Libertini', '']","In a remote woodland cabin, a small-town doctor discovers Nell - a beautiful young hermit-woman with many secrets.",$33.68M,['Michael Apted']
Si lo hubiera sabido,Drama            ,35 min,UA 16+,6.2,"['Salva Reina, ', 'Megan Montaner, ', 'Miquel Fernández, ', 'Irina Bravo', '']","Follow the story of a 30-year-old woman who, when feeling dissatisfied with her marriage and family life, finds herself sent back in time 10 years following a lunar eclipse.","1,236",
Import Export,Drama            ,141 min,,7,"['Ekateryna Rak, ', 'Lidiya Oleksandrivna Savka, ', 'Oksana Ivanivna Sklyarenko, ', 'Dmytro Andriyovich Gachkov', '']","A nurse from Ukraine searches for a better life in the West, while an unemployed security guard from Austria heads East for the same reason.","6,115",['Ulrich Seidl']
Blackbird,Drama            ,97 min,R,6.6,"['Sam Neill, ', 'Susan Sarandon, ', 'Anson Boon, ', 'Kate Winslet', '']",A terminally ill mother arranges to bring her family together one last time before she dies. A remake of the 2014 Danish film 'Silent Heart'.,"5,423",['Roger Michell']
The Heart Is Deceitful Above All Things,Drama            ,98 min,Not Rated,6.3,"['Asia Argento, ', 'Dylan Sprouse, ', 'Cole Sprouse, ', 'Jimmy Bennett', '']","Seven-year-old Jeremiah is pulled from his foster home and thrown into a troubled life on the road with his teenage mother, Sarah.",$0.03M,['Asia Argento']
A Family Man,Drama            ,108 min,R,6.5,"['Gerard Butler, ', 'Gretchen Mol, ', 'Alison Brie, ', 'Anupam Kher', '']","A headhunter whose life revolves around closing deals in a survival-of-the-fittest boiler room battles his top rival for control of their job placement company, but his dream of owning the company clashes with the needs of his family.","12,971",['Mark Williams']
Expecting Amish,Drama            ,88 min,,6.1,"['AJ Michalka, ', 'Jesse McCartney, ', 'Alyson Stoner, ', 'Cayden Boyd', '']","Expecting Amish on Lifetime tells the story of 18-year-old Hannah Yoder, who is ready to join the Amish Church and marry her boyfriend Samuel. But things change when she goes to Hollywood and gets a glimpse of the world beyond.",804,['Richard Gabai']
If I Can't,Drama            ,,,5.2,"['Mena Monroe, ', 'Tristin Fazekas, ', 'Crystal The Doll, ', 'Tonja Brown', '']","It tells the story of woman, who's in search for love after a tragedy and finds it in the hands of an abuser.",190,['Mena Monroe']
Dalva,Drama            ,83 min,,7.7,"['Zelda Samson, ', 'Alexis Manenti, ', 'Fanta Guirassy, ', 'Marie Denarnaud', '']","Dalva is 12, but she dresses and lives like a woman. One day, she's taken away from her house. Dumbfounded at first, she later meets Jayden, a social worker, and Samia, a teen with a temper. A new life seems to start for Dalva.",692,['Emmanuelle Nicot']
The Ballad of Jack and Rose,Drama            ,112 min,R,6.5,"['Daniel Day-Lewis, ', 'Catherine Keener, ', 'Camilla Belle, ', 'Ryan McDonald', '']",A father and daughter isolated on an island off the East Coast and living on a once-thriving commune grapple with the limits of family and sexuality.,$0.71M,['Rebecca Miller']
Vanity Fair,Drama            ,60 min,,7.3,"['Michael Palin, ', 'Olivia Cooke, ', 'Tom Bateman, ', 'Johnny Flynn', '']",An adaptation of the 1848 novel by William Makepeace Thackeray.,"5,399",
Ask Me Anything,Drama            ,100 min,,6,"['Britt Robertson, ', 'Molly Hagan, ', 'Andy Buckley, ', 'Robert Patrick', '']","A confused teenager writes a blog revealing her daily activities and secrets, advised to do so by her high school guidance counselor in lieu of moving on to her first year in college.","12,748",['Allison Burnett']
Skymed,Drama            ,44 min,16,6.4,"['Natasha Calis, ', 'Morgan Holmstrom, ', 'Praneet Akilla, ', 'Aason Nadjiwon', '']","Follows intense character journeys and high-stakes medical rescues, heartbreaks and tribulations of budding nurses and pilots flying air ambulances.","1,114",
The Boys in the Band,Drama            ,121 min,18,6.8,"['Jim Parsons, ', 'Zachary Quinto, ', 'Matt Bomer, ', 'Andrew Rannells', '']","At a birthday party in 1968 New York, a surprise guest and a drunken game leave seven gay friends reckoning with unspoken feelings and buried truths.","17,001",['Joe Mantello']
The Colour Room,Drama            ,108 min,,6.8,"['Phoebe Dynevor, ', 'Matthew Goode, ', 'Kerry Fox, ', 'Darci Shaw', '']",Clarice Cliff breaks the glass ceiling and revolutionizes the workplace at a pottery factory in 1920s England.,"1,407",['Claire McCarthy']
Piccoli fuochi,Drama            ,95 min,,5.6,"['Dino Jaksic, ', 'Valeria Golino, ', 'Carlotta Wittig, ', 'Mario Garriba', '']","Little boy Tommaso has several imaginary friends who like to play cruel pranks on the staff in his house. When new maid Mara arrives, Tommaso bonds with her, but his jealous imaginary friends devise the cruelest prank yet for her.",319,['Peter Del Monte']
The Sweet East,Drama            ,104 min,,7.2,"['Talia Ryder, ', 'Earl Cave, ', 'Simon Rex, ', 'Ayo Edebiri', '']","A picaresque journey through the cities and woods of the Eastern seaboard of the U.S undertaken by Lillian, a high school senior from South Carolina. She gets her first glimpse of the wider world on a class trip to Washington, D.C.",62,['Sean Price Williams']
Silk,Drama            ,60 min,,8,"['Maxine Peake, ', 'Rupert Penry-Jones, ', 'Neil Stuke, ', 'Theo Barklem-Biggs', '']","Drama series about life at the Bar, the dilemmas and problems that modern day barristers have to face, and what it means to become a silk.","5,349",
Skate Kitchen,Drama            ,106 min,R,6.8,"['Rachelle Vinberg, ', 'Dede Lovelace, ', 'Nina Moran, ', 'Kabrina Adams', '']",A teenaged skateboarder makes friends with a bunch of other skateboarding girls in New York City.,$0.24M,['Crystal Moselle']
Yukinojô henge,Drama            ,115 min,,7.4,"['Kazuo Hasegawa, ', 'Fujiko Yamamoto, ', 'Ayako Wakao, ', 'Eiji Funakoshi', '']","Yukinojo, a Kabuki actor, seeks revenge by destroying the three men who caused the deaths of his parents. Also involved are the daughter of one of Yukinojo's targets, two master thieves, and a swordsman who himself is out to kill Yukinojo.","2,687",['Kon Ichikawa']
Lifeguard,Drama            ,96 min,,6.6,"['Sam Elliott, ', 'Anne Archer, ', 'Stephen Young, ', 'Parker Stevenson', '']","Rick, still in his 30's, works full-time as a lifeguard on the beaches of Los Angeles. When he meets his divorced high school girlfriend and her five-year-old son after fifteen years, he considers switching to a more ""serious"" job.","1,714",['Daniel Petrie']
Village,Drama            ,120 min,,5.8,"['Arata Furuta, ', 'Wataru Ichinose, ', 'Hana Kino, ', 'Haru Kuroki', '']","Yu Katayama is a young man who lives in the remote but beautiful village Kamonmura. He has lived there since he was a child and is unable to leave due to an incident in his past. To pay off...                See full summary »
",547,['Michihito Fujii']
Two-Lane Blacktop,Drama            ,102 min,,7.2,"['James Taylor, ', 'Warren Oates, ', 'Laurie Bird, ', 'Dennis Wilson', '']","While drag-racing through the American Southwest in a Chevvy 150, a driver and his mechanic cross paths with an alluring hitchhiker and the inexperienced, tall tale-spinning driver of a GTO.","13,060",['Monte Hellman']
Le jeu avec le feu,Drama            ,112 min,,5.8,"['Jean-Louis Trintignant, ', 'Philippe Noiret, ', 'Anicée Alvina, ', 'Sylvia Kristel', '']","A man whose girl is threatened to be kidnapped sends her for protection with a private detective. He takes her to a mansion, where many kidnapped girls waiting to be ransomed are drugged and subjugated to all kinds of sexual depravities.",580,['Alain Robbe-Grillet']
Carne trémula,Drama            ,103 min,R,7.3,"['Liberto Rabal, ', 'Francesca Neri, ', 'Javier Bardem, ', 'Ángela Molina', '']","After leaving jail, Víctor is still in love with Elena, but she's married to the former cop -now basketball player- who became paralysed by a shot from Víctor's gun...",$1.54M,['Pedro Almodóvar']
The Integrity of Joseph Chambers,Drama            ,96 min,,5.7,"['Clayne Crawford, ', 'Jordana Brewster, ', 'Michael Raymond-James, ', 'Carl Kennedy', '']","A family man, hoping to prove his survivalist capabilities and manliness to his family, decides to irresponsibly head off into the woods and go deer hunting by himself.",664,['Robert Machoian']
Full Circle,Drama            ,30 min,,6,"['Christopher Gorham, ', 'Aaron Haedt, ', 'David Crane, ', 'Dougray Scott', '']",Follows a group of adults whose lives are unknowingly intertwined.,229,
Piccole labbra,Drama            ,86 min,,5.3,"['Pierre Clémenti, ', 'Katya Berger, ', 'Ugo Bologna, ', 'Michele Soavi', '']","A writer returns home from World War I. He has developed a very bad case of post traumatic stress disorder. He contemplates suicide, but becomes interested in the 12 year old niece of the innkeeper at the place where he is recuperating.",837,['Mimmo Cattarinich']
Full Body Massage,Drama            ,93 min,R,5.5,"['Mimi Rogers, ', 'Bryan Brown, ', 'Christopher Burgard, ', 'Elizabeth Barondes', '']","A successful but world-weary art dealer finds out that her usual masseur has sent a substitute for her regular weekly massage at her home. They find that they are both mutually attracted, and annoy one another a great deal.","1,550",['Nicolas Roeg']
Starlet,Drama            ,103 min,,6.9,"['Dree Hemingway, ', 'Besedka Johnson, ', 'Boonee, ', 'Stella Maeve', '']",An unlikely friendship forms between twenty-one-year-old Jane and the elderly Sadie after Jane discovers a hidden stash of money inside an object at Sadie's yard sale.,$0.09M,['Sean Baker']
The Hour,Drama            ,60 min,,8,"['Romola Garai, ', 'Ben Whishaw, ', 'Dominic West, ', 'Anna Chancellor', '']","A behind-the-scenes drama and espionage thriller in Cold War-era England that centers on a journalist, a producer, and an anchorman for an investigative news programme.","10,736",
L'acrobate,Drama            ,134 min,,6,"['Sébastien Ricard, ', 'Yury Paulau, ', 'Victor Fomine, ', 'Lise Roy', '']","Montreal is snowed under. While the downtown cranes dance their hypnotic ballet, two strangers meet randomly in an unfinished apartment. Their chance encounter leads to a violent attraction and a dependency beyond reason.",803,['Rodrigue Jean']
Passing,Drama            ,98 min,16,6.7,"['Tessa Thompson, ', 'Ruth Negga, ', 'André Holland, ', 'Bill Camp', '']","""Passing"" follows the unexpected reunion of two high school friends, whose renewed acquaintance ignites a mutual obsession that threatens both of their carefully constructed realities.","15,825",['Rebecca Hall']
The Good Lawyer,Drama            ,,,,"['Kennedy McMann, ', 'Felicity Huffman', '']","Joni, a woman in her 20's, struggles with OCD while becoming a brilliant attorney.",,
Wild at Heart,Drama            ,47 min,,7.4,"['Stephen Tompkinson, ', 'Deon Stewardson, ', 'Nomsa Xaba, ', 'Thapelo Mokoena', '']",The story of an English family who moves to the South African bush to set up and run a game reserve.,"1,634",
Divine Secrets of the Ya-Ya Sisterhood,Drama            ,116 min,A,6.1,"['Sandra Bullock, ', 'Ellen Burstyn, ', 'Fionnula Flanagan, ', 'James Garner', '']","After years of mother-daughter tension, Siddalee receives a scrapbook detailing the wild adventures of the ""Ya-Yas"", her mother's girlhood friends.",$69.60M,['Callie Khouri']
Where the Heart Is,Drama            ,50 min,,6.7,"['Lesley Dunlop, ', 'Christian Cooke, ', 'Philip Middlemiss, ', 'William Travis', '']","A warm hearted drama series that follows the lives of the people of Skelthwate, and their local health center.",511,
Viskningar och rop,Drama            ,91 min,A,8,"['Harriet Andersson, ', 'Liv Ullmann, ', 'Kari Sylwan, ', 'Ingrid Thulin', '']","When a woman dying of cancer in early twentieth-century Sweden is visited by her two sisters, long-repressed feelings between the siblings rise to the surface.",$1.74M,['Ingmar Bergman']
Ben Is Back,Drama            ,103 min,UA,6.7,"['Julia Roberts, ', 'Lucas Hedges, ', 'Courtney B. Vance, ', 'Kathryn Newton', '']",A drug addicted teenage boy shows up unexpectedly at his family's home on Christmas Eve.,$3.70M,['Peter Hedges']
Tyrannosaur,Drama            ,92 min,,7.5,"['Peter Mullan, ', 'Archie Lal, ', 'Jag Sanghera, ', 'Mike Fearnley', '']","Joseph, a man plagued by violence and a rage that is driving him to self-destruction, earns a chance of redemption that appears in the form of Hannah, a Christian charity shop worker.",$0.02M,['Paddy Considine']
The Bookshop,Drama            ,113 min,PG,6.5,"['Emily Mortimer, ', 'Bill Nighy, ', 'Hunter Tremayne, ', 'Honor Kneafsey', '']","England 1959. In a small East Anglian town, Florence Green decides, against polite but ruthless local opposition, to open a bookshop.",$1.33M,['Isabel Coixet']
Jugar con Fuego,Drama            ,43 min,18,5.9,"['Jason Day, ', 'Margarita Rosa de Francisco, ', 'Carlos Ponce, ', 'Laura Perico', '']","Three prosperous women, including a mother and her daughter, fall for a seductive man in Colombia's Coffee Triangle.","1,103",
Ruthless,Drama            ,45 min,,4.8,"['Melissa L Williams, ', 'Baadja-Lyne Odums, ', 'Matt Cedeño, ', 'Lenny Thomas', '']","This spinoff of ""The Oval"" follows Ruth Truesdale as she is forced to play nice with a scandalous, religious cult of powerful, sex-crazed fanatics in the hope of freeing herself and her daughter.",907,
Nine Seconds,Drama            ,,,8.6,"['Gavin Casalegno, ', 'Shaun Peter Cunningham, ', 'Jamie Dugger', '']","While preparing for the USATF National Youth Championships, a high school runner and track coach struggle to come to terms with an irrecoverable loss.",21,['Jared Cline']
Summit Fever,Drama            ,115 min,R,5.1,"['Ryan Phillippe, ', 'Hannah New, ', 'Freddie Thorp, ', 'Mathilde Warnier', '']","A daring dream to scale the world's most challenging trio of mountains soon turns into a terrifying nightmare for a group of friends when a deadly storm traps the climbers near the summit ...                See full summary »
","1,540",['Julian Gilbey']
Mustang,Drama            ,97 min,PG-13,7.6,"['Günes Sensoy, ', 'Doga Zeynep Doguslu, ', 'Tugba Sunguroglu, ', 'Elit Iscan', '']","When five orphan girls are seen innocently playing with boys on a beach, their scandalized conservative guardians confine them while forced marriages are arranged.",$0.85M,['Deniz Gamze Ergüven']
The Magic of Ordinary Days,Drama            ,98 min,,7.5,"['Keri Russell, ', 'Skeet Ulrich, ', 'Mare Winningham, ', 'Tania Gunadi', '']","Pregnant out of wedlock, an educated young woman is pressured by her father into an arranged marriage with a lonely farmer in this drama set during WWII.","5,467",['Brent Shields']
Alice,Drama            ,100 min,R,5.5,"['Keke Palmer, ', 'Common, ', 'Jonny Lee Miller, ', 'Gaius Charles', '']",A slave in the antebellum South escapes her secluded plantation only to discover a shocking reality that lies beyond the tree line.,"2,792",['Krystin Ver Linden']
Upstairs Downstairs,Drama            ,60 min,,7.4,"['Keeley Hawes, ', 'Ed Stoppard, ', 'Adrian Scarborough, ', 'Neil Jackson', '']",A new family and their servants live at the London townhouse at 165 Eaton Place in 1936.,"6,579",
The Wife,Drama            ,99 min,UA,7.2,"['Glenn Close, ', 'Jonathan Pryce, ', 'Max Irons, ', 'Christian Slater', '']",A wife questions her life choices as she travels to Stockholm to see her husband receive the Nobel Prize for Literature.,$9.60M,['Björn Runge']
Insta Millionaire (Pocket FM) Hindi,Drama            ,,,7.5,"['Riddhi Kotecha, ', 'Aakash Abhang, ', 'Ratish Mangalam', '']","A Humble and Sweet boy, Laxman aka Lucky becomes a Billionaire the same night his Heart is Broken into pieces by his Girlfriend for being so Poor. His account gets Credited with all the Family's Wealth and it's now up to him how to use it","2,597",
Summerland,Drama            ,60 min,,6.8,"['Lori Loughlin, ', 'Merrin Dungey, ', 'Ryan Kwanten, ', 'Jesse McCartney', '']","Bradin, Nikki and Derrick are 3 kids from an average normal Kansas household. Their whole life is thrown upside-down when their parents are tragically killed in a car accident.","3,948",
Mending the Line,Drama            ,122 min,R,6.6,"['Brian Cox, ', 'Perry Mattfeld, ', 'Sinqua Walls, ', 'Patricia Heaton', '']",A Marine wounded in Afghanistan is sent to a V.A. facility in Montana where he meets a Vietnam Vet who teaches him how to fly fish as a way of dealing with his emotional and physical trauma.,209,['Joshua Caldwell']
Swingers Sex Party,Drama            ,87 min,,4.3,"['Jack Ketchmark, ', 'Christine Nguyen, ', 'Katrina Isis, ', 'Frank Mercuri', '']","Five friends at a gathering to celebrate the upcoming marriage of two of them discuss sex, marriage and infidelity.",220,['J.W. McHausen']
Jungleland,Drama            ,90 min,R,6.2,"['Charlie Hunnam, ', ""Jack O'Connell, "", 'Naheem Garcia, ', 'Fran Kranz', '']",Two brothers try to escape their circumstances by travelling across the country for a no holds barred boxing match that becomes a fight for their lives.,"6,997",['Max Winkler']
A Love Song for Bobby Long,Drama            ,119 min,R,7.1,"['Scarlett Johansson, ', 'John Travolta, ', 'Gabriel Macht, ', 'Deborah Kara Unger', '']",A headstrong young woman returns to New Orleans after the death of her estranged mother.,$0.16M,['Shainee Gabel']
De nærmeste,Drama            ,106 min,,5.6,"['Ine Marie Wilmann, ', 'Simon J. Berger, ', 'Anneke von der Lippe, ', 'Silje Storstein', '']",Two half-siblings who grew up apart meet for the first time as adults and fall in love.,"1,653",['Anne Sewitsky']
Shelter,Drama            ,105 min,,6.5,"['Adolfo Mendez-Nouel, ', 'Anthony Mackie, ', 'Kevin Arnold Hoffman, ', 'Teddy Cañez', '']","Hannah and Tahir fall in love while homeless on the streets of New York. Shelter explores how they got there, and as we learn about their pasts we realize they need each other to build a future.","5,191",['Paul Bettany']
Bisyo!,Drama            ,89 min,,3.2,"['Gold Azeron, ', 'Aerol Carmelo, ', 'Mark Anthony Fernandez, ', 'Angelica Hart', '']",James wants his way out of a syndicate and dreams to start his own business. But his dreams turn to nightmare because getting out of the group will never be easy.,9,['Daniel Palacio']
Pamasahe,Drama            ,104 min,,6.2,"['Azi Acosta, ', 'Mark Anthony Fernandez, ', 'Felix Roco, ', 'Shiena Yu', '']","A penniless mother, with her infant child, takes on a journey by land and sea to find her husband in Manila. But this trip won't be free for she has to use her body to get to her destination.",785,['Roman Perez Jr.']
Days of Wine and Roses,Drama            ,117 min,A,7.8,"['Jack Lemmon, ', 'Lee Remick, ', 'Charles Bickford, ', 'Jack Klugman', '']","An alcoholic marries a young woman and systematically addicts her to booze so that they can share his ""passion"" together.","13,570",['Blake Edwards']
Whore,Drama            ,85 min,NC-17,5.6,"['Theresa Russell, ', 'Benjamin Mouton, ', 'Antonio Fargas, ', 'Elizabeth Morehead', '']",A night in the life of a cynical prostitute forms the basis of Ken Russell's portrait of the world's oldest profession.,$1.01M,['Ken Russell']
The Flying Doctors,Drama            ,50 min,,6.7,"['Lenore Smith, ', 'Maurie Fields, ', 'Robert Grubb, ', 'Val Jellay', '']","This series chronicles the events surrounding the activities of the Royal Flying Doctors Service, which operates its own aircraft--in this case from the base at Coopers Crossing, an ...                See full summary »
",985,
M.A.S.H.,Drama            ,,,4.8,"['Sabrina Perez, ', 'Amaris Davidson, ', 'Charles Porter, ', 'Scott Hislop', '']","Four sisters navigate very different lives as they experience trials that test their faith, hope and love.",37,
La Vénus à la fourrure,Drama            ,96 min,,7.1,"['Emmanuelle Seigner, ', 'Mathieu Amalric', '']",An actress attempts to convince a director how she's perfect for a role in his upcoming production.,$0.34M,['Roman Polanski']
Meel patthar,Drama            ,98 min,13,6.6,"['Mohinder Gujral, ', 'Pavitra Mattoo, ', 'Lakshvir Saran, ', 'Suvinder Vicky', '']","Recently marking 500,000 kilometers on the road, a newly bereaved trucker faces the threat of losing the job that has come to define him to a new intern.",730,['Ivan Ayr']
You Can Count on Me,Drama            ,111 min,Not Rated,7.5,"['Laura Linney, ', 'Matthew Broderick, ', 'Amy Ryan, ', 'Michael Countryman', '']","A single mother's life is thrown into turmoil after her struggling, rarely seen younger brother returns to town.",$9.18M,['Kenneth Lonergan']
Flesh and Bone,Drama            ,60 min,,7.8,"['Sarah Hay, ', 'Ben Daniels, ', 'Emily Tyra, ', 'Irina Dvorovenko', '']",A talented but emotionally troubled dancer runs away to New York City and quickly finds herself immersed in the cutthroat world of professional ballet.,"11,055",
Dertigers,Drama            ,24 min,,7.8,"['Wieger Windhorst, ', 'Joy Wielkens, ', 'Justus van Dillen, ', 'Lykele Muus', '']","Eight Dutch college friends, now in their thirties, navigate life, love and a shared trauma.",302,
Kumonosu-jô,Drama            ,110 min,U,8.1,"['Toshirô Mifune, ', 'Minoru Chiaki, ', 'Isuzu Yamada, ', 'Takashi Shimura', '']","A war-hardened general, egged on by his ambitious wife, works to fulfill a prophecy that he would become lord of Spider's Web Castle.","54,192",['Akira Kurosawa']
Last Exit to Brooklyn,Drama            ,102 min,,6.8,"['Jennifer Jason Leigh, ', 'Stephen Lang, ', 'Burt Young, ', 'Peter Dobson', '']",Set in Brooklyn during the 1950s against a backdrop of union corruption and violence. A prostitute falls in love with one of her customers. Also a disturbed man discovers that he is homosexual.,$1.73M,['Uli Edel']
The Billionaire's Accidental Bride,Drama            ,,,,"['Alicia Blasingame, ', 'Jared Rider, ', 'Jay Kiman', '']","Eric needs to get married in 20 minutes, but his bride is no where seen. Emma is stood up at the alter. When these two cross paths, desperation will kick in.",,['Collier Landry']
God's Country Song,Drama            ,,,5.6,"['Justin Gaston, ', 'Christopher Michael, ', 'Justene Alpert, ', 'Mariel Hemingway', '']","Noah Bryan wants nothing more than to be the next big country music star, until his past catches up to him. With the help of his seasoned manager Larry Walker, Noah is quickly on his way to...                See full summary »
",52,['Johnny Remo']
Zabriskie Point,Drama            ,113 min,A,6.9,"['Mark Frechette, ', 'Daria Halprin, ', 'Paul Fix, ', 'G.D. Spradlin', '']","At a time of chronic civil unrest in late 1960s America, a young idealist and an anthropology student cross paths at Zabriskie Point in Death Valley, California. They start an unrestrained relationship by making love on the dusty terrain.",$1.05M,['Michelangelo Antonioni']
The Man Without a Face,Drama            ,115 min,UA,6.7,"['Mel Gibson, ', 'Nick Stahl, ', 'Margaret Whitton, ', 'Fay Masterson', '']",Chuck wants to leave home but can't make the grade for boarding school. Then he finds out the disfigured recluse living nearby is an ex-teacher.,$24.76M,['Mel Gibson']
Mutt,Drama            ,87 min,,6.9,"['Lio Mehiel, ', 'Cole Doman, ', 'MiMi Ryder, ', 'Alejandro Goic', '']","Within the space of 24 hours, Feña is swept through the extremes of human emotion when people who seemed to disappear when he transitioned are suddenly back in his life.",175,['Vuk Lungulov-Klotz']
Babettes gæstebud,Drama            ,103 min,,7.8,"['Stéphane Audran, ', 'Bodil Kjer, ', 'Birgitte Federspiel, ', 'Jarl Kulle', '']","During the late 19th century, a strict religious community in a Danish village takes in a French refugee from the Franco-Prussian War as a servant to the late pastor's daughters.",$4.40M,['Gabriel Axel']
Swingtown,Drama            ,,,7.6,"['Molly Parker, ', 'Jack Davenport, ', 'Grant Show, ', 'Lana Parrilla', '']","As America celebrates its 200th birthday, two generations of friends and neighbors in a Chicago suburb explore new freedoms and seek connections with each other in the midst of the socio/sexual revolution.","2,808",
Une vraie jeune fille,Drama            ,93 min,,5.3,"['Charlotte Alexandra, ', 'Hiram Keller, ', 'Rita Maiden, ', 'Bruno Balp', '']","Reluctantly, a sulky adolescent returns to her parents' house for yet another boring summer vacation, dabbling in desire and the art of desirability, eventually mixing reality with vision, caged fantasies with the fierce female sexuality.",$0.00M,['Catherine Breillat']
Friend of the Family,Drama            ,103 min,R,4.5,"[""Shauna O'Brien, "", 'Griffin Drew, ', 'Burke Morgan, ', 'Lisa Boyle', '']","A mysterious, but kind-hearted, drifter tries to help a wealthy, but dysfunctional, Malibu family with their personal and romantic problems between them.","1,022",['Edward Holzman']
"First Comes Love, Then Comes Murder",Drama            ,,,8.2,"['Guyviaud Joseph, ', 'Marissa Bennett, ', 'Leslie Black, ', 'Faith Bogle', '']","A devoted wife evades death when the man, her manipulative husband hires to kill her, has a change of heart.",14,['Bobby Yan']
Vanity Fair,Drama            ,141 min,PG-13,6.2,"['Reese Witherspoon, ', 'Romola Garai, ', 'James Purefoy, ', 'Jonathan Rhys Meyers', '']","Growing up poor in London, Becky Sharp defies her poverty-stricken background and ascends the social ladder alongside her best friend, Amelia Sedley.",$16.14M,['Mira Nair']
It Is in Us All,Drama            ,92 min,,5.4,"['Cosmo Jarvis, ', 'Rhys Mannion, ', 'Claes Bang, ', 'Antonia Campbell-Hughes', '']","A formidable man who cares for nothing is forced to confront his self-destructive core when a violent car crash involving a sexually charged boy who epitomizes life, challenges him to face his truth.",343,['Antonia Campbell-Hughes']
Une belle course,Drama            ,91 min,,6.9,"['Line Renaud, ', 'Dany Boon, ', 'Alice Isaaz, ', 'Jérémie Laheurte', '']","Madeleine, leaves small suburban to join a nursing home, on the other side of Paris. Charles, a taxi driver, comes to pick her and in no hurry to reach, she asks him to go through places of the capital, which have counted in her life.",928,['Christian Carion']
Sorry We Missed You,Drama            ,101 min,,7.6,"['Kris Hitchen, ', 'Debbie Honeywood, ', 'Rhys Mcgowan, ', 'Katie Proctor', '']","Hoping that self-employment through gig economy can solve their financial woes, a hard-up UK delivery driver and his wife struggling to raise a family end up trapped in the vicious circle of this modern-day form of labour exploitation.","24,106",['Ken Loach']
Howards' Way,Drama            ,50 min,,6.7,"['Jan Harvey, ', 'Stephen Yardley, ', 'Glyn Owen, ', 'Susan Gilmore', '']","Tom Howard is made redundant from his job as a senior aircraft designer and decides to invest his skill, time and redundancy money in a run-down local boat-building yard. The decision puts a great strain on his marriage.",259,
Blondi,Drama            ,87 min,,6.9,"['Dolores Fonzi, ', 'Carla Peterson, ', 'Rita Cortese, ', 'Toto Rovito', '']","The misadventures of a woman who was a teenage mother, while her son seeks to build a future for himself.",573,['Dolores Fonzi']
Il deserto rosso,Drama            ,117 min,,7.5,"['Monica Vitti, ', 'Richard Harris, ', 'Carlo Chionetti, ', 'Xenia Valderi', '']","In an industrial area, unstable Giuliana attempts to cope with life by starting an affair with a co-worker at the plant her husband manages.","16,858",['Michelangelo Antonioni']
Okuribito,Drama            ,130 min,PG-13,8,"['Masahiro Motoki, ', 'Ryôko Hirosue, ', 'Tsutomu Yamazaki, ', 'Kazuko Yoshiyuki', '']",A newly unemployed cellist takes a job preparing the dead for funerals.,$1.50M,['Yôjirô Takita']
Temptation: Confessions of a Marriage Counselor,Drama            ,111 min,PG-13,4.9,"['Jurnee Smollett, ', 'Vanessa Williams, ', 'Brandy Norwood, ', 'Kim Kardashian', '']","An ambitious married woman's temptation by a handsome billionaire leads to betrayal, recklessness, and forever alters the course of her life.",$51.98M,['Tyler Perry']
Postcards from London,Drama            ,90 min,,5.2,"['Harris Dickinson, ', 'Jonah Hauer-King, ', 'Alessandro Cimadamore, ', 'Leonardo Salerni', '']","A stylish, sexy film about a young man's journey into an unusual form of escort work, set in an imaginary vision of London's Soho.",$0.01M,['Steve McLean']
The Beaver,Drama            ,91 min,PG-13,6.6,"['Mel Gibson, ', 'Jodie Foster, ', 'Anton Yelchin, ', 'Cherry Jones', '']",A troubled husband and executive adopts a beaver hand-puppet as his sole means of communication.,$0.97M,['Jodie Foster']
The Newsreader,Drama            ,313 min,,7.7,"['Anna Torv, ', 'Sam Reid, ', 'William McInnes, ', 'Michelle Lim Davidson', '']",The Newsreader provides an insight into the smoky Australian newsrooms of the 1980s and the people who brought us our nightly news.,"2,559",
Vixen!,Drama            ,70 min,,5.6,"['Erica Gavin, ', 'Garth Pillsbury, ', 'Harrison Page, ', 'Jon Evans', '']","A naive bush pilot flies tourists to the wilderness of NW Canada while his nympho wife gets lonely - or does she? A Mountie, a married couple and her biker brother drop by while hubby's away.",$6.00M,['Russ Meyer']
Miracle in East Texas,Drama            ,100 min,PG,1.9,"['John Ratzenberger, ', 'Kevin Sorbo, ', 'Louis Gossett Jr., ', 'Tyler Mane', '']",Two con men try to convince a group of widows to invest in worthless oil wells during the Great Depression.,201,['Kevin Sorbo']
Rosario Tijeras,Drama            ,,,7.8,"['Valeria Gomez, ', 'Nando Monge, ', 'María Fernanda Yepes, ', 'Sebastian Martínez', '']",A legendary story tells of a beautiful woman from a poor neighborhood and her love affairs with two best friends who come from wealthy families.,402,
Great Expectations,Drama            ,60 min,,7.5,"['Douglas Booth, ', 'Jack Roth, ', 'Ray Winstone, ', 'David Suchet', '']",The orphan Pip becomes a gentleman when his life is transformed by a mystery benefactor.,"8,041",
The Nun's Story,Drama            ,149 min,U,7.5,"['Audrey Hepburn, ', 'Peter Finch, ', 'Edith Evans, ', 'Peggy Ashcroft', '']","After leaving a wealthy Belgian family to become a nun, Sister Luke struggles with her devotion to her vows during crisis, disappointment, and World War II.",$12.80M,['Fred Zinnemann']
Le notti di Cabiria,Drama            ,110 min,,8.1,"['Giulietta Masina, ', 'François Périer, ', 'Franca Marzi, ', 'Dorian Gray', '']",A waifish prostitute wanders the streets of Rome looking for true love but finds only heartbreak.,$0.75M,['Federico Fellini']
I Call First,Drama            ,90 min,,6.6,"['Harvey Keitel, ', 'Zina Bethune, ', 'Anne Collette, ', 'Lennard Kuras', '']",A young man can't accept the girl he likes because of her bitter past.,"9,601",['Martin Scorsese']
Bodies,Drama            ,60 min,,8.4,"['Tamzin Malleson, ', 'Max Beesley, ', 'Keith Allen, ', 'Patrick Baladi', '']","A young registrar, Rob Lake starts work under established gynecologist Roger Hurley whom he finds to be an affable man. All is not as it first appears, however, and Lake soon develops grave misgivings about his boss and his methods.","1,406",
Jungfrukällan,Drama            ,89 min,A,8.1,"['Max von Sydow, ', 'Birgitta Valberg, ', 'Gunnel Lindblom, ', 'Birgitta Pettersson', '']","In 14th-century Sweden, an innocent yet pampered teenage girl and her family's pregnant and jealous servant set out from their farm to deliver candles to church, but only one returns from events that transpire in the woods along the way.",$1.53M,['Ingmar Bergman']
Found,Drama            ,,,,"['Shanola Hampton, ', 'Azaria Carter, ', 'Bill Kelly, ', 'Sterling Jones', '']","Each year, over 600,000 people are reported missing in the U.S., but not all cases receive the proper attention. Gabi Mosely and her crisis management team make sure there is always someone looking out for the forgotten missing people.",,
House of Cards,Drama            ,226 min,,8.5,"['Ian Richardson, ', 'Susannah Harker, ', 'Miles Anderson, ', 'Alphonsia Emmanuel', '']",The schemes of a ruthlessly ambitious British politician who will stop at nothing to get to the top.,"14,783",
A Mother's Intuition,Drama            ,,,6.7,"['Denise Boutte, ', 'Tamar Braxton, ', 'Rachelle Carson-Begley, ', 'Matt Cedeño', '']",It tells the story of a sculptor and an investigator. They try to find her missing newborn and uncover a dark and fatal secret.,15,['Cas Sigers-Beedles']
The Outrun,Drama            ,,,,"['Saoirse Ronan, ', 'Paapa Essiedu, ', 'Stephen Dillane, ', 'Nabil Elouahabi', '']","Rona, fresh out of rehab, returns to the wild Orkney Islands after more than a decade away. As she reconnects with the dramatic landscape where she grew up, memories of her childhood merge ...                See full summary »
",,['Nora Fingscheidt']
Conviction,Drama            ,42 min,,7.1,"['Hayley Atwell, ', 'Eddie Cahill, ', 'Shawn Ashmore, ', 'Merrin Dungey', '']",A brilliant attorney and former First Daughter is blackmailed to heading a unit that investigates cases of wrongful conviction.,"7,573",
Les fruits de la passion,Drama            ,83 min,R,5.4,"['Klaus Kinski, ', 'Isabelle Illiers, ', 'Arielle Dombasle, ', 'Pîtâ', '']","A girl loves an older man. He demands that she goes in a brothel, as evidence that she loves him.","1,565",['Shûji Terayama']
"Signed, Sealed, Delivered: Home Again",Drama            ,87 min,,7.7,"['Eric Mabius, ', 'Kristin Booth, ', 'Yan-Kay Crystal Lowe, ', 'Geoff Gustafson', '']",The Postables discover a vase with a letter inside and must find the vase's owner. The vase's origin is suspicious and the Postables will have to decide whether to do what is right or what is legal.,972,['Kevin Fair']
Ghahreman,Drama            ,127 min,U,7.5,"['Amir Jadidi, ', 'Mohsen Tanabandeh, ', 'Sahar Goldoost, ', 'Fereshteh Sadre Orafaiy', '']","Rahim is in prison because of a debt he was unable to repay. During a two-day leave, he tries to convince his creditor to withdraw his complaint against the payment of part of the sum. But things don't go as planned.","27,649",['Asghar Farhadi']
Alba,Drama            ,50 min,A,6.4,"['Elena Rivera, ', 'Eric Masip, ', 'Álvaro Rico, ', 'Pol Hermoso', '']",A chain of events is kickstarted when a young girl is gang-raped by four boys.,"1,815",
O Fantasma,Drama            ,87 min,,5.7,"['Ricardo Meneses, ', 'Beatriz Torcato, ', 'Andre Barbosa, ', 'Eurico Vieira', '']","Young and handsome Sergio works the night shift as a trash collector in Lisbon, Portugal. He can't force himself to connect with his pretty female co-worker Fatima, who displays an avid ...                See full summary »
",$0.13M,['João Pedro Rodrigues']
Manderlay,Drama            ,139 min,,7.2,"['Bryce Dallas Howard, ', 'Isaach De Bankolé, ', 'Danny Glover, ', 'Willem Dafoe', '']","A story of slavery, set in the southern U.S. in the 1930s.",$0.08M,['Lars von Trier']
Take Me to the River,Drama            ,84 min,,6.2,"['Logan Miller, ', 'Robin Weigert, ', 'Josh Hamilton, ', 'Richard Schiff', '']",A Californian teenager's plan to come out at his Nebraskan family reunion gets derailed when a bloodstain on his young cousin's dress makes him the unwitting suspect of abuse.,"2,629",['Matt Sobel']
Gandu,Drama            ,85 min,(Banned),5.5,"['Anubrata Basu, ', 'Joyraj Bhattacharya, ', 'Rituparna Sen, ', 'Kamalika Banerjee', '']","After Nihilistic rapper Gandu steals from his mother's lover, he embarks on a drug-fueled rampage with a rickshaw puller in this abstract film.","2,647",['Qaushiq Mukherjee']
The Great Santini,Drama            ,115 min,PG,7.2,"['Robert Duvall, ', 'Blythe Danner, ', ""Michael O'Keefe, "", 'Lisa Jane Persky', '']","As he approaches manhood, Ben Meechum struggles to win the approval of his demanding alpha male father, an aggressively competitive, but frustrated Marine pilot.","6,752",['Lewis John Carlino']
Choir Girl,Drama            ,95 min,,4.1,"['Peter Flaherty, ', 'Krista Vendy, ', 'Jack Campbell, ', 'Sarah Timm', '']","Eugene, a lonely photographer, becomes fixated on a young street prostitute, Josephine, in his rundown neighborhood. She becomes his muse and his photographs could be a way out for both of them - yet is Eugene saving Josephine or is he using her?",134,['John Fraser']
Land Man,Drama            ,,,,"['Billy Bob Thornton, ', 'Michelle Randolph, ', 'Jacob Lofland', '']","Set in the proverbial boomtowns of West Texas, Land Man is a modern day tale of fortune seeking in the world of oil rigs. The series is an upstairs/downstairs story of roughnecks and ...                See full summary »
",,
The Teacher,Drama            ,60 min,,5.8,"['Sheridan Smith, ', 'Samuel Bottomley, ', 'Cecilia Noble, ', 'David Fleeshman', '']",An emotionally troubled teacher's life begins to fall apart as she faces accusations of sleeping with a student.,"2,365",
Good Sam,Drama            ,43 min,Not Rated,6,"['Sophia Bush, ', 'Jason Isaacs, ', 'Skye P. Marshall, ', 'Michael Stahl-David', '']",Follows a talented yet stifled surgeon who embraces her leadership role after her renowned and pompous boss falls into a coma.,"2,442",
In America,Drama            ,105 min,PG-13,7.7,"['Paddy Considine, ', 'Samantha Morton, ', 'Djimon Hounsou, ', 'Sarah Bolger', '']",A family of Irish immigrants adjust to life on the mean streets of Hell's Kitchen while also grieving the death of a child.,$15.54M,['Jim Sheridan']
Giant Little Ones,Drama            ,93 min,R,7.2,"['Josh Wiggins, ', 'Darren Mann, ', 'Taylor Hickson, ', 'Maria Bello', '']","Two popular teen boys, best friends since childhood, discover their lives, families, and girlfriends dramatically upended after an unexpected incident occurs on the night of a 17th birthday party.",$0.18M,['Keith Behrman']
Never Rarely Sometimes Always,Drama            ,101 min,PG-13,7.4,"['Sidney Flanigan, ', 'Talia Ryder, ', 'Théodore Pellerin, ', 'Eliazar Jimenez', '']",A pair of teenage girls in rural Pennsylvania travel to New York City to seek out medical help after an unintended pregnancy.,"30,075",['Eliza Hittman']
Moving On,Drama            ,45 min,,7.5,"['Neil Bell, ', 'Alicia Brockenbrow, ', 'John Draycott, ', 'Olivia Fenton', '']","Series of daytime plays set in contemporary Britain, all sharing the theme of someone going through some kind of life change.",486,
The Astronaut Wives Club,Drama            ,42 min,,7.3,"['JoAnna Garcia Swisher, ', 'Yvonne Strahovski, ', 'Dominique McElligott, ', 'Odette Annable', '']","Based on Lily Koppel's best-selling titular novel, which tells the real story of the women who stood beside some of the biggest heroes in American history during the height of the space race.","3,315",
Bastard Out of Carolina,Drama            ,98 min,Not Rated,7.3,"['Jennifer Jason Leigh, ', 'Ron Eldard, ', 'Glenne Headly, ', 'Lyle Lovett', '']",A mother and daughter find their lives adversely affected when a new man enters the picture. Will their family ever be what they expect?,"4,679",['Anjelica Huston']
One True Thing,Drama            ,127 min,U,6.9,"['Meryl Streep, ', 'Renée Zellweger, ', 'William Hurt, ', 'Tom Everett Scott', '']",A career woman reassesses her parents' lives after she is forced to care for her cancer-stricken mother.,$23.25M,['Carl Franklin']
La vita bugiarda degli adulti,Drama            ,50 min,A,6.4,"['Valeria Golino, ', 'Veronica Powers, ', 'Alessandro Preziosi, ', 'Giordana Marengo', '']","A girl in search of her true reflection in a divided Naples: the Naples of the heights, which assumes a mask of refinement, and the Naples of the depths, a place of excess and vulgarity.","1,432",
Ba jiao long zhong,Drama            ,117 min,,6.7,"['Baoqiang Wang, ', 'Yongsheng Chen, ', 'Andrew Derry, ', 'Max Grandi', '']",A former boxing champion takes decides to break a few rules and train orphans from China's remote countryside in order to give them a future.,143,['Baoqiang Wang']
"Madrid, 1987",Drama            ,105 min,,6.2,"['José Sacristán, ', 'María Valverde, ', 'Ramon Fontserè, ', 'Alberto Ferreiro', '']","Two characters: old and young; teacher and pupil; man and woman. Four walls within which they conjure intellectualism, relive the profession (journalism), explore politics and discover each other.","2,155",['David Trueba']
Gülcemal,Drama            ,124 min,,7.2,"['Murat Ünalmis, ', 'Melis Sezen, ', 'Edip Tepeli, ', 'Nilay Erdönmez', '']",Abandoned by his mother as a boy. A man years later vows to get revenge on the mom and her new family all while unknowingly falling in love with her adopted daughter.,"1,080",
Crossroads,Drama            ,30 min,,4.3,"['Noele Gordon, ', 'Roger Tonge, ', 'Susan Hanson, ', 'Anthony Morton', '']","The four-or-five-times-a-week adventures of a motel owner and her son, daughter and staff. Drama was never far away from the ringing of the reception bell.",396,
Fremont,Drama            ,91 min,,7.1,"['Anaita Wali Zada, ', 'Jeremy Allen White, ', 'Gregg Turkington, ', 'Hilda Schmelling', '']",Follow the woman who served as a translator for US troops in Afghanistan,132,['Babak Jalali']
The Last Black Man in San Francisco,Drama            ,121 min,16,7.3,"['Jimmie Fails, ', 'Jonathan Majors, ', 'Rob Morgan, ', 'Tichina Arnold', '']",A young man searches for home in the changing city that seems to have left him behind.,$4.52M,['Joe Talbot']
The Woodsman,Drama            ,87 min,R,7.2,"['Kevin Bacon, ', 'Kyra Sedgwick, ', 'Yasiin Bey, ', 'David Alan Grier', '']",A child molester returns to his hometown after 12 years in prison and attempts to start a new life.,$0.04M,['Nicole Kassell']
London's Burning,Drama            ,50 min,,7,"['Glen Murphy, ', 'Richard Walsh, ', 'Ben Onwukwe, ', 'Shirley Greenwood', '']",The lives of firefighters at Blackwall Fire Station.,885,
Kardeslerim,Drama            ,120 min,Not Rated,6,"['Celil Nalçakan, ', 'Cüneyt Mete, ', 'Fadik Sevin Atasoy, ', 'Ahu Yagtu', '']",4 siblings have to struggle with life after their parents' death.,"1,759",
The Slap,Drama            ,42 min,,6.2,"['Brian Cox, ', 'Melissa George, ', 'Lucas Hedges, ', 'Marin Ireland', '']",A once happy family suddenly begins to fall apart following a seemingly minor incident in which a man slaps another couple's misbehaving child.,"3,680",
Eureka,Drama            ,140 min,,6,"['Viggo Mortensen, ', 'Chiara Mastroianni, ', 'Viilbjørk Malling Agger, ', 'Rafi Pitts', '']",Murphy searches for his daughter after she is kidnapped by the outlaw Randall.,44,['Lisandro Alonso']
For Colored Girls,Drama            ,134 min,R,6.2,"['Janet Jackson, ', 'Anika Noni Rose, ', 'Whoopi Goldberg, ', 'Kimberly Elise', '']","Each of the women portray one of the characters represented in the collection of twenty poems, revealing different issues that impact women in general and women of color in particular.",$37.72M,['Tyler Perry']
Nurses,Drama            ,44 min,,6.1,"['Tiera Skovbye, ', 'Natasha Calis, ', 'Jordan Johnson-Hinds, ', 'Sandy Sidhu', '']","The series follows five young nurses working on the front lines of St. Mary's Hospital dedicating their lives to helping others, while figuring out how to help themselves.","2,186",
Ida,Drama            ,82 min,PG-13,7.4,"['Agata Kulesza, ', 'Agata Trzebuchowska, ', 'Dawid Ogrodnik, ', 'Jerzy Trela', '']",A novice nun about to take her vows uncovers a family secret dating back to the German occupation.,$3.83M,['Pawel Pawlikowski']
Tomboy,Drama            ,82 min,,7.4,"['Zoé Héran, ', 'Malonn Lévana, ', 'Jeanne Disson, ', 'Sophie Cattani', '']","A family moves into a new neighborhood, and a 10-year-old named Laure deliberately presents as a boy named Mikhael to the neighborhood children.",$0.13M,['Céline Sciamma']
The Emperor's Club,Drama            ,109 min,PG-13,6.9,"['Kevin Kline, ', 'Emile Hirsch, ', 'Joel Gretsch, ', 'Embeth Davidtz', '']",An idealistic prep school teacher attempts to redeem an incorrigible student.,$14.06M,['Michael Hoffman']
The Angry Silence,Drama            ,95 min,,7.2,"['Richard Attenborough, ', 'Pier Angeli, ', 'Michael Craig, ', 'Bernard Lee', '']",A young factory worker decides to stand up against his workmates and fellow union members when they want to hold a wildcat strike.,"1,615",['Guy Green']
En la cama,Drama            ,85 min,,6.2,"['Blanca Lewin, ', 'Gonzalo Valenzuela', '']","A young man and woman have a sensual, one-night stand in a motel room where they confide in each other about their troubled lives.","3,441",['Matías Bize']
The United States of Leland,Drama            ,108 min,R,7,"['Ryan Gosling, ', 'Don Cheadle, ', 'Kevin Spacey, ', 'Chris Klein', '']",A young man's experience in a juvenile detention center that touches on the tumultuous changes that befall his family and the community in which he lives.,$0.34M,['Matthew Ryan Hoge']
Blackout,Drama            ,,,7.6,"['Rami Malek, ', 'Chloe Brooks, ', 'Seychelle Gabriel, ', 'T.C. Carter', '']","Academy Award® winner Rami Malek stars in this apocalyptic thriller as a small-town radio DJ fighting to protect his family and community after the power grid goes down nationwide, upending...                See full summary »
",271,
The Sunset Limited,Drama            ,91 min,,7.3,"['Samuel L. Jackson, ', 'Tommy Lee Jones', '']","Through a chance encounter, two men of opposing ideologies deliberate spiritual, philosophical, and profound matters in a New York City apartment.","31,064",['Tommy Lee Jones']
The God Committee,Drama            ,98 min,,5.8,"['Kelsey Grammer, ', 'Julia Stiles, ', 'Colman Domingo, ', 'Janeane Garofalo', '']","An organ transplant committee has one hour to decide which of three patients deserves a life-saving heart. Seven years later, the committee members struggle with the consequences of that fateful decision.","4,405",['Austin Stark']
Cruel Intentions,Drama            ,45 min,,7.2,"['Nathalie Kelley, ', 'Sarah Michelle Gellar, ', 'Anne Winters, ', 'Peter Gallagher', '']","Fifteen years after the death of her brother, villainous Kathryn Merteuil seeks to manipulate her nephew, Bash, and gain control of the family business Valmont International.",510,['Roger Kumble']
David Copperfield,Drama            ,185 min,,7.7,"['Daniel Radcliffe, ', 'Trevor Eve, ', 'Pauline Quirke, ', 'Laura Harling', '']",A gentle orphan discovers life and love in an indifferent adult world.,"4,843",
Baisers cachés,Drama            ,87 min,,7.3,"['Patrick Timsit, ', 'Barbara Schulz, ', 'Bruno Putzulu, ', 'Bérenger Anceaux', '']","Nathan goes to a high school party and meets Louis. The two find themselves out of sight and kissing, but someone takes a photo of them. When the photo is placed online, a storm overtakes their lives.","4,789",['Didier Bivel']
Zemheri,Drama            ,120 min,Not Rated,7,"['Ayça Aysin Turan, ', 'Alperen Duymaz, ', 'Caner Cindoruk, ', 'Hazal Filiz Küçükköse', '']","Firuze and Ayaz. Two beautiful heart, two family carrying children overhead. Fate brought them together. Her father's unjust conviction in the elevator accident that killed thirteen people ...                See full summary »
","1,756",
Margaret,Drama            ,150 min,R,6.5,"['Anna Paquin, ', 'Matt Damon, ', 'Mark Ruffalo, ', 'J. Smith-Cameron', '']","A young woman witnesses a bus accident, and is caught up in the aftermath, where the question of whether or not it was intentional affects many people's lives.",$0.05M,['Kenneth Lonergan']
Günesi Beklerken,Drama            ,120 min,,6.8,"['Kerem Bürsin, ', 'Hande Dogandemir, ', 'Yagmur Tanrisevsin, ', 'Ismail Ege Sasmaz', '']","Looking for a better life, Demet tries to convince her only daughter Zeynep to leave their home village. They move into Demet's old friend's house Jale, and Zeynep is able to enroll at the ...                See full summary »
","3,573",
Young. Wild. Free.,Drama            ,105 min,,7.5,"['Algee Smith, ', 'Sierra Capri, ', 'Sanaa Lathan, ', 'Mike Epps', '']",A teenager struggling to provide for his younger siblings in Compton finds his life turned upside down when he's held at gunpoint by the girl of his dreams.,61,['Thembi Banks']
Ana de nadie,Drama            ,60 min,,8.6,"['Paola Turbay, ', 'Sebastián Carvajal, ', 'Jorge Enrique Abello, ', 'Laura Archbold', '']","Ana, a dedicated wife and mother, must reinvent her life after divorcing her philandering husband. When she meets and falls in love with a much younger man named Joaquín, her family and future change forever.",69,
The Virtues,Drama            ,47 min,,8.2,"['Stephen Graham, ', 'Niamh Algar, ', 'Helen Behan, ', 'Frank Laverty', '']","Falling into despair after his nine-year-old son leaves for Australia with his ex, Joseph walks away from his present life and boards a boat for Ireland to confront painful memories from his childhood.","6,339",
Don't Make Me Go,Drama            ,109 min,A,6.7,"['John Cho, ', 'Mia Isaac, ', 'Kaya Scodelario, ', 'Josh Thomson', '']","When a single father to a teenage daughter learns that he has a fatal brain tumor, he takes her on a road trip to find the mother who abandoned her years before and to try to teach her everything she might need over the rest of her life.","3,479",['Hannah Marks']
Doctor Thorne,Drama            ,48 min,,7.3,"['Harry Richardson, ', 'Tom Hollander, ', 'Stefanie Martini, ', 'Rebecca Front', '']","Penniless Mary Thorne grows up with her uncle, Doctor Thorne, and develops a friendship with the family at the nearby Greshamsbury Park estate.","5,029",
Baba,Drama            ,120 min,Not Rated,6.3,"['Haluk Bilginer, ', 'Tolga Saritas, ', 'Ayda Aksel, ', 'Özge Yagiz', '']","The life of Emin Saruhanli, who has been at odds with his brother Mehmet Ali for years, will be told that suddenly changed with the plane crash.",840,
Anne+,Drama            ,94 min,18,6.1,"['Hanna van Vliet, ', 'Jouman Fattal, ', 'Thorn de Vries, ', 'Jade Olieberg', '']","A twenty-something lesbian university graduate in Amsterdam prepares to leave for Montreal, meanwhile navigating her social life and writing carreer.","1,888",['Valerie Bisscheroux']
La scuola cattolica,Drama            ,106 min,A,5.7,"['Benedetta Porcaroli, ', 'Giulio Pranno, ', 'Emanuele Maria Di Stefano, ', 'Giulio Fochetti', '']","In late September 1975, a renowned Catholic school in Rome for sheltered, upper-middle-class boys is attacked in what became known as the Circeo Massacre. The film examines what triggered the violence.","3,232",['Stefano Mordini']
The Apostle,Drama            ,134 min,PG-13,7.2,"['Robert Duvall, ', 'Todd Allen, ', 'Paul Bagget, ', 'Lenore Banks', '']","After his happy life spins out of control, a preacher from Texas changes his name, goes to Louisiana and starts preaching on the radio.",$20.73M,['Robert Duvall']
Call Me Chihiro,Drama            ,131 min,UA 16+,6.9,"['Kasumi Arimura, ', 'Hana Toyoshima, ', 'Tetta Shimada, ', 'Van', '']","Chihiro works at a small beachside bento shop, Nokonoko Bento, and becomes a popular figure in the city.","2,495",['Rikiya Imaizumi']
Luden: Könige Der Reeperbahn,Drama            ,52 min,A,7,"['Aaron Hilmer, ', 'Jeanette Hain, ', 'Henning Flüsloh, ', 'Lena Urzendowsky', '']","The rise of Sonny Boy Klaus Barkowsky, who is made into a pimp by the tough prostitute Jutta and founds the 'Nutella' gang, which soon engages in a battle for power with the established 'GMBH.",937,
Soshite chichi ni naru,Drama            ,121 min,,7.8,"['Masaharu Fukuyama, ', 'Machiko Ono, ', 'Yôko Maki, ', 'Lily Franky', '']","Ryota is a successful workaholic businessman. When he learns that his biological son was switched with another boy after birth, he faces the difficult decision to choose his true son or the boy he and his wife have raised as their own.",$0.28M,['Hirokazu Koreeda']
The Last Tycoon,Drama            ,61 min,,7.6,"['Matt Bomer, ', 'Kelsey Grammer, ', 'Lily Collins, ', 'Dominique McElligott', '']","Centers on Hollywood's first wunderkind studio executive in the 1930s, Monroe Stahr, and the power struggle between him, his mentor, and current head of the studio, Pat Brady.","5,414",
Clean and Sober,Drama            ,124 min,,6.7,"['Michael Keaton, ', 'Kathy Baker, ', 'Morgan Freeman, ', 'Tate Donovan', '']",A hustling drug addict checks himself into rehabilitation to escape trouble with the law and realizes that it's exactly what he needs.,$8.67M,['Glenn Gordon Caron']
The Poker House,Drama            ,93 min,R,6.3,"['Jennifer Lawrence, ', 'Javon Johnson, ', 'Sophi Bairley, ', 'Bokeem Woodbine', '']",A dramatization of Lori Petty's teenage years spent in small town Iowa.,"5,698",['Lori Petty']
Kafas,Drama            ,,A,6.8,"['Sharman Joshi, ', 'Mona Singh, ', 'Zarina Wahab, ', 'Tejasvi Singh Ahlawat', '']","A middle-class family sees a brighter tomorrow when their son meets with a life-changing career opportunity. But this transition only unravels a web of trauma, raising poignant questions about wealth, power, and morality.",469,
Sundown,Drama            ,82 min,R,6.6,"['Tim Roth, ', 'Albertine Kotting McMillan, ', 'Samuel Bottomley, ', 'Charlotte Gainsbourg', '']","Neil and Alice Bennett are the core of a wealthy family on vacation in Mexico until a distant emergency cuts their trip short. When one relative disrupts the family's tight-knit order, simmering tensions rise to the fore.","5,683",['Michel Franco']
Anniversary,Drama            ,,,,"['Mckenna Grace, ', 'Diane Lane, ', 'Zoey Deutch, ', 'Kyle Chandler', '']","A close-knit family is torn apart as a new movement ""The Change"" envelops the country.",,['Jan Komasa']
Bu Sehir Arkandan Gelecek,Drama            ,120 min,,6.4,"['Kerem Bürsin, ', 'Gürkan Uygun, ', 'Leyla Lydia Tugutlu, ', 'Osman Alkas', '']","Rauf, who is working as a cook on cargo ships, adopts and raises Ali who witnessed his mother's death when he was 5 years old. They work on ships for 24 years together. Rauf was both mother...                See full summary »
","2,531",
Laurel Canyon,Drama            ,103 min,R,6.4,"['Frances McDormand, ', 'Alessandro Nivola, ', 'Christian Bale, ', 'Kate Beckinsale', '']","When an uptight young man and his fiancée move into his libertine mother's house, the resulting clash of life attitudes shakes everyone up.",$3.66M,['Lisa Cholodenko']
Mahjong Nights,Drama            ,111 min,,5.8,"['Angeli Khang, ', 'Sean De Guzman, ', 'Mickey Ferriols, ', 'Jay Manalo', '']",Alexa witnesses a simple mahjong night turned bloody when all the player's dark secrets are discovered - including Alexa's illicit affair with her stepfather.,758,['Lawrence Fajardo']
A Jazzman's Blues,Drama            ,127 min,A,6.7,"['Joshua Boone, ', 'Amirah Vann, ', 'Solea Pfeiffer, ', 'Austin Scott', '']","Follows an investigation into an unsolved murder unveiling a story full of forbidden love, deceit and a secret.","3,924",['Tyler Perry']
The Smell of Us,Drama            ,92 min,,4.8,"['Lukas Ionesco, ', 'Diane Rouxel, ', 'Théo Cholbi, ', 'Hugo Behar-Thinières', '']",A story centered around a group of self-destructive skateboarders in Paris.,"1,787",['Larry Clark']
The Village,Drama            ,60 min,,7.7,"['David Ryall, ', 'Maxine Peake, ', 'John Simm, ', 'Charlie Murphy', '']",Follows the residents of one English village across the 20th century and their turbulent lives.,"2,518",
The Death & Life of John F. Donovan,Drama            ,123 min,R,6.1,"['Kit Harington, ', 'Natalie Portman, ', 'Jacob Tremblay, ', 'Susan Sarandon', '']","A decade after the death of an American television star, a young actor reminisces about the written correspondence he shared with him, as well as the impact those letters had on both their lives.",$0.13M,['Xavier Dolan']
An Amish Sin,Drama            ,85 min,,6.7,"['Dylan Ratzlaff, ', 'Kellie Martin, ', 'Rukiya Bernard, ', 'Troy Mundle', '']",An Amish teenager tries to escape the harsh 18th-century-style lifestyle where she grew up to find her own voice and independence.,230,['Michael Nankin']
Ta'm e guilass,Drama            ,95 min,,7.7,"['Homayoun Ershadi, ', 'Abdolrahman Bagheri, ', 'Afshin Khorshid Bakhtiari, ', 'Safar Ali Moradi', '']",An Iranian man drives his car in search of someone who will quietly bury him under a cherry tree after he commits suicide.,$0.31M,['Abbas Kiarostami']
Palm Royale,Drama            ,,,,"['Kristen Wiig, ', 'Allison Janney, ', 'Leslie Bibb, ', 'Laura Dern', '']",Chronicles a woman reconstructing her identity in the 1960s after being dismissed by her husband and her entire social circle.,,
Kwinmeikeo,Drama            ,60 min,UA 16+,7.6,"['Alexandra Bokyun Chun, ', 'Ell, ', 'Kim Hee-ae, ', 'Moon So-ri', '']",An accomplished fixer for a powerful business conglomerate jumps into politics to make a headstrong civil rights lawyer the next mayor of Seoul.,"1,001",
Somewhere Boy,Drama            ,23 min,,7.3,"['Lewis Gribben, ', 'Samuel Bottomley, ', 'Rory Keenan, ', 'Lisa McGrillis', '']","Danny was a baby when his mother was killed in a car crash. Overcome with grief, his father locked him away in a house, telling him the outside world is full of monsters that will spirit him away like his mother.","1,167",
20.000 especies de abejas,Drama            ,128 min,,6.5,"['Sofía Otero, ', 'Patricia López Arnaiz, ', 'Ane Gabarain, ', 'Itziar Lazkano', '']","During a summer in a village house linked to beekeeping, an eight-year-old and her mother experience revelations that will change their lives forever.",990,['Estibaliz Urresola Solaguren']
Donde Hubo Fuego,Drama            ,45 min,A,6.2,"['Eduardo Capetillo, ', 'Esmeralda Pimentel, ', 'Iván Amozurrutia, ', 'Giovanny Camarena', '']","When clues to his brother's murder lead Poncho to a fire brigade, he joins it to investigate further and finds romance, family - and a serial killer.",714,
Querelle,Drama            ,108 min,,6.7,"['Brad Davis, ', 'Franco Nero, ', 'Jeanne Moreau, ', 'Laurent Malet', '']","A handsome sailor is drawn into a vortex of sibling rivalry, murder, and explosive sexuality.","7,078",['Rainer Werner Fassbinder']
Marquis de Sade: Justine,Drama            ,90 min,,5.1,"['Klaus Kinski, ', 'Romina Power, ', 'Maria Rohm, ', 'Rosemary Dexter', '']","Penniless and separated from her sister, a beautiful, chaste orphan must endure an endless parade of villains, perverts and degenerates who covet her virtue and life.","1,965",['Jesús Franco']
The Significant Other,Drama            ,109 min,,6.9,"['Tom Rodriguez, ', 'Lovi Poe, ', 'Erich Gonzales, ', 'Dina Bonnevie', '']","A neophyte model from a lowly working-class background gets her big break and share top catwalk billing with her idol, a highbred fashion princess who is on the comeback trail after a ...                See full summary »
",82,['Joel Lamangan']
Veda Mektubu,Drama            ,,,5.7,"['Nurgül Yesilçay, ', 'Selim Bayraktar, ', 'Rabia Soyturk, ', 'Emre Kivilcim', '']",The series will follow the showdown that results from the love that blossoms between two kids of lovers who parted ways years ago because of a letter.,275,
Scener ur ett äktenskap,Drama            ,283 min,,8.5,"['Liv Ullmann, ', 'Erland Josephson, ', 'Bibi Andersson, ', 'Gunnel Lindblom', '']",Ten years within the marriage of Marianne and Johan.,"16,948",
Nathalie...,Drama            ,106 min,,6.3,"['Fanny Ardant, ', 'Emmanuelle Béart, ', 'Gérard Depardieu, ', 'Wladimir Yordanoff', '']",A rich woman hires an elite prostitute in order to verify her husband's faithfulness. Before long the experiment gets out of control.,$0.02M,['Anne Fontaine']
You Can't Win,Drama            ,,,,"['Jeremy Allen White, ', 'Will Patton, ', 'Michael Pitt, ', 'Hannah Marks', '']","The true-crime story of Jack Black, whose 1926 memoir became an unlikely bestseller upon its release and later inspired generations of counter-cultural writing.",,['Robinson Devor']
Udaan,Drama            ,134 min,UA,8.1,"['Rajat Barmecha, ', 'Ronit Roy, ', 'Manjot Singh, ', 'Ram Kapoor', '']","Expelled from his school, a 16-year old boy returns home to his abusive and oppressive father.",$0.01M,['Vikramaditya Motwane']
Sibyl,Drama            ,100 min,,5.8,"['Virginie Efira, ', 'Adèle Exarchopoulos, ', 'Gaspard Ulliel, ', 'Sandra Hüller', '']",A jaded psychotherapist returns to her first passion of becoming a writer.,"3,853",['Justine Triet']
The Stoning of Soraya M.,Drama            ,116 min,R,8,"['Shohreh Aghdashloo, ', 'Jim Caviezel, ', 'Mozhan Marnò, ', 'Navid Negahban', '']",A desperate woman asks for a meeting with a journalist to disclose the cruel and inhumane punishment of her niece.,$0.66M,['Cyrus Nowrasteh']
King Lear,Drama            ,115 min,,6.2,"['Jim Broadbent, ', 'Jim Carter, ', 'Tobias Menzies, ', 'Emily Watson', '']","An aging King invites disaster when he abdicates to his corrupt, toadying daughters, and rejects his loving and honest one.","4,040",['Richard Eyre']
Miss Violence,Drama            ,98 min,,7.1,"['Themis Panou, ', 'Reni Pittaki, ', 'Eleni Roussinou, ', 'Sissy Toumasi', '']","An unnerving story about a horrid family drama kept behind closed doors, and an elaborate facade where appearances can be deceiving, and nothing is as it seems.","9,162",['Alexandros Avranas']
København findes ikke,Drama            ,99 min,,6,"['Angela Bundalovic, ', 'Jonas Holst Schmidt, ', 'Zlatko Buric, ', 'Vilmer Trier Brøgger', '']","A young woman named Ida disappears without a trace. Her boyfriend voluntarily lets himself be locked up to be questioned by Ida's father and brother, but Sander does not tell the whole truth.",173,['Martin Skovbjerg']
The Beach House,Drama            ,92 min,,6.5,"['Minka Kelly, ', 'Andie MacDowell, ', 'Chad Michael Murray, ', 'Makenzie Vega', '']","The story follows Caretta ""Cara"" Rutledge, a woman who's tried to move beyond a difficult past but is forced to grapple with history head-on when she returns to fix the family beach house. ...                See full summary »
","2,242",['Roger Spottiswoode']
The Enemy Within,Drama            ,43 min,,7.1,"['Jennifer Carpenter, ', 'Morris Chestnut, ', 'Raza Jaffrey, ', 'Kelli Garner', '']",FBI agent Will Keaton enlists the most notorious traitor in American history to help catch a spy.,"6,893",
Blind,Drama            ,96 min,,6.8,"['Ellen Dorrit Petersen, ', 'Henrik Rafaelsen, ', 'Vera Vitali, ', 'Marius Kolbenstvedt', '']","Forsaken in a new Oslo apartment, a frail blind woman battles to come to terms with her condition, as she slowly retracts into an elaborate fantasy bubble. Are her stories fanning her suspicions, or is this what total blindness looks like?","8,904",['Eskil Vogt']
Efter brylluppet,Drama            ,120 min,R,7.7,"['Mads Mikkelsen, ', 'Sidse Babett Knudsen, ', 'Rolf Lassgård, ', 'Neeral Mulchandani', '']","A manager of an orphanage in India is sent to Copenhagen, Denmark, where he discovers a life-altering family secret.",$0.41M,['Susanne Bier']
Kiss of the Spider Woman,Drama            ,120 min,,7.3,"['William Hurt, ', 'Raul Julia, ', 'Sonia Braga, ', 'José Lewgoy', '']",A gay man and a political prisoner are together in a prison. The gay man narrates the stories of two fake movies and his own life.,$17.04M,['Hector Babenco']
Dogdugun Ev Kaderindir,Drama            ,120 min,,6,"['Demet Özdemir, ', 'Zuhal Gencer, ', 'Senan Kara, ', 'Fatih Koyunoglu', '']",The house where you were born even decides who you love and who you marry. First the mothers take the pen in his hand and start writing.,"2,143",
Vento Seco,Drama            ,110 min,,6.4,"['Leandro Faria Lelo, ', 'Allan Jacinto Santana, ', 'Renata Carvalho, ', 'Rafael Theophilo', '']","The area around Catalan in Brazil's state of Goiás is dry, very dry. Sandro's life here is just as dry--somewhat monotonous. He works in a fertilizer factory and divides his days between ...                See full summary »
","1,170",['Daniel Nolasco']
De Droom van de Jeugd,Drama            ,,,7.7,"['Mark Rietman, ', 'Tamar van den Dop, ', 'Peter Paul Muller, ', 'Jacob Derwig', '']","Childhood Dreams is a family saga, starting in the tumultuous 1960s, charting the bittersweet journey of a family as they navigate the water of love, loss, and life over several generations.",149,
For the People,Drama            ,43 min,,7.3,"['Hope Davis, ', 'Ben Shenkman, ', 'Jasmin Savoy Brown, ', 'Susannah Flood', '']","Set in the Southern District of New York Federal Court, brand-new lawyers work for both the defense and the prosecution as they handle the most high-profile and high-stakes cases in the country--all as their personal lives intersect.","6,174",
A Vida Invisível,Drama            ,139 min,R,7.7,"['Julia Stockler, ', 'Carol Duarte, ', 'Flávia Gusmão, ', 'António Fonseca', '']","Kept apart by a terrible lie and a conservative society, two sisters born in Rio de Janeiro make their way through life each believing the other is living out her dreams half a world away.","9,212",['Karim Aïnouz']
Queer,Drama            ,,,,"['Daniel Craig, ', 'Jason Schwartzman, ', 'Lesley Manville, ', 'Drew Starkey', '']","Lee, who recounts his life in Mexico City among American expatriate college students and bar owners surviving on part-time jobs and GI Bill benefits. He driven to pursue a young man named Allerton, who is based on Adelbert Lewis Marker.",,['Luca Guadagnino']
Away from Her,Drama            ,110 min,PG-13,7.5,"['Julie Christie, ', 'Michael Murphy, ', 'Gordon Pinsent, ', 'Stacey LaBerge', '']","A man coping with the institutionalization of his wife because of Alzheimer's disease faces an epiphany when she transfers her affections to another man, Aubrey, a wheelchair-bound mute who also is a patient at the nursing home.",$4.57M,['Sarah Polley']
La notte,Drama            ,122 min,,8,"['Jeanne Moreau, ', 'Marcello Mastroianni, ', 'Monica Vitti, ', 'Bernhard Wicki', '']",A day in the life of an unfaithful married couple and their steadily deteriorating relationship.,$0.04M,['Michelangelo Antonioni']
Downtown Owl,Drama            ,91 min,,6.7,"['Lily Rabe, ', 'Vanessa Hudgens, ', 'Ed Harris, ', 'Henry Golding', '']","Based on the novel by Chuck Klosterman, Downtown Owl is a sparkle dark Reagan Era comedy set in the fictional town of Owl, North Dakota in the leading days up to the region's blizzard in Minnesota's century.",21,
Sauvage,Drama            ,99 min,,7,"['Félix Maritaud, ', 'Farid-Eric Bernard, ', 'Nicolas Dibla, ', 'Philippe Ohrel', '']","Leo is 22 and sells his body on the street for a bit of cash. The men come and go, and he stays right here - longing for love. He doesn't know what the future will bring. He hits the road. His heart is pounding.",$0.06M,['Camille Vidal-Naquet']
Vivre sa vie: Film en douze tableaux,Drama            ,80 min,,7.8,"['Anna Karina, ', 'Sady Rebbot, ', 'André S. Labarthe, ', 'Guylaine Schlumberger', '']",Twelve episodic tales in the life of a Parisian woman and her slow descent into prostitution.,"33,767",['Jean-Luc Godard']
Nelyubov,Drama            ,127 min,R,7.6,"['Maryana Spivak, ', 'Aleksey Rozin, ', 'Matvey Novikov, ', 'Marina Vasileva', '']",A couple going through a divorce must team up to find their son who has disappeared during one of their bitter arguments.,$0.57M,['Andrey Zvyagintsev']
Hot Milk,Drama            ,,,,"['Emma Mackey, ', 'Fiona Shaw, ', 'Vicky Krieps', '']","With a strange illness, a mother and her daughter embark on a journey to the Spanish coast to find a cure, and along the way the daughter discovers another reality far from her controlling mother.",,['Rebecca Lenkiewicz']
Kördügüm,Drama            ,140 min,13,6.6,"['Ibrahim Celikkol, ', 'Alican Yücesoy, ', 'Belçim Bilgin, ', 'Rojda Demirer', '']","Ali Nejat Karasu is a former race-driver and a playboy turned into a businessman. He runs Karas Holdings which is part of a group his father built while making a fortune in ship building. ...                See full summary »
","1,391",
Bad Class,Drama            ,106 min,,7.4,,"Ji-eun has a bad impression of men due to bad experiences with her father but her mom Hyeon-ah convinces her into getting tuition from an art student. Jeong-woo is surprised at how cold she...                See full summary »
",61,['Han Dong-ho']
Driveways,Drama            ,83 min,,7.2,"['Lucas Jaye, ', 'Hong Chau, ', 'Brian Dennehy, ', 'Laurent Rejto', '']","A lonesome boy accompanies his mother on a trip to clean out his late aunt's house, and ends up forming an unexpected friendship with the retiree who lives next door.","6,002",['Andrew Ahn']
Black Justice,Drama            ,214 min,,9.5,"['Alok Nath Pathak, ', 'Priya Gamre Amar, ', 'Virdi Supriya Singh, ', 'Aftab Karim', '']",Pandey aka J.P. is practicing lawyer in sessions court and supreme court of India. JP is very honest whose only aim is to speak for the justice. J.P. decides to file a PIL for the reforms in current judicial system.,96,
Murina,Drama            ,96 min,,6.8,"['Gracija Filipovic, ', 'Leon Lucev, ', 'Danica Curcic, ', 'Cliff Curtis', '']",A teenage girl decides to replace her controlling father with his wealthy foreign friend during a weekend trip to the Adriatic Sea.,"2,759",['Antoneta Alamat Kusijanovic']
Lioness,Drama            ,,,,"['Atungsiri Bertrand, ', 'Claudia Fonguh, ', 'Michael Fonyuy, ', 'Neh Hotance', '']","Add a Plot
",,['Wasi Fathes']
La strada,Drama            ,108 min,,8,"['Anthony Quinn, ', 'Giulietta Masina, ', 'Richard Basehart, ', 'Aldo Silvani', '']","A care-free girl is sold to a traveling entertainer, consequently enduring physical and emotional pain along the way.","65,146",['Federico Fellini']
The Palace,Drama            ,,,,"['Andrea Riseborough, ', 'Donald Sage Mackay, ', 'Guillaume Gallienne, ', 'Louie Mynett', '']",An authoritarian regime is about to unravel. Follows a story of one year within the walls of its palace.,,
The Spitfire Grill,Drama            ,117 min,PG-13,7,"['Alison Elliott, ', 'Ellen Burstyn, ', 'Marcia Gay Harden, ', 'Will Patton', '']","Oscar-winner Ellen Burstyn (The Exorcist) headlines this critically praised drama about a young woman, just out of prison, who finds spiritual redemption working at a cafe in Maine.",$12.64M,['Lee David Zlotoff']
The Tattooist of Auschwitz,Drama            ,,,,"['Jonah Hauer-King, ', 'Melanie Lynskey, ', 'Avital Lvova, ', 'Andrei Nova', '']","Based on the eponymously titled novel, this is the powerful real-life story of Lale Sokolov, a Jewish prisoner who was tasked with tattooing ID numbers on prisoners' arms in the Auschwitz-Birkenau concentration camp during World War Two.",,
Three Women,Drama            ,,,,"['Shailene Woodley, ', 'Betty Gilpin, ', 'DeWanda Wise, ', 'Gabrielle Creevy', '']","This is an intimate, moving, uplifting portrait of real women reclaiming their lives for themselves.",,
Everything Is Both,Drama            ,81 min,,8.6,"['Jason Mitchell, ', 'Barton Fitzpatrick, ', 'J.J. Green, ', 'Stakiah Lynn Washington', '']",It follows Dysha as she runs for her life and depends on a mysterious stranger to escape danger and pull off the biggest score of her life.,28,['Ceth Watson']
Norwegian Dream,Drama            ,97 min,,6.7,"['Øyvind Brandtzæg, ', 'Izabella Dudziak, ', 'Runar Koteng Frønes, ', 'Hubert Milkowski', '']","A 19-year-old Polish immigrant working at a fish factory in Norway has feelings for his colleague. A strike begins among the Polish workers at the factory testing their relationship, and with their fellow workers.",210,['Leiv Igor Devold']
"Grandview, U.S.A.",Drama            ,97 min,,5.4,"['Jamie Lee Curtis, ', 'C. Thomas Howell, ', 'Patrick Swayze, ', 'Troy Donahue', '']","With only a week left before graduation, a young dreamer itches to renounce an uninspiring scholarship, stand up to his despotic father and pursue a career in oceanography. But, has anyone ever spread his wings away from Grandview, U.S.A.?",$4.74M,['Randal Kleiser']
Hemel,Drama            ,80 min,,5.7,"['Hannah Hoekstra, ', 'Hans Dagelet, ', 'Mark Rietman, ', 'Barbara Sarafian', '']","A promiscuous young woman struggles with her emotions when the one man she cares deeply about, her equally restless father, finally finds true love.","1,712",['Sacha Polak']
Nostalgia,Drama            ,117 min,,6.8,"['Pierfrancesco Favino, ', 'Francesco Di Leva, ', 'Tommaso Ragno, ', 'Aurora Quattrocchi', '']","After 40 years of absence, Felice returns to his hometown: Naples. He rediscovers the places, the codes of the city and a past that eats away at him.","2,507",['Mario Martone']
Julia,Drama            ,117 min,U,7.1,"['Jane Fonda, ', 'Vanessa Redgrave, ', 'Jason Robards, ', 'Maximilian Schell', '']","At the behest of an old and dear friend, playwright Lillian Hellman undertakes a dangerous mission to smuggle funds into Nazi Germany.","10,153",['Fred Zinnemann']
The Black Velvet Gown,Drama            ,103 min,,6.9,"['Bob Peck, ', 'Janet McTeer, ', 'Geraldine Somerville, ', 'Brendan P. Healy', '']","In the 1830's in northern England, Riah Millican, a widow with three children, takes a job as housekeeper to a reclusive former teacher, Percival Miller. Miller makes Riah the gift of a ...                See full summary »
",639,['Norman Stone']
The Rain People,Drama            ,101 min,,6.8,"['James Caan, ', 'Shirley Knight, ', 'Robert Duvall, ', 'Marya Zimmet', '']","When a housewife finds out she is pregnant, she runs out of town looking for freedom to reevaluate her life decisions.",$0.16M,['Francis Ford Coppola']
Montana Story,Drama            ,114 min,R,6.5,"['Haley Lu Richardson, ', 'Owen Teague, ', 'Gilbert Owuor, ', 'Kimberly Guerrero', '']","Two estranged siblings return home to the sprawling ranch they once knew and loved, confronting a deep and bitter family legacy against a mythic American backdrop.","2,946",
The Wrong Wife,Drama            ,,,6.4,"['Mark Stauffer, ', 'Lynn Winkle', '']",Lexi has been keeping a steamy and erotic secret from Kyle for a long period of time. Sexual passion drives the human soul as she reluctantly reveals the details of her sexy indiscretions.,78,['Jacob Hutton']
"4 luni, 3 saptamâni si 2 zile",Drama            ,113 min,,7.9,"['Anamaria Marinca, ', 'Laura Vasiliu, ', 'Vlad Ivanov, ', 'Alexandru Potocean', '']",A woman assists her friend in arranging an illegal abortion in 1980s Romania.,$1.19M,['Cristian Mungiu']
El deseo de Ana,Drama            ,79 min,,6.2,"['Laura Agorreca, ', 'David Calderón León, ', 'Ian Garcia Monterrubio, ', 'Simone Bucio', '']","After years of absence Juan returns to Ana, his older sister. Both have changed, but none of them has been able to overcome the love affair they lived in their youth that marked them forever.",83,['Emilio Santoyo']
Lady in the Lake,Drama            ,,,,"['Natalie Portman, ', 'David Corenswet, ', 'Bianca Berry Tarantino, ', 'Moses Ingram', '']",Based on the Laura Lippman novel.,,
The Beautiful Lie,Drama            ,60 min,,7.4,"['Sarah Snook, ', 'Rodger Corser, ', 'Sophie Lowe, ', 'Celia Pacquola', '']",Anna is happily married. She has the perfect family. But one man will change it all.,"1,349",
Grey Matter,Drama            ,,,,"['Elizabeth Berrington, ', 'Stephanie Beacham, ', 'Kierston Wareing, ', 'Harry Kirton', '']","When Chloe's Nan gets diagnosed with Alzheimer's, she's forced to become a stay-at-home teenager overnight.",,['Arabella Burfitt-Dons']
Born Innocent,Drama            ,98 min,,6.2,"['Linda Blair, ', 'Joanna Miles, ', 'Allyn Ann McLerie, ', 'Mary Murphy', '']",Young girl runs away from her abusive family only to end up in a juvenile detention center for girls where she's raped and brutalized by her sadistic peers. Only one honest social worker shows interest in helping her.,"1,119",['Donald Wrye']
La luna,Drama            ,142 min,A,6.4,"['Jill Clayburgh, ', 'Matthew Barry, ', 'Veronica Lazar, ', 'Renato Salvatori', '']","While touring in Italy, a recently-widowed American opera singer has an incestuous relationship with her 15-year-old son to help him overcome his heroin addiction.","5,178",['Bernardo Bertolucci']
Hamlet,Drama            ,135 min,U,6.7,"['Mel Gibson, ', 'Glenn Close, ', 'Alan Bates, ', 'Paul Scofield', '']","Hamlet, Prince of Denmark, finds out that his uncle Claudius killed his father to obtain the throne, and plans revenge.",$20.71M,['Franco Zeffirelli']
La Mujer del Diablo,Drama            ,60 min,,8.2,"['Carolina Miranda, ', 'José Ron, ', 'Adriana Louvier, ', 'Mónica Dionne', '']",Natalia is a school teacher who wants to dedicate herself to local tourism. Cristo is a criminal who pretends to be a benefactor to those in need. Cristo becomes obsessed with Natalia and does unimaginable things to win her over.,114,
Radio Flyer,Drama            ,114 min,U,6.9,"['Lorraine Bracco, ', 'John Heard, ', 'Adam Baldwin, ', 'Elijah Wood', '']",A father recounts a dark period of his childhood when he and his little brother lived in the suburbs.,$4.65M,
Novitiate,Drama            ,123 min,R,6.7,"['Melissa Leo, ', 'Lisa Stewart, ', 'Alyssa Brindley, ', 'Chelsea Lopez', '']","Set in the early 1960s and during the era of Vatican II, a young woman in training to become a nun struggles with issues of faith, the changing church and sexuality.",$0.58M,['Maggie Betts']
En los márgenes,Drama            ,105 min,,6.6,"['Penélope Cruz, ', 'Luis Tosar, ', 'Christian Checa, ', 'Aixa Villagrán', '']",Interwoven stories told over the course of one day.,"1,718",['Juan Diego Botto']
Badmaash Babes,Drama            ,94 min,,6.7,"['Bhumika Gurung, ', 'Pratibha Phogat, ', 'Chandni Srivastava', '']","When the stripper from Alisha's bachelor party is found dead the next morning, the high society lives of best friends Alisha, Maya and Zee go through a roller coaster ride.",10,['Ajay V.']
Laruan,Drama            ,86 min,,5.9,"['Franki Russell, ', 'Jay Manalo, ', 'Kiko Estrada, ', 'Ava Mendez', '']","Camille, Rene's wife, always invites her other man, Geoff, over dinner for them to make out in the house. But when a new woman, Thea, enters the picture, Camille's wild and crazy game play changes.",492,['Yam Laranas']
Kus Uçusu,Drama            ,45 min,UA 16+,6.3,"['Birce Akalay, ', 'Miray Daner, ', 'Ibrahim Celikkol, ', 'Burak Yamantürk', '']","A young fan maneuvers her way into a seasoned anchor's newsroom but soon confronts the dark side of ambition, envy and the desire to be seen.","5,030",
The Namesake,Drama            ,122 min,U,7.5,"['Kal Penn, ', 'Irrfan Khan, ', 'Tabu, ', 'Jacinda Barrett', '']","American-born Gogol, the son of Indian immigrants, wants to fit in among his fellow New Yorkers, despite his family's unwillingness to let go of their traditional ways.",$8.66M,['Mira Nair']
Las oscuras primaveras,Drama            ,100 min,,6.2,"['José María Yazpik, ', 'Cecilia Suárez, ', 'Irene Azuela, ', 'Hayden Meyenberg', '']","Igor is a plumber; Pina serves coffee. It is winter and they both deeply desire each other, but they are not free. In trying to figure out how to realize their love, she decides to make a ...                See full summary »
",648,['Ernesto Contreras']
The Half Life of Timofey Berezin,Drama            ,97 min,R,6.7,"['Paddy Considine, ', 'Oscar Isaac, ', 'Valeriu Pavel Dan, ', 'Kenneth Bryans', '']","A worker at a Russian nuclear facility gets exposed to a lethal dose of radiation. In order to provide for his family, he steals some plutonium and sets out to sell it on Moscow's black market with the help of an incompetent criminal.","4,051",['Scott Z. Burns']
Dirty Sexy Money,Drama            ,45 min,U,7.2,"['Peter Krause, ', 'Donald Sutherland, ', 'William Baldwin, ', 'Natalie Zea', '']",A lawyer is forced to take care of one of New York City's wealthiest families.,"12,091",
Lip Service,Drama            ,60 min,,7.5,"['Fiona Button, ', 'Heather Peace, ', 'James Anthony Pearson, ', ""Natasha O'Keeffe"", '']","Sex, lies and true love in modern Scotland. Following the lives and loves of a group of twenty-something lesbians living in Glasgow.","4,471",
Os Outros,Drama            ,50 min,,8.3,"['Adriana Esteves, ', 'Milhem Cortaz, ', 'Maeve Jinkings, ', 'Thomas Aquino', '']","Add a Plot
",420,
Fanfik,Drama            ,95 min,,5.6,"['Alin Szewczyk, ', 'Jan Cieciara, ', 'Dobromir Dymecki, ', 'Wiktoria Kruszczynska', '']",Two high school students form an intense connection as they navigate the challenges of discovering and expressing their truest selves.,755,['Marta Karwowska']
Maharani,Drama            ,43 min,A,7.9,"['Uday Atroliya, ', 'Huma Qureshi, ', 'Sohum Shah, ', 'Kani Kusruti', '']","CM Rani Bharti is accused of misgovernance and 'jungle raj' in the state. With the crumbling political scenario and constant opposition, will she succeed in this game of power?","8,636",
Foxes,Drama            ,106 min,A,6.1,"['Jodie Foster, ', 'Cherie Currie, ', 'Marilyn Kagan, ', 'Kandice Stroh', '']","A group of four teenage girls come of age in the asphalt desert of Los Angeles' San Fernando Valley arranged with a blazing soundtrack and endless drinking, drugs and sex.","4,821",['Adrian Lyne']
Paradise Alley,Drama            ,107 min,,5.7,"['Sylvester Stallone, ', 'Lee Canalito, ', 'Armand Assante, ', 'Frank McRae', '']","Three Italian-American brothers, living in the slums of 1940's New York City, try to help each other with one's wrestling career using one brother's promotional skills and another brother's con-artist tactics to thwart a sleazy manager.","5,672",['Sylvester Stallone']
Escaping My Stalker,Drama            ,,,4.8,"['Ezmie Garcia, ', 'Andrew James Allen, ', 'Alexandra Paul, ', 'Linden Ashby', '']",Adopted teen Taylor (Ezmie Garcia) finds her new life threatened when an assailant breaks into her home. Returning to the back alleys of LA to find her stalker triggers a deadly game of cat and mouse.,214,['Linden Ashby']
Harriet Craig,Drama            ,94 min,,7.3,"['Joan Crawford, ', 'Wendell Corey, ', 'Lucile Watson, ', 'Allyn Joslyn', '']",Harriet Craig enjoys married life but constantly tries to control those around her. She does not trust her husband Walter; she always check up on him.,"2,200",['Vincent Sherman']
Alias el Mexicano,Drama            ,,,8.6,"['Juan Sebastián Calero, ', 'Carolina Gaitan, ', 'Flora Martínez, ', 'Rafael Novoa', '']","Gonzalo Rodriguez Gacha, a humble young man, becomes an emerald miner to one of Colombia's most powerful drug lords.",49,
Melissa P.,Drama            ,100 min,,4.8,"['María Valverde, ', 'Letizia Ciampa, ', 'Primo Reggiani, ', 'Fabrizia Sacchi', '']","An adolescent girl, living with her mother and her grandmother, will have her first sexual experiences in a heavy and excessive way.","6,833",['Luca Guadagnino']
Radical,Drama            ,122 min,,8.6,"['Eugenio Derbez, ', 'Daniel Haddad, ', 'Jennifer Trejo, ', 'Mia Fernanda Solis', '']","Based on a true story, follows a teacher in a Mexican border town full of neglect, corruption, and violence, as he tries a radical new method to unlock their students' curiosity, potential - and maybe even their genius.",96,['Christopher Zalla']
Los herederos de la tierra,Drama            ,50 min,A,7.1,"['Yon González, ', 'Elena Rivera, ', 'Jesús Carroza, ', 'Rodolfo Sancho', '']",Resourceful young Hugo Llor works to make a name for himself in 14th-century Barcelona while keeping a vow he made to the Estanyol family.,"1,439",
Barbara,Drama            ,105 min,PG-13,7.2,"['Nina Hoss, ', 'Ronald Zehrfeld, ', 'Rainer Bock, ', 'Christina Hecke', '']",A doctor working in 1980s East Germany finds herself banished to a small country hospital.,"15,227",['Christian Petzold']
Kuzey Güney,Drama            ,90 min,,7.7,"['Kivanç Tatlitug, ', 'Bugra Gülsoy, ', 'Öykü Karayel, ', 'Mustafa Avkiran', '']","Kuzey and Güney are brothers, yet they cannot be more different, both in character and also in their perception, much like their names they are north and south. While the older brother ...                See full summary »
","10,582",
Little Buddha,Drama            ,123 min,U,6.1,"['Keanu Reeves, ', 'Bridget Fonda, ', 'Ruocheng Ying, ', 'Chris Isaak', '']","After the death of Lama Dorje, Tibetan Buddhist monks find three children - one American and two Nepalese - who may be the rebirth of their great teacher.",$4.86M,['Bernardo Bertolucci']
Shortland Street,Drama            ,30 min,,4.5,"['Michael Galvin, ', 'Ben Mitchell, ', 'Sally Martin, ', 'Ben Barrington', '']","Shortland Street, a five-night-a-week soap set in an Auckland City hospital, follows the complicated personal and professional lives of its staff, family and friends.","1,025",
Pretty Red Dress,Drama            ,110 min,,6.6,"['Natey Jones, ', 'Alexandra Burke, ', 'Temilola Olatunbosun, ', 'Tsemaye Bob-Egbe', '']",Follows a South London family and how one red dress is the center of their lives.,287,['Dionne Edwards']
Kan Çiçekleri,Drama            ,,Not Rated,7.2,"['Ekrem Aral Tuna, ', 'Nuray Serefoglu, ', 'Baris Baktas, ', 'Yagmur Yuksel', '']","Dilan and Baran are forced to marry to end a feud and save their brother, but their uncle wants to rekindle it. This conflict-filled relationship will bring strong winds between two hearts, but will it turn into a real marriage?",493,
Io capitano,Drama            ,121 min,,,"['Affif Ben Badra, ', 'Hichem Yacoubi, ', 'Princess Erika, ', 'Bamar Kane', '']","It tells the story of two young men, who leave Dakar for Europe.",,['Matteo Garrone']
Matria,Drama            ,99 min,,6.9,"['María Vázquez, ', 'Susana Sampedro, ', 'Santi Prego, ', 'Francisca Iglesias Bouzón', '']","A woman in a Galician fishing village is struggling to get by with hard work and rough charm. With her 18-year-old daughter now ready to stand on her own two feet, Ramona begins to question her life up to this point.",266,
El príncipe,Drama            ,96 min,,6.4,"['Juan Carlos Maldonado, ', 'Alfredo Castro, ', 'Gastón Pauls, ', 'Cesare Serra', '']","A '70s-set homoerotic prison drama based on a low-circulated pulp novel, tracking the sexual, often-violent and eventually murderous experiences of 20-something narcissist Jaime.","1,571",['Sebastián Muñoz']
The Servant,Drama            ,116 min,,7.8,"['Dirk Bogarde, ', 'Sarah Miles, ', 'Wendy Craig, ', 'James Fox', '']","Upper-class Tony hires servant Hugo Barrett, who turns out to have a hidden agenda.",$0.04M,['Joseph Losey']
Zee van tijd,Drama            ,116 min,,7.6,"['Sallie Harmsen, ', 'Reinout Scholten van Aschat, ', 'Elsie de Brauw, ', 'Gijs Scholten van Aschat', '']","Lucas and Johanna live in the 80s, madly in love, in a world full of dreams and ideals. Then a disastrous accident, during their sailing trip on the Atlantic, separates them. Thirty-five ...                See full summary »
",864,['Theu Boermans']
Una,Drama            ,94 min,R,6.2,"['Ruby Stokes, ', 'Rooney Mara, ', 'Riz Ahmed, ', 'Ben Mendelsohn', '']","When a young woman unexpectedly arrives at her much-older former lover's workplace, looking for answers, the secrets of their dark past threaten to unravel his new life. What follows is an ...                See full summary »
","11,145",['Benedict Andrews']
Marasli,Drama            ,120 min,,7.7,"['Burak Deniz, ', 'Alina Boz, ', 'Serhat Mustafa Kiliç, ', 'Saygin Soysal', '']","Marasli (BurakDeniz) is a retired soldier turned bookstore owner. For Marasli, life changed drastically after his daughter is shot. One day, the beautiful Mahur (AlinaBoz) enters Marasli's ...                See full summary »
","3,341",
Wild Bill,Drama            ,98 min,,7.2,"['Charlie Creed-Miles, ', 'Will Poulter, ', 'Sammy Williams, ', 'Iwan Rheon', '']","A street-toughened parolee finds his two boys abandoned by their mum and fending for themselves. Time to step up, or not.","14,169",['Dexter Fletcher']
The Jury,Drama            ,300 min,,7.7,"['Paul Bhattacharjee, ', 'Gerard Butler, ', 'Nina Sosanya, ', 'Nicholas Farrell', '']",Twelve men and women are called for jury service in the retrial of a man accused of a triple murder after the High Court overturns the original verdict.,"1,220",
The Gabby Petito Story,Drama            ,85 min,,5.4,"['Skyler Samuels, ', 'Evan Hall, ', 'Thora Birch, ', 'Douglas Taurel', '']","Follows Gabby's tragic murder, centering on her complicated relationship with her fiancé Brian Laundrie and what might have gone wrong during their cross-country trip.",541,['Thora Birch']
The Mattachine Family,Drama            ,99 min,,7.6,"['Jake Choi, ', 'Garrett Clayton, ', 'Carl Clemons-Hopkins, ', 'Juan Pablo Di Pace', '']","While Thomas and Oscar are very much in love, after their first foster child returns to his birth mother, they find that they have different ideas about what making a family actually means.",86,['Andy Vallentine']
1976,Drama            ,95 min,,6.7,"['Aline Küppenheim, ', 'Nicolás Sepúlveda, ', 'Hugo Medina, ', 'Alejandro Goic', '']","Chile, 1976. Carmen heads off to her beach house. When the family priest asks her to take care of a young man he is sheltering in secret, Carmen steps onto unexplored territories, away from the quiet life she is used to.","1,276",['Manuela Martelli']
Mia aioniotita kai mia mera,Drama            ,137 min,,7.9,"['Bruno Ganz, ', 'Isabelle Renauld, ', 'Fabrizio Bentivoglio, ', 'Ahilleas Skevis', '']","Famous writer Alexander is very ill and has little time left to live. He meets a little boy on the street, who is an illegal immigrant from Albania, and goes on a journey with him to take the boy home.",$0.11M,['Theodoros Angelopoulos']
East of Eden,Drama            ,,,,"['Jennifer Lawrence', '']","In the farmlands of the Salinas Valley in California, successive generations of two families, the Trasks and the Hamiltons, are destined to reenact the fateful story of Cain and Abel.",,['Gary Ross']
The Wayward Bus,Drama            ,87 min,,6.5,"['Joan Collins, ', 'Jayne Mansfield, ', 'Dan Dailey, ', 'Rick Jason', '']","Three strangers, a stripper, an alcoholic wife and a travelling salesman embark on a life-changing journey. As the road presents challenges, each character faces his or her own shortcomings, not knowing where life will lead next.",809,['Victor Vicas']
Concussion,Drama            ,96 min,R,5.6,"['Robin Weigert, ', 'Maggie Siff, ', 'Johnathan Tchaikovsky, ', 'Ben Shenkman', '']","After a blow to the head, Abby decides she can't do it anymore. Her life just can't be only about the house, the kids and the wife. She needs more: she needs to be Eleanor.",$0.04M,['Stacie Passon']
Indian Summers,Drama            ,52 min,,7.3,"['Henry Lloyd-Hughes, ', 'Jemima West, ', 'Julie Walters, ', 'Rick Warden', '']",Drama set in 1932 during the final years of British colonial rule in India.,"4,403",
The Secret Life of Us,Drama            ,60 min,,7.6,"['Deborah Mailman, ', 'David Tredinnick, ', 'Samuel Johnson, ', 'Sibylla Budd', '']","This iconic Australian series follows eight people living in St Kilda, Melbourne who are all looking for the same thing - love, sex, romance, success - and anything else that's worth going after.","1,404",
Courageous,Drama            ,130 min,PG-13,6.9,"['Alex Kendrick, ', 'Ken Bevel, ', 'Kevin Downes, ', 'Renee Jewell', '']","When a tragedy strikes close to home, four police officers struggle with their faith and their roles as husbands and fathers. Together they make a decision that will change all of their lives.",$34.52M,['Alex Kendrick']
Freud's Last Session,Drama            ,,,,"['Anthony Hopkins, ', 'Matthew Goode, ', 'Jodi Balfour, ', 'Orla Brady', '']","Set on the eve of WWII and towards the end of his life, Freud's Last Session sees Freud (Hopkins) invite iconic author C.S. Lewis for a debate over the existence of God. Exploring Freud's ...                See full summary »
",,['Matt Brown']
Au hasard Balthazar,Drama            ,95 min,,7.8,"['Anne Wiazemsky, ', 'Walter Green, ', 'François Lafarge, ', 'Jean-Claude Guilbert', '']",The story of a mistreated donkey and the people around him. A study on saintliness and a sister piece to Bresson's Mouchette.,$0.04M,['Robert Bresson']
Stuart: A Life Backwards,Drama            ,92 min,,7.7,"['Benedict Cumberbatch, ', 'Tom Hardy, ', 'Nicola Duffett, ', 'Claire-Louise Cordwell', '']","A writer takes a backwards look at the life of his unlikely friend, Stuart, a homeless alcoholic who experienced a traumatic childhood event.","13,259",['David Attwood']
Marfa Girl,Drama            ,105 min,,5.2,"['Adam Mediano, ', 'Drake Burnette, ', 'Jeremy St. James, ', 'Mary Farley', '']","A story centered on a directionless 16-year-old living in Marfa, Texas and his relationships with his girlfriend, his neighbor, his teacher, a newly arrived local artist, and a local Border Patrol officer.","1,766",['Larry Clark']
Le lycéen,Drama            ,122 min,,6.9,"['Paul Kircher, ', 'Vincent Lacoste, ', 'Juliette Binoche, ', 'Erwan Kepoa Falé', '']","A 17-year-old high school student trying to get to grips with the new challenges posed by death, life, the city and ""the temptation of renouncement"".","1,082",['Christophe Honoré']
On Sacred Ground,Drama            ,86 min,,5.7,"['William Mapother, ', 'David Arquette, ', 'Amy Smart, ', 'Frances Fisher', '']",A journalist and oil company executive find themselves on opposite sides of the fight during the construction of the contentious Dakota Access Pipeline that runs through the Standing Rock Indian Reservation in North Dakota.,242,
Sagrada familia,Drama            ,40 min,A,6.5,"['Najwa Nimri, ', 'Alba Flores, ', 'Álex García, ', 'Macarena Gómez', '']","A family hiding a shocking secret starts over in Madrid, where new relationships complicate their plans and the past begins to catch up with them.","2,142",
A Walton Easter,Drama            ,120 min,,7,"['Richard Thomas, ', 'Ralph Waite, ', 'Michael Learned, ', 'Jon Walmsley', '']","In 1969, John-Boy is a TV news anchorman in New York and he is in the throes of writing a new book. He and a very pregnant Janet are making plans to return to Walton's Mountain for the ...                See full summary »
",306,['Bill Corcoran']
The Uncle,Drama            ,87 min,,7.1,"['Rupert Davies, ', 'Brenda Bruce, ', 'Robert Duncan, ', 'Ann Lynn', '']",Seven-year-old Gus struggles with the responsibility placed upon him when nephew Tom arrives to spend summer holidays with his family.,101,['Desmond Davis']
DOC - Nelle tue mani,Drama            ,55 min,,7.8,"['Luca Argentero, ', 'Matilde Gioli, ', 'Sara Lazzaro, ', 'Alberto Boubakar Malanchino', '']","Dr Andrea Fanti, one of the most brilliant there ever were, forgets who he is.","1,464",
Working Girls,Drama            ,93 min,,6.7,"['Louise Smith, ', 'Ellen McElduff, ', 'Amanda Goodwin, ', 'Deborah Banks', '']","A day in the life of several prostitutes in an upscale Manhattan whore house. The film is a stark portrayal of the women prostitutes, the male customers and the motivations of both. Watch ...                See full summary »
",$1.78M,['Lizzie Borden']
Twee vorstinnen en een vorst,Drama            ,102 min,,5.8,"['Eric Clerckx, ', 'Linda van Dyck, ', 'Kitty Courbois, ', 'Jan Decleir', '']","At the deathbed of his used-to-be militant mother an older man looks back at his childhood, when he was in love with his sensual aunt Coleta.",241,['Otto Jongerius']
Delta of Venus,Drama            ,102 min,A,4.7,"['Audie England, ', 'Costas Mandylor, ', 'Eric da Silva, ', 'Raven Snow', '']","A struggling American writer (England) and a fellow American expatriate (Mandylor) begin a sordid affair among the chaos and discord of 1940 Paris, France on the brink of World War II.",$0.06M,['Zalman King']
Opening Night,Drama            ,144 min,,7.9,"['Gena Rowlands, ', 'John Cassavetes, ', 'Ben Gazzara, ', 'Joan Blondell', '']",A renowned actress teeters on the edge of a breakdown as she counts down the days toward a big Broadway opening.,"11,503",['John Cassavetes']
The Pawnbroker,Drama            ,116 min,A,7.7,"['Rod Steiger, ', 'Geraldine Fitzgerald, ', 'Brock Peters, ', 'Jaime Sánchez', '']","A Jewish pawnbroker, victim of Nazi persecution, loses all faith in his fellow man until he realizes too late the tragedy of his actions.","10,260",['Sidney Lumet']
Tetro,Drama            ,127 min,R,6.8,"['Vincent Gallo, ', 'Alden Ehrenreich, ', 'Maribel Verdú, ', 'Silvia Pérez', '']","Bennie travels to Buenos Aires to find his long-missing older brother, a once-promising writer who is now a remnant of his former self. Bennie's discovery of his brother's near-finished play might hold the answer to understanding their shared past and renewing their bond.",$0.52M,['Francis Ford Coppola']
Bez wstydu,Drama            ,81 min,,5.2,"['Mateusz Kosciukiewicz, ', 'Agnieszka Grochowska, ', 'Anna Próchniak, ', 'Maciej Marczewski', '']",A young man entertains an unhealthy desire for his older and unstable half-sister.,"1,492",['Filip Marczewski']
Lubo,Drama            ,175 min,,,"['Franz Rogowski, ', 'Valentina Bellè, ', 'Joel Basman, ', 'Noémi Besedes', '']","Lubo loses his family at the hands of an organization based on the principles of eugenics. His revenge will have unexpected implications, reconsidering the blurred lines between good and evil.",,['Giorgio Diritti']
Topâzu,Drama            ,135 min,NC-17,5.9,"['Miho Nikaido, ', 'Yayoi Kusama, ', 'Sayoko Amano, ', 'Tenmei Kano', '']","A submissive hooker goes about her trade, suffering abuse at the hands of Japanese salarymen and Yakuza types. She's unhappy about her work, and is apparently trying to find some sort of ...                See full summary »
",$0.28M,['Ryû Murakami']
Arctic Air,Drama            ,60 min,,6.8,"['Adam Beach, ', 'Pascale Hutton, ', 'Kevin McNulty, ', 'Stephen Lobo', '']",Series set in Yellowknife portrays renegade bush pilots at work and play in northern Canada.,"1,182",
Goat,Drama            ,96 min,R,5.7,"['Ben Schnetzer, ', 'Nick Jonas, ', 'Gus Halper, ', 'Danny Flaherty', '']","Reeling from a terrifying assault, a 19 year-old enrolls into college with his brother and pledges the same fraternity. What happens there in the name of ""brotherhood"" tests him and his loyalty to his brother in brutal ways.",$0.02M,['Andrew Neel']
Land Girls,Drama            ,225 min,,7,"['Becci Gemmell, ', 'Susan Cookson, ', 'Mark Benton, ', 'Mykola Allen', '']","Follow the lives, loves and highs and lows of four members of the Women's Land Army who are working at the Hoxley Estate during World War II.","3,478",
Nothing Is Private,Drama            ,124 min,R,6.9,"['Summer Bishil, ', 'Aaron Eckhart, ', 'Peter Macdissi, ', 'Chris Messina', '']","A young Arab-American girl struggles with her sexual obsession, a bigoted Army reservist and her strict father during the Gulf War.",$0.37M,['Alan Ball']
The Last Descent,Drama            ,105 min,PG,5.6,"['Chadwick Hopson, ', 'Alexis Johnson, ', 'Landon Henneman, ', 'Jyllian Petrie', '']","In 2009, John Jones explored an unmapped section of the famous Nutty Putty Cave. After becoming stuck in a hole 18 inches wide and 150 feet underground, rescue crews worked frantically and ...                See full summary »
","1,019",['Isaac Halasima']
The Road Dance,Drama            ,116 min,,7.1,"['Hermione Corfield, ', 'Will Fletcher, ', 'Mark Gatiss, ', 'David Brooks', '']","A young girl lives in the Outer Hebrides in a small village in the years just before WWI. Isolated and hard by the shore , her life takes a dramatic change when a terrible tragedy befalls her.",759,['Richie Adams']
Der Bergdoktor,Drama            ,45 min,,6.3,"['Hans Sigl, ', 'Heiko Ruprecht, ', 'Monika Baumgartner, ', 'Ronja Forcher', '']","A medic lives with his small, strange family in the mountains, and in every episode he comes across a situation with not only his patients but also his family and friends.",623,
Vozvrashchenie,Drama            ,110 min,,7.9,"['Vladimir Garin, ', 'Ivan Dobronravov, ', 'Konstantin Lavronenko, ', 'Nataliya Vdovina', '']","In the Russian wilderness, two brothers face a range of new, conflicting emotions when their father - a man they know only through a single photograph - resurfaces.",$0.50M,['Andrey Zvyagintsev']
Castaways,Drama            ,91 min,,4.3,"['Paige McGarvin, ', 'Sofia Masson, ', 'Joel Berti, ', 'Andre Heimos', '']","In a post apocalyptic world, two women find themselves shipwrecked and alone on a deserted island. As the girls fight to survive, their shared experience bonds them together in ways they could never have imagined.",215,['Ilyssa Goodman']
L'année des méduses,Drama            ,110 min,,5.6,"['Valérie Kaprisky, ', 'Bernard Giraudeau, ', 'Caroline Cellier, ', 'Jacques Perrin', '']","Chris, a sexy teenager who appears mostly bare-breasted on the French Riviera, has a crush on Romain, her mother's lover. In reaction to her inability to attract his attention, she experiments with other risque affairs.","1,343",['Christopher Frank']
Mary & George,Drama            ,,,,"['Nicola Walker, ', 'Tony Curran, ', 'Niamh Algar, ', 'Trine Dyrholm', '']","Follow the story of the Countess of Buckingham who molded her son to seduce King James I and become her all-powerful lover, through intrigue, becoming richer, more titled and influential than England has ever seen.",,
The Gray House,Drama            ,,,,"['Daisy Head, ', 'Paul Anderson, ', 'Robert Knepper, ', 'Ben Vereen', '']",It centers on the three women who General Ulysses S. Grant credited as helping the North win the Civil War.,,
Nil by Mouth,Drama            ,128 min,R,7.3,"['Ray Winstone, ', 'Kathy Burke, ', 'Charlie Creed-Miles, ', 'Laila Morse', '']","A rough, short-tempered patriarch of a working-class family sees his life and the relationships around him slowly unravel.","9,879",['Gary Oldman']
Secrets,Drama            ,103 min,,5.3,"['Janelle Tee, ', 'Benz Sangalang, ', 'Felix Roco, ', 'Denise Esteban', '']","A dark tale of sexual experimentation and perversion when a young couple escape to a beach house in order to sort out their relationship, but find themselves entangled in a trap set by a seductive stranger.",263,['Jose Javier Reyes']
Las edades de Lulú,Drama            ,95 min,,5.5,"['Francesca Neri, ', 'Óscar Ladoire, ', 'María Barranco, ', 'Fernando Guillén Cuervo', '']",The story of a young woman's descent into the kinky and dangerous sexual underground in Madrid.,"4,101",['Bigas Luna']
Sarah T. - Portrait of a Teenage Alcoholic,Drama            ,96 min,,6.4,"['Linda Blair, ', 'Larry Hagman, ', 'Verna Bloom, ', 'William Daniels', '']",This movie is a teaching tool about a teenage girl struggling with alcoholism to cope with her feelings of insecurity and usual problems of adolescence.,624,['Richard Donner']
Zorras,Drama            ,,,4.4,"['Andrea Ros, ', 'Mirela Balic, ', 'Tai Fati, ', 'Nico Romero', '']",Follows three women who unintentionally launch a feminine revolution when they create a secret group to fulfill their sexual fantasies.,18,
"Bright Lights, Big City",Drama            ,107 min,A,5.7,"['Michael J. Fox, ', 'Kiefer Sutherland, ', 'Phoebe Cates, ', 'Swoosie Kurtz', '']",A disillusioned young writer living in New York City turns to drugs and drinking to block out the memories of his dead mother and estranged wife.,$16.12M,['James Bridges']
Sans toit ni loi,Drama            ,105 min,,7.7,"['Sandrine Bonnaire, ', 'Macha Méril, ', 'Stéphane Freiss, ', 'Setti Ramdane', '']","A young woman's body is found frozen in a ditch. Through flashbacks and interviews, we see the events that led to her inevitable death.","12,636",['Agnès Varda']
The Best Place to Be,Drama            ,195 min,,7.5,"['Donna Reed, ', 'Efrem Zimbalist Jr., ', 'Mildred Dunnock, ', 'Betty White', '']","A widow's life is thrown into turmoil by her hippie daughter, her rebellious teenage son, and an affair she is having with a much younger man. Then, as if all that wasn't quite enough, a ...                See full summary »
",62,['David Miller']
Maternal,Drama            ,46 min,,7.7,"['Parminder Nagra, ', 'Lara Pulver, ', 'Lisa McGrillis, ', 'Julie Graham', '']",Drama about three doctors returning to post-pandemic frontline medicine after maternity leave.,654,
Lagaslas,Drama            ,94 min,,6.2,"['VR Relosa, ', 'Maebelle Medina, ', 'Julio Diaz, ', 'Rubi Rubi', '']","A young man named Edmar falls madly in love with Karisma, a barrio lass. Will he still love her if he finds out Karisma's deepest darkest secret?",422,['Christopher Novabos']
Sur les chemins noirs,Drama            ,95 min,,6.9,"['Jean Dujardin, ', 'Joséphine Japy, ', 'Izïa Higelin, ', 'Anny Duperey', '']","Pierre is a famous writer and explorer. But one drunken night, a terrible fall leaves him in a coma. When he wakes up, barely standing up and against everyone's advice, he decides to explore France on foot, along the smallest paths.",435,['Denis Imbert']
The Killing of Two Lovers,Drama            ,85 min,R,6.9,"['Clayne Crawford, ', 'Sepideh Moafi, ', 'Chris Coy, ', 'Avery Pizzuto', '']",David desperately tries to keep his family of six together during a separation from his wife. They both agree to see other people but David struggles to grapple with his wife's new relationship.,"4,847",['Robert Machoian']
NCR Days,Drama            ,40 min,Not Rated,9.1,"['Nikhil Vijay, ', 'Raghvika Kohli, ', 'Ambrish Verma, ', 'Heer Kaur', '']",NCR Days depicts the life of a small town guy studying in a city that is completely contrasting to his perspectives in life.,"38,663",
The Messenger,Drama            ,50 min,,6.5,"['William McKenna, ', 'Alexandra Jensen, ', 'Chris Alosio, ', 'Kartanya Maynard', '']","Ed's life is one peaceful routine until playing cards inscribed with cryptic tasks start to arrive in the mail. Choosing to care, Ed makes his way through town helping and hurting.",228,
La Salamandre,Drama            ,116 min,,7.2,"['Marina Foïs, ', 'Maicon Rodrigues, ', 'Anna Mouglalis, ', 'Bruno Garcia', '']",A troubled woman meets a mysterious younger man who triggers in her an obsession to both destroy and reinvent herself.,51,['Alex Carvalho']
Rien à foutre,Drama            ,115 min,,6.4,"['Adèle Exarchopoulos, ', 'Alexandre Perrier, ', 'Mara Taquin, ', 'Arthur Egloff', '']",A young flight attendant loses her job at a low-cost airline.,"3,640",
The Inside Man,Drama            ,,,8.1,"['Benjamin Adnams, ', 'Abe Jarman, ', 'Brandon Potter, ', 'Kathryn Georghiou', '']","Meet Mark, a man with secrets. This lonely hacker must blag his way into Khromacom's security team and destroy the company. His new colleagues present a heartbreaking dilemma: satisfy his sinister controller or betray his loveable friends?",183,
Disco Boy,Drama            ,92 min,,6.6,"['Franz Rogowski, ', 'Morr Ndiaye, ', 'Laetitia Ky, ', 'Leon Lucev', '']","After a painful journey through Europe, Aleksei arrives in Paris to join the Foreign Legion. In the Niger Delta, Jomo struggles against the oil companies threatening his village and the ...                See full summary »
",531,['Giacomo Abbruzzese']
"Marcus Welby, M.D.",Drama            ,60 min,,7,"['Robert Young, ', 'James Brolin, ', 'Elena Verdugo, ', 'Pamela Hensley', '']","The show is about doctors Marcus Welby, a general practitioner and Steven Kiley, Welby's young assistant. The two try to treat people as individuals in an age of specialized medicine and ...                See full summary »
","1,703",
Ahlat Agaci,Drama            ,188 min,,8,"['Dogu Demirkol, ', 'Murat Cemcir, ', 'Bennu Yildirimlar, ', 'Hazar Ergüçlü', '']","An unpublished writer returns to his hometown after graduating, where he seeks sponsors to publish his book while dealing with his father's deteriorating indulgence into gambling.",$0.03M,['Nuri Bilge Ceylan']
Oliver Twist,Drama            ,116 min,,7.8,"['Robert Newton, ', 'Alec Guinness, ', 'Kay Walsh, ', 'Francis L. Sullivan', '']","In Charles Dickens' classic tale, an orphan wends his way from cruel apprenticeship to den of thieves in search of a true home.","13,165",['David Lean']
Just Say Goodbye,Drama            ,106 min,,6.3,"['Katerina Eichenberger, ', 'Max MacKenzie, ', 'Bill Galatis, ', 'Jesse Walters', '']","Sarah slashes down the days to her summer vacation trip with all the gusto of Zorro and his infamous 'Z', until she discovers her best friend's plot to end his life while she's away.",217,['Matt Walting']
The Oscar,Drama            ,119 min,,5.2,"['Stephen Boyd, ', 'Elke Sommer, ', 'Milton Berle, ', 'Eleanor Parker', '']",Snotty Hollywood actor becomes even more full of himself after he's nominated for the Academy Award for Best Actor.,"1,423",['Russell Rouse']
Elmer Gantry,Drama            ,146 min,,7.7,"['Burt Lancaster, ', 'Jean Simmons, ', 'Arthur Kennedy, ', 'Dean Jagger', '']","A fast-talking traveling salesman with a charming, loquacious manner convinces a sincere evangelist that he can be an effective preacher for her cause.",$11.34M,['Richard Brooks']
After Love,Drama            ,89 min,,7.3,"['Joanna Scanlan, ', 'Nathalie Richard, ', 'Talid Ariss, ', 'Nasser Memarzia', '']","Set in the port town of Dover, Mary Hussain suddenly finds herself a widow following the unexpected death of her husband. A day after the burial, she discovers he has a secret just twenty-one miles across the English Channel in Calais.","3,782",['Aleem Khan']
Brother,Drama            ,119 min,,7.3,"['Lamar Johnson, ', 'Aaron Pierre, ', 'Marsha Stephanie Blake, ', 'Kiana Madeira', '']","Sons of Caribbean immigrants, Francis and Michael face questions of masculinity, identity and family amid the pulsing beat of Toronto's early hip-hop scene.",349,['Clement Virgo']
Il colibrì,Drama            ,126 min,,6.5,"['Pierfrancesco Favino, ', 'Nanni Moretti, ', 'Kasia Smutniak, ', 'Bérénice Bejo', '']",The life of male protagonist from the 1970s to the near future and the myriad relationships that have criss-crossed its path along the way.,859,['Francesca Archibugi']
Morvern Callar,Drama            ,97 min,R,6.7,"['Samantha Morton, ', 'Kathleen McDermott, ', 'Linda McGuire, ', 'Paul Popplewell', '']","After her beloved boyfriend's suicide, a mourning supermarket worker and her best friend hit the road in Scotland, but find that grief is something that you can't run away from forever.",$0.27M,['Lynne Ramsay']
Long Day's Journey Into Night,Drama            ,,,,"['Jessica Lange, ', 'Ed Harris, ', 'Ben Foster, ', 'Colin Morgan', '']","Over the course of a day, a married couple, Mary and James Tyrone, and their two sons, Jamie and Edmund, grapple with Mary's morphine addiction and confront each other over the past in a series of emotionally tense and volatile exchanges.",,['Jonathan Kent']
My Salinger Year,Drama            ,101 min,R,6.5,"['Margaret Qualley, ', 'Sigourney Weaver, ', 'Douglas Booth, ', 'Seána Kerslake', '']","A college grad takes a clerical job working for the literary agent of the renowned, reclusive writer J.D. Salinger.","6,062",['Philippe Falardeau']
Thirty,Drama            ,20 min,,,"['Brandon Moten, ', 'Bobby Musique Cooks, ', 'Eric Russell, ', 'Aigner Edgerson', '']",The worst part about love is that it's never enough.,,
Close to Me,Drama            ,60 min,,6,"['Connie Nielsen, ', 'Christopher Eccleston, ', 'Tom Taylor, ', 'Rosy McEwen', '']","Jo Harding is a woman who has a perfect life with her partner until a fall erases an entire year from her memory. As she struggles to piece events together, Jo discovers that her life was in fact far from perfect.","2,144",
Akahige,Drama            ,185 min,U,8.3,"['Toshirô Mifune, ', 'Yûzô Kayama, ', 'Tsutomu Yamazaki, ', 'Reiko Dan', '']","In 19th-century Japan, a rough-tempered yet charitable town doctor trains a young intern.","20,233",['Akira Kurosawa']
A torinói ló,Drama            ,155 min,,7.7,"['János Derzsi, ', 'Erika Bók, ', 'Mihály Kormos, ', 'Ricsi', '']",A rural farmer is forced to confront the mortality of his faithful horse.,$0.05M,
A Civil Action,Drama            ,115 min,U,6.6,"['John Travolta, ', 'Robert Duvall, ', 'Kathleen Quinlan, ', 'Tony Shalhoub', '']","A tenacious lawyer takes on a case involving two companies responsible for causing several children to be diagnosed with leukemia due to the town's water supply being contaminated, at the risk of bankrupting his firm and career.",$56.70M,['Steven Zaillian']
Dog Years,Drama            ,94 min,R,7,"['Burt Reynolds, ', 'Ariel Winter, ', 'Clark Duke, ', 'Chevy Chase', '']","An aging former movie star is forced to face the reality that his glory days are behind him. On its surface, the film is a tale about faded fame. At its core, it's a universal story about growing old.",$0.01M,['Adam Rifkin']
Hou lang,Drama            ,45 min,,5.6,"['Gang Wu, ', 'Lusi Zhao, ', 'Yizhou Luo, ', 'Meng Zhang', '']","The story of Ren Xinzheng, a professor at the University of Traditional Chinese Medicine, who is committed to promoting traditional Chinese medicine and resigns to establish a traditional ...                See full summary »
",132,
Farha,Drama            ,92 min,,8.1,"['Karam Taher, ', 'Ashraf Barhom, ', 'Ali Suliman, ', 'Tala Gammoh', '']",A 14-year-old girl in 1948 Palestine watches from a locked pantry as catastrophe consumes her home.,"79,817",['Darin J. Sallam']
Out of Bounds,Drama            ,90 min,,4.5,"['Sophie Ward, ', 'Sophia Myles, ', 'George Asprey, ', 'Michael Elphick', '']","18-year-old Louise is stuck in a run-down girls' boarding school in the heart of the English countryside. Her only consolation, during the long cold nights, is Matthew, the American art ...                See full summary »
",350,['Merlin Ward']
Mijn beste vriendin Anne Frank,Drama            ,103 min,16,6.2,"['Aiko Beemsterboer, ', 'Roeland Fernhout, ', 'Josephine Arendsen, ', 'Björn Freiberg', '']","Hannah is imprisoned at camp Bergen Belzen days before being liberated, where she thinks back of her time in Amsterdam with her best friend Anne the first few years of the war. Hannah finds...                See full summary »
","5,070",['Ben Sombogaart']
Wakefield,Drama            ,106 min,R,6.3,"['Bryan Cranston, ', 'Jennifer Garner, ', 'Victoria Bruno, ', 'Ellery Sprayberry', '']",A lawyer on the edge of madness decides to disassociate himself from his own life.,$0.26M,['Robin Swicord']
Twelve,Drama            ,125 min,R,6.6,"[""Jahi Di'Allo Winston, "", 'Meek Mill, ', 'William Catlett, ', 'Donielle T. Hansley Jr.', '']","Fourteen-year-old Mouse desperately wants to join the Midnight Clique, an infamous group of Baltimore dirt-bike riders who rule the summertime streets.","2,827",['Angel Manuel Soto']
Hoard,Drama            ,,,,"['Joseph Quinn, ', 'Hayley Squires, ', 'Samantha Spiro, ', 'Cathy Tyson', '']",It follows the close bond between a mother and daughter.,,['Luna Carmoon']
Shoot the Moon,Drama            ,124 min,,6.8,"['Albert Finney, ', 'Diane Keaton, ', 'Karen Allen, ', 'Peter Weller', '']","A mother of four is abandoned by her husband for a younger woman. Husband, wife and children struggle to survive the seemingly inevitable divorce.",$9.22M,['Alan Parker']
His Wife's Secret Life,Drama            ,,,6.9,"['Aaron Groben, ', 'Vanessa Papa', '']","Sarah and Bob had very happy marriage,along there marriage life, Sarah was having affair with someone that her husband never knew.",39,['Bob Bragg']
The Last Bus,Drama            ,86 min,,6.6,"['Timothy Spall, ', 'Phyllis Logan, ', 'Natalie Mitson, ', 'Ben Ewing', '']","After the death of his wife, an aging man travels across the UK by bus to fulfill his pledge to spread her ashes near their first home.","2,999",['Gillies MacKinnon']
The Boys in the Band,Drama            ,118 min,,7.6,"['Kenneth Nelson, ', 'Peter White, ', 'Leonard Frey, ', 'Frederick Combs', '']",Tempers fray and true selves are revealed when a heterosexual accidentally intrudes on a homosexual party.,$7.63M,['William Friedkin']
The Shipping News,Drama            ,111 min,U,6.7,"['Kevin Spacey, ', 'Julianne Moore, ', 'Judi Dench, ', 'Cate Blanchett', '']",An emotionally beaten man with his young daughter moves to his ancestral home in Newfoundland to reclaim his life.,$11.43M,['Lasse Hallström']
How to Please a Woman,Drama            ,111 min,,6.2,"['Sally Phillips, ', 'Hayley McElhinney, ', 'Caroline Brazier, ', 'Tasma Walton', '']","When her all-male house-cleaning business gets out of control, a mature woman must embrace her own sexuality, if she is to make a new life for herself.","1,434",['Renée Webster']
Nowhereland,Drama            ,95 min,,6.2,"['Nicole I. Butler, ', 'Emily Cheree, ', 'Ginny Jones, ', 'Jessica Taylor Haid', '']","A teenage girl, whose mother is at the end of her career as a sex escort, has to find a way to make money to support them both in Los Angeles.","6,874",['Robin Bain']
"Deux jours, une nuit",Drama            ,95 min,PG-13,7.3,"['Marion Cotillard, ', 'Fabrizio Rongione, ', 'Catherine Salée, ', 'Baptiste Sornin', '']","Liège, Belgium. Sandra is a factory worker who discovers that her workmates have opted for a EUR1,000 bonus in exchange for her dismissal. She has only a weekend to convince her colleagues to give up their bonuses in order to keep her job.",$1.44M,
Safe Home,Drama            ,,,8.1,"['Aisha Dee, ', 'Mabel Li, ', 'Thomas Cocquerel, ', 'Antonia Prebble', '']","Phoebe leaves her job at a law firm and begins work at a family violence centre and she must navigate a path that isn't always clear, and people and events that aren't always as they appear.",334,
Lazarus,Drama            ,,,,"['Tom Hardy, ', 'Zazie Beetz', '']","Follows the police detective Saga Bauer as she investigates the case of a young man that suddenly appears, after went missing thirteen years earlier, along his sister, both presumably killed by the notorious serial killer Jurek Walter.",,
Un village français,Drama            ,52 min,,8.4,"['Robin Renucci, ', 'Audrey Fleurot, ', 'Thierry Godard, ', 'Marie Kremer', '']","Traces the experiences of various residents of a fictional small village just inside the occupation zone during WWII. Deals with issues including collaboration, the Resistance, the fate of French Jews, and war profiteering.","1,605",
War Room,Drama            ,120 min,PG,6.4,"['Priscilla C. Shirer, ', 'T.C. Stallings, ', 'Karen Abercrombie, ', 'Beth Moore', '']","A seemingly perfect family looks to fix their problems with the help of Miss Clara, an older, wiser woman.",$67.79M,['Alex Kendrick']
Extraordinary Measures,Drama            ,106 min,Not Rated,6.4,"['Brendan Fraser, ', 'Keri Russell, ', 'Harrison Ford, ', 'Meredith Droeger', '']",A drama centered on the efforts of John and Aileen Crowley to find a researcher who might have a cure for their two children's rare genetic disorder.,$11.85M,['Tom Vaughan']
Suntan,Drama            ,104 min,,6.6,"['Makis Papadimitriou, ', 'Elli Tringou, ', 'Hara Kotsali, ', 'Milou Van Groesen', '']","On a hedonistic Greek island, a middle-aged doctor becomes obsessed with a young tourist when she lets him tag along with her group of hard partying friends.","7,746",['Argyris Papadimitropoulos']
The Code,Drama            ,60 min,,6.3,"['Anna Wood, ', 'Ato Essandoh, ', 'Phillipa Soo, ', 'Raffi Barsoumian', '']","A look at the professional and personal lives of some of the military's brightest legal minds in the courtroom, where each attorney is trained as a prosecutor, a defense lawyer, an investigator - and a Marine.","2,135",
Fairyland,Drama            ,114 min,,6.7,"['Emilia Jones, ', 'Scoot McNairy, ', 'Nessa Dougherty, ', 'Geena Davis', '']",A young girl recounts growing up in San Francisco in the '70s and '80s with her gay dad.,142,['Andrew Durham']
Tystnaden,Drama            ,96 min,R,7.8,"['Ingrid Thulin, ', 'Gunnel Lindblom, ', 'Birger Malmsten, ', 'Håkan Jahnberg', '']","Two estranged sisters, Ester and Anna, and Anna's 10-year-old son travel to the Central European country on the verge of war. Ester becomes seriously ill and the three of them move into a hotel in a small town called Timoka.","20,702",['Ingmar Bergman']
Girl in the Closet,Drama            ,87 min,,5.5,"['Tami Roman, ', 'Remy Ma, ', 'Stevie Baggs Jr., ', 'Danielle LaRoach', '']","After her mother suffered an aneurysm, 10-year-old Cameron was adopted by her Aunt Mia, who already had a husband and a daughter. Soon after coming to her new home, Cameron started hearing ...                See full summary »
",410,['Jaira Thomas']
Dr. Kildare,Drama            ,60 min,,7,"['Richard Chamberlain, ', 'Raymond Massey, ', 'Lee Kurty, ', 'Jean Inness', '']",The dramatic relationship between a young medical intern and his surgeon mentor.,936,
Días mejores,Drama            ,50 min,,7.6,"['Blanca Portillo, ', 'Francesc Orella, ', 'Marta Hazas, ', 'Erick Elias', '']","The series recounts the hard times that result from the loss of a loved one, optimistically showing how, despite the wounds, sooner or later it is possible to laugh again, love and, above all, live again.",355,
Scener ur ett äktenskap,Drama            ,169 min,PG,8.3,"['Liv Ullmann, ', 'Erland Josephson, ', 'Bibi Andersson, ', 'Gunnel Lindblom', '']","Scenes from a Marriage chronicles the many years of love and turmoil that bind Marianne (Liv Ullmann) and Johan (Erland Josephson) through matrimony, infidelity, divorce, and subsequent partners.",$0.68M,['Ingmar Bergman']
Prisma,Drama            ,44 min,A,7.8,"['Mattia Carrano, ', 'Lorenzo Zurzolo, ', 'Caterina Forza, ', 'Chiara Bordi', '']","Prisma explores the relationships and the identities of Andrea and Marco, two twins identical on the outside, but very different in their approach on life; and of their group of friends, united by the search for their place in the world.","1,348",
"You Sing Loud, I Sing Louder",Drama            ,96 min,,8,"['Ewan McGregor, ', 'Jake Weary, ', 'Travis Hammer, ', 'Kim Zimmer', '']","A father takes his estranged daughter on a road trip in an effort to get her out of trouble. Along the way they meet all types of strangers, as their strained relationship is put to the test.",37,['Emma Westenberg']
Sugar,Drama            ,,,,"['Colin Farrell, ', 'Massi Furlan, ', 'Nate Corddry, ', 'Bernardo Badillo', '']",Plot under wraps.,,
Central do Brasil,Drama            ,110 min,R,8,"['Fernanda Montenegro, ', 'Vinícius de Oliveira, ', 'Marília Pêra, ', 'Soia Lira', '']","The emotive journey of a former schoolteacher who writes letters for illiterate people, and a young boy whose mother has just died, as they search for the father he never knew.",$5.60M,['Walter Salles']
The Accident,Drama            ,43 min,,6.3,"['Sarah Lancashire, ', 'Sidse Babett Knudsen, ', 'Joanna Scanlan, ', 'Genevieve Barr', '']",A Welsh community devastated by tragedy is forced to confront difficult truths amid the search for justice.,"2,651",
Der siebente Kontinent,Drama            ,108 min,,7.6,"['Birgit Doll, ', 'Dieter Berner, ', 'Leni Tanzer, ', 'Udo Samel', '']","A European family who plan on escaping to Australia seem caught up in their daily routine, only troubled by minor incidents. However, behind their apparent calm and repetitive existence, they are actually planning something sinister.","16,236",['Michael Haneke']
Scarlet Diva,Drama            ,91 min,R,5,"['Asia Argento, ', 'Jean Shepard, ', 'Herbert Fritsch, ', 'Gianluca Arcopinto', '']","A young Italian actress embarks on a self-destructive spree of sex, drugs and other excess while doing some soul searching to find the path for redemption.",$0.02M,['Asia Argento']
Happy End,Drama            ,107 min,R,6.6,"['Isabelle Huppert, ', 'Jean-Louis Trintignant, ', 'Mathieu Kassovitz, ', 'Fantine Harduin', '']",A well-to-do French family deals with a series of setbacks and crises.,$0.30M,['Michael Haneke']
Me Chama de Bruna,Drama            ,60 min,,6.7,"['Maria Bopp, ', 'Simone Mazzer, ', 'Stella Rabello, ', 'Nash Laila', '']","A middle-class teen runs away from home and decides to work as a call girl. In little time, she becomes Bruna Surfistinha and gains notoriety after writing her routine on a blog.",405,
The Dirty D,Drama            ,,,7.6,"['Phillip Granger, ', 'Mena Monroe, ', 'Demaris Harvey, ', 'Makeiva Albritten', '']","What happens when you mix drugs, money, sex, and drama together with beautiful, money hungry, conniving Bottle Girls, inside one of Detroit's hottest nightclubs ran by a shady power couple....                See full summary »
",247,
Ömer,Drama            ,,,5.8,"['Selahattin Pasali, ', 'Gökçe Bahadir, ', 'Baris Falay, ', 'Merve Dizdar', '']","Ömer's life turns upside down when he falls in love with Gamze, a relationship that his conservative father will never approve of. She is a middle-aged woman, who returns to her old ...                See full summary »
",405,
Catching Dust,Drama            ,96 min,,8.7,"['Erin Moriarty, ', 'Jai Courtney, ', 'Dina Shihabi, ', 'Ryan Corr', '']","Geena finally decides to leave her criminal husband Clyde and their isolated Texas hideout, but a couple from NY suddenly arrives. Ignoring the risks, she convinces Clyde to let them stay, a decision with dangerous consequences.",28,['Stuart Gatt']
Beecham House,Drama            ,45 min,18,6.8,"['Tom Bateman, ', 'Lesley Nicol, ', 'Leo Suter, ', 'Dakota Blue Richards', '']",A look at the lives of residents living in a Delhi mansion at the cusp of the 19th Century.,"2,480",
Garden Party,Drama            ,88 min,,5.5,"['Erik Smith, ', 'Tierra Abbott, ', 'Vinessa Shaw, ', 'Christopher Allport', '']","April (age 15) is running from one bad situation into another, hoping to find an answer that doesn't involve nudity, and falls in with a group of confused kids chasing their dreams. The black widow in the web is the sexy, pot-dealing Sally.",$0.02M,['Jason Freeland']
Rambling Rose,Drama            ,112 min,A,6.6,"['Laura Dern, ', 'Robert Duvall, ', 'Diane Ladd, ', 'Lukas Haas', '']",A young woman who exudes sexuality battles temptation.,$6.27M,['Martha Coolidge']
Zielona granica,Drama            ,147 min,,,"['Behi Djanati Atai, ', 'Agata Kulesza, ', 'Piotr Stramowski, ', 'Maja Ostaszewska', '']","Follows a family of Syrian refugees, an English teacher from Afghanistan and a border guard. They all meet on the Polish-Belarusian border during the most recent humanitarian crisis in Belarus.",,['Agnieszka Holland']
Good Girls Revolt,Drama            ,55 min,,8.1,"['Genevieve Angelson, ', 'Anna Camp, ', 'Erin Darke, ', 'Hunter Parrish', '']",A look at the personal and professional lives of employees at an American news magazine in the late 1960s.,"6,097",
Såsom i en spegel,Drama            ,90 min,,7.9,"['Harriet Andersson, ', 'Gunnar Björnstrand, ', 'Max von Sydow, ', 'Lars Passgård', '']","Recently released from a mental hospital, Karin rejoins her emotionally disconnected family in their island home, only to slip from reality as she begins to believe she is being visited by God.","26,516",['Ingmar Bergman']
Aruitemo aruitemo,Drama            ,115 min,,7.9,"['Hiroshi Abe, ', 'Yui Natsukawa, ', 'You, ', 'Kazuya Takahashi', '']",A family gathers together for a commemorative ritual whose nature only gradually becomes clear.,$0.16M,['Hirokazu Koreeda']
Sweetness in the Belly,Drama            ,110 min,,5.6,"['Wunmi Mosaku, ', 'Rafael Goncalves, ', 'Dakota Fanning, ', 'Chris McHallem', '']","Based on the novel by Camilla Gibb, Lilly is an English child abandoned in Africa, forced to flee Ethiopia for England amid civil war. There she befriends Amina, an Ethiopian refugee, and they begin a mission to reunite scattered families.",749,['Zeresenay Mehari']
Mrs. 'Arris Goes to Paris,Drama            ,92 min,,7.2,"['Angela Lansbury, ', 'Diana Rigg, ', 'Lothaire Bluteau, ', 'John Savident', '']",An elderly charwoman in 1950s London spots a Dior dress at the home of her employer and becomes determined to travel to Paris and buy one herself.,"1,026",['Anthony Pullen Shaw']
HIT,Drama            ,,,7.2,"['Daniel Grao, ', 'Carmen Arrufat, ', 'Luisa Vides, ', 'Olaya Caldera', '']",A close-up look into those Spanish classrooms where things aren't going as well as they should.,288,
Two Girls and a Guy,Drama            ,84 min,R,5.5,"['Robert Downey Jr., ', 'Heather Graham, ', 'Natasha Gregson Wagner, ', 'Angel David', '']","Two girls wait outside a young actor's door and find out he's had them both as ""only"" girlfriend the last ten months. They wait inside after breaking in. When Blake comes home he just can't stop lying but they stay.",$1.95M,['James Toback']
L'amour et les forêts,Drama            ,105 min,,6.9,"['Virginie Efira, ', 'Melvil Poupaud, ', 'Dominique Reymond, ', 'Romane Bohringer', '']","Follows Blanche Renard who meets Greg Lamoureux and believes he is the one, but soon she finds herself caught up in a toxic relationship with a possessive and dangerous man.",496,['Valérie Donzelli']
The Sixth Commandment,Drama            ,,,8.1,"['Adrian Rawlins, ', 'Amanda Root, ', 'Conor MacNeill, ', 'Éanna Hardwicke', '']","Follows the deaths of Peter Farquhar and Ann Moore-Martin in the village of Maids Moreton, Buckinghamshire, and the extraordinary events that unfolded in the following years.","1,803",
